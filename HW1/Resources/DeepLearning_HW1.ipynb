{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HdU-jSaL9Gi"
      },
      "source": [
        "## Full Name: Javad Razi\n",
        "## Student ID: 401204354\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1qqZWeHWKvC"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this practical assignment, we will practice using PyTorch to implement neural networks. We will work with the Fashion-MNIST dataset, and after visualizing the data to get familiar with it, we will use t-SNE and implement the PCA algorithm to reduce the dimensionality of the data for visualization in a 2D plot.\n",
        "\n",
        "## Tasks\n",
        "\n",
        "1. Implement the PCA algorithm.\n",
        "2. Apply PCA and t-SNE to the Fashion-MNIST test set.\n",
        "3. Train a simple stacked autoencoder consisting of several MLP layers.\n",
        "4. Use PCA and t-SNE to visualize the encoding of the test set calculated by the trained autoencoder.\n",
        "5. Add a classification layer on top of the autoencoder's encoder and use its trained weights to predict each image label.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. For task 1, you can use the following steps:\n",
        "\n",
        "    a. Import the necessary libraries.\n",
        "    b. Define the PCA class.\n",
        "    c. Instantiate the PCA class and fit it to the Fashion-MNIST test set.\n",
        "    d. Transform the Fashion-MNIST test set using the fitted PCA model.\n",
        "\n",
        "2. For task 2, you can use the following steps:\n",
        "\n",
        "    a. Import the necessary libraries.\n",
        "    b. Instantiate the PCA and t-SNE classes.\n",
        "    c. Transform the Fashion-MNIST test set using the PCA model.\n",
        "    d. Transform the PCA-transformed Fashion-MNIST test set using the t-SNE model.\n",
        "    e. Visualize the t-SNE-transformed Fashion-MNIST test set using a scatter plot.\n",
        "\n",
        "3. For task 3, you can use the following steps:\n",
        "\n",
        "    a. Import the necessary libraries.\n",
        "    b. Define the stacked autoencoder class.\n",
        "    c. Instantiate the stacked autoencoder class and train it on the Fashion-MNIST training set.\n",
        "\n",
        "4. For task 4, you can use the following steps:\n",
        "\n",
        "    a. Transform the Fashion-MNIST test set using the PCA model.\n",
        "    b. Transform the PCA-transformed Fashion-MNIST test set using the trained autoencoder's encoder.\n",
        "    c. Visualize the t-SNE-transformed encoding of the Fashion-MNIST test set using a scatter plot.\n",
        "\n",
        "5. For task 5, you can use the following steps:\n",
        "\n",
        "    a. Import the necessary libraries.\n",
        "    b. Define the classification layer class.\n",
        "    c. Add the classification layer to the trained autoencoder's encoder.\n",
        "    d. Train the classification layer on the Fashion-MNIST training set.\n",
        "    e. Evaluate the classification layer on the Fashion-MNIST test set.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "In this practical assignment, we have learned how to use PyTorch to implement neural networks and apply dimensionality reduction techniques to data visualization. We have also learned how to train and evaluate classification models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2OtGuCk_SBx"
      },
      "source": [
        "# Import Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCIancBx_Rcg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from random import sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRXLad8IAwnq"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trk4HT7VAwH4"
      },
      "outputs": [],
      "source": [
        "RANDOM_STATE = 42\n",
        "random.seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G24CJRs6G3T2",
        "outputId": "4c149bbc-4cac-4332-9467-2613e4237f46"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwwTDCTF-rFz"
      },
      "source": [
        "# Load Fashion MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqAKLByx-WpL",
        "outputId": "11ec7471-efc4-48c2-cae7-aae39074fa6d"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = fetch_openml(name='Fashion-MNIST')\n",
        "\n",
        "X, y = fashion_mnist.data.astype('float32'), fashion_mnist.target.astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWcg0o80_0cM"
      },
      "outputs": [],
      "source": [
        "class_names = [\n",
        "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\",\n",
        "    \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6_SsGJF_n0l"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS3vBosN_db0",
        "outputId": "7edb32f5-5590-4154-9a31-24541ca2a907"
      },
      "outputs": [],
      "source": [
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GPHbx7f_ekY",
        "outputId": "cfcaa62e-17af-4694-aea0-2c1ecc5bc8fc"
      },
      "outputs": [],
      "source": [
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngVKkt_QFrO4",
        "outputId": "fcf0f368-5ed9-4cfb-dd8b-650ec36f54c5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(), test_size=0.1, random_state=RANDOM_STATE)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.075, random_state=RANDOM_STATE)\n",
        "\n",
        "print(f'Shape of Training Data: {X_train.shape}')\n",
        "print(f'Shape of Test Data: {X_test.shape}')\n",
        "print(f'Shape of Validation Data: {X_val.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E8xgaRQ_szD"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1zU5UMF_fmz"
      },
      "outputs": [],
      "source": [
        "def visualize_one_image_per_category(X, y, class_names):\n",
        "    unique_labels = np.unique(y)\n",
        "    fig, ax = plt.subplots(1, len(unique_labels), figsize=(20, 4))\n",
        "\n",
        "    for i, label in enumerate(unique_labels):\n",
        "        # Find the first image for the current label\n",
        "        image_idx = np.where(y == label)[0][0]\n",
        "        image = X.iloc[image_idx].values.reshape(28, 28)  # Use .iloc to access by index\n",
        "\n",
        "        ax[i].imshow(image, cmap='gray')\n",
        "        ax[i].set_title(class_names[label])\n",
        "        ax[i].axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "flNIYp4T_xST",
        "outputId": "eca4a346-24c7-4863-9354-2fd32c06d90d"
      },
      "outputs": [],
      "source": [
        "visualize_one_image_per_category(X, y, class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOAJYdRSAWHQ"
      },
      "source": [
        "# Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZZihuIZBRi4"
      },
      "outputs": [],
      "source": [
        "def visualize_2d(reduced_data, labels, method='PCA', class_names=class_names):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    scatter = plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=labels, cmap='tab10', alpha=0.5, s=5)\n",
        "    plt.title(f'{method} Visualization')\n",
        "    plt.xlabel(f'{method} Component 1')\n",
        "    plt.ylabel(f'{method} Component 2')\n",
        "\n",
        "    plt.colorbar(scatter, ticks=np.arange(len(class_names)), label='Class',\n",
        "                 format=plt.FuncFormatter(lambda val, loc: class_names[int(val)]))\n",
        "\n",
        "    for i, label in enumerate(class_names):\n",
        "        indices = labels == i\n",
        "        plt.text(reduced_data[indices, 0].mean(), reduced_data[indices, 1].mean(),\n",
        "                 label, fontsize=10, ha='center', va='center')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQCwGm22VpPQ"
      },
      "source": [
        "#### For this part and the following part, apply PCA and t-SNE to test dataset, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S5v2nPoAckD"
      },
      "source": [
        "## PCA (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcdDwrxPoZFB"
      },
      "source": [
        "### Principal Component Analysis (PCA) - Step-by-Step Explanation\n",
        "\n",
        "Principal Component Analysis (PCA) is a technique used for dimensionality reduction and data visualization. It aims to transform a dataset into a new coordinate system (a lower-dimensional space) while retaining the most important information.\n",
        "\n",
        "1. **Center the Data**:\n",
        "   - Calculate the mean of each feature in the dataset.\n",
        "   - Subtract the mean from each feature value to center the data around the origin. This ensures that the new coordinate system is centered at the origin.\n",
        "\n",
        "2. **Calculate Covariance Matrix**:\n",
        "   - Compute the covariance matrix for the centered data.\n",
        "   - The covariance matrix provides information about how features vary with each other.\n",
        "\n",
        "3. **Calculate Eigenvectors and Eigenvalues**:\n",
        "   - Compute the eigenvectors and eigenvalues of the covariance matrix.\n",
        "   - Eigenvectors represent the directions of maximum variance, and eigenvalues quantify the amount of variance in those directions.\n",
        "\n",
        "4. **Sort Eigenvectors**:\n",
        "   - Sort the eigenvectors based on their corresponding eigenvalues in descending order.\n",
        "   - The eigenvectors with higher eigenvalues capture more variance and are prioritized.\n",
        "\n",
        "5. **Select Principal Components**:\n",
        "   - Choose the top `n` eigenvectors (principal components) based on the desired number of dimensions for the reduced dataset.\n",
        "   - These eigenvectors represent the directions in the original feature space that capture the most variance.\n",
        "\n",
        "6. **Project Data**:\n",
        "   - Project the centered data onto the lower-dimensional subspace formed by the selected principal components.\n",
        "   - Multiply the centered data by the selected eigenvectors to obtain the new representation in the lower-dimensional space.\n",
        "\n",
        "7. **Transform the Original Data:**:\n",
        "   - Multiply the original data by the projection matrix to obtain the new lower-dimensional representation of the data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "PCA helps in reducing the dimensionality of the dataset while retaining the most critical information. The first few principal components capture the majority of the variance, allowing for effective visualization and analysis of the data in a lower-dimensional space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1AIYnhgn8ZJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class PCA:\n",
        "    def __init__(self, n_components):\n",
        "        self.n_components = n_components\n",
        "        self.means = None\n",
        "        self.eigenvectors = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        self.means = np.mean(X, axis=0)\n",
        "        X_centered = X - self.means\n",
        "        \n",
        "        covariance_matrix = np.cov(X_centered, rowvar=False)\n",
        "        \n",
        "        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
        "        \n",
        "        idx = np.argsort(eigenvalues)[::-1]\n",
        "        eigenvalues = eigenvalues[idx]\n",
        "        eigenvectors = eigenvectors[:, idx]\n",
        "        \n",
        "        self.eigenvectors = eigenvectors[:, :self.n_components]\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_centered = X - self.means\n",
        "        \n",
        "        return np.dot(X_centered, self.eigenvectors)\n",
        "    \n",
        "    def fit_transform(self, X):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSJCUITOdO70"
      },
      "source": [
        "## Apply `PCA` and `t-SNE` to the testset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "m5rKJD_DpB2a",
        "outputId": "7ff18326-5644-43c5-8737-363b29a08603"
      },
      "outputs": [],
      "source": [
        "pca = PCA(2)\n",
        "X_pca = pca.fit_transform(X_test)\n",
        "visualize_2d(X_pca, y_test, 'PCA')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO84cdMaDYa6"
      },
      "source": [
        "## t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "CNabVxKsBlpr",
        "outputId": "6b2517b2-4586-4996-ee98-23955412e37e"
      },
      "outputs": [],
      "source": [
        "tsne = TSNE(n_components=2, random_state=RANDOM_STATE)\n",
        "X_tsne = tsne.fit_transform(X_test)\n",
        "visualize_2d(X_tsne, y_test, 't-SNE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-QhrJrlC2Xl"
      },
      "source": [
        "## **Question:** (10 points)\n",
        "\n",
        "- Explain the differences between PCA (Principal Component Analysis) and t-SNE (t-distributed Stochastic Neighbor Embedding) in terms of their preservation of distance, handling of non-linearity, and preservation of data structure. How does each technique aim to maintain distance or similarity relationships between data points in the lower-dimensional space, handle non-linear relationships in the data, and preserve the global or local data structure? Provide examples or illustrations to support your explanation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ4xSyHHDrB7"
      },
      "source": [
        "## Solution:\n",
        "\n",
        "PCA and t-SNE are both techniques used for dimensionality reduction, but they differ significantly in their approaches and outcomes:\n",
        "\n",
        "1. Preservation of Distance:\n",
        "PCA preserves linear variance and projects data into a new coordinate system where the greatest variances lie on the axes. It maintains global structure but can fail to capture complex, non-linear relationships.\n",
        "t-SNE, on the other hand, preserves local distances and similarities, especially the structure of the nearest neighbors. It can capture non-linear structures by converting high-dimensional Euclidean distances into conditional probabilities representing similarities.\n",
        "\n",
        "2. Handling of Non-linearity:\n",
        "PCA is a linear technique and is not designed to reduce dimensions based on non-linear relationships.\n",
        "t-SNE excels in handling non-linear data structures. It maps complex manifolds by focusing on local relationships, often revealing clusters at several scales on a single map.\n",
        "\n",
        "3. Preservation of Data Structure:\n",
        "PCA tends to preserve the global data structure and can sometimes blend distinct, local clusters if the global variance is more pronounced in other areas of the data.\n",
        "t-SNE preserves local data structures and can separate clusters that are not distinguishable by PCA. However, t-SNE does not preserve global relationships and distances between clusters can be arbitrary.\n",
        "\n",
        "Both PCA and t-SNE aim to maintain certain relationships between data points when mapping to a lower-dimensional space. PCA maintains the global structure by projecting the data along axes of maximum variance, while t-SNE maintains local similarities and is more focused on revealing local clusters and data patterns.\n",
        "\n",
        "Examples:\n",
        "    In an image dataset where global brightness varies more than the content of the images, PCA might prioritize brightness variance over the actual image content, while t-SNE would group similar images regardless of brightness.\n",
        "    In a dataset with nested clusters, PCA might project the data in a way that the clusters overlap, while t-SNE would unfold the manifolds and separate the clusters in the lower-dimensional space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp_TSX8KFQgE"
      },
      "source": [
        "# Deep Auto-Encoder For Representation Learning\n",
        "\n",
        "In the previous section, you observed the results of applying two renowned dimensionality reduction techniques to the data. Additionally, a representation of the data can be learned by an **autoencoder**, which is a neural network that takes an image (or a noisy version of it) as input and attempts to reconstruct the image after encoding the pixels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSlog8eDGR9r"
      },
      "source": [
        "## Create Dataset & Datalodaer (5 points)\n",
        "\n",
        "- Note: If you are unfamiliar with PyTorch's `Dataset`, `Transforms`, and `Dataloader` modules, consult the following link for assistance: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxjt38hNDjLr",
        "outputId": "6a4db145-9353-4c32-eda4-29084b6b259a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class CustomFashionMNISTDataset(datasets):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.X[idx]\n",
        "        label = self.y[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Assuming X_train, y_train, X_val, y_val, X_test, and y_test are already defined in the notebook\n",
        "BATCH_SIZE = 64\n",
        "train_transform = transforms.Compose([transforms.ToTensor()])\n",
        "test_transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_dataset = CustomFashionMNISTDataset(X_train, y_train, train_transform)\n",
        "val_dataset = CustomFashionMNISTDataset(X_val, y_val, test_transform)\n",
        "test_dataset = CustomFashionMNISTDataset(X_test, y_test, test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlR9zjO-GfxH"
      },
      "source": [
        "## Define Model (5 points)\n",
        "\n",
        "**Caution:** You may only use multilayer perceptron (MLP) layers.\n",
        "\n",
        "- Note: If you are unfamiliar with custom models using PyTorch, consult the following link for assistance:\n",
        "https://pytorch.org/tutorials/beginner/examples_nn/polynomial_module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dyMwCyh6GcB-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Autoencoder(\n",
              "  (encoder): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=12, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=12, out_features=3, bias=True)\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (0): Linear(in_features=3, out_features=12, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=12, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=128, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=128, out_features=784, bias=True)\n",
              "    (7): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # Encoder layers\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 12),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(12, 3),  # Compressed representation\n",
        "        )\n",
        "        # Decoder layers\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(3, 12),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(12, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 28*28),\n",
        "            nn.Sigmoid(),  # Output a value between 0 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "autoencoder = Autoencoder()\n",
        "autoencoder.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFaw1V_3Gids"
      },
      "source": [
        "## Trainin Loop (10 points)\n",
        "\n",
        "#### Complete the `train_at_epoch`, `test_ae`, and `train_ae` functions.\n",
        "\n",
        "#### Define your `Optimizer`, `Learning Rate Scheduler`, and `Criterion` inside the `train_ae` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fXzkJnz6orc"
      },
      "outputs": [],
      "source": [
        "def train_ae_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, data)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    mean_loss = total_loss / len(train_loader)\n",
        "    return mean_loss\n",
        "\n",
        "def test_ae(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data, _ in test_loader:\n",
        "            data = data.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, data)\n",
        "            total_loss += loss.item()\n",
        "    mean_loss = total_loss / len(test_loader)\n",
        "    return mean_loss\n",
        "\n",
        "def train_ae(model, train_loader, val_loader, num_epochs, learning_rate, device):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    train_loss_history = []\n",
        "    val_loss_history = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_ae_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss = test_ae(model, val_loader, criterion, device)\n",
        "        train_loss_history.append(train_loss)\n",
        "        val_loss_history.append(val_loss)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "    return train_loss_history, val_loss_history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3cLIViOIMzQ",
        "outputId": "3be27e9e-4209-4c00-8245-0f9f91639341"
      },
      "outputs": [],
      "source": [
        "ae_train_loss_history, ae_val_loss_history = train_ae(autoencoder, train_loader, val_loader, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3py8m2JiMV1u"
      },
      "source": [
        "### **Advantages of Using PyTorch Lightning for Training Neural Networks**\n",
        "\n",
        "When working on training neural networks, it's essential to choose the right tools and frameworks to ensure efficient development, robustness, and maintainability of the code. PyTorch Lightning is a popular and powerful framework that simplifies the training process and offers several advantages over writing the training loop from scratch. In this exercise, we will explore these benefits by comparing manual implementation with PyTorch Lightning.\n",
        "\n",
        "1. **Structured and Readable Code:**\n",
        "PyTorch Lightning enforces a clear structure by separating the PyTorch components (such as model, optimizer, and scheduler) into dedicated methods like training_step, validation_step, and configure_optimizers. This separation results in more readable and organized code, making it easier to understand and maintain.\n",
        "\n",
        "2. **Reduced Boilerplate Code:**\n",
        "Writing a training loop involves a significant amount of boilerplate code for handling various aspects of training, such as iterating over the dataset, updating parameters, and logging metrics. PyTorch Lightning abstracts away much of this boilerplate, allowing you to focus on the essential components of your model and experiment.\n",
        "\n",
        "3. **Flexibility and Customization:**\n",
        "Despite providing a high-level interface, PyTorch Lightning remains flexible and allows for customization. Users can override specific methods to tailor the training process to their needs while leveraging the standardized structure provided by the framework.\n",
        "\n",
        "4. **Enhanced Reproducibility:**\n",
        "PyTorch Lightning promotes code modularity and follows best practices, contributing to enhanced reproducibility. With a consistent structure across experiments, it becomes easier to replicate and compare results.\n",
        "\n",
        "5. **Integration with Advanced Features:**\n",
        "PyTorch Lightning seamlessly integrates with advanced features such as distributed training, mixed-precision training, and automatic optimization, among others. These features are often complex to implement manually but can be easily utilized with PyTorch Lightning.\n",
        "\n",
        "In summary, PyTorch Lightning provides a high-level and well-structured interface for training neural networks, offering benefits such as code readability, reduced boilerplate, flexibility, reproducibility, integration with advanced features, and a vibrant community. By using PyTorch Lightning, we can expedite the development process, enhance code quality, and facilitate experimentation and research in the field of deep learning.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KKh9oaeMm_p"
      },
      "source": [
        "## Migrate to PL\n",
        "\n",
        "#### In addition to all components defined in the preceding training phase, incorporate the early stopping module from the PyTorch Lightning API and a model checkpoint that saves the best model in each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unbWz8WvMxi7",
        "outputId": "2d1695f0-ebb9-47fe-cb9d-e201c751c7c1"
      },
      "outputs": [],
      "source": [
        "! pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwGPvP_2NXAt"
      },
      "source": [
        "### Complete The Code For the PL Trainer (15 point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QardEIAcMVcE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "class AE_Trainer(pl.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super(AE_Trainer, self).__init__()\n",
        "        self.model = model\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the autoencoder\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # Perform a training step\n",
        "        x, _ = batch\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x_hat = self(x)\n",
        "        loss = self.criterion(x_hat, x)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # Perform a validation step\n",
        "        x, _ = batch\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x_hat = self(x)\n",
        "        loss = self.criterion(x_hat, x)\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Configure the optimizer and learning rate scheduler\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "        return {\n",
        "            'optimizer': optimizer,\n",
        "            'lr_scheduler': {\n",
        "                'scheduler': scheduler,\n",
        "                'monitor': 'val_loss',\n",
        "            },\n",
        "        }\n",
        "\n",
        "autoencoder = Autoencoder()\n",
        "ae_trainer = AE_Trainer(autoencoder)\n",
        "\n",
        "# Define early stopping and model checkpoint callbacks\n",
        "early_stopping = EarlyStopping('val_loss', patience=5)\n",
        "checkpoint_callback = ModelCheckpoint(dirpath='checkpoints/', save_top_k=1, monitor='val_loss')\n",
        "\n",
        "# Initialize the trainer\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=50,\n",
        "    accelerator='gpu' if torch.cuda.is_available() else None,\n",
        "    callbacks=[early_stopping, checkpoint_callback],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.fit(ae_trainer, train_loader, val_loader)\n",
        "autoencoder = ae_trainer.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmmp2kqtHXQJ"
      },
      "source": [
        "## Visualize Losses\n",
        "\n",
        "##### Visualize Train_Loss and Val_Loss durining the trainin phase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "w_-Xs-KrBOzs",
        "outputId": "1a1d0792-702d-4842-b808-7058b1624667"
      },
      "outputs": [],
      "source": [
        "plt.plot(ae_trainer.train_losses, label='Train Loss')\n",
        "plt.plot(ae_trainer.val_losses, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrKtvAGSHwZ3"
      },
      "source": [
        "## Evaluate on Testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A_DmnAIJXDZ",
        "outputId": "35b8d19c-e16f-4f4a-8ad1-fa8ff83ba68c"
      },
      "outputs": [],
      "source": [
        "test_ae(autoencoder, test_loader, nn.MSELoss(), device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWFdOTUvXyeT"
      },
      "source": [
        "## Visualize Model Output (8 points)\n",
        "\n",
        "\n",
        "##### For each category in the test set:\n",
        "\n",
        "1. Randomly select an image from that category.\n",
        "2. Generate a reconstruction of the image.\n",
        "3. Display the original image and its reconstruction side-by-side.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A7NBxjAdL0Nh",
        "outputId": "1f9fd62e-0062-4a5e-e92d-13cc6436825a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "def visualize_input_reconstructed(autoencoder, test_loader, device, class_names):\n",
        "    autoencoder.eval()\n",
        "    fig, axes = plt.subplots(nrows=len(class_names), ncols=2, figsize=(10, 4 * len(class_names)))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, class_name in enumerate(class_names):\n",
        "            # Find an image of the given class\n",
        "            for images, labels in test_loader:\n",
        "                idx = (labels == i).nonzero(as_tuple=True)[0][0]\n",
        "                original_image = images[idx]\n",
        "                break\n",
        "            \n",
        "            # Generate reconstruction\n",
        "            reconstructed_image = autoencoder(original_image.view(1, -1).to(device)).cpu().view_as(original_image)\n",
        "\n",
        "            # Plot the original image\n",
        "            axes[i, 0].imshow(original_image.squeeze(), cmap='gray')\n",
        "            axes[i, 0].set_title(f'Original - {class_name}')\n",
        "            axes[i, 0].axis('off')\n",
        "\n",
        "            # Plot the reconstructed image\n",
        "            axes[i, 1].imshow(reconstructed_image.squeeze(), cmap='gray')\n",
        "            axes[i, 1].set_title(f'Reconstructed - {class_name}')\n",
        "            axes[i, 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "class_names = [str(i) for i in range(10)]  # Replace with actual class names if available\n",
        "visualize_input_reconstructed(autoencoder, test_loader, device, class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i5hvxABNRU5"
      },
      "source": [
        "## Visualize Embeddings (5 points)\n",
        "\n",
        "Generate image embeddings for the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7WTVEhPMY24"
      },
      "outputs": [],
      "source": [
        "def generate_embeddings(autoencoder, test_loader, device):\n",
        "    embeddings = []\n",
        "    autoencoder.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, _ in test_loader:\n",
        "            images = images.to(device)\n",
        "            encoded_images = autoencoder.encoder(images.view(images.size(0), -1))\n",
        "            embeddings.append(encoded_images.cpu().numpy())\n",
        "    embeddings = np.concatenate(embeddings, axis=0)\n",
        "    return embeddings\n",
        "\n",
        "embeddings = generate_embeddings(autoencoder, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZnXeSqz2N28k",
        "outputId": "ce38e094-60f2-48e7-d11a-385144a64958"
      },
      "outputs": [],
      "source": [
        "tsne = TSNE(n_components=2, random_state=RANDOM_STATE)\n",
        "embeddings_tsne = tsne.fit_transform(embeddings)\n",
        "visualize_2d(embeddings_tsne, y_test, 'AE t-SNE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rYLgh8sZGel"
      },
      "source": [
        "# Train a Classifier (8 points)\n",
        "\n",
        "In the previous part, we saw that the encoder has learned to project images into representations with semantic meaning. In this part, you will transfer the knowledge learned by the encoder to a classification task by adding classification layers on top of it. This is a common technique in transfer learning, and it can be used to improve the performance of a classifier on a new task, even if the classifier is trained on a limited amount of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "217R52ZdN908"
      },
      "outputs": [],
      "source": [
        "def get_encoder(autoencoder):\n",
        "    encoder = autoencoder.encoder\n",
        "    # Remove the last layer (bottleneck) if necessary\n",
        "    return nn.Sequential(*list(encoder.children())[:-1])\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, encoder, num_classes):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.classifier_layer = nn.Sequential(\n",
        "            nn.Linear(64, num_classes)  # Assuming the encoder's last layer outputs a feature vector of size 64\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input\n",
        "        x = self.encoder(x)\n",
        "        x = self.classifier_layer(x)\n",
        "        return x\n",
        "\n",
        "encoder = get_encoder(autoencoder)\n",
        "classifier = Classifier(encoder, 10)\n",
        "classifier.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A2j_ODEOyQi"
      },
      "source": [
        "## Training Loop (9 Points)\n",
        "\n",
        "Implement the `train_clf_epoch`, `test_clf`, and `train_clf` functions. In the `test_clf` function, in addition to the loss, calculate and return the accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThaT4RDsaFs4"
      },
      "outputs": [],
      "source": [
        "def train_clf_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    mean_loss = train_loss / len(train_loader)\n",
        "    return mean_loss\n",
        "\n",
        "def test_clf(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    mean_loss = test_loss / len(test_loader)\n",
        "    return mean_loss, accuracy\n",
        "\n",
        "def train_clf(model, train_loader, val_loader, num_epochs, device):\n",
        "    learning_rate = 1e-3\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "    train_loss_history = []\n",
        "    val_loss_history = []\n",
        "    val_acc_history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_clf_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc = test_clf(model, val_loader, criterion, device)\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val ACC: {100 * val_acc:.2f}\")\n",
        "\n",
        "        train_loss_history.append(train_loss)\n",
        "        val_loss_history.append(val_loss)\n",
        "        val_acc_history.append(val_acc)\n",
        "\n",
        "    return train_loss_history, val_loss_history, val_acc_history\n",
        "\n",
        "clf_train_loss_history, clf_val_loss_history, clf_val_acc_history = train_clf(classifier, train_loader, val_loader, 30, device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCl5L5f3Psjl"
      },
      "source": [
        "## Visualize Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "FvoqnvOBa_2v",
        "outputId": "6822e180-ee9c-4810-e95f-cf79c1d69054"
      },
      "outputs": [],
      "source": [
        "plt.plot(clf_train_loss_history, label='Train Loss')\n",
        "plt.plot(clf_val_loss_history, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9yhp8q4Pvs8"
      },
      "source": [
        "## Visualize Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "-GjKoTN3bASy",
        "outputId": "b47853db-fc86-43d4-80f6-4f7ef61ed661"
      },
      "outputs": [],
      "source": [
        "plt.plot(clf_val_acc_history, label='Val Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHPyLTbjP7Mc"
      },
      "source": [
        "## Evaluate on Testset (20 points)\n",
        "\n",
        "Your model must achieve an accuracy of at least 90% on the test set to receive full marks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5vaLwhac_7Q",
        "outputId": "d79112ad-2ec7-4f74-c90b-1e8981d93143"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = test_clf(classifier, test_loader, nn.CrossEntropyLoss(), device)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test ACC: {100 * test_acc:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
