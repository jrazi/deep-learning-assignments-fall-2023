{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISKf-ajkZKU6"
      },
      "source": [
        "# Homework 3\n",
        "\n",
        "## Course Name: Deep Learning\n",
        "#### Lecturer: Dr. Beigy\n",
        "\n",
        "---\n",
        "\n",
        "#### Notebooks Supervised By: Zeinab Sadat Taghavi\n",
        "#### Notebooks Prepared By: Zahra Rahimi, Zahra Khoramnejad, Mehran Sarmadi\n",
        "\n",
        "**Contact**: Ask your questions in Quera\n",
        "\n",
        "---\n",
        "\n",
        "**Note**: Replace the placeholders (between `## COMPLETE THE FOLLOWING SECTION  ##` and `## THE END ##`) with the appropriate details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7FFJaRgaqC1"
      },
      "source": [
        "---\n",
        "---\n",
        "## 1 Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q8G6YosbKrX"
      },
      "source": [
        "In this notebook you have to design and train models for a time series prediction task on the provided dataset using these three different architectures:\n",
        "\n",
        "- Simple RNN\n",
        "\n",
        "- GRU\n",
        "\n",
        "- LSTM\n",
        "\n",
        "You will compare and rank them at the end of the notebook and explain why they were ranked that way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FANbmLJ2d2dp"
      },
      "source": [
        "---\n",
        "### 1.1 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WdzOu4UGgDFQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prWan6z7eKEp"
      },
      "source": [
        "---\n",
        "---\n",
        "## 2 Dataset\n",
        "Electric Production IP Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rtouQ7MVomh0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./Electric_Production.csv', index_col='Date', parse_dates=True, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "-m3r2Dw_os75",
        "outputId": "63e9538a-5b47-4a55-9ace-eac8aa05734d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-324a28f6-cf79-4a9b-9dd5-a5e42420a238\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1985-01-01</th>\n",
              "      <td>72.505203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985-02-01</th>\n",
              "      <td>70.671997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985-03-01</th>\n",
              "      <td>62.450199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985-04-01</th>\n",
              "      <td>57.471401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985-05-01</th>\n",
              "      <td>55.315102</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-324a28f6-cf79-4a9b-9dd5-a5e42420a238')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-324a28f6-cf79-4a9b-9dd5-a5e42420a238 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-324a28f6-cf79-4a9b-9dd5-a5e42420a238');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b966f2a4-a1be-4a46-b482-2c5ba698d2c4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b966f2a4-a1be-4a46-b482-2c5ba698d2c4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b966f2a4-a1be-4a46-b482-2c5ba698d2c4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                Value\n",
              "Date                 \n",
              "1985-01-01  72.505203\n",
              "1985-02-01  70.671997\n",
              "1985-03-01  62.450199\n",
              "1985-04-01  57.471401\n",
              "1985-05-01  55.315102"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc6T4bkqqVQX",
        "outputId": "5907a8f3-08f0-4220-94c7-67f210dafe51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 397 entries, 1985-01-01 to 2018-01-01\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Value   397 non-null    float32\n",
            "dtypes: float32(1)\n",
            "memory usage: 4.7 KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "o_WhChFOqYb4",
        "outputId": "7944b627-7aa5-4bcd-c28b-66a3d968f016"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGwCAYAAACD0J42AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADS70lEQVR4nOy9eZxkZXk9fm7tvff0bD0DAwybA8q+IyrKhEUgEPmKKIoEBDVogvwUJQFUoqJEEwIS0WgQVBIlKi5JICMYQBx2RpAdWWaGYWaYpfeu/f7+uPW893mXW1W39+55zufDZ7q76q5V1HvqPOc5j+f7vg+BQCAQCASCGYTEdJ+AQCAQCAQCgQkhKAKBQCAQCGYchKAIBAKBQCCYcRCCIhAIBAKBYMZBCIpAIBAIBIIZByEoAoFAIBAIZhyEoAgEAoFAIJhxSE33CYwF1WoVGzZsQEdHBzzPm+7TEQgEAoFA0AR838fg4CCWLl2KRKK+RjIrCcqGDRuwbNmy6T4NgUAgEAgEY8C6deuw8847133OrCQoHR0dAIIL7OzsnOazEQgEAoFA0AwGBgawbNkytY7Xw6wkKFTW6ezsFIIiEAgEAsEsQzP2DDHJCgQCgUAgmHEQgiIQCAQCgWDGQQiKQCAQCASCGYdZ6UERCAQCgWAiUKlUUCqVpvs05gzS6TSSyeSE7EsIikAgEAh2OPi+j40bN6Kvr2+6T2XOobu7G729vePOKROCIhAIBIIdDkROFi1ahNbWVgn9nAD4vo+RkRFs3rwZALBkyZJx7U8IikAgEAh2KFQqFUVO5s+fP92nM6fQ0tICANi8eTMWLVo0rnKPmGQFAoFAsEOBPCetra3TfCZzE3Rfx+vtiU1Q7r33Xpx66qlYunQpPM/D7bffrj3+hS98AStWrEBbWxvmzZuHlStX4sEHH9Ses23bNpx99tno7OxEd3c3zj//fAwNDY3rQgQCgUAgiAMp60wOJuq+xiYow8PDOOCAA3DDDTc4H997773xzW9+E08++SR+97vfYbfddsPxxx+PN954Qz3n7LPPxlNPPYVVq1bh17/+Ne69915ceOGFY78KgUAgEAgEcwqe7/v+mDf2PPz85z/H6aefHvmcgYEBdHV14Te/+Q2OO+44PPPMM9h3333x8MMP49BDDwUA3HHHHXj3u9+N9evXY+nSpdY+CoUCCoWCts9ly5ahv79fou4FAoFAEAv5fB4vv/wyli9fjlwuN92nM+dQ7/4SJ2hm/Z5UD0qxWMR3vvMddHV14YADDgAArF69Gt3d3YqcAMDKlSuRSCSsUhDh6quvRldXl/pPJhkLBAKBQBAfxx57LC6++OLpPo2mMCkE5de//jXa29uRy+XwT//0T1i1ahUWLFgAIGjtWrRokfb8VCqFnp4ebNy40bm/yy67DP39/eq/devWTcZpCwQCgUAwY3HqqafixBNPdD523333wfM8PPHEE1N8VvGwsX+06edOCkF55zvfiTVr1uD3v/89TjzxRJx55pmqL3osyGazanKxTDAWCAQCwY6I888/H6tWrcL69eutx2666SYceuih2H///afhzJrHX/3osaafOykEpa2tDXvuuSeOPPJIfO9730MqlcL3vvc9AEBvb69FVsrlMrZt24be3t7JOB2BQCAQCOrC932MFMtT/l8cG+gpp5yChQsX4vvf/77296GhIdx22204/fTT8f73vx877bQTWltbsd9+++Hf//3f6+7T1Y3b3d2tHWPdunU488wz0d3djZ6eHpx22ml45ZVXmj5vjnK1+eudkqC2arWqTK5HHXUU+vr68Oijj+KQQw4BANx9992oVqs44ogjpuJ0BAKBQCDQMFqqYN8r75zy4z591QlozTS3FKdSKZxzzjn4/ve/j7/7u79T7by33XYbKpUKPvjBD+K2227DZz/7WXR2duK//uu/8KEPfQh77LEHDj/88DGdX6lUwgknnICjjjoK9913H1KpFL70pS/hxBNPxBNPPIFMJhNrf+VKtennxlZQhoaGsGbNGqxZswYA8PLLL2PNmjVYu3YthoeH8bd/+7d44IEH8Oqrr+LRRx/Feeedh9deew3vfe97AQD77LMPTjzxRFxwwQV46KGHcP/99+MTn/gEzjrrLGcHj0AgEAgEggDnnXce/vSnP+Gee+5Rf7vppptwxhlnYNddd8WnP/1pHHjggdh9993xyU9+EieeeCJ+8pOfjPl4P/7xj1GtVvHd734X++23H/bZZx/cdNNNWLt2Lf7v//4v9v4mVUF55JFH8M53vlP9fskllwAAPvzhD+PGG2/Es88+i5tvvhlbtmzB/Pnzcdhhh+G+++7Dm9/8ZrXNj370I3ziE5/Acccdh0QigTPOOAPXXXdd3FMRCAQCgWBC0JJO4umrTpiW48bBihUrcPTRR+Pf/u3fcOyxx+LFF1/Efffdh6uuugqVSgVf+cpX8JOf/ASvvfYaisUiCoXCuBJz//CHP+DFF19ER0eH9vd8Po8//elPsfdXrkwiQTn22GPr1sx+9rOfNdxHT08Pbr311riHFggEAoFgUuB5XtOllunG+eefj09+8pO44YYbcNNNN2GPPfbAO97xDnzta1/DP//zP+Paa6/Ffvvth7a2Nlx88cUoFouR+/I8z1rTeUT90NAQDjnkEPzoRz+ytl24cGHsc69Umy/xzI5XQyAQCAQCAQDgzDPPxN/8zd/g1ltvxS233IKPf/zj8DwP999/P0477TR88IMfBBD4P59//nnsu+++kftauHAhXn/9dfX7Cy+8gJGREfX7wQcfjB//+MdYtGjRhHTQlmIoKDIsUCAQCASCWYT29na8733vw2WXXYbXX38d5557LgBgr732wqpVq/D73/8ezzzzDD760Y9i06ZNdff1rne9C9/85jfx+OOP45FHHsHHPvYxpNNp9fjZZ5+NBQsW4LTTTsN9992Hl19+Gf/3f/+Hv/7rv3a2OzdCOYaCIgRFIBAIBIJZhvPPPx/bt2/HCSecoBpMLr/8chx88ME44YQTcOyxx6K3t7fuKBoA+MY3voFly5bhbW97Gz7wgQ/g05/+tOZZaW1txb333otddtkF73nPe7DPPvvg/PPPRz6fH5OiUm6en4xvFs90IU6Wv0AgEAgEHDKLZ3JR7/4u///+E6/843unfxaPQCAQCAQCARCE4VVitBkLQREIBAKBQDDpiGOQBYSgCAQCgUAgmALEMcgCQlAEAoFAsINiFlowZwWi7mucFFlACIpAIBAIdjBQGy3P+xBMHOi+8nZlIF6KLCBBbQKBQCDYwZBMJtHd3Y3NmzcDCFppafCeYOzwfR8jIyPYvHkzuru7kUzqMf5xBgUCQlAEAoFAsAOit7cXABRJEUwcuru71f3lKMUs8QhBEQgEAsEOB8/zsGTJEixatEibPSMYH9LptKWcEERBEQgEAoGgSSSTycgFVTCxEJOsQCAQCASCGYe4JlkhKAKBQCAQCCYdpZglHiEoAoFAIBAIJh1S4hEIBAKBQDDjENckKwRFIBAIBIJpwvfvfxlf+OVTO0SqrSgoAoFAIBDMEnxj1fP4/u9fwbpto9N9KpMOMckKBAKBQDBLkC9Vgn/LlWk+k8lHSYYFCgQCgUAw8+H7Pko1VaFYjrd4z0aIgiIQCAQCwSxAkZlGizENpLMRYpIVCAQCgWAWgKsmpR1AQYk7i0cIikAgEAgE04ASK3mUYpY/ZiMq4kERCAQCgWDmQ1NQdoAST1wSJgRFIBAIBIJpACclhR2gxCMmWYFAIBAIZgEKO5iCUpYSj0AgEAgEMx+clOwIBEVKPAKBQCAQzALsaB4UMckKBAKBQDALwEnJjhDUJgqKQCAQCASzAJyUFHeANmMxyQoEAoFAMAtQ3ME8KGKSFQgEAoFgFmCHS5IVBUUgEAgEgpmPHW0Wz6SbZO+9916ceuqpWLp0KTzPw+23364eK5VK+OxnP4v99tsPbW1tWLp0Kc455xxs2LBB28e2bdtw9tlno7OzE93d3Tj//PMxNDQU91QEAoFAIJi1KO1gBGXSFZTh4WEccMABuOGGG6zHRkZG8Nhjj+GKK67AY489hp/97Gd47rnn8Od//ufa884++2w89dRTWLVqFX7961/j3nvvxYUXXhj3VAQCgUAgmLXQSzzxTbK/WPMavn7nc/D92WGwjetBScU9wEknnYSTTjrJ+VhXVxdWrVql/e2b3/wmDj/8cKxduxa77LILnnnmGdxxxx14+OGHceihhwIArr/+erz73e/G17/+dSxdujTuKQkEAoFAMOtQ1IYFxldQ/uY/1gAADl/eg7fvvXCiTmvSMOO6ePr7++F5Hrq7uwEAq1evRnd3tyInALBy5UokEgk8+OCDzn0UCgUMDAxo/wkEAoFAMJsxUUFt67ePTsTpTDpmlEk2n8/js5/9LN7//vejs7MTALBx40YsWrRIe14qlUJPTw82btzo3M/VV1+Nrq4u9d+yZcsm87QFAoFAMAtRKFeQL1Wm+zSaxkQFtY0UyxNxOpOOGZMkWyqVcOaZZ8L3fXzrW98a174uu+wy9Pf3q//WrVs3QWcpEAgEgrmAStXHUVffjaO/ejfKs8Rwqge1xTtn7jsZLswOUlaqxlNQYntQmjqJGjl59dVXcffddyv1BAB6e3uxefNm7fnlchnbtm1Db2+vc3/ZbBbZbHYyTlUgEAgEMwi+78PzvNjbbRsuYttwEQDQN1rCgvaZv2aMZ1hgmS32I6XZoaDEJY4TrqAQOXnhhRfwm9/8BvPnz9ceP+qoo9DX14dHH31U/e3uu+9GtVrFEUccMdGnIxAIBIJZgmrVx/u+/QDO+beHYnemzKbSDkH3oMS7Xk5oRmaJghLXJBtbQRkaGsKLL76ofn/55ZexZs0a9PT0YMmSJfh//+//4bHHHsOvf/1rVCoV5Svp6elBJpPBPvvsgxNPPBEXXHABbrzxRpRKJXziE5/AWWedJR08AoFAsANj+0gRD72yDQBQKFeRSyeb3naY+TBmS2x8cRweFP784VniQZn0Es8jjzyCd77zner3Sy65BADw4Q9/GF/4whfwy1/+EgBw4IEHatv99re/xbHHHgsA+NGPfoRPfOITOO6445BIJHDGGWfguuuui3sqAoFAIJhDKLBFt1CKR1CG8oygjCFTZDowHg8Kf/5gfnYQlLgm2dgE5dhjj60rvTUjy/X09ODWW2+Ne2iBQCAQzGHwMk2+XEEX0k1vO1QIF+nZkso6njZjvm3/aGnCzmkyMaPajAUCgUAgaBamghIHnKDETSydLozHJMsX+/6R2UFQpt0kKxAIBALBWMAVlEI5nvFzVpZ4OEGJec5cQekbLU7YOU0myjE9KEJQBAKBQDAjwBWU/DgUlNlT4gkX7LjnzBWXvlmioEiJRyAQCASzEuNSUAo7VhePVg4rVzFanPmtxjMmSVYgEAgEgjgwF9040Eo8s4SglMZhkjWfH7fMM1Is4/X+qZ3hM+OGBQoEAoFgx0KpUkUlpt8AMLp4YgavzXYFZTxdPED8Ms9f3vQw3n7Nb7F5MB9ru/GgJAqKQCAQCKYLxXIVb7/mt/iLf7k/9rbjUlC4B2WWmGTHMyzQUlBiEpSXtwyjVPGndBLypCfJCgQCgUAQhec2DuL1/jxe78+jWvWRSDQ/V6cwQR6U2dJmPJ6oe5PQ9Mcs8VBHzXimKMeFmGQFAoFAMG3g5CCupD+uLp5Z6EHRTLKVaqz5Q2bXz/aYCgrdo6m8V2KSFQgEAsG0gXtP4kr6WhfPeDwos6TEY6oXcXJCzG1HYnbx0GszlQqKmGQFAoFAMG3gBCXut/MJ86DMFgXFuMY498ssl8S916R0TWmJRxQUgUAgEEwX+MIZlyhMVFDbVJd4fN8fU9eSeZ5xyIK5bSnGtr7vq9ep3mtUKFcmlMCIgiIQCASCaQMv04yrxBPDJOv7/rR6UM75t4fwZ/90T+zF3Hx+HEI3HvWFk6moc+4fLeGtX70b7/326qb3Ww++78eOupcuHoFAIBBMGEYZyYhd4imNrcRTKFe1xS9ut8h4cf+LW1D1gU0DeSzraW16O7tMM3aTbDHGts3cq589th5bhorYMjQxc37ikhNAFBSBQCAQOBCno4QjPw6Cki+PLaiNl3fGctzxoFL1QWtvXNXHJBlxyjTj86/w/BX3Of/+T1vVz1WDXPi+HztIbywlMCEoAoFAINBQLFdxwrX34oJbHom9rU5Q4i1KY1VQeHknOK697VChjP98dD36Ryd2sF5xjL4Zfm9StayYOCUe8xrLYzTYul4j3/fx+xe3hM8xzK0f++GjOOxLv8Ebg4UYx4xPGoWgCAQCgUDDa32jeH7TEO5+dnNsJYUv0uNRUGIRFEtBsc/52lXP49O3/QEfufnhWOfUCMUxdh5xMtKWTVn7inPcYH8xSjxG/oqJ5zcNYbjoJpq+7+POpzZhsFDGqqc3xTimKCgCgUAgGCeoVFGp+rFVkInyoIynxONa6Fc9EyymD7+yPdY5NQJf4OOUeHg5p71GUMZSpskkE/G3bWCSfWpDv/Y7JzRcgVrUkW36mOJBEQgEAkHT2D5cxKdv+wMeenmb9neugozGDADjxCLuTJyxKijmOboW64OWdauftw41X5poBJ2gxFdQkgkP2TSRjPgm2dZssrZt88dupKCYpSr+nLXbRtTPqWTzYwzIg5KOsY0QFIFAINhBseqZTfjPR9fjX+97Sfs7JxkjpbK5WV1wBSXuTBzNgxJDQTG/nbsW6/Zc2LRqErLxQCvxxPCg0HaZZGJMKgiRv7bMWNQX5kFxkCrTOMvLM5ygxDG+0nshzmwmISgCgUDQAP0jJbzjH36Lq//7mek+lQnFYM1capZT+O/jUVDG1cUTQ40wF0qX34H/7cEJJCilMZZ4SJVIJz2kawQllgeFFJRMsrZtfLLA98NRL6WWE5Q4ig+9RikhKAKBQDBxeGpDP17dOoI7nto43acyoRgtBgTFJBK8VBF3xgsvD8Qt8YxVQakaRl7Xosv/9tjaifOhjNkkSwpKKqnKHrG6eGrbt43Bv1LWunjq36vgOeHz141ZQQmem/SEoAgEAsGEoVD7wI6b/TDTQeTD/CasKSgxr5krLrFLPGXuX4mx4DZR4uHXOFyIV7aqh7HODyKSkE56yKTGUOKpEEGJ70EpNfDNmH+LUlDivL6ioAgEAsEkgBbLuPNhZjqIfJgZGoXxmGTLk9vFU6n6+ONr/Vrnjhkk5io98GuM21Hy1IZ+nHbD/bifZYOExxqb6kPZIilW4hkLyRiLB6VRkqw1ZTnCgxKnxEP7SApBEQgEgolDSFDmloJC5MPM0OAkI26JhxOa0gR38Tz66nYc8qVVOOX63+GSH69RfzdLDW4FhRGUmK3Tf/Mfa/CHdX04+7sPWo+NtcQTKgqhSTaOalQwSjxxclC4MdaVJGsNMaz9XqpUsaEvr/5eGYOCIgRFIBAIJhC0cBTKVevb+mxGWOKpo6DE7OLh5lYzgbQezMwV12L/X0+8jr6RIIdj/fZRbVsO10LPF/C4pafBfHT6rN7FE6PzqBKWPKjEE4fglMwST5xtYyoodKxtw0XtXsdSUGr3PCltxgKBQDBxGGvWxUwHERSzxKO1Gcct8WgKytiTUV1qFVdY+EJZMUyyrhIOP5e4CkpnLh352FjfG2rBTnjIpQOSMZY25TGVeLRZPK42Y3eJxzxGHJMsV4yahRAUgUAgaAB93srsKfPc8/wbeHJ9f+TjpI5YJllGBMbnQWl+ATPva7nq1/XG8MWSFr96eSJcNXE97vt+ZKx/V0s0QWlkOI1CWQWXJZCrBbXFeW+FCsr4clAadTzxfZvCk+uYmwfzOONbv8dtj6zT/l6WEo9AIBBMPDhBidvVMl3YNJDHuTc9hFO/+Tt81whiI4xGlHjGkySreVBilFJci7u5UHLywx+jNmNa6BuXeOzpvOf820M47Yb7napAJyMoJonRu3iav1cVZhrNpgIFJR8nR6Ws56CMpdzC96PtO4KgmKUxl1J1w90v4tFXt+Mz//mE9nfp4hEIBIJJAP/Ani0KytahImgt/fJ/P4PX+kat50R6ULhJNm6bcWlsJlm6r7TgBn+LVlB4mYZ+plKJ0yRbp8RTKFdx3wtb8MT6fry6ddjatpOl0A7ko+f+xCnR0GKfYlH3Y5mG3K5Msvq2o8UKbrr/ZazdOmJt2zAHxfKgBM8382ZcZC5KRaLjSJKsQCAQTCAKWolnZnlQHl+7HUdffRf+89H12t85yfB99/wZIhN2DsrYFZSoMkzD7ZgiQMFlpiJRiGhhpoWz3kwb/nxT2RlgJlhXCSLBwsW2GPdxvCWeVNJDrqagxFFg1P2KKPHc+tBafPFXT+Pt//Bba9tSXA9KlRSUxt1SHYzMcSgFRYLaBAKBYOIw3hLPQy9vcyoY44Xv+/iLf/k9NvTn8cVfPaU9Vi9sixCloIw16r5S9bVv8nFKPHTMbCqpSh6mItHIg0ILvduDEi6uvq9/+x8YDVWRRsmqW4eK+mNjLPGEXTwJpfzEU1DIJOvu4nlx81Dkeek5KI0JCv1uKk8uBaWDGYpHiuF9FQ+KQCAQTALG2koKAE+s78OZ316Nt3717ok+LW2mzPIFbdpjNkGxF5N8Ex6UOCUes/wVp8RD55tNM9NoXQXF7uJpqePHiGqdBfQ2YhdJKGkERVdQxpqDwhfssZhkVRcPKSgGWdh1fqv6+bFX+/RjN1BQzPcDnatZ4nHdZ2qZBnQypxSUpHTxCAQCwYShWOFD7OIRlAde2jrRp6PwE9Yp0dOW0R6rtyADgfpC5KNqKAqFBl0867eP4Jt3v4C+EV1NMNWlOCWeZhQUTh64YZMMp/UUlKhFFwiHJgJuFYQvxFuGi8ZjY/OgUMhZOhmaZMeUg8LajLmBl7/+ZgKu3sXjIHO1fefSeleUWeIxu6zM425l96o8FSbZe++9F6eeeiqWLl0Kz/Nw++23a4//7Gc/w/HHH4/58+fD8zysWbPG2kc+n8dFF12E+fPno729HWeccQY2bdoU91QEAoFgSqCVeIrxPChxuiviYmA0/OZvyu2WrG+cR7FSNUK33AutK6jtw//2EL7+v8/jUqNTw24Vju9ByaYSzDRaX0GhBblieVCaICjsd+5BcZEMvu2WQV1BKfD7FoO8lipjV1CqVV8t+K21oDazbMXP5T6LoHAFxT6mnbHiq+NyuLp4NILC1CYiZJNqkh0eHsYBBxyAG264IfLxY445Bl/72tci9/GpT30Kv/rVr3DbbbfhnnvuwYYNG/Ce97wn7qkIBALBlGA8OShx59HEAf/GXS8NFnB3eXDw7RtF3f/pjaDT5X+f1r9YmvcmzjRjIgz1FAXzd1V6qP3bUqeLxyRonDjqCkojVWBiSjw8uCxuUBt/LYlEAPo18X29uGlQ277hLJ4KGXD1+2kpKA4Cqvl1uIKiPDfWJpFw223r4KSTTsJJJ50U+fiHPvQhAMArr7zifLy/vx/f+973cOutt+Jd73oXAOCmm27CPvvsgwceeABHHnlk3FMSCASChugbKeID//og/vzApfjYO/aItW0xYvFuBpNJUPjiaCsopmKgP24SD/74WE2ypn8jzrWTCpJMeMjUunjqmXfp8XQyoRbOsM04UFc81jFiEjS+uOoelPqzaUyTbKMunrVbR3DVr5/GR9+xOw7brYcdP+ziyabcnpsoaAQlm9T+3gKb3NUzTDuD2gwFhcijqaC4TLK6gmJ7UJIzOUn20UcfRalUwsqVK9XfVqxYgV122QWrV692blMoFDAwMKD9JxAIBHHw+Lo+PP36AH722PrGTzagl3jiERQ9r2NiyYrWOmtle9T3g9Tzi/AFLU7X0ng8KHyYXDjdtz7posdViYd9PTe3tUs8zSsofF91u3gc9+rzv/wjfvPMJrz3Rn19o/fCWKLuecdOq6aguMtNZiovv/ZK1Y+cZWQOIrTbjOvnoPASz5R4UMaLjRs3IpPJoLu7W/v74sWLsXHjRuc2V199Nbq6utR/y5Ytm4IzFQgEcwn04R93tgxQ/9toIzSKFR8P+P4aKSiNSjxRYXRx7petcMSf1ZLwOEGpX+IpGd/saaE3t61UfZhf9vnj3MvjNsmOvcSzzTDVElTUfSK6aykKpUq42AeEzlac6r3+Zvt31PRiCs0jcmPNPIphkp2z04wvu+wy9Pf3q//WrVvXeCOBQCBgoIUnrgICTJwHxdXSCQDrto3g/O8/jIdY23Dc82rkQYlX4qmvGEVlbdXztTQCj0JPp2yCUjJMvfyc6WktLIU2Ki2V2mCju3jq+ypMotdoWGBvV079zLts6PySzHPT7HuLXncicorQMc9P3Q4oh2Gao2SUeOj+VYztnCZZbih2KCgzmqD09vaiWCyir69P+/umTZvQ29vr3CabzaKzs1P7TyAQzF5MdKmjGdDiMRYFhS9wsYfnsUUnSn358E0P4a5nN+OCWx6Jte/6HpT6ZIGHaJmPax6UUsWaP8ONmfy4+SbC4aKglXgS9RUBIkhq4awpAplkQj1WNMgNIZxdwxQUTlAadPGY2S7cCOxSXxZ3hgRli+bJCPaZ0rp4mjXJBsch5YQIik6WojugzP//rGA2amHO6l08dpuxy4MSHmer43pnNEE55JBDkE6ncdddd6m/Pffcc1i7di2OOuqoqT4dgUAwxfjTG0M48KpV+Mb/Pjelx6UP4dFSxTL7Ndx2HCbZ4WL9xQ8AXqp1xfSzUkMz4CUUc/FolIMSVY7xfV8jA2Y6LBDmYwDA9hHeqVFftakHKh/wEk9R60oJz7c9o8+fUdsm3OUhfp+o00f3oDQwyZb5fa5TOqnYfg7O7ficn9CTkWBdS829t+j1ydS2c12z+ZppKbx1IuurVV/drzaji8cMamvYZjw8Pg9K7C6eoaEhvPjii+r3l19+GWvWrEFPTw922WUXbNu2DWvXrsWGDRsABOQDCJST3t5edHV14fzzz8cll1yCnp4edHZ24pOf/CSOOuoo6eARCHYAfO1/nsVQoYzr734R/9/xb5qy45rGT/p22Az0Ek889WeowCfw2gvQcCEkMCt6O2Ltm1+TuXA2SpI1lSRahFwqz2ixohZR8zlbh4pY0J4NzqFB6aAeiDSmkp7q9OBm0LxalBNBmaZgl3iSXqC+FKEvutyQGpZ4IhSUBsmq5n00c0QK5YpmXOWk45WtIzi01smjzeJhUfdm95EL9H4kU7Cr68kaE1C274e5P0B/zVqNEk/sNuOhorqecHrzJHbxPPLIIzjooINw0EEHAQAuueQSHHTQQbjyyisBAL/85S9x0EEH4eSTTwYAnHXWWTjooINw4403qn380z/9E0455RScccYZePvb347e3l787Gc/i3sqAoFgFmIy227rgX8Ixy3zjGcWDycgLnLz+No+9fPCjmzM8+KyfdwSTwRBYedIX3bNa+Yqg6tTI+PwkDRCWTPJerW/8QWXkmYTlmLAyY3Lv0KLZjrpqW/wpQgFxaViRJWLzP0E5xm9+GsKCgtqyzJFqqC9T8v4t9+9jPXb9YnEJkFxXbOdIeMeE2Bux39uy+hqkxXU1mCkQJkFypWmQkE59thjrXokx7nnnotzzz237j5yuRxuuOGGyLA3gUAwd+GShacCjeLb62E8s3g4QXEpCg++HEbhW1NkK9W6s0v4/sz7aueg6L/bhtZgeyphJRMe2jJJDOTLGpkpVaqR0e9EKFozSRTL1XglHuZByTjajIncZVNJpAzFQCc3tfIQK8vQftKJkNzEazOuYzBtECbHX6NXtoZEQ0XdJ8JpxrQ9KSq//sPruOrXT+OqXz+NP1x5PLpa09oxiAi6rtn2oESTLP4Yv57WrF5Ka0pBcQwaTCcTs8ODIhAIdmzEWbQmEpqC4ohvr7utZiCNW+Kp70F55vUw14kf55FXtmG/L/wvbv79K5H71jwoEZ4DWsTMmStRCkqeKRXUFcPJjKmmaApKpXGiaxSqLKgtXHBt02cunbAITLgt1GN88aTzSKcSIbmpPe77fhNBbXqreNTMG36e6nf2mnMFpaQIWQLppKfUKk6AuXJy+S/+aB0zaxCUugpKnS4eVyt8OsnKYTEUFIuglXVyIwRFIBDMWLjSJ6cChXGUeMYaXAY0VlD4/vhid9nPnsRoqYLP//Ip537NgC1bQQn225HV00Bdxw221z0ouXRSEQ3+3Lxx7/RW0mBb2i6OB0UtYJ5nKST8vLKMZKh8DmOxN7ctaSUefdEdLla0jBRzgXUFmUXNMHJtz+/B5gE2m4ayTJIePE/3oRD4Ue974Q1rn5kmPChUUtGD2+p4UEidSSas/YZKFbTfo66X/x5e7wxOkhUIBDs2zJCoqcJ40mDHk4MyzEyyrvIQ/2bLj8MzPRqdE+DyoASPt+d0oyNh1GgzpvIAXV8ulWCLZnRwG28lNSPn46hlVWeJx77v2VTSaqtVBMVzlztUiScZEhgiN1w9AWyVyznXRxvKF61UmL+7wtKIQLji7vm9zjuILBmXU04FJXh+Z0u6tj0nbI09KOlUQpE5UnvCxN7a69tkiSd4bo2gNDAAcwhBEQgEU4rpKvHwb5Bc1WgE3/eNEk/zBKVYrtYN+QrOy+0N6MjVtwiaC0FUkqwK2zIejy7xhApK1vGt3lRetrhKPI6skUagpyYiou5DZSehFuSwi8cuD7kVFHvR5f6T4DiNw+bqvaZWiUdTNcLHzGRVV9y9TlDC0hIdI/SgeLVzse9XZ+191KyCUmAKijLflkkFqRGjtO3jce2L72/OJskKBIK5g+kyyY61E6dc9bUsizgeFJMIuTwofOHg59iRTdfdt5X+GbHoKAXFWDhGIko8RMAyqQRy9K3eCG7j4AoRqRIUhhanxMODy+p5KrKppFV60HNQaos1J34qedWzykOmgmK+vq5F2JVSG5ZSGi/+AIu6r12rUqvKbtWEb8/LMHwfvIxHzyEFRSfC0e3gat+phArMo/cGnXPWkcbrusbgWOJBEQgEswTTkSILjN2DYn4jjKOgDBkEpZGCUoxQUFydk+a+fF83MRLxac+6Szyml4TCyLgHxVXiqTfDZzwlHi2oLWV7KlSJJ22rIKrNOBHGxuvlFF7i0b/9m++FKAUlmQiNrK7xBe0OpcL8nQ/t49ksACvxaOU0N8FVZC1NHhSd0JUrVfVadOZqBKVkE0nzGvjPGdbOXTTMyOHr23yJR3Xx1K9cahCCIhAIphTT12Y89QRl2Fpg6ntQ+Dl25EIFZdBRknLN9eEqivKgZJss8RgKSi7Nh9hF+3fMBRgYWxePCluLaDNWxCmVtEoPvM2YFm0t94PNrlE5KKQKNJiYzLtanImttecToayXg8L3x2cPAVDltIJWTnOXjwoRCgoRCU7OuhwKij2V2FZXMknbjNyMgkLHpveO2aI8o6cZCwSCHRu8/l0vU2mioZtkm/egWFOAHbNpomCWeNwKirvEQ6UKAOgbtiPw6bktbIIv96HQQqfmqUSUeGghoce5GTX0RVSs7VznbLYZl6t+02MFeImHFjFttgxTUMzSA29RDgfvuTwonqWgNJ6YHK2+VFkQGZXkzFEIliejZCzYVOJxmGTN9yldE1c5AFiEjZMcRZwcKgkRDT1JNizxmcpMVREUt0LGO57aa/cjVFDCTqtmIQRFIBBMKfiH2lS2HBciuiMawVxgqr5dw48Cj7kHojwoeomHyA//dto3WrS2o0WjlXX76IoDlXhCssBBix+VAEpqwa59g04lVIBY3tFmTAufnhxaI038nJrs2tJMssaCG1xPuKiaigE3YCoFhXe9cJNsROssEcKoEk8mabcwcwI1vz0DABgYNU23bgJE/x+kDJNsPUMykRc6blbN4tHPi46RSnjqtXApXa7BidzfYpqRGykomofKeH+IgiIQCGY8SprBcHoUlDgEpeBQKpodGNicgsIVpXCx5eRt+4itoKjzykQoKKrEQwTEUFCKehuqKnlQwmkyXNxci2Z3q/4NOdhW7+IBmvehKBXEizDJKsWHJck6OkQUqXIoO7yLR0WwV/RSmGmSpetLswW75Cil0NRiPjyRb6+uo/beoftM1+L2oLhHDJghfKbSQcfIphJORSk0M9vqSoFdb9gdZCgo1MVTpxvIVG7CWTxCUAQCwQxFhX2oxenyGC/MGSfNgj5027IpUIRDsz4U0yTrip83VaSwZh8+t2/EVlC4TK+CsxxdL+ZEWgJdA3kUyCTLF2RaiFyLZndLRjtffnxO5pr1oZRZFHqYBhvemzy7XjMtNsxB4QqKq8Rj56AQ2VAmV2vKc23blGeVlviCTHOU+gwyabch11dQtFBAi6CQcmO2GeuKUmiiTSri45rFEyoo9pcGbpI11aZcRImnwIZhmp1cPIivWQhBEQgEUwr9w3DqCMpYFZRQTg8XRpdB1QVLQYmQ+13P4bdm+7CDoKg00aSlCnDi06GC2twmWUVQLDMjK/FwX4ShoGgR6qwEQOuQi4RuHy7iQ997EL9Y85r6GzfJOqPumTcmLNPoAWIJTUHR5wcBepsxbUtEpc2hJvDnpXkuiCI34X57WgPCxhUU/jq0GCbYsuHJyDnIIN1ret/RY42i7ukY2VTCSdjUzKSsXaZzdfGUjfvcSEEJJk4ntb/JLB6BQDDjwT+Ap5Kg1PtmWg/ah66ju6QeGrWw1ico4WOuEk+JnVfYbWGXHlwlHt/31eJHQV5U4gn3645fV94V6g7RFJTQ+Jk2IuU5vvzfz+C+F7bgb/5jjfobT5J1xdXzoLbIacYJt4JSdJZ4aterTJ0hQeEmaO5BMSchc78GETb+Wrnaxuk9oLp4kmZQm0OtaqU0WL2LJ5xmrJe8SGHhJR6ti6d2/m1OD0qozpglHirTRJlkFXFK2gbbsnG9zUAIikAgmDIUy1VNtp/KVNnxthlnkolw8F6TCoqV7hrRNppOekyK1z/QgYgSTyVcDJJG6YEfJyzxsHJJqarC5zqNEk+JKyh1vtWT8lJkCzpvnXWRDMKT6/utv5U1guKaZmxH3VszYiIUlLJSOniJx1BQsmHujCubhnfxKJMsI4nzagoKf63qddOYAW/m61+p+mr/tG8qc5ldPJYHhU1+dpd4dA+KlhnD2oxNBcVlktUGJ1bC8zI7hMrKgyJdPAKBYAaiXsjXZEPr4okTV1/h3yht82Y9WBOGzd/ZQpIxygeNTLLKK5JirbNV3YMQEB/7WzLvDqEuHqUosAXZHdQWPN7dEua0hB1AtUU36VnlEA4+pZfQ0CTLwslMkuHyoLiUuqDEo5MfZZLNuQkKT6E1F2xOXua1kYISEhR6POGFBMhUUMyoezpv/hrRvhuVeGwPSsLpbTG7eIoOQpZxELKqrxMUfh18P5r6YhiZpYtHIBDMSJhtk9PmQYkxi0evq+vfchshTFa1yw58P1n+jdNQBQC7M0Q7L66gqAUq9C6YplAgNAnz4/IUUiBYkEMFhZObYFsqO/BzpkUonUg4VRDCsEPBqjAVxCwtBOdQ6+JJJRXJKBoLZyrhqTwRXQVhPhJDbVKG0XRS+WZchlJXizJ/b3STgsIya/hQP6VklIx7ZUbd1x4nMu95LGzNKPGYJlmziyeTTFjHBViJJ2un7vJ9q9JhTSlRCgozQZcjCErGej/XyJoQFIFAMBNhds+UyvbiNRnwfb/pEo8ZwlZkkvdYSzxtDikd0NtBTQNuhS3s/aMOBYXJ6eaiy7s4XESBFr/WTJjKStN/+YLsykEZNcy1/JxLvEyTcJd4+DduvlZVGMmgc+IlQF1BMcybvMTj8HJowwKN+6FakFPuxbzE77PZZuwo8QwWyjZRcHhBSoZp1JxmTPe5JZ1UBlsrqC1ZPwclm05Y+/V9Xx27JW2H+LlMsnTNVaPEA0QQlKRN5kNCJgRFIBDMQJjEYKpKPK40WBfuef4NHPDF/8V/P/l6uK3jA7tZ5Ud9O8/aiyagEwmT/DStoKSSSLJvusFxQmUm5VAjRtjil7IUhbBM4xpgR9u2ZVNsQB6VLRqXeF7bPqp+XtCeVT8TIUtoUfeOEg8jZGY5TAtq00yhYTnMjm+vPcZSaLV0X+YVUWqUob5kkgl0taSVAkOtxlyNML0gdL1kJrZmBNWUqhbHTCQqFVolHiNJNptKWhH6FTb80qWguFqy6ZrNWUv8PvLzCgzlevnI7FpqBkJQBALBlMHMD5mqEo+peETloHz43x7CQL6Mv/rRY9a2mmzdtIISPC9SQWFEwtw37+LZOhRtkk0nPatjxqXMlF0EJWN7X/gClXWUeOg1bHGQKlqwU4nwuGZZ609bhtTPnIRVGnpQmEk2pSsZfNCgS/UpMTKQtoLaws6jMCwtasHWr5f7k5IJT/l5yCjLvSJ0L11qU3B8nXSNstfIJIpEdOn+p0yCqgW16cSI3/OWekmypoJSDhUUnbg0KPGYHhTJQREIBDMR1oC6KSIopmckX6o2PSOGt11m6nSmuGCaEaO6eHh8e0F9sw/Pb6RYsUgVX/zMLh7ufajXEdOaSYWTgc2SB1dQHF08LoJSZuoLLX6mWvXyG8PqZ15a4K3CKcNgGTyX+UisNmOobV0KSr2oexchc5pkU3YKLS9pAMA8o9VYV1D0Eo/ZZmwSJ17iMYkiL+9p25olHo2g6NcLMOLsKPFkUwnN0FpiCkoyET7Gy3CuEo/ZaSU5KAKBYEZiugiKS/Go18kzvy0TbsvaeU3jXyOEZsQoD0pIJNQHurGAEbYMuiPU3SbZ0INgLsiArqBEzZfRPShcQQnLUq7WWKA2A6ZGbszXfO22sINHy1BhPhJX3kyJl4+MUgtPoXUpKHqJx2id5aZgR4lHb7vVy0M8Fh6AMspuNxQUzaxqkrkoBUWRyKR1TWYXj62gsBKPQYw4oQjTXu3cl3TSg+fp7eLcJ+R6XxU1QuZWUJIxWIcQFIFAMGUwSzzFKTLJqth3NiPG9INwcyzFlgNuybvZEo+loFhBbTUFJc1Msg4FBQDeGCpov7vMmxWHxO/yc5Aaw1WQsIsnLHnkHIP36HlaWUqpEeG2dM1mazlP1+UZKuFEYrsrhf+sl1rIJBs8J+G5FRSNZJieG5b74g55Y6U0o52Xx8IDoYJCJR5n5HxJL7WQKmOSTCJ2Oc2DoitkYYnH7OIJCar5GhLR87zQS1LkhMw4L+6N4fN06HGtzZi/N6z3c0gim4UQFIFAMGWYbgUllw4VA1PN4J0yGkFhXS3mh24jlE0PikFs6ntQDIIyqBMU/u09aZhG9VbRYL9VP9wn/3ZulnjC5FQ2LNAR8pVKepbPhCsoFAJmlnhM5YoW6gorH6SZIqCmO7PSU8q4XtVmzHJfOBnmRle7i6dad1u9A0hXUEyiEIa1lbTHs8lEaFY1TaNU4jFIpqagUImHPChmDkpEm3ngfXErKOkEL8OE7zWuKNE9o3uofEJMQeFx93VzUCo68WkGQlAEAsGUYbw5KL7v45FXtjln09SDa7qr6QdZz7pLeO2dL2BxTbJKQcnqi0R4XlyKd3fxEPnYYigoWptxbTFQCgrr4uCGRpcB0yzxaEmyKuTNV/vmwwTVvBW1bUgEiNyYpNQK6zOv1ws7gOjY/N8UW1jNYYEJL8xuifKR1OvEMbNo+H3hBDXMQdFn5YQlnhpBqYQKWVQ5jMiFIl1V/TVqzaRY67ROjOi9HHqQ9Ndf7x4K1KpQIfOs1nbzemkfQE1BYe9J04/D95Nh7w2LkImCIhAIZiJGzRyUmARlzbo+/L8bV+PSnz4Ra7t6AVKE1/pCgqJ9o2SBWq5yST3Qt8ZIBcVhkg1Dz4J/eztzABwEhV2TUlCMEg9PA+XnPeLIQVEEhS3mvJ00b5Qm+Ddwq1MjGXpQzNfcJCjmPJ1kIlzw+eOqHTgZLo4lVeJhbcYuDwp7DaMUI05AneWhFPfzuEs83WaJpxQu2Lybxvf1xZ7ODYgq8eidOJZJNqkTNhfxpb/zziOzvMeviZSm8H5VNRLpNMlWov8/M03BzUAIikAgmDLYJZ54HpQNfXkAepZGM3B9YNdTUFzfoFOJsSgowfNaIyblKqUjbS/29MG/uDMoN5klHj7ELiwP1L5hs4WTExTaJ+/EMVuU9VyQcFta8NU37JRnqz5M5WiNUFDMEo8iN6p8YHSPOLwxSvUxFJSk4UGh8pA28M/MQWH7ra8ocNWA7nO4X7qfdGztcUO546oD7bNZkyyfkEzHNYdFuhRDOq9C2X7f8OvlRBAIBxEWK2HnWyrpNskWXF8EjPZmSZIVCAQzEuMt8dC3v7xhNiWsWdeHG+/5kzUDxx1Xr++Dkx7+ga0PwNNNko1AH8oUiFWp+nqwFe/isRSUYNverhgKiiPhNJnwVGJrqKDUTLKZlOXJ4Z6bBCNl+dqCz0stYUmEFqHQCBnVZpyPCOvjXR7JhKdCz8LzChdO00SryA1rjfZ9tm05VEm4v4WfczqCgGolHsOzYUfOG/fSkYNSKFc11SGlvB5mmzG9RrpJlpNn2idXOfhxqfzHI/wbqYm8nZv/WypXw7h6pqA4Z/Ekk1Ynltm11AyEoAgEOyhKlSp+9YcN2DyYj73txv48zvjW7/GLNa/F2i5vqBaxCYqRlGniA//6AL76P8/iH/73Oe3vruAqUwXhA+yiJO/YCkpt2xbWPaTPPWHdNhHlkt7OFgDAlqHoNmOzoyKyy0MtfqTsJK1Yee65AaBm24wWK9o3/4xDcSgzchPVxUMJqeZ1cB+J59kTjfWJxPo5V7mCYpQ0gn2E29olHlbCc5V42IJtmnNNv0Z4L/VSi5kky42lYYlHV3a4ysUHIPL3XiapE6MwfC48rsfuSaFU1d43ppEV0H1E/BhB1D3UY6bZmO/HOc2YvUbNQgiKQLCDYtXTm/DJf38c19zxXOMnG7j3hTfw6Kvbcdsj62NtZyobcUs89GFntisTqJzw7Xte0v6uzyZxG1a3MuMtJyh8wY49zdjo4uHXoJ2Xg6CUlYISlHjqmWRDP4C+cNLikmHfgoFw4F9rJizxmIsubcPD2sxv/uaCzo2QUTkotgfF9pHw45drpQXiRlqQm9GSnaj5V2gNNH0zrhIP96DQe8OloLim+5pE0CRVUUFtXHWgbcwFn/uEeJIs7TPhhduYLcqcdAHQJhrrZSf7/Vw2tuU+Fa6QuRSUZgi3dPEIBIKGIE+DufA1A/rgjyIKUTCzPZpVIgiFBgQlw749c9Mrr7tHTSR2qSaAXuKJUlB+8sg6nHzdfdjQp3tjaNtcOqHKLPy4BRZ6FvWBvrhmkjU9KHxxNIO6bBOl3rnCZ/GQx8Dl9QjOPcxw4eoPVxzMJNl00kNLjZSZnpOoLh7bNBqeV4kpDilDQeGJwKmErRjwY2jqC5V42IJslqz4vUzz8pCjlGaeM3/c9D7x9xe9L8yZSGqkQCbcNs8UEO4tMU2yZsIt/csVmKhcH0sVYqVHOm3eZlyKbDMOt+OTkKWLRyAQNEQ4PyUeSQAYQYnwgkTBPFZ8D0rtwzuC2PAE2P96YoP62WmSLbsXSvNnLcgrgqBc+p9P4KkNA/i7nz+p/Z0WomQiodJkB/NhicM5zdjoWlnSFZR4zLh7Lb494V44VZaFEWzGk2TNkgdfkAGEGRylqqaApZOMCDgUlLDEE56z7/uKsJDCojwobBYPXRedM1/QeWmCp5vybTmpoucF98HOUOEljboelJQ9CZlnxujnTCUeNs2YdeJw0ut5epIsPZZnGTlcxTJ9L3zbsvUa6ipIsaKXeFw5KPxeBfsIy0AVTUHRy2z8uKaCwr+XCEERCAQNYRr54oA+PE1PSSPQh1mrY0hZM+Dftl3b8muhjh/+93oD/1ydO8E529+go877jxsGtN/5QkThb9zzo5V4TONnbdvOlpQiCTzuXldQdFUg7C5J1v7V9z3KygdRnThmeSBfqjCDbLCwRpWl0smE0yQbdNYEP3e1pLVtq5aCwkoL7H7rpTZfKzFQ9cAc+sdLHqZ/hV+vu4vH3rZxicdUUMLpvgVmNuUttxZRZKSa56Bw0mNvq3/poPcrH6Og5+foKgfAX0P7daCXQS/xuBUUFeLHrte85kYQgiIQ7KAIWyHj+UCA8Zd4QoIyNg9K1LG18km5Yv3sGp5GcMWq83PkbaiFCIIS1QqcSnpY1GG3C7tm8ZhqRCqRwIL22rasHMdTSk0Pim2S1csHoQEzZeVzmBI/n8djhXglQxWEZ3ukEh5aHR4UXt4hghI1TE4r8XDvS8KYD8MICm1rKihlRdgS1r3QhgU6c1DCbc1SWYE9xv91elAcXTzcj2GaZPlrmGMKCFdWzG3pXnDVh59XsVLVzomTHKUKlfXXmPtUNAWldsx/f2gd1tXmK7nUmSJTjMxrbgQhKALBDgo1Mn4qFZTaB1xLRpf3m4VOUOxtNVLC56loH8q2ERIIuzUA04MSfiin2TfRKHBPBPdVLOoIvCSbBzhBYbN4TA8KUysWOsgN79QwPSjmN2hzdg1PkiUvQ9UPtjclft5BYj6mSJUj26PF0cVD5Z1MMoFcRn8dohSUIjNnknITqiBGiYcIijHksKhIpufo4gmvyaWu8ZEC5n1UpbQGCooW1FaqOP0YZqcVJz88MG8gH6TUcnJhBvXRezljkIxi2SjxsIycMA1YJ0+8bKWl/db+fs/zb+B9316t7UM34Prae0NKPAKBoCFMOTgO1EyQuAoKlXjSgR+j3kLvAic0poJSrepehXxZLy0AdvR31L75z1zyjprF05ELu3S4ObfCSh6LXCWeOrN4+CJGCsoWh4LCW2dNk2TWWDgtAyZrYaV7wqPf6TlAcD/Nx0Jvg93h4wpq48QoY5TLiGgkDA9KueJbZSfuBeGEkDwoWSN5VR80aAS18deX3hu8FbxEia4Jy8hqdjxF5qCk9anCFaOMAvB5OlXtuJmUQVBqM6M4ueCETTuvlPE6cYJihPjR/4vmLB6e/cOD2jjR2NCfV9dG++a+l4qhgDWL2ATl3nvvxamnnoqlS5fC8zzcfvvt2uO+7+PKK6/EkiVL0NLSgpUrV+KFF17QnrNt2zacffbZ6OzsRHd3N84//3wMDQ3FPRWBQDAOjEtBKY7PJNsyTg8K4DC5GvviCkrJ9cFpKSi64mKmkKYc0e6u83pu42C4T6a+LOokghJR4okIakslIwiKq83YUlDc3SXc+2KmxZr+CB4SZqkr7H6Y2R4tjmGB3PvSKAqdR/AXjeNyIuD6dm4qKHqSrK5U8HJLPQUlmGuk+1csD4rRtqsUMqN8RI+7FJSqH5BtbjhNsrLWQM1knWWkhV5/c1uXSZaTl2QiJBquidR8HzzqPghqs+mDS52psPPxvElOkh0eHsYBBxyAG264wfn4Nddcg+uuuw433ngjHnzwQbS1teGEE05APh9+azj77LPx1FNPYdWqVfj1r3+Ne++9FxdeeGHcUxEIBOPAuLp41DdT3aTYCJYHJca2QP0SjxnexskTz8GI6uIxfSXmlN1UwrPMpvQ4V2Oe2xQSFF6mqVvicSoo4SK2sD3oTuIEhX9bTSpVwPY+AHaJh5eWuNmVG2FDk6xd4jH9CcWyno6aTiaUB6XIFAOVYJtOaqUDuo9AqIJwhcVUUNJscaTtEx5UR4ypoKjtU56lVLiGAbq8Trm0PS8pqp2XSixaycPZxcOMrnyoY7VqkR8iXaSgZJN824S2bVSJr1CuWuqaec31DLZVdt4uJURTZxjxJRUtjnoCAKnGT9Fx0kkn4aSTTnI+5vs+rr32Wlx++eU47bTTAAC33HILFi9ejNtvvx1nnXUWnnnmGdxxxx14+OGHceihhwIArr/+erz73e/G17/+dSxdutTab6FQQKEQ/o85MDAQ97QFAoGBYmUcBIWRgUK5ombNNAItCoqgxFRvOIkwI9QLFeN37kHhi5DjWzI3hxJKlSrSyYT2jZI+X/m25nms3coSadkHOpV4Nrm6eNJ6F48eTJao70FJJtSCHZkky0oTvBRGZYdsKoFiuaqVY2ifGU0l0YkC/2bOlYyEp6fnjhTL6MilQ3NuJloxom/YtHgXK8wXk9DVFSAkEFyNyDIFxffDb/CpRDgWgNQGviBnDXNt8HOooESFvEUN7dOi7tlkaFMR4tcW7N+3XsNsOonBQjks8ThMsnQfrVIcIyHm/KB00sNoibe3G6+xQ61KJjwMs/bxnbpb1HPo3HgJiohpHP8JMMEelJdffhkbN27EypUr1d+6urpwxBFHYPXqwESzevVqdHd3K3ICACtXrkQikcCDDz7o3O/VV1+Nrq4u9d+yZcsm8rQFgh0SYVbDWAhKhf3c/Pb0wUnyf1xyxEmH6UGpp6AQEeJpofy6K1UfviHm0LdgXvJwzeIZMab18g9uXragEs8bXEEphYsfJwKm8TMs8bjbjMNZPLYqQM+hv2uzXOjbeW1h5hktFODG71fY4aGnvfISTzD7JchIoURXKu2MagFxuuGYJ8UGxw8fNxdNviDT+y/BItSVWlGy4/lNpaLRsECuoNTr0gn2oUfHu7xPADBcsBdsrqaUmSoXvkbBv2SS5fvj25YYuXG+/sY5Z1JhubVa1Tux+D6KlSqqfkhQ/rQ5tGXQ/eaEjL9Go0pBiUc5JpSgbNy4EQCwePFi7e+LFy9Wj23cuBGLFi3SHk+lUujp6VHPMXHZZZehv79f/bdu3bqJPG2BYIeEOackDnSC0rwPRU33TddvM35u4yD+5j8ex8tbhrW/6yZZo8RjEC3Ng8K+NbrC1lzdROobJZUHEnrrJMFMRuW/8wFpi2qJsIOFsnqOq8RjRqGnEh4WdOgelHIlDL/i7a9KQYn4Zl+q+Np9oXtB/w4VQoKScigoZocHP2e6T7Toep7daswVlKyhoPBBdMF18TZjo2TBFrpRh4KiPChm6SnladuWK74W1JZN6edE1xbco1BBUV06Vtu1TmBcSbL8fqQdbcbBedmJsUQi+x0Kiq6+hCRUtRmz19AkVRlGqngqrLltqaynwZIxVrsfquSV1EqHdL3TqqBMFrLZLDo7O7X/BALB+GB+qMRBvo6SQfi/5zbjpH++D398rV/9zRyeF9Vm/J5/uR+/WLMBf/Wjx7S/c2JgHte8Dk1BccSZFzSFJVzE6Iu4K5/DnLUC2LNmuILCs0w6smHgGnXyaF0PWlutrqAsJAWlVuLh9y1QUPTzMttMeXoqXXeSDXxTBIUrKIYRtlCuhApKykFQqiGRI5hGWT5fxryXtDZaQW1a63PwtwQzjRZcJR6loOiKUdpUUJi/JcpAzctw5sThqBKPK8gtlQyVriGHguJ5oWG1zIylyoNSu6a+kVLt97CElmATq8tG2Qow2owrIYng++f3AghfRz2oLfx/4c1Lw3XY5bkBQp/MWD0oE0pQent7AQCbNm3S/r5p0yb1WG9vLzZv3qw9Xi6XsW3bNvUcgWA2Im5o2XRD5U/4iGV0BZor8Zx708N45vUBfOLWkGTQN7Rcun4Xz3DtA+2lN/TuvnpBbZbp1aGgaB6UiLbiFuPceNulS32pNwxPkZta2UMZZQdJCXEvjmZbJikow7W4e06oMimuoOjf7K3uEv4NmnkE6PWg0gOPYNcUFLW46eUfLQadEQCz1ZiXeMxgOiprmaWFUpkHm7G23Nrj9RWUivYeS9USULmXqMxKGubryxflXCqJjDG3yDTJ8qnCVVamUQs2KQp0n41UVbq+Qik8rhraWLsmF0EJ9hU8L1+qqHKl5UFxlHi4gdZsFefP42bnVMLDv5x9MN75poW167UJGf+XhlNOq4KyfPly9Pb24q677lJ/GxgYwIMPPoijjjoKAHDUUUehr68Pjz76qHrO3XffjWq1iiOOOGIiT0cgmDLc/ewmvOXzd+LfH1o73afSNLQFOqaKohGUBq3GQwVe8jC6eBqUl3i+CGCUeMySjqmglLiCYpMMl4mWE4XQz8E8Cg5yY5Z4RhwlHuocUVkoAwXNvGmad82W3bZMUou754bgFGsVpRKM6UHg5RTewUOgezJYWzh5PobmQYko8RRZfgr3GRDZG7VKPCntmzlPoU2YBKXC/S28JGIQFKcHRS8PeZ4e0a+VtJIJizTx95SmoFglHJ0IAgEZt30kNSIYoSjQNXEVLmNs2zcS+JBaDIJC7zFu2rbMzGWXByVUsooGmQv2wbqp2Gu06/w2XH7Kvtp9iNr3lCkoQ0NDWLNmDdasWQMgMMauWbMGa9euhed5uPjii/GlL30Jv/zlL/Hkk0/inHPOwdKlS3H66acDAPbZZx+ceOKJuOCCC/DQQw/h/vvvxyc+8QmcddZZzg4egWA2YM3aPpSrPh55Zft0n0rTaOTBqAdODhopR23Z8IPUajMu11du2rMGQeHSu6WgBI911kiNHlcelnhcJKPEvgmbLbn8WyP/Vk+gxYQ+e+nDmHfiEIGgePehQkkr46T5IEJDSqdFVXXyDBW0hcDz2FwUY1icShJlC7YrKp1ICJV4+Dd7jYSYJZ6kfc58EWpRCkpZuzdcQbGGyXn2whi+fvZ50fXwb+fheVWsFmV+vcMFvpjbSbL8vZ1NJSwPitmSzVWpUsW35uZQZD2ZkU3TKO2fG69Nk2zfaEn7PdxWJwP8uK42Y7sF3TY682sqVnibse4FKld9jXCbQX5EUJPJSSYojzzyCA466CAcdNBBAIBLLrkEBx10EK688koAwKWXXopPfvKTuPDCC3HYYYdhaGgId9xxB3K5nNrHj370I6xYsQLHHXcc3v3ud+OYY47Bd77znbinIhDMGNCCbXZ0NIN120ZwwS2P4JFXtk30adWFRlDGoaCY3TMmeAsyKQrNBrW1mwpKHWJEj3XWSEAwmE5fsAMPSjh4jcC/ZZtZJ7yLx5U0Sh++82s+EfoGyztxaPEIFzi9rTmd8rTzckWhq3k8gyFByar90kLh/iabZSUPbvokEIEZKtgppdyDohawhC7/F8p2DD4QElG6J/SatRpJsto8HUeCqelB4efobDN2eFDSjmviSkUqYXfxFAwiaL43ohZ7ICCxpsJC8f50n+0SD70OwTUlvPCas4bh2FRQiDRwRS9lvE5FZqDNGiSCe1C0GUGONnPlE2IlL9MXBYSvERHBuF08sXNQjj32WPU/vQue5+Gqq67CVVddFfmcnp4e3HrrrXEPLRDMWBQME2Ac/NeTr2PV05vQkUvh0N16JvrUIhE1vbcRfN+P1cXTxvIwzBKPS7nhny/1FBS7iyc4j66WNNZvH639rYpcOqn5SKhLxJV1YUZ0A9BKF/xbve/78DxPveYL2rN4Y7CgSGrZ8JEExw8XA64emcqOS42Y3xYQlG3DxTDnorYNN1fS/gG3gsI7hwjkbxhyeCOy2uKmKwbcs+E651ZjHo8KasskQ/JodC2FCoq9cGrR8LWf6f3H24z5t37TMMrvx3BBNwWrHJSKrqCQ8qGIYMVQDNjrkPACXxcnA2bYGilVpieD7h15VDKO14jAc2aCcyP1JZx3ZPqIOGkicuHKSNHvs172Alyvka/9v0nvi7ba/7/UGj2tJlmBYEcFLZZjUVDoA2WqTbZjVVBKFV+T5F05Kvw+tDGSQSbZlnR0DsoA6yRpz6b1c9bajN2m2M5cuE3YSk1JovpU2fCawm/ZioSUHSbZWueD74dkgK51QS3tNV8zOJo+EgDaN3De0skNmkEyrcP4qbImKo5v7hQg5g5qy7kUFO5BSeulB5faUChVw7ZpR3eIGZEenLP+rZ9/++f5Gq6Bf7SAlhnJ4N/ArfJBwkGqyiERTDvUlyHDFMwXa98PW7KJuPCIfd7J5fTGFEOzKr1vWjIGETQJSm3/5FFxqVwEyySboBIPvYZuwsZbgQEjbM9ZDqtdD/v/Talc7PXQSku17clDtr3mm5mTbcYCwUwHGUV5TbtZkPrSqFQy0RirgmImp7qI1VYWKMY/lGyTrK3GbhsuWn8jcFJhmnPpetqySeUHoXurCEgioXWeEHjyphlnzmVtfTx98Lgq8bRl1GOjJX14Xjjkzi7x0Dddvm+XqVCX6SvafpPKCxD4BPgAPMBQUFg4HEGVPBwmWeccF4f5sq6C4irxOLYNrsUkc/x6bCJA7wPXvSqwbA+XB8VUjPhrUKxU1b6JHIZJsbqhlKtRaYP8AOH9z6X1xziZ49uOFhsrKCZBodea3o/csMsJW6HiJre8SyvlUlA4QfF0EgnoHWBkdCYFtH/EXdJqBCEoAsEEIF/SJeyxbDuWRNfxoJFJdt22ETz0su2LMc2pLoLCSQapAb7v2yZZx3H5tubj9WfxUHeKPjkWgCZdm50afL98wiuRFr448m+ltM1I7bjdrRmVoTJSLFvR77QPui76Zq8WR7ZYEdFNcsWAh62ZCkoiVFBcXoAcux/OEk9aX7C1cgjzxoQqielBCYkAX4TCQYOGgqLloNQv8USVaRRBoSRZR9S9Zux1lHhGCnpgGr8nxbJN5pQZuepr/x/oxKmmgjCCYrYKRyooKielom0H2KZYy4NimGSdJNPZxRP+v+hSqsxuKSAkkfx59J7l95AUFDL2JqczSVYg2FFBC8ZYPCj0AWvmeEw2GpV4Trvhfpz57dWWedckBma7L6CTDHo+X7DrmWS3D9tx7gC0mn+wX3cXTzaZ0Abc8eOkU/pUWYJrYJzZ/pqqBZuZ83joG2tbNqm11VaYiuE5fBWmeZMHeVFuRKQqYMxacQV88W2y7H6Yra/8Z1d3iUtBoXOm6y2zBZtva+aKqDbjdLSCombxsFKbq3wUZmzYbcau9mdX2UIRMsPUSdvmDTLnGoDHJwLz4ww5FAVlko3yoCiSUdaOC9iKSUtGX76VSbZkkxtNfSvrj3MFRQ3V1BQhu305DNNjCopD9aESLbVGiwdFIJgGmN8QY21bniYFRSvxRJdabn1wrfZ3s7TiLPFoBCV4nJc8WtUsnvolHk5gysa8nKgunmw6YSkoZbagu+LquZmRdyZwUpUykjVpG1pMWjMpdV0jxbCrRV+8QqXDle0RllpsX4VGbiK6R8rVqtYCHSoDXEFxlXgMBcVBXgqOacbcqDmQr0+qABbUxoYFBp4muzzEiaKZJ8Mfzzs8KPRYwUGqgvOyg+kAPaG2WAkVFCIH3HOhFuSIMg3dS5cZ2eX1CX4n9UVvTw7OQX+uWfIxW5SjjK5W2ivr4jGHMvLnjRZtkyxvcR92GHupC48+D9JS4hEIph6kEgwXy3W73NzbTr1JtsKGggH1TbKPrtWzXczzdCXJbhsusMdrKgYzhVJtulL1rf1tG3ETFCvKPmIWTzaVjFZQkm4FJQw2YwMBm0jWBHTjJ09ODZUXWy4vshJPRiun0GJQ0Y5pHtdMME06SjzpJPvmzhUUVQqzFz/lQYnwvpjdNBmmKA26MlSSOlGkf3OGgsIDwMx7VapGeVBqXTwOQ3HGSars+zzk8twoz4VdDtMUAweJ4L8PORZsUj3INGp14hiLfT0FJWdtW6fEk7TfO1mD3EYZnc12bs9zv06u6+2o/X9O6bfdLaFPqxkIQREIJgD0wev78ab78m2nUkExF/t6JtlXt45oj1slngYKiqliAEB3a1r5NfgEXcAo8VSiSVRU1H0wOdbwoJRDfwRfcIlMuks8vt5pY3hF6MOcyERrhhOUspafQnCVeFxli2HHeHp9W31xpGNUqvYkWyBKQbEfdy3Y3INilqU8z1Oq0aBqJWXbGlNuC6z8oE3JJSOy57jeCPOm2cWje1B4WcpedMMclDpE0KGg8NcjVCqiVBAiGSGRINWDvhuYbfR0jq5yidVmHGGSpf8v+LZ1pxmzvBlSqjKO9+yoKuFFdB45fDNmjtG8Nr0rrxGEoAgEEwBumItrlFUm2Sns4jFNsSY5MlWgJ9b3q5/NLh6Xd2bbkMODUjum5wUfevTtiqazErZqHhS7DKP2a3bxsIXXVlDCEg8tGL7vmjqbCOfWVNzD06IUlNZsiiWnVrQZL2ofrMTj/mavt+WmXIsua51VBIUlepoD7ABDQakT1GaaYPl+CjzIy9FK7FZQ9HKYCglLG7OHHMF0epKsTbrsqHv1UMT8IJt01e1achiKPS9sB6frzaZMgkKKgk0UTMWkLWMQFMpBKdrbNt9m3KRJljwoDVrFaT+u14jvJyzxhOdlErDuVlFQBIIpR14jKPFKNdNhkm2koJjekDXr+tTPzZV4mIJCHhRj2i0lvlKIE2G75kGpp6BElXhsBcVV4gF4GJutoPDoby5rh9+wa74jap1lJZ7RYsWdyskWbFfmRDi7hBQUu6RRrLBWUaN9uVx1DwPkXS3mN2i6ZxyuJFl9cbNbiQcdYVy81AJAOzfX9GZXmaZU8Z3DAsPSg915oi3IdYLaXN00/L2TNxQUfr1UtjBLPIqg5B0qiEEq+BgIgCkoLvXFNMlaXTwGuXG9ho7wOM3rQ6qf43UgcJWLX6/TJGsqKK2ioAgEUw6uQAyPVUGZyhJPnfZd1+MjrGXSJigNTLJl3SRLH6QUqDZgKChRHpR6wwD54xkWxhZMdtVzQfgHNy2cPCGVEwFFIlwko6Zi0L1pzSRVAB1XUNxlGrfSYZpkXQsyJwpppaBwZcYmPrqCEt1mTHApKEBIxvg37BZTQXF18ZCCwl4jPhmYTLL8XtF+eJmGm3fDWTxU4gnPn/uMnETQIBHNKihAaPDuG3UbP01FwdUtRTAVhrSpoDiUKkKjqHueUaK8QKxV3Bzop6lNKfteEezOI6OkxZ7fmRMFRSCYdoxHQZmJHhTzcX5uZinKdd59I7oKUqmGfg76IO1SCopO6HjJp14rdFTUfTal56BwFSaVTFidGnzfeg5K1SJVgF224Nke9I14pFhGxelBCVtnlQfF2THh6OJx+QhIQWElHtMESfeE7oe7i8etApiPuUoiLRmdoCRdfo5yLZmVHZsWTV7iSXiOe8W+2acdZM85i4fnoDjKQyrqvhhdliqUK04Fha63P0pBqRGDIYeiYJV4LA+Kp52X7kHRj2OWfMwWZRfp0rJZLA8Kn0jN33c6IYks8TjKUmYS9DwhKALB1INngYzETJOlD9hKNTSpTTYaKSZmuYn/3kybsWl8LZTtqbKdLW4PCr9//Lysc4xqMzY8KJx8qdk0xsBAPerelrydRMHI9gjajMMSj/PDnrcDuxZOwyTbSEFxpYG6TLJ6F0/oAwmPaxou3d+gXUFuoYISvI5ph2/GJIpmO7crhZbuM/fruLwRyoPSMLvFJjCkVMVTUGoEZdQerBhcg+HJ4K+DcZ+jTLIjzjbjcFvPc5FKXX1xdTwNOsLjXIqhq4uHYIatmQqKlHgEghmEspGEGbfEo8e3TxNBifE7ERL6cHUSlIJ+D/IluxMjqsTDv+W52oxpgTCJklbi0RSUcB+qPdYoPYRGyrDLJypiPWspKHaJZ7hhm3Hoq9C7LfThelGeDDpfWqRas1RaKkeUjuonyZrfxvlizmP4XQpKq6mgJOzjci8IHTtUKtwmWW1uUR3zLqkcmkmWGTvp/enOm3HMrWHvjXxJv89ASMjIg2J38RglHof6Qmg1fidyN9wgqK0lnVThfwR6n9ULauMIxxW41CabKBKMy7WuV+viEZOsQDC9MEnFWLt4AFsVmCxYHpQYJR4KbOqufRtylVrs7XlXCykotknW932N4LlMskRsShVdceKx5FlNQQn24XnhAsgH4PF9ByWeUI2oF1xVKFdQrfrq+lsy3CQbRt3zRTXlKPHUVVAc7Z4u42c7C75zx9WHJSD6hu0KagvP0ygnGIsQvx+UxzGQr7PYl6vae5u3GZcq4bBA/uVcNxRTiYd/s695LlwlHka4qJvGFT4Xts7aj2kKisskW/Og2DkonnbcenH1donHWOwdnVjBz/rrFVyDqaBEG115Ro6eUGy/J6MUIvucXSUeUVAEgmmFqSDE8aD4vh5UNhYfitkF0wwsD0pZ79oxz8M1pE8RFEPJGGLlHaV2sEm49MGpPChMQcmXqtqkZB4oR4tFT1tGfRi/MRQGwhWYqpBzKCjphD1+njpxOFkgbwT3oLhIRLFc1VquWzNJvc3YRW4cJZ76HhR7odAm0taez7tBKAQsqjxA97ueedNclMLwMXsRajVKPC7Vh3eP0OLI72PVqTaxNmNj+GHwc7g9oPtX9LlGdvhcVHmEP1aMyIxpVe3xjdqMa/eZE4sGJR46D/p/IOo1NA2yQEhmRx0lHpqmTOD3p81Fqh2qH8H2oET7ZpIJT1OJ6P/5ZiEERSAYJ8zFPI4HJYj5jt5XI/z22c3Y/wv/i+vueiHWdqZiYppkzfNwlXjow8Y0zdI3+LZMUnU8cCWDvnGRw39gNCQ0rvIYnRsv8ew8rwUA8MqWkfCcWUBV1uFBcS1CTg+KI+qefyjTQlEoVzUymkuxoLZS/S6eYsUPh9i5ungcOShpx8JJZCrF2qe3D5N5022CJUKbrfON3AzjMksifAEjUkbn5E5lDVU1cxJy1Q+35YcNg9pCpUzzoBjEQFeqwoRbV1nKUowc/pWgzTh4HbQ2Y1XicSsoaUNR4F0tZvqrqaCYi7+2rdZybC/ddG+INLs6nly/c1LtGqxozhoyz9Eq8UR0KnXmUpYy1whCUASCccJUUOJ4UGwfRbwSz6U/fQIA8I+rno+1XSOTrKtEQ6CSBsVWm9dPXoT2XEotbPlSxcpYcJV4XJ4AM+Qrk0pg1/ltAIBXtw5b5xypoDg+sAsG+cmk9CTZcGF0kxs1WyadRCLhqeAtPiyQfyjzEo8azOZQZ5weFM2TYftMaCFQCgo750QibK/uVwpKnS6eiAVNLX7cJGssuq5Si0v1aWUhZS71RZv8XLEVFFPlSRieDDNyXiOCpufG0VYbqaAYOShRHhRnDkojk6xRPuGlpXqEEggVoorjfVWPoLRlw9b4ksNzFfweTVCsEo+xLU00ntcWz38CCEERzEG8MVho/KQJxHhKPFaWR8w0WbMDplk0MsXaXTxV6zEiGOY10ILQnk2pb3o8jyJVp8RDH3JdbGaHiklnC9zyBQFBeZkRFLWYpHUPCuWVRMW3A3rSrDaLxwiXC/Yf7nukFBpkAf5ttOwu4bASjzNALBVub22bCrstio5vurTQUEieuSjRIjvgKE1YC7aloBhmTq3E426V5dfram/mfh86J1cwnT7ELlpBsdQH6tRxtd2aC7CrRbniVlBaiIQ6zKjB73oLe9ahVgCBWmQqIVGZKtZ+nCWeaBJiqiAZB+EaLpSdhDw4L7YvkwgaJR4r66XmGYtrkAWEoAjmGP7jobU47Mu/wU8eWTdlxzRNonFMss1kitRDvSF/dberGC26MUyyRDSoTXi0FoZGCBWUtPpg56UW0yTLSRbdu/ZsUlug+DllkgnsOr8VAPAqL/GwxykzosDSYKOSNfm/PAclKuGUd8TwDBQA7mGBjrJEqeIr349rRsyIU0GpeWPK9sC34J7pCor5LZi+jdPC6spJUedZZ7EDdMJGA/Bcj/FyScFQUICQVA0oBcU+B54kqysdDfI5DN9M2qHsEJzR/g0UFPMazPM29wfohKQtm7I7cepsy2P2TdXKvIbgPKJ/17uw7Anc1jVwgmIqKGZbtfFeoZEWcQ2ygBAUwRzDsxsHAQDPvD4wZcc01YY4HpR6eSMTge/e9xI+cetjltJimmJLpqJSx5NCH2KkgHAPARCaAzu1Ek9VS3MNHreD2pR/JZvSPAiAXobZrVbieUVTUKjjIqEWYz7N1rkIUZIs809oAWH1/CvliirFUGlHN8na2R70c9SMGL44mtumuYLSVInHraCo39m3cPObvNXFU8dU2pKJ9lHwNmM+zJFA943eA/zbOR9w5wpqaxTBbia6pusQMtfAxmK5ftQ9wTR+RpXHAF35MOfwAC7lSt8XnYd5/oDtG6pHMlwm2UD1s0tp5jVYHhTmJTL3DYTvy7ghbYAQFMEcA32wu7I5Ju2YhgoSy4NiTQYemyIShS/91zP49ROv45Tr79O7hRq0GdM10Wc+bxGlhZUIBhB6JoCw9h6UeEhtsNuMeYmHFJgRtuCbWSW6B6WmoGwdUdu6gtoK5WpEiUcnAtxIyxfGepNw3QpK6EGpZ5LVg9qiu0sSjvJQVCQ5dfKEJllzcYsmHeaisvvCNu13c1+uqHu137S92ANujwKdM5X53PcqTMd1BbUR7BKPQVAiyiXm77yN3JUZY6oX3YYyUK88xomOOYcHqK+gBNvXUVAM/4qt5Lg9R9SVVPX5bKLofVkEJUK5IlBYm3mfmoEQFMGcAn2QjcaMmx8PJtSDEkNB4Z035geuiXXbRvFfT7yufm8YdV/7neRZLXK+tmi3pJNqsRlh1zHgIiiszVgFtdVKRDybI1RQklYbKScgO89rRTLhYbRUwebBghajzoPa9C4evggltX2WHCWeUtl3Dk/LsmviIW38Xx5178qjKEXMzLGIgLMDKCw9pLXFXvegWCUe41u3WT7geNteC4xto7+Nm4rCgvascztX260q8TgICle81HTniDIFoJM5wDbJZhyvA6GHfbvnBDRM3Y1WUCyCUodkuEpyHGaZxiYoNa+To4unnn/FPHaUqhMaf6PLQ1FdPFHnvMfCdgDA3os7rHNuBPsOCQSzGLSwjk6lgmIFtcUhKG7lohlwM7DrG1W1qpdxNg3m1c/NJsd25NIYyJcND0rYFdOSSaI4WsVo0S7TtOdSSk3KlyvIIThH+kBrSSeRSngoV30M5Etoy6bCwXvZlNa1ws8pm0oik0pgp+4WrN02gle2DGuLRDaVZNHu3IPiKtPY/hZOBCqOsDVe4qHXWplk06xls0IKSviBTYSjFDUjxiARSUeAWKnia+dLoAXP5TEB6isoHLvNb9U6bACXgsJKPIaCsqgjJCj8/Mib5DpnIrVRWSbNpKM2bI2uc595hwnvxKIvDPzemfemu0UvXZglnqxBBHPpBPKlquVdAXT/DmCTDOoCcga11em8AfT7ZZZs6JzIC1RPfYkaFkgw7+2Fb98dx75pId40BoIiCopgTqFY+0AZneBSST3kjQVhuBCnxBPdLdMImwZCwuEiNua+uKpEC1xOtYGaQW3Bc6lF0OVBySQ9zRRKoBJPRy6tKxmGGuF5XthqXOviGFYlnqRWagnOUS9r9NQWlf7RknZ+QYknNIQWHWZU7jPg1x/koDhKPFoXj8skG9wnWnQKZfcwQKXORJR4mlFQeHy7y3BqPj+8L8m6vxPesfdC62/1TLQmOV7UkVM/88GMg462W3r/kIISpZCMOnJhmm0zJp5er8QznxGU1mzY1ZJn6cTmORO6YigoQEguXATFKlMZRESVeOokyarzqKN6ma+n8gKp18Hc1vZRqeM0uN5kwsM+SzothasZCEERzCkoD8o0lHhowYyloIzDJLtpIFRQzE4afl6EYW0Inz5Pp2gc14yV5+dVZIt2i4ug1AhaB28zLrlTWbuMTp5hzSSrt2uaqkELIyF0rTREjXtB6ga1lXWTLG99DVqjo7fNlypKOaLwLr54UbaHKym2VPHrRt0TolpDXamd5oJntRmbCorx+5mH7oyd57Xgb1buDROuqHSCpaB0ZrXf6fUigsIXR7OLh5OMZMJTYWthiad5D0q9czavnSsonHS7FRSjxGOYZM3uIpNI0f1ylXgalmnSdRSUGMRhl55W7TEiZfT/oV3iib7v9TJWxgsp8QjmFJQHZQwlnu3DRfz0sfU47cCdsLAj23iDGogUzWvN4PX+/JS1GW9mJRsgKGfwb7PmPRhxzLhpz6awZaiozbwBeInH9qDwBFQ+vZdAC3MQ1FZTUMoVtFQo9TT88ONtyAAjKJmwi8eVgxJsG5KfcA5PEGff6sgjiZpYG9yP8Dkt7JpKzjbjsDxkmmSD4wO+H6pCKce3zwozfsb1oAT3yS55tBumS+ubu6Wg6I9/7Yz9Adh+FNdzXcMC6Xx7jG6NbDqJ4WIl9KA4fBjhoEF7YSywkQL11Ca7hBWt+piPaQpKJiRNJea3IrQYuS9mvkdUe3d4nqSgjMUk23yJp17n1b5LOrXHSEEhD0o9k+xei9r141rR9xNHUERBEcwp0Id+3IF9APD/3fYHfOm/nsFHbn441nYkA89vnwAFJUZpamO/TlBMQmIn3NolnjaHCRYIyQCVYArlqlJoysz8SSFdIxpBCU2yWc0LYpdLTKKgSjy8zbhitxkDISngCgotPLoXxJWDEpZpgmPQvkNyM1qqoOKIWHfloNA2nudZs2miwsXUzJQ67a9JreQR/uxKKW3P1i81mKqBuZB4nuckJ+ZxzH3zxXJhR9Y2qxoKil7iobk2ttrkOkf9m7z+XLONtd625vW4PCibmULJ1SlTQaGRDa7juM6DiIOrxBPloyG0qBKPvXTXUz0A/Zr3XaoTFP7/kmtffNu37NRV9ziNDPtxIAqKYE6BZPOxtOve/exmAMAf1vfH2i5ftks81arfVM3VNQm4WfASD2ATFEtBYd6YgkFQombxdLAP32KlimwqqXWf8ORUgirx5FLqW3u+VHGXS1jSKMBLPHU8KLVt+L7DvIrgMVpEeNhW1MA//m8mmWTkpsySZO3yAM9B4YtWSyaF4WLFqQpoQ+wo4bROtgdfsDwviKuPykExv5HPN6LFc0abaRQZccFWI8Jt+bXzDh4CnWNY4rFVH3rPmD6SeuFj5sJvKhl1SzzGY7xMQ+WOLbVBlFnW2QXo19uetefLWCZZg0zQ/zPOHJQGCsqZhy5D30gJx+2z2Nq2UZvx1qGi+nmvxboKYp5LvfLZW3bqNJ5bv7Q2HghBEcwpjKfEM1aQ6sG/wY2WKs5vSCZMlSMOsTLD18zWajvh1lZQlAclos2Y18mL5YCg8NJEq/HNCzAICjOUhl0t9oJMnpjQJBt28YQkQjeG5riCorwCtgHRZcA0PSjhvJ5QQcmXQnLDFyE156dUVe3VPKxMGT8dHhT+s3PqrOVBsRcs/lq5OmIIlBWj9s0Wys6YU2XrKSi8rEit49pxqd3XoaA0GpZnLpQu9Y1gekHqtUabSkXKQUCInHYYCgm/XlepxfSgZI1roPePU0ExtjVJ5nH7LHaSE9e2JnF4YfNQeE4G4TRVIXNfr20fVT8vX6CTG/M1ct2TsUJKPII5hfHkoJgfjs2CFsfu1rQKNms2rK1gdfE0f94mqbDJTrQHxSQgVomnFLYZh+dmh5q5TLJhiSfN2n0rrDQUXeIZ0XJQIkyyRFBSjEiQgpLSvSBASORcLarmvgPSxYfY2TNxsiwEbtTIQeE/hx6U8LjJhKfOa8RR4mnUOltPxjcXPBqoSOALxwE76zJ9I5iLveYjSumKggm6JiJseoqp/nxTdbQISp0cFDOPpF64nBfRzuw6J/O+8veHq5xhKhlW5kqNdCxot5NV+bZdLWn13GZgHTeGF6RRB9hzmwbVz1HDAgljibSPghAUwZxCgSkoZldLI5iLQbMgItCSTir/QbMEKV9n5k0jmJ03VonHOAfdgxJ6PYDooLZsKpzuS+fGp/DWazPWTLKsi8fVKkoEgdSX1gz3oOglnnAeSUh+wqFuwd+4FyTsTLCVCiI2vHyUS4fkRvlIIrp4TA8K/9mloHiep7IuaFtXPguhUWdKVPBXRy5lLRT8uQftMg9xYBku2WLISQUntOY5uzwo5sJoeVDqKDc2QWm+xMNhlsZMNcEkXVGdVeo41muk7++S4/fG3757BU54c6+9LTvH5QvaYpXhLAXFOI93rVgEAPjIMcutbc1WcfNe0TWbRmTAVozGEmkfBSnxCOYU9Km71VhyYyrhYSxzkPlAsdZs4D8YbnIeDy2sHdkUBgvlmAQlOucECJWdlnQSo6WK5kGhcourSyf4PSynZGtlBdXxwsoeYTtvsO9CuRKm0Ob4NGMWde9QMui6R5hJVnlQHGFqgOFBUXN4bC+IIigpV2mJVCFf/d3zPLSkkxgpVlSAmJaD4hoWqCWN6p0pLum9WAlVNte+CXFaR/liv9t8e3Hj/y8cPA6Ckkx4kf4qp4JSO2cin3qbsWEK9ppXjKwSTwMFxbx3BDN4zSRN9Uq1LpWikSdjj4XtKl3VBCc/uy9ocz4nCo1Msv945gG4/8Wt+LN97RJRm1niMdSYfz3nEFz938/iG2ce4DguV6bilw/rQRQUwZwCVxXilnlMqbJZFNS396TW3trctka3TAzvjFniMbuH6PpVd1GJKyjBtku6ckh4wPaREu55/o3wvBjp4qZQftx00tO6ZYBwUQYCqdwVde8yK9I+NZNsUn8sqotHN8naSkbYIeIgGaUgLbZS1TNarAAxZ5sxGxbIFjE6r3CuifubravEE1dBiTLJmjkXQBiBDwAHLItX4uHHOWy3aHJjdrQAIWkccky7NRf/OCUekxyYQ/vqRftzmKSKlweBcNyDC5z0Rp1XHNMov97lMQlKoxJPd2sGJ++/xHk+Jkkz7/u7VizGqkvegf137raPa+QajbVU7oIQFMGcAl+0R2IaZaMk4EZQaZPpUFEYbrrEEzyvi7XzNgtasOnzwPKg1B4nox2fskzbLu7M4dyjA8n3itv/aHe18BJPyWjJTdo5KHSMlnRSRWjTdZaaajO2c1BI3TBzUGjh423GOUdKaf+ovTCqa6pUNTKpIuvNMg0vDzEPCp1vi6PEQzCNrnT9oe8lusQTp+2WL7SuHB9uqjYXpEZY0duJZMLD4ct78O0PHmo9ftJbepFMeDjr8F2sx+iciQS6phkT6plXAb201EgxaHQv1TkYKo7nedp51VNQXKrMHgvbVXmtLZOMlanEz3H3CJUlclt2PxKebZKuB/MexPks5M+dyPIOMEkEZXBwEBdffDF23XVXtLS04Oijj8bDD4fZEr7v48orr8SSJUvQ0tKClStX4oUXXpiMUxHsYOClitgKCvvwq1Sb96/wGTFtasFuTkGhhTUkKM2fMy3YtK2Vg1LU2595maag1IwELjl+b3RkU1i7bQTP18xwRU1BSartK1Vfiw43PSh0DvT3rKPNWPsWzAhKuRKOt+clnjCOXi/xkHqTL1WZB4WXeHQVxJUkWmA+kmTCU4sa5buQIqSTiGC/vh8u+i4PCsFOB40mHVZMeJ1v456nL2i8zOQyYH7sHbtj+YI2fPU9+1mPNcIBy7rx2BV/hh9feKQV7Q4AN3zgYDzx+eOxtLvFeqze5GBTvbAzVPRFl2/rmjCtb9tcicdFQLRWYocqFHUMIMhUuf9z78LP/+po3PmptzvLXlFITZCCsuei9qa6CAktDcpc9cDv61gmFtfDpBCUj3zkI1i1ahV+8IMf4Mknn8Txxx+PlStX4rXXXgMAXHPNNbjuuutw44034sEHH0RbWxtOOOEE5PP5BnsWCKJRrlTBeYWpKDQClyab7cIBoEWW0+jyZj0oYSCaPfOm4XFrzyVzoEnIiCz0tIXf4Og5XCFpz6ZUUBURpAIjXdxQys20qaSnPthIrSI1Iky8DNWGMOreJiiFclVTvFozbJpx7Zik4JhJsqOlijpfVyT5gMMky8tHoTE3qXwbJrnhH/78GERgWlm6qKlOWK2zdbpL7Hk50YtsJqlnmfCfF3fmYGLPRR347aePdaoczaCrJR1p2kwkvMhFzWr35SpXQw9K+NyOXDrS++I6drMR7GYbsbm/eiWeqC6b1kwKB+0yDzvPa17FAMIyGADstiDetpz4u0ox9cA9KJlkItIj4wJ/jWa8gjI6Ooqf/vSnuOaaa/D2t78de+65J77whS9gzz33xLe+9S34vo9rr70Wl19+OU477TTsv//+uOWWW7BhwwbcfvvtE306gh0I1nC8mASFd/0M5ZsnKGEKaUJ1jsT2oNS6H+LkoKh5OVEKSu33zpZwrg0RL2WCrX24mGZVTmC454ITFC0HpbZfM7hMHxboGLzHunhI8aFvylTfL5kKCnlQlL/FTpINHq+pIAVSQXiZJvSgkO+Ff9O1OnHqeB+A+iUes0xRr3XYXETfttcC7fd6agsAfPDIXfCWnTpxyv5LrcemC812HgH1c1BcRIJg3nPzOOa+AOCvj9sLXS1pfO7EfaxtuRrlIj9f+Yv9sPfidvzdyfa248FurCwTtwzHy1/7x2wj58d6U29HLN8M/39johWUCe/iKZfLqFQqyOV0Bt/S0oLf/e53ePnll7Fx40asXLlSPdbV1YUjjjgCq1evxllnnWXts1AooFAI+ysGBgYm+rQFcwCNuloagbf8DsWYSMy9BPSNsNm4e1IsOsdQ4lEKSguRG7eC0pJOojWTQv9oSZ0X71oBwoVPxcozMsBLLXxmj54kW9H+pQUjx6Pu60zvLZarmtGVUlODc9JJU1YpKKEHpZ6CEp6v25xLapcrzpzOyWwVzqYSGiHWk2RjduIYOSmENy/txJIuvWRSLxYfAL50evzyzWSjHkHJphJIJjxVUq1HUDodLcwEVyorP24q4Vnvh0v+bG9cfNxeTlWGezJcJZoPHLELPnDE2JSoeth1fhtuv+itsXwrBE4U9tspLkEJr9dMim2EzGxSUDo6OnDUUUfh7//+77FhwwZUKhX88Ic/xOrVq/H6669j48aNAIDFi/VWp8WLF6vHTFx99dXo6upS/y1btmyiT1swB2B2tcRVUPgCPxihoGwfLuKBl7Zqags3jbbFNMnSOaupwTEUFPKRKA9KRJJsLh16Y0aUgqIv9qbfo6AUiYTWVkskI5nwkEx4Vu6LIkWGghKoL9FtxsVK1UqDDcswxiyeZFJ7XpQHxSYo9nELpQobUKi3KHM0GsSmtRkbre2Np+y6P4bPPmJX6298MVg0hkVsOlCvxMMHOwKue8UzVuooKI7Be/w4K/dZ7IwciCoZcUUhjodkInDgsm7s5PDyNAL3ze2zJB7J4ITszUvjkRtOwCcypA2YJA/KD37wA/i+j5122gnZbBbXXXcd3v/+9yORGNvhLrvsMvT396v/1q1bN8FnLJgLMBWUOB4U3/edce0mTrn+dzjrOw/gjj+GZJqrEUpBaVKBIULSVfOgNHvOvh9OwyWCYnYt8QA5IgykFnDfDJ074DCkGiUe+jt9KNEHuTLJGrkgnESUGLkh8KA2sxMnXeecgn2HHpR6JlmCM6iNdeJoCkq6vgrC81Zy6YS20JnSvLkw2p0q+u9f/ou34IK3LceZh+4ME3zBXtJl+0xmIiwvSDI6CM1KKWVrRr18DZeCwvG+w+N9qdUUlDrEaCZh3yWdOP3Apbj0xDfFjpvnE5rNYYCNwFW9rglWUCblzu+xxx645557MDw8jIGBASxZsgTve9/7sPvuu6O3N0jP27RpE5YsWaK22bRpEw488EDn/rLZLLLZ2fFtQTB9MD0ocaYKFytV8ODZKA/Ka33BTIpVz2zCSfst0Y6bTiaUWTKugkJG12bPmZdaiKDkI3JQcumEWnxNBUW17ColQzfJZpLuEo/qpDGUmREV/Z5SxzbPR++mCdUZM8uEJ8nyrJKMUeLhOSj827qpoERF3btKPFaZxpyvoh0nelYLAOvbcKNpty7lxPXc3tlCUAxCYhIWTlDMwLBmSzwuDwovN7x9r4XNnWwNfMGO09EynUgkPFx71kFj2pb/f7qityPWtnqJZ4Z7UDja2trQ1taG7du3484778Q111yD5cuXo7e3F3fddZciJAMDA3jwwQfx8Y9/fDJPRzDHYfo34nhQTHPqUKEU8cwA3NlfYmoEffNqts1YKSitodHV9/2GEde8nBXZZsxKJmY7sElQzMh51cWTTmpqg/KRUDuuMSxwJKLEA4RmVS0HhXXTKKMrlXhSIUHh6phtko0q8ZhlGnercN9oEGDWVsfomjbUX02pMb6tmpkSZmhasyUeF/hzZ4uCYk7zNUs+H3nbcvz44XV4y05dVodRsyUeF4k4eo/5uOq0N+PgXebFDg9r5EGZa1i+oA0fP3YPLO1uia2+pCYxB2VS7vydd94J3/fxpje9CS+++CI+85nPYMWKFfjLv/xLeJ6Hiy++GF/60pew1157Yfny5bjiiiuwdOlSnH766ZNxOoIdBJZJNkaJx0xwdXlQuO+kzUFQsqn4QW1Fw0cCNBfRz681iqCocksmqSTwkWI5KA8ZmSJcJeHlo0xS96DYJZ7gsVLFR6kSduLQ39NJDwkPqPphSqzbJFtR50/f5igDo1g2CEpSV1CKlTByvh5xiJoavL2WsOoyyRLqKSjz2vRvjfzbd0s6aWWSRCXLNgP+XNNAO1PRKFn1fYftgvcd5jacagpKnRLP4ct7rL95nodzjtotxpmGmE4PynTA8zx89sQVY9p2MnNQJuXO9/f347LLLsP69evR09ODM844A1/+8peRTgcnf+mll2J4eBgXXngh+vr6cMwxx+COO+6wOn8EgjgYjwfFXNxdHhROOnhdmk/CbVNdPPGmGfNR8SPFirbQvrp1GAOjZezHWgfpmKlE2Dlkz+KplUxSSS2fhZeHlILCVBLzcddjaaPEQ+dtzqbxPA+52lybYZeConXxkAdFL/EUK1UUKuG1EcHhBIRUkPpdPLZyAwDbhgO1TC/x1G9/5QTFLOHw4+7S02qpYaZiEie1MzMLFZRm80hc0Es89nL1P3/zNjz8yja879CJbZzgatps8aBMF7i6OCsUlDPPPBNnnnlm5OOe5+Gqq67CVVddNRmHF+ygsLp4xlPicSgo29ksEwqUqlZ9NQSPz6ZpNqiNzrklk0QmlUCxXLXI0lnfeQCv9+fxi4veigOWdQfbsRJNC/NiaNfEFBSez8LvU9Ys8VSqWqksG5GDwktD1CY6WqxYJR7ax0ixEpZ4IoLaCsqDUjPJMg8Kv15a8DlJ6BsJSEaO56AYBIV/u0skPKSTHkoVH9uGgwgDbrQ0yY3pf+Clq5269RIO33aZYyaOqZiY5aN64Iv7rPGg1GkzbgT+XnF5UPZZ0hm7Y6UZ8PfOjqCgjAf882LGtxkLBBOBuCmwwPhKPObxXAoKH7ZGC3Wpqnsj6Ft4M+SoWvWVIpFNJRXRMLd9vT9IWL7+7hfV38jMmknZWSQEXjIhlWW4WNHuk6uLxyynhLHwVea3CRYOz/M08mOWeILjJ9W++TEBI6jNbDNm5MVsiwYCkkG/9xNBqeNB2WuRno5JJGPbCCko0R6UXYy5JtxXsbTbyHzSCIpdhkkzNabeZGAXeClythCUem3GjcAVo3oelIlGWx3jrkDHrvPbsKA9g13nt1pfCsYLISiCGYfbHlmHt3z+Ttz5lDsXJwrjISjmcwcdBGX7SEhQzGwOQE9WbSYqnysZmZQ9eA8ISAzhN89sUsSJd9koYhPRZhzkoITEic6Zskzo+HQ9fFpxQAJCr4fKMmHf+jlBUiUeRg5MP40rj4SbZOn5yjdTCNubzcWOnkuvVzaixNPTlsH8dr0TkI7t9qCEP3ueXcbh57HzPLPEE27ryrPg1x93QOUWRpLjJo1OFw6sqX6EbLL5RaxZD8pEQw2NTCfHPOV8R0EmlcDvPvsu3HXJOyZ833LnBTMOq1/ainLVx0Mvb4u1nRV1H6vEYygorhIPJyhlmuzL/BpJ3s7b+Ng8lC2bchMNs2x11zObtOPTLB0gUBG4kVdLkiUFpVDWDLD83Gm/auaNGYNfqqrYeV6m4J08I+yY/No4uFLhTpJNaM8bijhn8zhAdIlnT0M94efVyCTb25mzSFazJR5XIii/d3E6eABg21Cx8ZNmGHad34bDdpunfh+7B2XqCAqR49nSYjzdyE0SkROCIphxoFIKL6k0g/GVeMw2Y1eJJ2w9ViUe1tWSSHAPSmMFhYyfNJU2x0ol6jnGeW2tLVCcoOw6vw3ZVAKDhTJe3jJsbcsVlJFiRSsPEbiSEcbGU6uww4PCvvm3sH2PqhwURlCMxb0jGy40LpMsLf7tLLvFbIsm5NLRv/NzMMs7fF+DziTZ+j4SXpUxSzyckPU6hvbxEk9cguKj+SnbMwkfPDLMdolHUJprM55o0LFoiKdgeiB3XzDjQN9ot8YkKIVxmGTNDJVGJlmVbmr4KugbV6EchIvVy18osHAxHvnN1RzzvFTQGmsTzqQS2G+nLjzy6nY8vrYPuy9sR6UathK3pJOaOlMs64FntB+6noLhBeFtxqWq3sUDMAWlWLai7oEwGZbAFxpVPnIEtfHOo2iCkoz8nU8YdhEUW9lxKyhmjgmgvzfNibae5+G8ty7H6/2jOGw3u/11PCWez5/6Znzsh4/i4pV7xdpuunHK/kvx8Cvb0NOWjZVJkmAdUFNZ4jl413k467BleOueCxo/WTBpEIIimHHYqhSUQoNn6qBFrD2bwlChHK/NuEZm5rdlsHW4iJGSQ0EZsU2yRcM0yhe2kWIZHXVkaTOLpIWVSghm2WrYCFqjRfagXboDgrJuO844ZGft2nPppPJmjBYr1nEB0wui75v+zZcqqsSTchAU7kHhUfEmieBtm6p8pM3iCf7WXlNmipWquu5GBIV7UPQSj52OWS/RlJMbF0HZwkotrlC9K0/d1/obgZd4etriJWTvs6QT93zmnbG2mQlIJrwxDTLk7/+pVFDSyQS+esb+U3Y8gRtS4hHMOJBSEbfeTos25SWYZZt6oAV9Xu3b8IijTVhTUIwJu5lUWA6hL4iNfChKQUmHhjxzO5Nk0YwfU1E4aJegxv/42j4AOsnh/pZ82a1G8FILKSj0N67sOEs87Lx5OByBl11y6YQzj6RYDkPeQgUl3Af5fxp6UNjvnHAsX9gGE+Y04KiJxKYJFgC2DsUjzxy8xHPK/kvqPFPA38dxy2GC2Q95xQUzCvlSRX1b3jpc1EyfjaAICs2mKcfwoNS2JbneRS62OUo85oLteZ5WtuC4+9lN+OgPHkH/aOBliVRQik0oKBWToHQDAJ7dOIiRYlmbw5Ng/hbexeNUULQ8kmCbHFNIeKw/gXcf0YKieVBSnDToihInSeQFUcMC2RwgIocNPSiGSfazJ67ApSe+ydlNY5Kd9ogSz2KHj+TYNwWzXVylo0bYOJBXP//FQTvF3n5HwljiBgRzB1LiEcwocBJQKAcR5s066embP7n9TYNpPdAH4fwaQRktVVCt+lpGBYWBAbZJNm2oEaOliuYfyZcqOO/7jwAAjli+Hucds1xlWlBZwhW4FuVBKRgkY0lXC7pa0ugfLWHdtlHQ2kskg8hPEFfvMMnymThlMqvWFBRGbswk2WDfoUnW3WYcnQbKfSADo3aWSXs2hW3loiqvZQzVgysdCc/2dHz82D0QBXNGTCtPkmXnsMdCm4Rcfsq+2HdJJ949BgWEd/YsdRAnQYg4PjLB3IMQFEEkhgplPPbqdhy9x/wpywIwO3e2DRebJiihglIr8cRQUOibPzc8jpZ0crTN0WZsEgWAd72EBOm2R9apn4nzRCkoXL0xSdZQwT3sDwgW1f7REorlKsgWQYoC/aspKFElHqP0RHkbo6zEwxM+SW0YKpTUvqM8KGZsOL9vAzVjsh62lsS2YaCv1kFlqh5cMcmlkw2HLEYd2zznRMLDD88/AvlSxRmI1plL49y3Lm/6WBwXvn0PVH3gA8ZgPIGNw5f34AcPvDrdpyGYJghBEUTi2lXP47u/exn/9L4D8BcH7Twlx3QRFFebpwu04JOCEkcepkW5uzUNzwum3A4Xy4qg+L6veVBISXApCnyxJ9x0/yvWtlEelHomWduD4sgUYXNrlDqTqRldyxUVMuciVYEHhWb42MSp5DDYEkHhnS1m1D3BjA1PJDykEh7KVZ8pKPbziRxaQW2OxNpmwduf2zJJK9H1mL0mp4OjqyU95sFsOxpO2X8J0kkPb9mpq/GTBXMOQlAEkdjQPxr825dv8MyJAw9DA+JloVgelFIwmbeZb9V5HmqWTmKYGT6BgCiUWaorkSFXcJlJUEqVKl5i+SR0LCICtOi6ou7NEo/lQXEpN6WqSsvIKfNukwoKS3TNGuWhoAPIVeKpEZSaqdnzdCLBiYOrEyOTSqBcrGAgX9KOC4TkJ8qDwlWPODNezOe3SiDXjITneTjxLWIk3lEhJllBJOgbvvktvlnEMbgSthqdO3GyUMwuHsBOYo0Cj1nn+RsEs9SiclAogt3RmUL3jZQBAikkpHRkDaXCpaCEnTLuLh7+c4EN/AsVlNCDQo/p3TShsdckTkQCipWq8s1oJZ7a40QmW41Si+4psduu6TiDVOJhqlCboaCYZZl31MyqgDu7ph4ydZQdgUAw/RCCIogELVSFMTjpf/74ehzwxf/F6j9tjbWdXeJpvp2Tgtp49kizrcajTDUIo9vDBc/0s9gm2XBBJgWASERfBEEpGHkjzi6ekt5dNGx4ULKNfCS1v3GSQEQgatuQrOnnBUCpHHqJJ1jcqfW2JRNthI1SUDhcJZ4oBeUYFqTlmp9UD/waXFknAoFgeiEERRAJ+qY9FgXlvue3YCBfxgMvxSQoI2NXUGhRbsumlEm0WXJFRKYlnVQLLldQTD9LVJIswCb01shLv0FQ6Fhmq3CrU0GhfJaAdFlJshFpsOZkYJ7mSufjVF80BcXOdqFtXSUeGmRHfhd1P5oo8XC4JhJvH7HPGQhKAN/+0CEAgFMPWGrtux64svW3794n1rYCgWDyIbqmIBJKQYnRDUOgab6umTb1QOFsizuz2DRQiBXWxife5lJJjJYqTSsoXDVodXTTmPsxk2SjMkWAYIif61ihymGYZB3Hndca5rNUq74zy4QrN6WKrqCkkgmkkx5KldCMyrel9twiLw/VtvW8YMbQcLGCgdFy7fm2STbs4NE/VnKNFBSzM0crCenGV9cclxPe3It7PnOsczBfPZx64FL879ObcNm7V+BNvXbSrEAgmF4IQRFEghbQOImsBFIf4voCSEHZa1EHNg0ULNNsPRRZAmoubWeR1EOeqQYhQQnP3Rw8qLp4HCZZPlwPAPpG9WvIKw+KTjJyzi4ed/tzweVBYd6XkKDoXS6lSlm182Yc5+yaiQMEZZvhYkUpKCltWGB0Nom5H5cHxcw20Qb+ZaPbkjl2nW8nxTbCO9+0CE98/nire0cgEMwMSIlnDiNfquD6u17AWd9ZjbVbR2JvH5Z4pk5B6asRkuULggVnLF08AUGh0LPmyBX3dLgVFP0eEEEoOVp2GykooQdFN7KqvBFHkmxXS1qVrYYjpvuGJKPCOnHsbpoBV4mnZpItORSU4Nxq29bxoBDM+PnYHhQteTZV97njhZATgWDmQgjKHMb5Nz+Mb6x6Hg+8tA2/fW5z7O1Dk2x8BYVm2cQlKHTMBe2BXD/smIkTBe7LUAPumiRXXH1pU8mozCRb0hftZko8BcMkS91FREAKZlBbnRyUXDoZnlchVIaiBv6ZPhK+f5ePRJ/FYxtwiaCE29pBbQRzum+9oDZA74Ayn9+WiSY7AoFgbkP+b5/DeHJ9v/q50eA6F2ihipPIShirgkIlk572TOztlacjyRWU5s6dL8quRFdSYihjRREUVeIJF2yzzZgWdUokzRvEzwxT05NkQ2JERCBKQeEm2YIxGZj/rFQQh0m2XPXZHB87BI3UF17SMhWTBe3RBKXD0c5rqiL18kkmWkERCAQzF/J/+xwGDxYzPRTNwDRzxgEtsnE9KBQE1lMzhQ7mS/WebmzLFJTaotjsufMFn7I3RhyBaaSCmMMCtS6etLvEQ0Pn8lbYGgWihZHy4XFDBaWdnZeri4cfN1+KVlCIZLjajIHwnvPyEJEjekulE/ZjBNOsykkSbwFX522cBy+7WCUemWgrEOwwkP/b5zDKlZCgjCXLJOziiU9QSPmIq6AUDVPoUKHcdOBbkZU1cjFLPJqCYoSiAWFZhhbYctXXu2kcfg6zzbi3RlCsHBRjWGCxXEWlxgT4ebXWOlqGC2V3DgopNxE+kqwiKGXt+ebPYU6KnehK4IqR6UGh8pw6bqp+iYffu5yhkJjHFQVFINhxIP+3z2GUqyGxiKuglCvhIhl35HmpUlULaBwFJNi2pqDUCErVb/7cOVnIOkyyvu/joh89ho/94FFUq75z22wqibYaERhx5KBQiQcICIhrNo1pku0zSzwRXTx8MVYkpsxLPGE+i6vNWHlfShGdOGmdOPHFnntKVKIrUz7M8DWuGOXSCfBpAqaCwn2ojUyy5jydyTbJCgSCmQv5v32Oolr1wdfguGPLuWoSV0HhpZE4CggQLp5dLWm1sDVbJtK6eEhBYeRmsFDGfz35Ou54aiNe2DzkPG4mlVCL8TA3yZYppTZcMEuVqnM2jdlmbHpQorp4uNpBrxcv1bRxD4orqM1pkrU9KAR+zp7nqe3DEhAnN/W35T4UU0Hhz23L1M9BMQmKOck6a7QkCwSCuQvJQZmjKFV1UhFXQdEJSrxteWmk6geLrJmN4UKl6ivVhrwgg/kyBgtlLGrmnNmiTQsdv45hVm56duOACufialE2lVBEwNVm3Mk8FKVKRInHVFBG9BJPwUySTeqBaEHAnKGgpBPKMDpSiDDJalH3dpuxaWa1zKnJBIrlqoqM17t4TAVFb89tSSfV/VpgKCi7LWjDBW9bjp62LJKOtl7djKufk0lozJKPQCCYuxAFZY6iYpQw4pZpOCmJG9Q2bPhOBgvNlXmoXAIEC2CHGtrXWEHxfT1dNetQUPh+/vha2OHEBwpmInJQiOC1ZpJI1RZZntjqUlCK5WCacv8opePm1PHKFTYvxzG9l47NZ+qECoq7xEPqQhB1XyvxGEFtHCZBqRc5bxLMtGFW5a+d2cUDAH938r74+LF7WH8HgJPe0qt+fn6Trmxxz8r+O3fhsN16nPsQCARzD0JQ5ihKFZ2gxFZQSmNXUMzskqZLNAZRoMWpme3NbZWCwks8bD9PcoLCVJZMMvR6jDiG9uXSCbU4lzQPCmszZjkoo6WKei2oxAMEJSNXhoqZJsvzTFpZPoszSbaBgmIRlGR9gqIpKOn6BGWY3au4ZZij91yA0w8M5uis3EfXynraMvjgkbvgrMOW4d8vOFI8KALBDgQp8cxRlCtGiWecHhTf9+F5zaVucu8G0HwnT4kdM51IKIOkOaX254+vx7OvD+LgXefh+H0Xw/M8jWRka1H3QOgdAXTi9NRrA6hWfSQSnrrWZMJDKplwRt2rWT2pJNJJD6Ol4L7UT3StqvJOKuGp1mnaHy/fEFqMY3OTbJvq4oloM1b5K2EUfj0FxQw9swlKPQVFfy+Yil1cfOPMA7Fy38U4cFm39diXTt9vXPsWCASzE0JQ5ijsEk+8Mg1XTXw/UCia/WY8Mk4FJZ30kEh4aK/5Pfj2Q4UyPn3bE+r6fnHRW3HAsm5LBXEpKEOs1DRYKOPVbSNYvqDNKpe4FJRwmGCyNjumXDPJ2iUeblYlg2x3axqJhIdcOoF8qYpRVqbhSapEjvKmgpJOaAqKs82YHdcVdd/Ig2KqIjkHcSLMb4s3mK8RkgkPp+wfbxqxQCCY2xC9dI6iNE4Piklo4nTymAqKqYBEoVTWO2LIg8IVmKF8WSNfmwcLAGxyE3pQwvMeMojTi7VOngKLuQeYD6TAFZSaIpFJqnIOL/FoBCUZGnQHVMx9QLZC825FIx8EVeIpGmmzqaTqIBrMl9U94cP3eImHt02H+65PSMyST1QOSks6iV16WiEQCASTCSEocxRWiWccJlkgXpqs6UFpxuQKAMWKThTaHQTFJFp0XaYKoqLu2XWY50G/my25FIg2UqqoFulRVeJJOImAq8RTKFdDIlEjFy2MgITn7DLJ6iWeXDqhSM6mgbwiaZ0toQjKS0thAm20CtLIJKurL+Fx9u7tkCF7AoFg0iEEZY6iXJ04kywQT4EZGaMHpWgoKO1MMVDnYRAnsxRCi6wr6t48DyrhmCSDSim+HyonvMRD5xcEtdWfZkzHpHZZboJ1KSgtab3Ek3coKOu3jwIIyiK8bMPNueFwQ6agGCW6RimtvHzEyc2KxR0wcXitu+Z9hy6zHhMIBIKxQDwocxRls4tnHCZZ1+/1YCoog016UMxU1lBBCb0jZukpbyootUXVFXVvE5QIBYUt+iPFMloyybBtlxOUiDbjkKBULAWFDzF0tQrzica+72smWUqxpbJWZy6lGZf1YYGOoLaMTmZ2m9+m3Q/Tz8L3zcnMiiU2QbnxQ4fgN89swin7L7EeEwgEgrFAFJQ5Clo4KbOjUK5a8e71YJV4YrQaj1lBMTpTFEHJR5d4LDNpTSXIGkoEYJd4bAUl2CaRCFNVw8nDYamFHmsY1FapqmPStVAi60ixEpaNHHkjI8VKMO+n9pJlU0ktJA6wB++5FBQtBI2d4z5LOu0SD293Nh7jSg0F3HH0tGVw5qHLrEA3gUAgGCsmnKBUKhVcccUVWL58OVpaWrDHHnvg7//+77W4c9/3ceWVV2LJkiVoaWnBypUr8cILL0z0qezQII8Cj2ZvdnAeYCsmcbqAyCTrxYyqpzZjamFVOSj1PCg1M2mkgsJLPHk3QXFlitD2YeR88G9LOqkWcr2LJ1QblAelVFXHJIJChGEwX1KvUYthQAX0EhAQlIG43wSA9TuRs3ypokp8UWWaA3buggl9MrJe/kkwNWVFb6e1rUAgEEw0JpygfO1rX8O3vvUtfPOb38QzzzyDr33ta7jmmmtw/fXXq+dcc801uO6663DjjTfiwQcfRFtbG0444QTk8/mJPp0dFjQokM8yiUMyzOnHcRQUKvHQTJZmTbKFCAVF86CYJZ6ye/CeK+qeiM782iBCUnpcLbstRrvvqNZmXL/Ek2UKCnUOtWV1k+y24aJ6vtYhkyETbUV7DTLJhK2gZN0KCr9feox8+PN+O9kEhT9uZqTsvrANS7pyOGTXeWqQo0AgEEwmJlyP/f3vf4/TTjsNJ598MgBgt912w7//+7/joYceAhCoJ9deey0uv/xynHbaaQCAW265BYsXL8btt9+Os846a6JPaYeEMm/Wuk6KtVTTZtGMB+X+F7egM5fGfsa3cSIkizuzeGOwEKPNWF/sSUEZdgSmEUYjjK6uHBTaz8KOLLYOF8MSTyX0eRByEWbVIEm2FnVfqbrzSJJh5Dzdiw7Dg7JtpFi7Vk8jNxpBYR6VRMJDayaJZMJzdvDwczBTdcPzCn8+wBGIxks3ZqhbLp3E/33mWKQTUhUWCARTgwn/tDn66KNx11134fnnnwcA/OEPf8Dvfvc7nHTSSQCAl19+GRs3bsTKlSvVNl1dXTjiiCOwevVq5z4LhQIGBga0/2Yb1m8fwU8fXW+1/04WyCSbTiRYa+s4CIpBDN4YLODs7z6IU7/5O4s00MK/uCOIdo8f1GbkoNTxoJCyY2aZuGbx0H4W1WbijBrzblxmVbOLJ5syTbKOacZpu82Y5ugogjJU1I5jHtfV5eN5HjpZyc5UVOzgNU8bzkdJtACwx8J2mDhieTjnxsxIoWuX9mKBQDBVmHAF5XOf+xwGBgawYsUKJJNJVCoVfPnLX8bZZ58NANi4cSMAYPHixdp2ixcvVo+ZuPrqq/HFL35xok91SnHSP9+HwXwZ20eK+Mjbdp/041GJJ5UMWlH7R0uxWoVtIqATli1DBfXz6pe24p1vCmeocKUCsE2zUaByCZGL5jwouoKSNRSUvKPEs5BKT1TiqehEIPjZ7KYJntOSSTKTbNUZOU9Ep1L1MZAv1a4lXds+eIxKPKaptFVTUOxW4c6WNLbX4vMtk6yZBGu0Fe+5qANf/PM3Y5f5rc6pwm9hZZ+1W4etxwUCgWAqMeEKyk9+8hP86Ec/wq233orHHnsMN998M77+9a/j5ptvHvM+L7vsMvT396v/1q1bN4FnPDUgX8CqpzdNyfFIQUklvLBsMJ4Sj+H94L6Su5/ZrD1GUfeLagSl+Vk8Rg6Ky4MSYd61CQoZVe0240WdRJzcIW9A2G2TN8yqOWaS5UFtrjZjICQi7TX1gkgDlXhas3YpBQheKyJfPGyNqyZWicdIijV/B4APH72bRiY5+DUMx2xLFwgEgonGhBOUz3zmM/jc5z6Hs846C/vttx8+9KEP4VOf+hSuvvpqAEBvbzBafdMmfaHetGmTesxENptFZ2en9t9sxcgUffCHCkpCLdrxSjxGO6/xOycddz+7WevSMhUUMxcl8pgROSgFZkYNSy21a6IcFEPJUB0tjmGBRJxG63XxOIgCoCfJkjoC6EZXN0EhBUU3yZphabzEQ++VNqaycFLSSEGJO1UYAI7eY37sbQQCgWAyMOEEZWRkBAnDSJdMJlGtLZjLly9Hb28v7rrrLvX4wMAAHnzwQRx11FETfTozDuacmskCtZmOWUExZ/EYv3OC8lrfKP70RlgSIBKxwCilNIIyyRplGiAkEaSYzKtNBraC2pK6glKp+ihVggwYizhZQW12u2+hVFHkLFWbdkxKA00q5s+n51EFZWuNiJD/w/SgtKbNEk/w+2ixolQqrrJoCkpO3zaVTIBXblwKSiNce9aBWLnPYtx83uGxtxUIBIKJxIR7UE499VR8+ctfxi677II3v/nNePzxx/GP//iPOO+88wAERr+LL74YX/rSl7DXXnth+fLluOKKK7B06VKcfvrpE306Mw7mpN/JgirxJD0kE3ZoWSPYXTz15+u8MVjAnosC4yUpDgs6wjZj3/e1ZFIXzFZhrggUShW0Z1PqGrpb09g4kI+MuufkJl+qwPM8kMizqMMwyRoGW779aKnCOniS2vOIoLRmdPOo5wVBb/lSWAKiLh418K92/8z5OORRiVRQGEExFRQ6Nx6PHxeLOnL47ocPjb2dQCAQTDQmnKBcf/31uOKKK/BXf/VX2Lx5M5YuXYqPfvSjuPLKK9VzLr30UgwPD+PCCy9EX18fjjnmGNxxxx3I5XITfTozDs0aRseLMEk2odJk4xGU4LnppIdSxbfyR8z4erou3/cxYigoVT8gEGbrqnXOimQE55tIeMgkEyhWwuh2Oq+uWuw7nZc1i4eRjUK5qlpzEx5UjgeRLFercI518ZiprEpBGXUbXYGAXPF7RjkoZueNWeKhY4wUK0rh4c/hJR7Tg2Ie18wyEQgEgtmECScoHR0duPbaa3HttddGPsfzPFx11VW46qqrJvrwMx5xh/aNFbQgp5Ne2JEyhjbjrpY0tgwVHQqK25NSKFeVUsEDvYYK5YYExWwzBoIyRbFStfJIqMRjTzMOjkEqRrEW+07X055NqXKLta1GUEIlIwxpI2UnIFDbhwMFpS1rX1c2nQQYiSM/TYdRljEVFCI7+WJFqW08bE8v8dgKCj9ubgwlHoFAIJgpkE+wKUap0vw8nHEdp0ZQ+MTb0VhJssFzaRE0Sz58gB8QEhau0rRmkurbfzOlLbPEA4RlitCDEuxnXlta+12pIGxR5nH3PHKefB80S8dlkuVThU0FpbVGGN6otVpHKSgcVKahgX+EeiZZt4JSn6C47p1AIBDMRghBmQV4akM/vvo/zzYdGQ9ABcKlkglt0WsWpJh0tuhEgDBkEA4q8dAxKCG1LWtnmURBtRk7lIxQQSEPiqGg1NJgtYF3jGTQvWvLpjTVYrRYYSUeOxY+2FZXMkgFoSyYtoxDQWHX0MY8KnaJx62olKu+8rhoCkqDEg8/rpR4BALBbIaMHp0C8BZcIPi2b6Z+1sP7v/MABvJl9I0U8dUz9m9qG1XiSXjWIt8MSFUggmIrKO6JxWF2R7DQtmWSeAPNeW9cJEMN3jO6eLrpvIwcFJfRtVCuKsNpay1ojbw1I6Wyc1ueJEtqUacyugbHppfVLNOY+4oiGPw4rt+3OlqROcFpzzqUG3bcnea1WI8LBALBbIF8xZoCFI14+76RYsQz3RiolSd+/vhrTW9DpaQki7ofS5IsLcrmtqRIdLemtd9J0aBjRikoX/r107jhty/q51wO5wcRrBJPTdkhD0qxEhhgCw6jazhVmMfGJ7XzG+GJrUmHB6VYsSYSmz6SNkeJh59HO3u+2Xljlnh4PP1WpdBwgpOu/S2JlDOOPvzbgY55OwKBQDBbIARlClA01IftI6WIZ9aHa2BfFMrKcOohx+LT4x6rR03+NUo8tUWb5u1Q8igRGVIVaHHlptrNA3l893cv4x/ufA6bBsIJ1i4Piqn+0DV0tYYLfb5Uqaug5MshCckZxGmkUHFG3fNtqSVYERRDuTDTYM3z4EpHWyapZZWYBMXzPLTWjk0lJL7/ZfNakfCAXee3Wcc0cdCyeQ2fIxAIBDMVQlCmACax2B5TQeHfivmCXg8qqC0ZmmRHIhSUz//ijzjrO6u1Th06Z0pd7R/VSZUZG68UlGJtZo0iAsG/PKyNqyn3PP+G+rnISBXBVFDo325mFh3lBMVJbqpW6y0RqJFi2TksMMc6n5SCYpR4CC4FhXtLOEHxPE8zurY4tiVCubUW5sb339uVwy8/cQxu+svDrO0A4MXNQ+rnZT1S4hEIBLMXQlCmAKaCEqfE4/u+8pMAwGOvbm9qOxV1n0ioBdXMLgGA/3tuM25e/SoeeGkbnt4QTommGTYUahZFUBbXJgNbJZ6M3vHCDb5cjbnnOUZQjCRZINok25JJahOLnQP/FLnhg/eCx2nRHym6t1VlMTaRuCOixONSUN69Xzi2IWEE1PHtXQZbUlVcHhQgGOpH990En6HTKBhPIBAIZjKEoEwBbAWl+RLPcLGi1BAAeGxtkwSFDQsktaHfIEaVqo+v/Pcz6vcBRmDonBd2uhWUYUVQ9Hk7ZIalBb6dEQEC//m+F95Q5ahSjDbjXDqpddqoVuEk78QJFRQzzj5UUCpWhgrtHwjySGwFpbEH5T0H76x+Xr99RHuMG11dBlvTONvmMMNGge7dkbv3NL2NQCAQzEQIQZkCmCFncUo8JjFYu20k4pk6whJPQvk1+ox9vbxlGM9vCksCpOz4vm+VeAZGS6gyojRoKig1YpI3TLKkLgxpCkr480C+jKdqyk2pYvtIssZUYhU7n0pqnTYuD0qWE5iSrpK08hKPq4unFjmve1DIoJqCV8dHAgRhc/927qHoyKbwNyv30h7jBMWVoWIG2rn2H4UffuQInHrAUlz//oOb3kYgEAhmIqTNeApgl3iaV1DMchBNwW0EbpJVCopBUPg0XiAgIYDedUQlnqoPDBXL6MylUaqEhIAIitVmXFtU25UZNSQlpln3jcHADOr0kTAFxfd91cWTSye0tFfnROJUSGCUSTalm3dHtBwUW7lxeVASCQ/tmZQiLi6SAQDvWrEYT3zheKvUwluNXeTD/FscBeXw5T04fLmoJwKBYPZDFJQpgFniieNBMUnF1iYJCk+SJQWl31BBzOA3Ik78fDtbUmrh7q89zrcjhYWSYimtVikoGWozdpd4+DUWKxTP71ZQipUwRj9rlHiKNPDPtW05HPhHf+MlHreCEu7b9KAAho/E4UEhuHwgHQ1KPCbhiaOgCAQCwVyBEJQpQMGImB+OaPf96v88i4tufUwLdiNVg/JIqLOjESpssafBer6vG2VNgkJEgZ9vhm1Pj9M+sqnwsagclPZsWEohmKFtiqA0CFvjw/cCBSVUOYqO8pBLQQlNsrRtue404yCoTVdQAJ1kRCkoUdBLPDb5WNKlG2BdHheBQCCY6xCCMgWghFTCiCP2vVyp4sZ7/oT/euJ1PP162E1DqsbuC9sBBIt5yQh+c6Gkung8ZFPhTByawAvYcfXkUSEfSTaV0NpiqSREfpOOXEqVcIaL5aAEUwoTW4N/7aC2KAWl5BoWyDp1yIeS8ALixDtt3BOJ2baGSbY1Gyo7rm1p38VKVZ0fbxdub9CJUw9aiSdtkw8zAdbVJSQQCARzHUJQpgDNKCi8dJNkSV60OO42v1UZM5sx2ZYrYYkHgKWCAHUUFGPBpm1JzSFPRls2pRb6qh+oDVbUfYM2YyAkPqFJlueghFH3yiCbTsLzWIR/hI+Eqy/mNVGJZjBfcvtXWMsx+X7aI0o8rTE8IsG29Us8S7tDgpJKeNbgQYFAINgRIJ98UwAz6t41l2bzQEH9TJHvQKhqdLdm0FOLd3eVeX777GbcsvoV9buaxZPUSQY36A4ZCan9yoNSU1BqC7xJbvh2razjZKhQtnJQ2rKh14NgDi20Sjyudt9ShRlk9VbhfNmdJMuj7s2JxFRm4cRQGxbomATcEVHiia2g1PaTSnjOmUw7MYLSmklKnolAINghIQRlCkAKSgeLVzfBE2LzrC25XxGUtIqdNzt5CuUK/vL7D+PKXzyFP70RtA2X1DRjT20P6K3GRDSWduthbFEKiklQ2rIpJBKeWqCHC2WloNSbxWNmqAyYJZ5IBYU6cRK1f0MPilsF4VH3+jVR2WpdrW3b83QTbMJBHtomSEGhY7vUEwDYmZV4smkp7wgEgh0TQlCmAKRIzKsRjGGXgjIYKii8JESqRldLSFDMTp5HXwnD26j8onJQaiWe7pZMbX/htkQU6Bs7+VMKrJRCxwZCgjJsKC+tzIdiDQt0BLURientatH2W3C0GWcdJlk6rxzrxKHrjYq6J/8KdfGQikG5Mp25NBIJXanggWm5dELzxnAy0xqTRJB6E9Wds7A9q34ecqT/CgQCwY4AIShTAFp459VUDJeCsnmQKSglt4Iyv72moAwVtG3vfWGL+pnIT0hQEmp7vj+AKygmUdA7XmgxDwmKboRVRtlCxcpBaXMGtQXPWdKpKzeNTLKjJb30RASCX5O7A8g2yZKKoWb7sOGD4fZ84J/+uK6gxCMob+rtQHdrGocvn+98nBMlsxwmEAgEOwqkf3EKoAgKU1B839e8BZuYB4XnkNDi29WSxvy24Ju1qaDc90I4z4bIT9ko8bg8KEpBqZUUgqF60eWQ/lG9lZjUETUQsGArKB21hb1Y67TJpBJqaOESo7RULzBNK/HUiAMRoy2MsPEU1pDc2CbZTmPgHx8+SOAKihlvTx6UsZhYe9oyePBvjxPzq0AgENSBfELGBM8oaRa0OJLJterb4W1vRCgoVHbpask4SzxbhwoqKh5gCkpFV1BccfekhCzuyKlun4HRkqU2RJV4SDmgVuLhYtlqM+YhZqSiUJs15X30j5ZQqfqgDLm0s0xTsWL0iTS83p9Xz007ykO8RVmZZFt0wtFVe204ONlpz5oEJaWucywm1mxKzK8CgUBQD0JQYuD6u17A4V+5SxkrmwUpA12sjGC2+HIFRTPJMg9KWOIJCcq67aPafqh8oqYZJ3UPiquLpyOXUmWcvtGS5dcwCQodwy7xhAoKLe6pZEI9bzCvb08eFB6GBujTjLmCEnXcDX2jtevQVZAwqM2hChnP7XIoKPUICv0eJ4Y+DpYvaJuU/QoEAsFsgRCUGPjGqufxxmAB3/jf52JtR56OlnSSDanTvQXcg8JNsqqckk0yBSUkMybRod/Lqs1Y7+IZcOSgtGdT6K4pCP2jJeQjungGTQUloy/SQ8yD0uJY3CmBlq5pUUdWZbvwMo3L6Foos31naKpwcF7UAWWWYcKoe5YkW/tbNpXQjuMq8ey9uD28BmPfi2r+GXpNJhr/cvbBWNHbgW9/6JBJ2b9AIBDMdOxwBOW3z23G5bc/qZVR4sIkF43AMzp4OYRQqfrYwlQRUlAqVR+lWqkmm0o6PShDFkEJti2poLaaSZY8KKN2F09bNqV8Jn0jTEGhEo9hsB1RHhQ9zn4ob+egADwUrVbiKYbEiLphKAfG80JSxc8hX6oyf0vNg5ILQ+KC40QpKNVwmnHtb0FCbkg6XCbZj75jD/Xzq1uHtccO2LkLV532Znz5L/aztpsI7LOkE3dc/Hac8ObeSdm/QCAQzHTscATl2lXP44cPrMXqP20d8z7M4LVG4J6O0FAakpytwwUVrAaECgqfgszn3gyMRs+1od8rtRJPuuYt6awT1NaWTWkTj+3U1ZqCktc9JNReTI8PFUpuBUU9TgQlLNUQ+Vm/PSibtWdTmjeDDwscVdvRcXVVo9P4Pce2pWvinTm8zOMq8eyxsF2pKEfvsUB7zPM8nHPUbjhwWbe1nUAgEAjGjx2ui2dbLQfEnBIcB8XyWAlKqKBwYsFTZIFQQSkwL0o2ldCm8xLMeTpEApRJNql7Lkg18X1fRe63Z1Oaz0Sdb+14lPNRrFRRrlTVdqYXZNtwSZWWOEHpZLHyvu8zghIcdx1Gsb7mpTG9ITyufqSoqzMdEcZVc9uRUkURQJ4W29FSn6AAwE8/fjRue2Q9Tj1gqfNxgUAgEEwOZjVB4Qt1syAVwCyNNALv3mlmWB9HkU3L5amr5jkRSEEhopBMeEglw+m93KNielBoEadhgdSdQx03I6UKqlUfhXJVLdpt2aQ2M4fuK5VIeLlmhCkZbYaS8QZv983wDJEwTbZYCY/bkkkqQrKupqB0GkSBJ8kSqVOTks3W36x7W65O8RZmrrh0O7p4gmtL47xjljsfEwgEAsHkYVaXeJ7fOBjr+b7vKzJgLuyNwNuCx6WgsFAzglmmIYIQ+iYo2j34t1ipolpbdKncQkSErqtS0U2yRCZ8P1BoOEFry6RC4lQsh8dlhlLa/0ihovwzpKBQiWdzzaxK04YJ3CQ7yvw7rZmkUi7WbyMFxa2CAKHqZR5XHafOtgSNoDAy5PKgCAQCgWD6MKsJyqtb47X7jhRDqT8uQeHGWDPDpBFUAFk6qYgAJyWmmpNXCoqe6MrnstA5DKksk8BAS+ShZCTJ5tIJ1TEzXKiwTpxkME9HU1BsQymVeUaKZRUGR9u42n25j4R7WOg+ZpJBZgkRFIqcN0kHJxQ0xZmIR2s6CR4lElXiIZASReDlJFcXj0AgEAimD7OaoLyyZbjxkxh4KcX0bjRCvZJMI/AZM2EXD1dQKsbzK9p2RBRybLGm59B5Lay1vQ5HJMmaJIMbZIN/Q/OuSYyAsMwzUgwVFPobqR4Dtfsyr9WtbAwVSmGZprYttelurKkvZoBaOhmqN9uHdQUlkfDQnnFPGAYCQsI7gnLG8D9+rC5RUAQCgWBGYXYTlK1xCYqdAdIseFtw30ixzjNt8AwOIgIj7PjmuVgKSq3UkmKLNT1nqHZei2oKyog1iydcoHl5yRz451ZQwrcHPT5SdHlQjNh4w8/RydqMzbA1M0fENMny86AW6VZHC7P5c7gti743FJVGXTwCgUAgmD7MaoLycswSzwAjKEOOicL1wD0jw8VKLB+KKvE0UFCo/BPlQQFCFYByXIjoEEEJFRTyoDCSwcpLw0WDoLB8loIxlA8Ijal9I0VFfsh4a3o/TD+HMskygkIKCqXjEkyTLL/+7bUWaS3hlR3b9K8Ez7UHD5rHakknNSIjEAgEgunHrCYor24djjUbZyAfrVo0gvn8OCoKb9t1eVCILPTUFuu80cWjDcBjbbfBeVEqa07bV9no4gGgkaMh5SOhmTmhuuJWUILn8UC5VmMmDmGeoaBwD8qopaBktee6SUatzbl2Xq0RZR1TyQmuwR4eaB5LDLICgUAw8zCrCUq+VFXehWbginlvFmanzfaR5nNUeIqpq4uHzoUWa1JHXF4QU0EhL8mizlqJhxQUKvEwDwYvL9klnrD92UxdBcJ4eYqkz6QSynBqEhRLQaESTyFUblrTwd/mmyWeOgoKgZd4+IwcV4lHV1B0lWRBe1b7VyAQCAQzB7M6BwUAXn5jGEtqQ+caYTwmWfP522MoKJQ8y3NQOOEhUkGLNSkYpkkW0IPL+H6oxFOsVJEvVUDCUjoRLtBcQRk2TbKZ0GPSmrGJEaklRFDaMlyZSCKTTKjrtBWUMKiNXgMyqFolnjoKiuv39pxbTeHnFm6nE50jlvfg4pV7WSmxAoFAIJh+zGoFBQD+FKOTZ3AcJR5TQemLpaCEC75TQSlS9wuVeKI9KBlLQdFLPICuFCVdCoqziycMUzOTZIHQb/LGYEBQeJkF0NULs4ung+2b7hspJc2YZE1FhisonQ1Msr1d4X0xFZRUMoGLV+6Nw5f3WNsJBAKBYHox4QRlt912g+d51n8XXXQRACCfz+Oiiy7C/Pnz0d7ejjPOOAObNm0a8/Fer2VvNIOBcXTxmFklcTwoDRWUmi+D1AQiCHmjiwewFRS6jq6WtCIvPMbfqaA4u3jCEg+RH65UEClQCkpWX+w5Oeiq40GhTpzuluA52VRSK9O4SjzzDZ9KnBLP3os71M/Z9Kzn4wKBQLDDYMI/sR9++GG8/vrr6r9Vq1YBAN773vcCAD71qU/hV7/6FW677Tbcc8892LBhA97znveM+Xj5UvPdNLzNOG7U/YhV4olWULhxl08kzqWSiiTw4w8pD0qUgmIbPfO1+TI04bctG4bAcYKieVAyDgUloyso5aqvHtNMssqDEhCMFktBCYlFVA5KpepjU3/gGeJtvbzM41JQTJVFK/HU4u0zyYSzE2dFLyMoKSEoAoFAMFsw4R6UhQsXar9/9atfxR577IF3vOMd6O/vx/e+9z3ceuuteNe73gUAuOmmm7DPPvvggQcewJFHHuncZ6FQQKEQznkZGBgIH4sxj4eXeArlYPAdTxath2YUFN/38eGbHsbWoQJ+cdFbkUomFNkAgoWVvv1zYkXkp8fyoDhMsmnavqKpMG3ZFNqyKWwfKekEJSIHxeziaWWL/tbhYu243CRbU1AGbQ8KoCsZpgelLRMkvvo+1FBAXrbpacuoVGAzqI0eJyQ8/X6QauJSTwBDQZFWYoFAIJg1mNSvlMViET/84Q9x3nnnwfM8PProoyiVSli5cqV6zooVK7DLLrtg9erVkfu5+uqr0dXVpf5btmyZeiyOgjJgTDAejmGUNQfVuaYhr9s2inuffwNPbRjA6zWlgMfiZ1MJtdCPlmwPCplki+WqGuhH2/F90H7p/JMJD9lUQqkcdG7JhKdFzms5KEaJJxhGGOybBCDNJFvbdlBF5Ed7UEzPiOd56jhEUDQFhREQTnTU40xhaUkntWtqb0BQ9ljUpn6m8pJAIBAIZj4mlaDcfvvt6Ovrw7nnngsA2LhxIzKZDLq7u7XnLV68GBs3bozcz2WXXYb+/n7137p169RjY1VQgHhhbUQGltRMl9zPQnjk1W3WeZGCkkkmkEh4iuCMOoLa5rGFulCuMrOq3cWTL4WR84FC4SkjKxEUrp4AZg6KbpIN9qMv8ppJ1njM9qDwEo89GZhKN9QWzqPlyWPSlkk6FS2uoJilJdqvy7sC6KrJK1viBfsJBAKBYPowqW3G3/ve93DSSSdh6dKl49pPNptFNuvOqojnQdEJSRyjLJGB3q4cXtoyjIFRe9tHXt3O9q0TFFrsiWCMlirwfR+e56nzmK8RlIrW/UMglSNQUNxpsFEEhUjFKFdQmPLQlk2p8k5wXNskG/U7KRjppGc9BgQk4zVmaObD+SigLopk9DDCY+776D3nY+U+i3HqAUuc23K8FsNQLRAIBILpxaQpKK+++ip+85vf4CMf+Yj6W29vL4rFIvr6+rTnbtq0Cb29vWM6ThwFxVQ94gz9G1EKSotzXwDw6CuMoNQITd4wurawBZZ8MKSUdObS2qwdd4mn1sVTslUQIirUymuqEfW6ePh+wmNFKyhRJZ7u1oxWgiHwdl/AXeJxGWSBkMAAYYmN0JlL47sfPhSnHbiTc1sA+PvT3wIA+If/t3/kcwQCgUAwszBpBOWmm27CokWLcPLJJ6u/HXLIIUin07jrrrvU35577jmsXbsWRx111JiOUxiDgkIqRBwFhcgAlXhMctM/UsLzmwfV71TCIQJFx+QTdUeLFW0mT1s2pR4vlCvOqHtdQanFxteIxby2YIHfVCujpC2Cwrt49IF/wc/64u/yoEQ9lwiK2cFDWGoQFD5QkJJcowb28RKPGbbWDD505K74w5XH472HLmv8ZIFAIBDMCExKiadareKmm27Chz/8YaRSLB+jqwvnn38+LrnkEvT09KCzsxOf/OQncdRRR0V28DRCvkkFpcLaZ5d2teClLcOxCAqZZJd01zwohkn22Y0D4GOBiHiQgkIkI5VMqNTV0VIFJDakkx4yqQRy6SSGi5WagmKXeEhB4V087Vl9MvCLm4cA2GTBlSQbpaAkE56mwFglHkNtoXZfc5IxYUm3nvbLA9beuWIRTt5/Cd5zkFsF4Z6WQowhjRxdMm9HIBAIZhUmhaD85je/wdq1a3HeeedZj/3TP/0TEokEzjjjDBQKBZxwwgn4l3/5lzEfi7fx1gPvmlnYkcVLW4ZjZaEMOUyy5CEJftf3RVOG84aCQj8TQSFSQ+SB55y4clBoP/lS1coyoYX85Vq6rjljhjwog/mSlp9iPs7Pg2CWdHaepxOOw5f3YEF7FsfvuxguLGEKSkc2pZGfrpY0bvjAwc7tAF0JGm3y9RYIBALB7MakEJTjjz8+cspwLpfDDTfcgBtuuGFCjtXsN+oiex4pDWNSUGoelFLFR75UVZ6SoYLRwkwlHufgvSQGapN9K7WhflQy4Umxrsh55UEp2yoItePSoEBzzg2RDIqrB6K7eHabH7bnBtvqCgrPFwGAPRe14+G/O87pPwGgzUuKMsM2g2YJqUAgEAhmN2Z9tGazCxYRlFQizOTg/o96qFZ91Qq8oD2rjKzcKDsUoaCYHhQgNHpqrcK1c+KzdtxBbaGCQj6Y0P+hE5IoBaXGX5Cq5aeEj4cE5Yjd9fk0rUxdSSY8i8AAiCQngK6gjIegjDT5mgkEAoFgdmPWE5RmFZQSn4fDhtfFPUZrJqkIAfehmCWe0INSIyiOicSjpYrqDiJPh1NB0aLuQwWFCAq1Cpsza+a3uRUUQls2pQe5MRJyxPL5kdv2duYUkWoWiztDglKtutW1ZiAKikAgEOwYmPUEpdkFixb7TCoRKihNE5TwGNlUQrXDDtSZ7TNithlzBYXSZIt62BrtP9iu4pxmnGUKCh2fQtJ6jJLO/PboIXuAndrKM2XMCb+8vdf0nzQDTmhGSvHmIHF0tbhNuAKBQCCYW5gDBKUa6XfhIAUlnRy7gkKdLTQvhoe1UYmHyAS1AKsSD/egcAWlprSQQsHVlULdacYVq8TT02oSFP33dDKhEQUzDXY7my9kDuhLstC3ncZAUDhGx1CmufWCI7Dvkk786zmHjOvYAoFAIJgdmPUEBQCKlcZlHvKgZJIJ1ZbbtIJiKBn1FBQqZdgKip3Kmi+FRlciC0Q2BvNlK+SNn0O+VFWkiBSUlkxSUzpMDwqgqyamgvLRt++B3s4cvvjnb466FQCAnbvHR1DG4iM5eo8F+O+/eRsO2mXeuI4tEAgEgtmBOUFQmom7Lzo8KM0OCzTNqiFBCQkOqRmLOwNSMGJ6UBwqyGixos6BzonCyvpHS/WnGZcrGKx1DnUwosGVjwXtdjlkt/mt6mczOfZNvR144G+Pw4eP3s1xF4BlPQExOfWAsY0u+NxJKwAAX3/vAWPaXiAQCAQ7DiZ1Fs9kg/ydwUJevzOkxBSUsZZ4SMkISzxcQQl+XtShKyguo2tY4qmq55EHhQjKwGgpwiRbS5ItVVWLMp/ky2femB4UAHjz0i48trYPgHtycD38+hNvwxtDBey5qD3WdoSPvWMPnHXYssgwN4FAIBAICLOaoGRTCRTRXNx9gTwoKW/MJlnygnTUKfEsqiko5rDAnMsky9qMyYPiJCgRHhTiR3ySMCko2VTCiqMHgH2XdqqfTQWlEbpa0+NOZBVyIhAIBIJmMKsJSi6VQLHaXCdP0aGgjNuDMmqXeHojPCh8no6Wg6JKPKTOBPveOlxUCkkuwoNCxMlUUIDAf+LKJdl3SUhQ4iooAoFAIBBMFWb1CpVJJYFic1koPAeFTLLjLvE4gtrIJKtyUFQXT5QHxa2g8LRXl4LCz73dQVDMDh7Cm3rDBNg405wFAoFAIJhKzGqTbJiq2ryCkk4m1GC74WJFa1GuVn38+OG1eHbjgLZtpEmWeVAGjRKPSpJ1dPHwEg+ZadsNk+xmRlAySZugEDwPaM84CEqbm6Dw7dduG3Y+RyAQCASC6casJihhqmrzCko2lVDllErV17b9v+c347M/fRInXnuftq3pBaEyDHXxFMoVRYBUm3GpgmrVrxt1r3tQaupMjfxsGQoISiaZQIJlkJhD/NozKe3xI5b3IJtK4Ji9Fkbei3etWAQAOOuwXSKfIxAIBALBdGJWl3iCxboaW0HhQ/GGCmWlKqzfPqr+PpgvKfOpOfAvzCoJFBTerrywI1BQfD8o77ii7pUHpRhG3Zttxvo1Rv/O/ScAcOhuPfjjF0/QJgCbuOEDB+PZjQM4cFl35HMEAoFAIJhOzG4FRZlNm+jiYVH3iYSnFAtulOXzZp5c38+21Us8ZhcQ+U9aM0mt3DJcqLg7cViJZ6igKygWQUnrL1EqmUCKKSbtOZtj1iMnQFBiOmiXeXWH+wkEAoFAMJ2Y1QSFYtv5rJwolCqB14T8HK4sFOq8AYDH1/Wpn0OTrL4tKScUmNaeTWnkZ6RYrqugBB6UstoWCBQRzhtMzwmgz9ThLcYCgUAgEMwVzGqCkmOD8xpBlXgsFSQkN/znNU6CEhAD8rAMF8vwfd+aiUNKzEix4oy6b+FdPDSLp3Y+iYSntf8umxcmvxL2Whx24pglHoFAIBAI5gJmNUHJJpvv4lFtxkpBsUs8XEFZs65PdfgUSnpQGxEI3w9ICJV42mtqBu1bU1C0oLbg58F8WREnHqrGyzy7L2yzruUtLGxNFBSBQCAQzEXMboKSbr6Lh8/iAaCMsrzEwxWUNwYL6BspafunEk9LOgmygQwXymofNBOHFBTNg8JKPFS22TocthJz/4tOUOxY+Tfv1KV+lrA1gUAgEMxFzGqCMpYcFFJQXHH3XEEBgjRXwC7xeJ6nERzKQKF9tjEDrlNBMcy96aSniBMQthoDwO4LXApKSFCkxCMQCASCuYhZTVAyMXJQLAXFYZIlPwhh+wgRFHuqMDfKhiWelPbvQD6cp5NzBLWZ+yJw0uEq8ey1OFRV+kdK1uMCgUAgEMx2zGqCkkvFV1DSSXcnDhCmvxK2kYJSsluF21hc/hDr4gGAebWBeJsGWFx9ylZQ1L4yOkEZZkrOzg6TLG8jHmni2gUCgUAgmG2Y1QQlTJK1F+lyparF2BfLuoISzuMJFYjhYgRBcfhIeIloyOji6a5N/N04kFfP5wqK2TrcaigqW4eK6udkwp1V8venvwVLu3L4xDv3dD4uEAgEAsFsxqw2MGTTweJdMNqM86UKTvvm/cikEvjFRW9FIuGxLp5gm7DEwxSUWolnQXsGW4aKjKDUKfEUy1abMSkoG/sDgpJMeJrqkU0l4HlBFxAQthgTFrRnAQzWvfYPHbkrPnTkrnWfIxAIBALBbMWcUFDyhoLyn4+ux3ObBvHka/3YUuuUsRUU2yRLP+9UK6tsNxWUtE1QdJNsoJzMqykor9cISs6Ip/c8TxvmR2oO4e9PfwuO2XMBbv3IEY1vgkAgEAgEcxCznKDUkmSZguL7Pm7+/Svq9039NYJSifKg8C6egOgsm9cCwPag5BqUeNpViYc8KAFByTrSYHdfEBpdWw0PyvIFbfjhR47A0XsuiL54gUAgEAjmMGY1QSEvB1dQHlu7HS9sHlK/E0kwFRRnF0/tZzKmbjO7eJwm2YqVg0IlHiI4poICBCRE7StjExiBQCAQCHZkzGqCQm3Go6w9mE8kBkKjarFi5qCEcfVAoLwoBaUnUFCoxJMv2SZZrsAQQWk3TLIEs60Y0NuHTQ+KQCAQCAQ7OmY1QXHN0xnI6504m2sEhUyyaSNJlrYtVqooVwPXKs2/2VrHJNueCQkKmWTpfEyCsrS7xTp3UVAEAoFAIIjGrCYoPIuEMDCqB5dtNEo82YhpxiOM5Ow0T1dQXG3GfHtqVTa7eAjLeuwsEx5hb3pQBAKBQCDY0THLCUqwsA/mQ1IyUPu5s0YWNtbC0kqVQB2xpxkHBIVKPbl0otbmGyTL5kuViC6egKz0j5ZUCaij1sXTmkmqUhIA7OIgKPxvQ0ZAnEAgEAgEOzpmNUHpZCoGhbJRuWWvxR0AwhKPOYuHyM1IsYJqNfSftGVS6MylkKoFpG0fKYbTjB05KJR1EvwtnNXDyzwugsJn72xigW4CgUAgEAhmOUFpq6kkVR8YrZEIKvHstSgooVCJpxCRgwIE6gkpKa3ZJDzPw7y2sBOnXomH9t+STiLFVBNe5nERFAB4y06dAICT91sS57IFAoFAIJjzmNXmh5Z0EgkvICiD+TJaMyllkt2zRlD6RkrIlyqhSbZGInLphNp2uFBRZlkyz85vy+CNwQLeGCwo86xmklXlJb2Dh8DLQS4PCgDcesGReGHTIA7eZd447oJAIBAIBHMPs1pB8TzPIgrkR1nW06rUks0DhdAkW/ub53ma0ZU8KDQXx4yrBwwPimFs7TBahYdYN1FXi97VQ+jMpXHIrj3wPPe8HYFAIBAIdlRMCkF57bXX8MEPfhDz589HS0sL9ttvPzzyyCPqcd/3ceWVV2LJkiVoaWnBypUr8cILL4zpWB25YPEnoymVeDpzafR25gAEZRhTQQF0o+xIjaAQaemplXheZwQl49hW/W4oKGa7s0AgEAgEguYx4QRl+/bteOtb34p0Oo3/+Z//wdNPP41vfOMbmDcvLGNcc801uO6663DjjTfiwQcfRFtbG0444QTk8/HNotTaO6QUlODfzpYU5rcHJGPrUFimyTjKNMOFsirxkIJCBIUUlFTC0zwmbcb8nA6zxONIjxUIBAKBQNAcJtyD8rWvfQ3Lli3DTTfdpP62fPly9bPv+7j22mtx+eWX47TTTgMA3HLLLVi8eDFuv/12nHXWWbGO167KNIFyErYZp1VpZctQQT0/4+jEGeIKSq10QybZDf1BMq1JONpMBcX4/R/PPACf+PfH8flT9411PQKBQCAQCCZBQfnlL3+JQw89FO9973uxaNEiHHTQQfjXf/1X9fjLL7+MjRs3YuXKlepvXV1dOOKII7B69WrnPguFAgYGBrT/CFRaGciXUSxXVSYJJyhvDBXV89PJ0O+hFJQiU1BqykhPrU2YFBRz4F82lcCCdj6RWPeZHLH7fDz8dytxyv5LI+6UQCAQCASCKEw4QXnppZfwrW99C3vttRfuvPNOfPzjH8df//Vf4+abbwYAbNy4EQCwePFibbvFixerx0xcffXV6OrqUv8tW7ZMPaYUlHxZC2xrz6XQmXMoKI4yDR/4pzwotbA2RVAMBcXzPBy4rFv9bpZ4BAKBQCAQjB0TTlCq1SoOPvhgfOUrX8FBBx2ECy+8EBdccAFuvPHGMe/zsssuQ39/v/pv3bp16jHlQSmUlTG1PZtCMuGFCspgQFDSSU/rmOED//pGAnLT3RKoIj21Lp7BGnFxeUo4QTFLPAKBQCAQCMaOCScoS5Yswb776r6LffbZB2vXrgUA9Pb2AgA2bdqkPWfTpk3qMRPZbBadnZ3af4R25iMJO3iCv5keFK6e8G2HC2X017albea16SUbHtJGOHBZaPw1u3gEAoFAIBCMHRNOUN761rfiueee0/72/PPPY9dddwUQGGZ7e3tx1113qccHBgbw4IMP4qijjop9PGozHsyXWQdPuvZvQBqIoKQjjK6c3BBBmd+W1Z5LAwQ59tu5S/1MOSsCgUAgEAjGjwn/2v+pT30KRx99NL7yla/gzDPPxEMPPYTvfOc7+M53vgMg8G5cfPHF+NKXvoS99toLy5cvxxVXXIGlS5fi9NNPj328djYwkDp4OkwFZTAwydZTUPpGg+fQDB0+SwcAdl/QZh2bB7DVRgEJBAKBQCCYAEw4QTnssMPw85//HJdddhmuuuoqLF++HNdeey3OPvts9ZxLL70Uw8PDuPDCC9HX14djjjkGd9xxB3K5XOzjtedcJZ609i/N6cmYCkot82S4ULFKPLl0Em2ZJIZrQwR3X9juPP517z8IP3tsPT501K6xz10gEAgEAoEbk2KcOOWUU3DKKadEPu55Hq666ipcddVV4z5Wh9bFE5R4SEHpNCLmTQWFl3hMggIAPe0ZDG8LclB2X2grKADw5wcsxZ8fIK3EAoFAIBBMJGZ93KmmoFBIW41kmDNwTAWFSjzbhosqP6WLlXb4vJ0ogiIQCAQCgWDiMesJCjfJbh8JfCRdyiSrE5R0hIKyoS9QSRIe0M5IySCbp7OwXTfNCgQCgUAgmDzMeoLCTbKbB4JunUUdAZnoyKbABwUv7dY9LkRQtg4HxKazJY1EItyACA8AmTgsEAgEAsEUYtYTFB7UtqkWyLawIyAiiYSnPCoAsNeiDm1bM1yt21Bc5rVmIBAIBAKBYOox6wkKlXOqPvCnzUMAgMWdYTmGe0r2Wqx34pgTiU3PynXvPwgrejvwo48cMaHnLBAIBAKBoD5mffxpLp3Ewo4s3hgsqHk6izrDUk7Qahx4TPZcpBMUU0ExPSuH7DoPd1z89kk4a4FAIBAIBPUw6xUUAFhmpLxyQ2upEia87mFkmXTk0silw1vQLSUdgUAgEAhmBOYGQelpVT/3tGW0duLNg+Ek41xaL+kkEx4O2Llb/d7VMusFJYFAIBAI5gTmBkGZFxIU6uAh0JTiKByyazjwz/SgCAQCgUAgmB7MDYLSE5Z4uP8EAN5/+DIAwKkRaa+coHS3SIlHIBAIBIKZgDlR09iZKSiLDQXl8pP3xTF7LsSxb1ro3PagXUKC4kMm/gkEAoFAMBMwJwiKVuLp1AlKWzaFk/dfErltT1uomrRm5sTtEAgEAoFg1mNOrMhLunNIeEEWyqKO+BORbz7vcPzm6U044+CdJ+HsBAKBQCAQxMWcICjpZAJLulrwWt+oFtLWLN6x90K8Y293CUggEAgEAsHUY06YZAHgzEOXYY+FbThst57pPhWBQCAQCATjhOf7/qxzhg4MDKCrqwv9/f3o7Oyc7tMRCAQCgUDQBOKs33NGQREIBAKBQDB3IARFIBAIBALBjIMQFIFAIBAIBDMOQlAEAoFAIBDMOAhBEQgEAoFAMOMgBEUgEAgEAsGMgxAUgUAgEAgEMw5CUAQCgUAgEMw4CEERCAQCgUAw4yAERSAQCAQCwYyDEBSBQCAQCAQzDkJQBAKBQCAQzDgIQREIBAKBQDDjIARFIBAIBALBjENquk9gLPB9H0AwtlkgEAgEAsHsAK3btI7Xw6wkKIODgwCAZcuWTfOZCAQCgUAgiIvBwUF0dXXVfY7nN0NjZhiq1Sr23ntvPProo/A8L/b2hx12GB5++OExHXs6th0YGMCyZcuwbt06dHZ2TtlxZ+O2471X4zn2bNxW3lvNQ+5V85B71Tx2tHvl+z4OOeQQPP/880gk6rtMZqWCkkgkkMlkGrKvKCSTyTEvXtO1LQB0dnaOafvZeL3Tda/Ge+zZuC0g7604kHvVPOReNY8d6V5lMpmG5ASYxSbZiy66aIfadjyYjdc7XfdqvMeejduOB7PxeuVeTc2248FsvF65VxO/7aws8exoGBgYQFdXF/r7+8fF0HcEyL2KB7lfzUPuVfOQe9U85F5FY9YqKDsSstksPv/5zyObzU73qcx4yL2KB7lfzUPuVfOQe9U85F5FQxQUgUAgEAgEMw6ioAgEAoFAIJhxEIIiEAgEAoFgxkEIikAgEAgEghkHISgCgUAgEAhmHISgTBHuvfdenHrqqVi6dCk8z8Ptt9+uPb5p0yace+65WLp0KVpbW3HiiSfihRde0J6zceNGfOhDH0Jvby/a2tpw8MEH46c//an2nMceewx/9md/hu7ubsyfPx8XXnghhoaGJvvyJhQTca/+9Kc/4S/+4i+wcOFCdHZ24swzz8SmTZucxysUCjjwwAPheR7WrFkzSVc1OZiqezUX3ldXX301DjvsMHR0dGDRokU4/fTT8dxzz2nPyefzuOiiizB//ny0t7fjjDPOsO7F2rVrcfLJJ6O1tRWLFi3CZz7zGZTLZecx77//fqRSKRx44IGTdVmTgqm8VzfccAP22WcftLS04E1vehNuueWWSb++icZE3a+//uu/xiGHHIJsNtvwPfPiiy+io6MD3d3dE3w1MwdCUKYIw8PDOOCAA3DDDTdYj/m+j9NPPx0vvfQSfvGLX+Dxxx/HrrvuipUrV2J4eFg975xzzsFzzz2HX/7yl3jyySfxnve8B2eeeSYef/xxAMCGDRuwcuVK7LnnnnjwwQdxxx134KmnnsK55547VZc5IRjvvRoeHsbxxx8Pz/Nw99134/7770exWMSpp56KarVq7fPSSy/F0qVLJ/26JgNTca/myvvqnnvuwUUXXYQHHngAq1atQqlUwvHHH6/9P/apT30Kv/rVr3DbbbfhnnvuwYYNG/Ce97xHPV6pVHDyySejWCzi97//PW6++WZ8//vfx5VXXmkdr6+vD+eccw6OO+64Kbm+icRU3atvfetbuOyyy/CFL3wBTz31FL74xS/ioosuwq9+9aspvd7xYiLuF+G8887D+973vrrHK5VKeP/734+3ve1tE34tMwq+YMoBwP/5z3+ufn/uued8AP4f//hH9bdKpeIvXLjQ/9d//Vf1t7a2Nv+WW27R9tXT06Oe8+1vf9tftGiRX6lU1ONPPPGED8B/4YUXJulqJhdjuVd33nmnn0gk/P7+fvWcvr4+3/M8f9WqVdr+//u//9tfsWKF/9RTT/kA/Mcff3xSr2cyMVn3ai6+r3zf9zdv3uwD8O+55x7f94PrTqfT/m233aae88wzz/gA/NWrV/u+H7xfEomEv3HjRvWcb33rW35nZ6dfKBS0/b/vfe/zL7/8cv/zn/+8f8ABB0z+BU0iJuteHXXUUf6nP/1p7ViXXHKJ/9a3vnWyL2lSMZb7xdHoPXPppZf6H/zgB/2bbrrJ7+rqmujTnzEQBWUGoFAoAAByuZz6WyKRQDabxe9+9zv1t6OPPho//vGPsW3bNlSrVfzHf/wH8vk8jj32WLUfc8ZBS0sLAGj7mc1o5l4VCgV4nqcFH+VyOSQSCe0+bNq0CRdccAF+8IMfoLW1dYquYOowUfdqrr6v+vv7AQA9PT0AgEcffRSlUgkrV65Uz1mxYgV22WUXrF69GgCwevVq7Lfffli8eLF6zgknnICBgQE89dRT6m833XQTXnrpJXz+85+fikuZdEzWvSoUCtr7EwjeWw899BBKpdKkXtNkYiz3q1ncfffduO2225yq6VyDEJQZAHqjXnbZZdi+fTuKxSK+9rWvYf369Xj99dfV837yk5+gVCph/vz5yGaz+OhHP4qf//zn2HPPPQEA73rXu7Bx40b8wz/8A4rFIrZv347Pfe5zAKDtZzajmXt15JFHoq2tDZ/97GcxMjKC4eFhfPrTn0alUlHP8X0f5557Lj72sY/h0EMPnc5LmjRM1L2ai++rarWKiy++GG9961vxlre8BUDg8cpkMlZNf/Hixdi4caN6Dl9w6XF6DABeeOEFfO5zn8MPf/hDpFKzch6rhsm8VyeccAK++93v4tFHH4Xv+3jkkUfw3e9+F6VSCVu2bJnkK5scjPV+NYOtW7fi3HPPxfe///0dIhZfCMoMQDqdxs9+9jM8//zz6OnpQWtrK37729/ipJNO0r61XnHFFejr68NvfvMbPPLII7jkkktw5pln4sknnwQAvPnNb8bNN9+Mb3zjG2htbUVvby+WL1+OxYsXNzU5cjagmXu1cOFC3HbbbfjVr36F9vZ2dHV1oa+vDwcffLB6zvXXX4/BwUFcdtll03k5k4qJuldz8X110UUX4Y9//CP+4z/+Y0L3W6lU8IEPfABf/OIXsffee0/ovqcLk3WvgOAz7aSTTsKRRx6JdDqN0047DR/+8IcBQN5bDlxwwQX4wAc+gLe//e0Tvu8ZiemuMe2IgOEV4Ojr6/M3b97s+77vH3744f5f/dVf+b7v+y+++KLlJ/B93z/uuOP8j370o9Z+Nm7c6A8ODvpDQ0N+IpHwf/KTn0zsRUwRxnKvON544w1/+/btvu/7/uLFi/1rrrnG933fP+200/xEIuEnk0n1HwA/mUz655xzzqRcy2Rjsu4Vx1x4X1100UX+zjvv7L/00kva3++66y4fgLoHhF122cX/x3/8R9/3ff+KK66wvAEvvfSSD8B/7LHH/O3bt6v3Ef3neZ7621133TWZlzbhmMx7xVEsFv1169b55XLZ/5d/+Re/o6ND8zzNFoznfnFEeVC6urq091YikVDvre9973sTeSkzAkJQpgH1FhLC888/7ycSCf/OO+/0fT80JT799NPa844//nj/ggsuiNzP9773Pb+1tdX6H2O2YCz3yoW77rrL9zzPf/bZZ33f9/1XX33Vf/LJJ9V/d955pw/A/8///E9/3bp1E3kJU4bJulcuzMb3VbVa9S+66CJ/6f/f3v2FNNn2cQD/zr0azrJamaVlFqUnptlBoWBRVBgZlRAW0TI6aJOgP0pRdNBBNYomqR3UiRoShEjoQbiD3HZQiNRYuFo6DZcny4qwGuZ02+85iGc8e9SXF9rmre/3Azu5r2v3ff9+3IMvN9fFMjLE7XZPGf97IWNbW1v4WF9f37QLP0dGRsJzHj58KKmpqTI+Pi7BYDDiuXI6nWIwGCQ3N1ecTqf4fL7YFxoF8ejVTLZv3y7Hjh2LYjWxF41+/dNMAcXlckU8Wzdu3JBFixaJ0+mUb9++RbUmJWBAiZOfP3+Kw+EQh8MhAKS2tlYcDod8/PhRRERaW1vFarXKhw8fpL29XdauXSvl5eXh709MTMiGDRukpKREenp6ZHBwUO7evSsqlUqePXsWntfQ0CB2u136+/vl/v37kpycLHV1dXGv90/8aa9ERBobG6W7u1sGBwelpaVFtFqtXLx4ccZrDg0NzcldPPHq1Xx4rgwGgyxevFhsNpt4vd7wZ2xsLDxHr9dLVlaWWCwWef36tRQVFUlRUVF4PBAISF5enuzdu1fevHkjZrNZ0tLS5MqVKzNedy7u4olXr/r7+6WlpUXcbrf09PRIRUWFaLVaGRoaime5fywa/RIRGRgYEIfDIWfOnJGcnJzwb/vfO8T+Nt938TCgxInVahUAUz4nT54UEZG6ujpZvXq1JCYmSlZWlly7dm3KQ+l2u6W8vFxWrFghGo1G8vPzp2w7PnHihGi1WklKSpp2fC6IRq8uX74s6enpkpiYKBs3bhSTySShUGjGa87VgBKvXs2H52q6PgGQpqam8Jxfv35JVVWVLF26VDQajRw+fFi8Xm/EeTwej+zbt0+Sk5Nl+fLlUl1dLZOTkzNedy4GlHj1yuVyyebNmyU5OVlSU1Pl4MGD//XNnVJFq187duyY9jwzBbb5HlBUIiJ/vpKFiIiIKHrm5jJpIiIimtcYUIiIiEhxGFCIiIhIcRhQiIiISHEYUIiIiEhxGFCIiIhIcRhQiIiISHEYUIiIiEhxGFCIiIhIcRhQiCgmKisroVKpoFKpkJiYiPT0dOzZsweNjY0IhUL/83mam5uxZMmS2N0oESkSAwoRxUxpaSm8Xi88Hg86Ozuxc+dOnDt3DmVlZQgEArN9e0SkYAwoRBQzCxYswMqVK5GZmYktW7bg6tWr6OjoQGdnJ5qbmwEAtbW12LRpE1JSUrBmzRpUVVXB5/MBAGw2G06dOoXv37+H38Zcv34dAOD3+1FTU4PMzEykpKRg27ZtsNlss1MoEUUdAwoRxdWuXbtQUFCAp0+fAgASEhJQX1+Pd+/e4dGjR7BYLLh06RIAoLi4GPfu3UNqaiq8Xi+8Xi9qamoAAGfPnkV3dzeePHmC3t5eHDlyBKWlpRgYGJi12ogoevhvxkQUE5WVlRgdHUV7e/uUsaNHj6K3txcul2vKWFtbG/R6Pb5+/Qrg9xqU8+fPY3R0NDxneHgY69evx/DwMDIyMsLHd+/eja1bt+LWrVtRr4eI4us/s30DRPT/R0SgUqkAAM+fP4fRaERfXx9+/PiBQCCA8fFxjI2NQaPRTPt9p9OJYDCInJyciON+vx/Lli2L+f0TUewxoBBR3L1//x7r1q2Dx+NBWVkZDAYDbt68Ca1WixcvXuD06dOYmJiYMaD4fD6o1WrY7Xao1eqIsYULF8ajBCKKMQYUIoori8UCp9OJCxcuwG63IxQKwWQyISHh95K41tbWiPlJSUkIBoMRxwoLCxEMBvH582eUlJTE7d6JKH4YUIgoZvx+Pz59+oRgMIiRkRGYzWYYjUaUlZVBp9Ph7du3mJycRENDAw4cOICXL1/iwYMHEefIzs6Gz+dDV1cXCgoKoNFokJOTg+PHj0On08FkMqGwsBBfvnxBV1cX8vPzsX///lmqmIiihbt4iChmzGYzVq1ahezsbJSWlsJqtaK+vh4dHR1Qq9UoKChAbW0tbt++jby8PDx+/BhGozHiHMXFxdDr9aioqEBaWhru3LkDAGhqaoJOp0N1dTVyc3Nx6NAhvHr1CllZWbNRKhFFGXfxEBERkeLwDQoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKc5f64zSvctvCBAAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.plot();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXj1Z6_vgSIZ"
      },
      "source": [
        "---\n",
        "### 2.1 Load and prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Yd1P3PV4nZ2X"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(dataset, look_back):\n",
        "    \"\"\"Transform a time series data into a prediction dataset\n",
        "\n",
        "    Args:\n",
        "        dataset: A numpy array of time series, first dimension is the time steps\n",
        "        look_back: Size of window for prediction\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    dataset = np.array(dataset)\n",
        "    data_length = len(dataset)\n",
        "    for i in range(look_back, data_length):\n",
        "        input = dataset[i-look_back: i]\n",
        "        output = dataset[i]\n",
        "        X.append(input)\n",
        "        y.append(output)\n",
        "\n",
        "    return torch.tensor(np.array(X)), torch.tensor(np.array(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsSFy2eNF5e-",
        "outputId": "7d4d2033-7ea8-48dc-e787-5453b652bf83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH2FMeIhh169",
        "outputId": "f9e3336c-d21f-4f9c-fc7a-59f2bc2d9a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train data -> torch.Size([237, 60, 1]) \n",
            "Shape of y_train data -> torch.Size([237, 1]) \n",
            "Shape of X_val data -> torch.Size([40, 60, 1]) \n",
            "Shape of y_val data -> torch.Size([40, 1]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "look_back = 60\n",
        "\n",
        "data_length = len(df)\n",
        "\n",
        "train_data_size = int(data_length * 0.75)\n",
        "validaion_data_size = int(data_length * 0.25)\n",
        "\n",
        "\n",
        "train_data = df[: train_data_size]\n",
        "validation_data = df[train_data_size: ]\n",
        "\n",
        "\n",
        "X_train, y_train = prepare_dataset(train_data, look_back)\n",
        "X_val, y_val = prepare_dataset(validation_data, look_back)\n",
        "\n",
        "\n",
        "X_train = X_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "X_val = X_val.to(device)\n",
        "y_val = y_val.to(device)\n",
        "\n",
        "\n",
        "print(  f\"Shape of X_train data -> {X_train.shape} \\n\"\n",
        "        f\"Shape of y_train data -> {y_train.shape} \\n\"\n",
        "        f\"Shape of X_val data -> {X_val.shape} \\n\"\n",
        "        f\"Shape of y_val data -> {y_val.shape} \\n\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u78V0kKvjp8f"
      },
      "source": [
        "---\n",
        "---\n",
        "## 3 Trainer function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oEIg5tjsjnEi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import copy\n",
        "\n",
        "def trainer(model, X_train, y_train, X_val, y_val, optimizer, criterion, n_epochs):\n",
        "    early_stopping_patience = 150\n",
        "    early_stopping_counter = 0\n",
        "\n",
        "    valid_loss_min=np.inf\n",
        "    best_model = copy.deepcopy(model)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "\n",
        "        # Forward pass\n",
        "        output_train = model(X_train)\n",
        "        # Compute loss\n",
        "        train_loss = criterion(output_train, y_train)\n",
        "        train_losses.append(train_loss.item())\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            output_val = model(X_val)\n",
        "            valid_loss = criterion(output_val, y_val)\n",
        "            val_losses.append(valid_loss.item())\n",
        "\n",
        "            if valid_loss <= valid_loss_min:\n",
        "                best_model = copy.deepcopy(model)\n",
        "                print(f'Epoch {epoch + 0:01}: Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).')\n",
        "                valid_loss_min = valid_loss\n",
        "                early_stopping_counter = 0    # Reset counter if validation loss decreases\n",
        "            else:\n",
        "                print(f'Epoch {epoch + 0:01}: Validation loss did not decrease')\n",
        "                early_stopping_counter += 1\n",
        "\n",
        "            if early_stopping_counter > early_stopping_patience:\n",
        "                print('Early stopped at epoch :', epoch)\n",
        "                break\n",
        "\n",
        "            print(f'\\t Train_Loss: {train_loss:.4f} Val_Loss: {valid_loss:.4f}  BEST VAL Loss: {valid_loss_min:.4f}\\n')\n",
        "\n",
        "    return best_model, train_losses, val_losses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIfT0qVkOTzG"
      },
      "source": [
        "---\n",
        "---\n",
        "## 4 RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwmm5DhEBl8d"
      },
      "source": [
        "---\n",
        "### 4.1 Define single RNN cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5YeW2H2cKsH7"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class RNNCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, bias=True, nonlinearity=\"tanh\"):\n",
        "        super(RNNCell, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bias = bias\n",
        "        self.nonlinearity = nonlinearity\n",
        "\n",
        "        # Define the layers\n",
        "        self.x2h = nn.Linear(input_size, hidden_size, bias=bias)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        std = 1.0 / np.sqrt(self.hidden_size)\n",
        "        for w in self.parameters():\n",
        "            w.data.uniform_(-std, std)\n",
        "\n",
        "    def forward(self, input, hx=None):\n",
        "        if hx is None:\n",
        "            hx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
        "\n",
        "        gates = self.x2h(input) + self.h2h(hx)\n",
        "\n",
        "        if self.nonlinearity == \"tanh\":\n",
        "            hy = torch.tanh(gates)\n",
        "        elif self.nonlinearity == \"relu\":\n",
        "            hy = torch.relu(gates)\n",
        "        else:\n",
        "            raise RuntimeError(\n",
        "                \"Unknown nonlinearity: {}\".format(self.nonlinearity))\n",
        "\n",
        "        return hy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ay_sL8ZBq1R"
      },
      "source": [
        "---\n",
        "### 4.2 RNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KAcO44hi5HUf"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, bias, output_size):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, bias=bias, batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hx=None):\n",
        "        out, _ = self.rnn(input, hx)\n",
        "\n",
        "        # Only take the output from the final timestep\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msF4j7_fB6S5"
      },
      "source": [
        "---\n",
        "### 4.3 Train RNN model and plot losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwHvK1bI5GBz",
        "outputId": "2bdb06c8-aaf4-4ed2-c66c-4d5071597b37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SimpleRNN(\n",
              "  (rnn): RNN(1, 50, batch_first=True)\n",
              "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Instantiate model\n",
        "SimpleRNN_model = SimpleRNN(input_size=1, hidden_size=50, num_layers=1, bias=True, output_size=1)\n",
        "SimpleRNN_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "431lZ_uOlpsQ"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.008\n",
        "n_epochs = 2000\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(SimpleRNN_model.parameters(), lr = learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWMAFQBKQ5mq",
        "outputId": "44c6ff14-840c-4e27-f4d3-1399502afdef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 192: Validation loss decreased (1752.320557 --> 1735.432007).\n",
            "\t Train_Loss: 829.7449 Val_Loss: 1735.4320  BEST VAL Loss: 1735.4320\n",
            "\n",
            "Epoch 193: Validation loss decreased (1735.432007 --> 1718.722046).\n",
            "\t Train_Loss: 818.8247 Val_Loss: 1718.7220  BEST VAL Loss: 1718.7220\n",
            "\n",
            "Epoch 194: Validation loss decreased (1718.722046 --> 1702.191772).\n",
            "\t Train_Loss: 808.0508 Val_Loss: 1702.1918  BEST VAL Loss: 1702.1918\n",
            "\n",
            "Epoch 195: Validation loss decreased (1702.191772 --> 1685.838501).\n",
            "\t Train_Loss: 797.4228 Val_Loss: 1685.8385  BEST VAL Loss: 1685.8385\n",
            "\n",
            "Epoch 196: Validation loss decreased (1685.838501 --> 1669.659424).\n",
            "\t Train_Loss: 786.9384 Val_Loss: 1669.6594  BEST VAL Loss: 1669.6594\n",
            "\n",
            "Epoch 197: Validation loss decreased (1669.659424 --> 1653.655029).\n",
            "\t Train_Loss: 776.5960 Val_Loss: 1653.6550  BEST VAL Loss: 1653.6550\n",
            "\n",
            "Epoch 198: Validation loss decreased (1653.655029 --> 1637.822388).\n",
            "\t Train_Loss: 766.3950 Val_Loss: 1637.8224  BEST VAL Loss: 1637.8224\n",
            "\n",
            "Epoch 199: Validation loss decreased (1637.822388 --> 1622.160156).\n",
            "\t Train_Loss: 756.3328 Val_Loss: 1622.1602  BEST VAL Loss: 1622.1602\n",
            "\n",
            "Epoch 200: Validation loss decreased (1622.160156 --> 1606.666870).\n",
            "\t Train_Loss: 746.4085 Val_Loss: 1606.6669  BEST VAL Loss: 1606.6669\n",
            "\n",
            "Epoch 201: Validation loss decreased (1606.666870 --> 1591.341187).\n",
            "\t Train_Loss: 736.6202 Val_Loss: 1591.3412  BEST VAL Loss: 1591.3412\n",
            "\n",
            "Epoch 202: Validation loss decreased (1591.341187 --> 1576.181396).\n",
            "\t Train_Loss: 726.9672 Val_Loss: 1576.1814  BEST VAL Loss: 1576.1814\n",
            "\n",
            "Epoch 203: Validation loss decreased (1576.181396 --> 1561.186035).\n",
            "\t Train_Loss: 717.4470 Val_Loss: 1561.1860  BEST VAL Loss: 1561.1860\n",
            "\n",
            "Epoch 204: Validation loss decreased (1561.186035 --> 1546.354004).\n",
            "\t Train_Loss: 708.0590 Val_Loss: 1546.3540  BEST VAL Loss: 1546.3540\n",
            "\n",
            "Epoch 205: Validation loss decreased (1546.354004 --> 1531.683350).\n",
            "\t Train_Loss: 698.8016 Val_Loss: 1531.6833  BEST VAL Loss: 1531.6833\n",
            "\n",
            "Epoch 206: Validation loss decreased (1531.683350 --> 1517.172485).\n",
            "\t Train_Loss: 689.6732 Val_Loss: 1517.1725  BEST VAL Loss: 1517.1725\n",
            "\n",
            "Epoch 207: Validation loss decreased (1517.172485 --> 1502.820557).\n",
            "\t Train_Loss: 680.6722 Val_Loss: 1502.8206  BEST VAL Loss: 1502.8206\n",
            "\n",
            "Epoch 208: Validation loss decreased (1502.820557 --> 1488.624634).\n",
            "\t Train_Loss: 671.7977 Val_Loss: 1488.6246  BEST VAL Loss: 1488.6246\n",
            "\n",
            "Epoch 209: Validation loss decreased (1488.624634 --> 1474.585083).\n",
            "\t Train_Loss: 663.0475 Val_Loss: 1474.5851  BEST VAL Loss: 1474.5851\n",
            "\n",
            "Epoch 210: Validation loss decreased (1474.585083 --> 1460.699707).\n",
            "\t Train_Loss: 654.4210 Val_Loss: 1460.6997  BEST VAL Loss: 1460.6997\n",
            "\n",
            "Epoch 211: Validation loss decreased (1460.699707 --> 1446.967041).\n",
            "\t Train_Loss: 645.9167 Val_Loss: 1446.9670  BEST VAL Loss: 1446.9670\n",
            "\n",
            "Epoch 212: Validation loss decreased (1446.967041 --> 1433.384766).\n",
            "\t Train_Loss: 637.5330 Val_Loss: 1433.3848  BEST VAL Loss: 1433.3848\n",
            "\n",
            "Epoch 213: Validation loss decreased (1433.384766 --> 1419.953003).\n",
            "\t Train_Loss: 629.2683 Val_Loss: 1419.9530  BEST VAL Loss: 1419.9530\n",
            "\n",
            "Epoch 214: Validation loss decreased (1419.953003 --> 1406.669189).\n",
            "\t Train_Loss: 621.1217 Val_Loss: 1406.6692  BEST VAL Loss: 1406.6692\n",
            "\n",
            "Epoch 215: Validation loss decreased (1406.669189 --> 1393.532959).\n",
            "\t Train_Loss: 613.0914 Val_Loss: 1393.5330  BEST VAL Loss: 1393.5330\n",
            "\n",
            "Epoch 216: Validation loss decreased (1393.532959 --> 1380.541870).\n",
            "\t Train_Loss: 605.1768 Val_Loss: 1380.5419  BEST VAL Loss: 1380.5419\n",
            "\n",
            "Epoch 217: Validation loss decreased (1380.541870 --> 1367.695312).\n",
            "\t Train_Loss: 597.3759 Val_Loss: 1367.6953  BEST VAL Loss: 1367.6953\n",
            "\n",
            "Epoch 218: Validation loss decreased (1367.695312 --> 1354.991211).\n",
            "\t Train_Loss: 589.6877 Val_Loss: 1354.9912  BEST VAL Loss: 1354.9912\n",
            "\n",
            "Epoch 219: Validation loss decreased (1354.991211 --> 1342.428955).\n",
            "\t Train_Loss: 582.1108 Val_Loss: 1342.4290  BEST VAL Loss: 1342.4290\n",
            "\n",
            "Epoch 220: Validation loss decreased (1342.428955 --> 1330.006226).\n",
            "\t Train_Loss: 574.6439 Val_Loss: 1330.0062  BEST VAL Loss: 1330.0062\n",
            "\n",
            "Epoch 221: Validation loss decreased (1330.006226 --> 1317.723877).\n",
            "\t Train_Loss: 567.2855 Val_Loss: 1317.7239  BEST VAL Loss: 1317.7239\n",
            "\n",
            "Epoch 222: Validation loss decreased (1317.723877 --> 1305.577148).\n",
            "\t Train_Loss: 560.0354 Val_Loss: 1305.5771  BEST VAL Loss: 1305.5771\n",
            "\n",
            "Epoch 223: Validation loss decreased (1305.577148 --> 1293.567627).\n",
            "\t Train_Loss: 552.8907 Val_Loss: 1293.5676  BEST VAL Loss: 1293.5676\n",
            "\n",
            "Epoch 224: Validation loss decreased (1293.567627 --> 1281.691162).\n",
            "\t Train_Loss: 545.8514 Val_Loss: 1281.6912  BEST VAL Loss: 1281.6912\n",
            "\n",
            "Epoch 225: Validation loss decreased (1281.691162 --> 1269.950317).\n",
            "\t Train_Loss: 538.9151 Val_Loss: 1269.9503  BEST VAL Loss: 1269.9503\n",
            "\n",
            "Epoch 226: Validation loss decreased (1269.950317 --> 1258.340210).\n",
            "\t Train_Loss: 532.0822 Val_Loss: 1258.3402  BEST VAL Loss: 1258.3402\n",
            "\n",
            "Epoch 227: Validation loss decreased (1258.340210 --> 1246.860840).\n",
            "\t Train_Loss: 525.3499 Val_Loss: 1246.8608  BEST VAL Loss: 1246.8608\n",
            "\n",
            "Epoch 228: Validation loss decreased (1246.860840 --> 1235.511963).\n",
            "\t Train_Loss: 518.7176 Val_Loss: 1235.5120  BEST VAL Loss: 1235.5120\n",
            "\n",
            "Epoch 229: Validation loss decreased (1235.511963 --> 1224.290405).\n",
            "\t Train_Loss: 512.1846 Val_Loss: 1224.2904  BEST VAL Loss: 1224.2904\n",
            "\n",
            "Epoch 230: Validation loss decreased (1224.290405 --> 1213.196533).\n",
            "\t Train_Loss: 505.7487 Val_Loss: 1213.1965  BEST VAL Loss: 1213.1965\n",
            "\n",
            "Epoch 231: Validation loss decreased (1213.196533 --> 1202.227783).\n",
            "\t Train_Loss: 499.4095 Val_Loss: 1202.2278  BEST VAL Loss: 1202.2278\n",
            "\n",
            "Epoch 232: Validation loss decreased (1202.227783 --> 1191.384155).\n",
            "\t Train_Loss: 493.1654 Val_Loss: 1191.3842  BEST VAL Loss: 1191.3842\n",
            "\n",
            "Epoch 233: Validation loss decreased (1191.384155 --> 1180.663452).\n",
            "\t Train_Loss: 487.0157 Val_Loss: 1180.6635  BEST VAL Loss: 1180.6635\n",
            "\n",
            "Epoch 234: Validation loss decreased (1180.663452 --> 1170.064331).\n",
            "\t Train_Loss: 480.9588 Val_Loss: 1170.0643  BEST VAL Loss: 1170.0643\n",
            "\n",
            "Epoch 235: Validation loss decreased (1170.064331 --> 1159.586426).\n",
            "\t Train_Loss: 474.9935 Val_Loss: 1159.5864  BEST VAL Loss: 1159.5864\n",
            "\n",
            "Epoch 236: Validation loss decreased (1159.586426 --> 1149.228271).\n",
            "\t Train_Loss: 469.1191 Val_Loss: 1149.2283  BEST VAL Loss: 1149.2283\n",
            "\n",
            "Epoch 237: Validation loss decreased (1149.228271 --> 1138.988037).\n",
            "\t Train_Loss: 463.3342 Val_Loss: 1138.9880  BEST VAL Loss: 1138.9880\n",
            "\n",
            "Epoch 238: Validation loss decreased (1138.988037 --> 1128.864990).\n",
            "\t Train_Loss: 457.6376 Val_Loss: 1128.8650  BEST VAL Loss: 1128.8650\n",
            "\n",
            "Epoch 239: Validation loss decreased (1128.864990 --> 1118.857666).\n",
            "\t Train_Loss: 452.0283 Val_Loss: 1118.8577  BEST VAL Loss: 1118.8577\n",
            "\n",
            "Epoch 240: Validation loss decreased (1118.857666 --> 1108.966064).\n",
            "\t Train_Loss: 446.5052 Val_Loss: 1108.9661  BEST VAL Loss: 1108.9661\n",
            "\n",
            "Epoch 241: Validation loss decreased (1108.966064 --> 1099.187378).\n",
            "\t Train_Loss: 441.0675 Val_Loss: 1099.1874  BEST VAL Loss: 1099.1874\n",
            "\n",
            "Epoch 242: Validation loss decreased (1099.187378 --> 1089.521484).\n",
            "\t Train_Loss: 435.7136 Val_Loss: 1089.5215  BEST VAL Loss: 1089.5215\n",
            "\n",
            "Epoch 243: Validation loss decreased (1089.521484 --> 1079.966187).\n",
            "\t Train_Loss: 430.4427 Val_Loss: 1079.9662  BEST VAL Loss: 1079.9662\n",
            "\n",
            "Epoch 244: Validation loss decreased (1079.966187 --> 1070.521973).\n",
            "\t Train_Loss: 425.2536 Val_Loss: 1070.5220  BEST VAL Loss: 1070.5220\n",
            "\n",
            "Epoch 245: Validation loss decreased (1070.521973 --> 1061.185913).\n",
            "\t Train_Loss: 420.1456 Val_Loss: 1061.1859  BEST VAL Loss: 1061.1859\n",
            "\n",
            "Epoch 246: Validation loss decreased (1061.185913 --> 1051.958252).\n",
            "\t Train_Loss: 415.1171 Val_Loss: 1051.9583  BEST VAL Loss: 1051.9583\n",
            "\n",
            "Epoch 247: Validation loss decreased (1051.958252 --> 1042.837646).\n",
            "\t Train_Loss: 410.1676 Val_Loss: 1042.8376  BEST VAL Loss: 1042.8376\n",
            "\n",
            "Epoch 248: Validation loss decreased (1042.837646 --> 1033.822266).\n",
            "\t Train_Loss: 405.2960 Val_Loss: 1033.8223  BEST VAL Loss: 1033.8223\n",
            "\n",
            "Epoch 249: Validation loss decreased (1033.822266 --> 1024.911377).\n",
            "\t Train_Loss: 400.5009 Val_Loss: 1024.9114  BEST VAL Loss: 1024.9114\n",
            "\n",
            "Epoch 250: Validation loss decreased (1024.911377 --> 1016.103882).\n",
            "\t Train_Loss: 395.7816 Val_Loss: 1016.1039  BEST VAL Loss: 1016.1039\n",
            "\n",
            "Epoch 251: Validation loss decreased (1016.103882 --> 1007.398804).\n",
            "\t Train_Loss: 391.1370 Val_Loss: 1007.3988  BEST VAL Loss: 1007.3988\n",
            "\n",
            "Epoch 252: Validation loss decreased (1007.398804 --> 998.795593).\n",
            "\t Train_Loss: 386.5662 Val_Loss: 998.7956  BEST VAL Loss: 998.7956\n",
            "\n",
            "Epoch 253: Validation loss decreased (998.795593 --> 990.292175).\n",
            "\t Train_Loss: 382.0685 Val_Loss: 990.2922  BEST VAL Loss: 990.2922\n",
            "\n",
            "Epoch 254: Validation loss decreased (990.292175 --> 981.887695).\n",
            "\t Train_Loss: 377.6424 Val_Loss: 981.8877  BEST VAL Loss: 981.8877\n",
            "\n",
            "Epoch 255: Validation loss decreased (981.887695 --> 973.582153).\n",
            "\t Train_Loss: 373.2870 Val_Loss: 973.5822  BEST VAL Loss: 973.5822\n",
            "\n",
            "Epoch 256: Validation loss decreased (973.582153 --> 965.373047).\n",
            "\t Train_Loss: 369.0020 Val_Loss: 965.3730  BEST VAL Loss: 965.3730\n",
            "\n",
            "Epoch 257: Validation loss decreased (965.373047 --> 957.260132).\n",
            "\t Train_Loss: 364.7856 Val_Loss: 957.2601  BEST VAL Loss: 957.2601\n",
            "\n",
            "Epoch 258: Validation loss decreased (957.260132 --> 949.241821).\n",
            "\t Train_Loss: 360.6374 Val_Loss: 949.2418  BEST VAL Loss: 949.2418\n",
            "\n",
            "Epoch 259: Validation loss decreased (949.241821 --> 941.317993).\n",
            "\t Train_Loss: 356.5562 Val_Loss: 941.3180  BEST VAL Loss: 941.3180\n",
            "\n",
            "Epoch 260: Validation loss decreased (941.317993 --> 933.487488).\n",
            "\t Train_Loss: 352.5414 Val_Loss: 933.4875  BEST VAL Loss: 933.4875\n",
            "\n",
            "Epoch 261: Validation loss decreased (933.487488 --> 925.748718).\n",
            "\t Train_Loss: 348.5919 Val_Loss: 925.7487  BEST VAL Loss: 925.7487\n",
            "\n",
            "Epoch 262: Validation loss decreased (925.748718 --> 918.100769).\n",
            "\t Train_Loss: 344.7068 Val_Loss: 918.1008  BEST VAL Loss: 918.1008\n",
            "\n",
            "Epoch 263: Validation loss decreased (918.100769 --> 910.543640).\n",
            "\t Train_Loss: 340.8853 Val_Loss: 910.5436  BEST VAL Loss: 910.5436\n",
            "\n",
            "Epoch 264: Validation loss decreased (910.543640 --> 903.075562).\n",
            "\t Train_Loss: 337.1266 Val_Loss: 903.0756  BEST VAL Loss: 903.0756\n",
            "\n",
            "Epoch 265: Validation loss decreased (903.075562 --> 895.694641).\n",
            "\t Train_Loss: 333.4298 Val_Loss: 895.6946  BEST VAL Loss: 895.6946\n",
            "\n",
            "Epoch 266: Validation loss decreased (895.694641 --> 888.402161).\n",
            "\t Train_Loss: 329.7936 Val_Loss: 888.4022  BEST VAL Loss: 888.4022\n",
            "\n",
            "Epoch 267: Validation loss decreased (888.402161 --> 881.195007).\n",
            "\t Train_Loss: 326.2180 Val_Loss: 881.1950  BEST VAL Loss: 881.1950\n",
            "\n",
            "Epoch 268: Validation loss decreased (881.195007 --> 874.073425).\n",
            "\t Train_Loss: 322.7014 Val_Loss: 874.0734  BEST VAL Loss: 874.0734\n",
            "\n",
            "Epoch 269: Validation loss decreased (874.073425 --> 867.036316).\n",
            "\t Train_Loss: 319.2433 Val_Loss: 867.0363  BEST VAL Loss: 867.0363\n",
            "\n",
            "Epoch 270: Validation loss decreased (867.036316 --> 860.082397).\n",
            "\t Train_Loss: 315.8428 Val_Loss: 860.0824  BEST VAL Loss: 860.0824\n",
            "\n",
            "Epoch 271: Validation loss decreased (860.082397 --> 853.211304).\n",
            "\t Train_Loss: 312.4991 Val_Loss: 853.2113  BEST VAL Loss: 853.2113\n",
            "\n",
            "Epoch 272: Validation loss decreased (853.211304 --> 846.421875).\n",
            "\t Train_Loss: 309.2116 Val_Loss: 846.4219  BEST VAL Loss: 846.4219\n",
            "\n",
            "Epoch 273: Validation loss decreased (846.421875 --> 839.712891).\n",
            "\t Train_Loss: 305.9793 Val_Loss: 839.7129  BEST VAL Loss: 839.7129\n",
            "\n",
            "Epoch 274: Validation loss decreased (839.712891 --> 833.083618).\n",
            "\t Train_Loss: 302.8011 Val_Loss: 833.0836  BEST VAL Loss: 833.0836\n",
            "\n",
            "Epoch 275: Validation loss decreased (833.083618 --> 826.533875).\n",
            "\t Train_Loss: 299.6767 Val_Loss: 826.5339  BEST VAL Loss: 826.5339\n",
            "\n",
            "Epoch 276: Validation loss decreased (826.533875 --> 820.062134).\n",
            "\t Train_Loss: 296.6054 Val_Loss: 820.0621  BEST VAL Loss: 820.0621\n",
            "\n",
            "Epoch 277: Validation loss decreased (820.062134 --> 813.667053).\n",
            "\t Train_Loss: 293.5863 Val_Loss: 813.6671  BEST VAL Loss: 813.6671\n",
            "\n",
            "Epoch 278: Validation loss decreased (813.667053 --> 807.348755).\n",
            "\t Train_Loss: 290.6181 Val_Loss: 807.3488  BEST VAL Loss: 807.3488\n",
            "\n",
            "Epoch 279: Validation loss decreased (807.348755 --> 801.106445).\n",
            "\t Train_Loss: 287.7010 Val_Loss: 801.1064  BEST VAL Loss: 801.1064\n",
            "\n",
            "Epoch 280: Validation loss decreased (801.106445 --> 794.938110).\n",
            "\t Train_Loss: 284.8337 Val_Loss: 794.9381  BEST VAL Loss: 794.9381\n",
            "\n",
            "Epoch 281: Validation loss decreased (794.938110 --> 788.843933).\n",
            "\t Train_Loss: 282.0154 Val_Loss: 788.8439  BEST VAL Loss: 788.8439\n",
            "\n",
            "Epoch 282: Validation loss decreased (788.843933 --> 782.823181).\n",
            "\t Train_Loss: 279.2456 Val_Loss: 782.8232  BEST VAL Loss: 782.8232\n",
            "\n",
            "Epoch 283: Validation loss decreased (782.823181 --> 776.873901).\n",
            "\t Train_Loss: 276.5238 Val_Loss: 776.8739  BEST VAL Loss: 776.8739\n",
            "\n",
            "Epoch 284: Validation loss decreased (776.873901 --> 770.996765).\n",
            "\t Train_Loss: 273.8487 Val_Loss: 770.9968  BEST VAL Loss: 770.9968\n",
            "\n",
            "Epoch 285: Validation loss decreased (770.996765 --> 765.189392).\n",
            "\t Train_Loss: 271.2202 Val_Loss: 765.1894  BEST VAL Loss: 765.1894\n",
            "\n",
            "Epoch 286: Validation loss decreased (765.189392 --> 759.452332).\n",
            "\t Train_Loss: 268.6371 Val_Loss: 759.4523  BEST VAL Loss: 759.4523\n",
            "\n",
            "Epoch 287: Validation loss decreased (759.452332 --> 753.784302).\n",
            "\t Train_Loss: 266.0991 Val_Loss: 753.7843  BEST VAL Loss: 753.7843\n",
            "\n",
            "Epoch 288: Validation loss decreased (753.784302 --> 748.184570).\n",
            "\t Train_Loss: 263.6054 Val_Loss: 748.1846  BEST VAL Loss: 748.1846\n",
            "\n",
            "Epoch 289: Validation loss decreased (748.184570 --> 742.652344).\n",
            "\t Train_Loss: 261.1554 Val_Loss: 742.6523  BEST VAL Loss: 742.6523\n",
            "\n",
            "Epoch 290: Validation loss decreased (742.652344 --> 737.186462).\n",
            "\t Train_Loss: 258.7483 Val_Loss: 737.1865  BEST VAL Loss: 737.1865\n",
            "\n",
            "Epoch 291: Validation loss decreased (737.186462 --> 731.786804).\n",
            "\t Train_Loss: 256.3836 Val_Loss: 731.7868  BEST VAL Loss: 731.7868\n",
            "\n",
            "Epoch 292: Validation loss decreased (731.786804 --> 726.452515).\n",
            "\t Train_Loss: 254.0605 Val_Loss: 726.4525  BEST VAL Loss: 726.4525\n",
            "\n",
            "Epoch 293: Validation loss decreased (726.452515 --> 721.182495).\n",
            "\t Train_Loss: 251.7786 Val_Loss: 721.1825  BEST VAL Loss: 721.1825\n",
            "\n",
            "Epoch 294: Validation loss decreased (721.182495 --> 715.976196).\n",
            "\t Train_Loss: 249.5371 Val_Loss: 715.9762  BEST VAL Loss: 715.9762\n",
            "\n",
            "Epoch 295: Validation loss decreased (715.976196 --> 710.832642).\n",
            "\t Train_Loss: 247.3353 Val_Loss: 710.8326  BEST VAL Loss: 710.8326\n",
            "\n",
            "Epoch 296: Validation loss decreased (710.832642 --> 705.752075).\n",
            "\t Train_Loss: 245.1727 Val_Loss: 705.7521  BEST VAL Loss: 705.7521\n",
            "\n",
            "Epoch 297: Validation loss decreased (705.752075 --> 700.732300).\n",
            "\t Train_Loss: 243.0489 Val_Loss: 700.7323  BEST VAL Loss: 700.7323\n",
            "\n",
            "Epoch 298: Validation loss decreased (700.732300 --> 695.774048).\n",
            "\t Train_Loss: 240.9628 Val_Loss: 695.7740  BEST VAL Loss: 695.7740\n",
            "\n",
            "Epoch 299: Validation loss decreased (695.774048 --> 690.875610).\n",
            "\t Train_Loss: 238.9144 Val_Loss: 690.8756  BEST VAL Loss: 690.8756\n",
            "\n",
            "Epoch 300: Validation loss decreased (690.875610 --> 686.036926).\n",
            "\t Train_Loss: 236.9028 Val_Loss: 686.0369  BEST VAL Loss: 686.0369\n",
            "\n",
            "Epoch 301: Validation loss decreased (686.036926 --> 681.256409).\n",
            "\t Train_Loss: 234.9275 Val_Loss: 681.2564  BEST VAL Loss: 681.2564\n",
            "\n",
            "Epoch 302: Validation loss decreased (681.256409 --> 676.534363).\n",
            "\t Train_Loss: 232.9876 Val_Loss: 676.5344  BEST VAL Loss: 676.5344\n",
            "\n",
            "Epoch 303: Validation loss decreased (676.534363 --> 671.870483).\n",
            "\t Train_Loss: 231.0831 Val_Loss: 671.8705  BEST VAL Loss: 671.8705\n",
            "\n",
            "Epoch 304: Validation loss decreased (671.870483 --> 667.262451).\n",
            "\t Train_Loss: 229.2134 Val_Loss: 667.2625  BEST VAL Loss: 667.2625\n",
            "\n",
            "Epoch 305: Validation loss decreased (667.262451 --> 662.710632).\n",
            "\t Train_Loss: 227.3774 Val_Loss: 662.7106  BEST VAL Loss: 662.7106\n",
            "\n",
            "Epoch 306: Validation loss decreased (662.710632 --> 658.214844).\n",
            "\t Train_Loss: 225.5749 Val_Loss: 658.2148  BEST VAL Loss: 658.2148\n",
            "\n",
            "Epoch 307: Validation loss decreased (658.214844 --> 653.773560).\n",
            "\t Train_Loss: 223.8056 Val_Loss: 653.7736  BEST VAL Loss: 653.7736\n",
            "\n",
            "Epoch 308: Validation loss decreased (653.773560 --> 649.385925).\n",
            "\t Train_Loss: 222.0686 Val_Loss: 649.3859  BEST VAL Loss: 649.3859\n",
            "\n",
            "Epoch 309: Validation loss decreased (649.385925 --> 645.052917).\n",
            "\t Train_Loss: 220.3634 Val_Loss: 645.0529  BEST VAL Loss: 645.0529\n",
            "\n",
            "Epoch 310: Validation loss decreased (645.052917 --> 640.771912).\n",
            "\t Train_Loss: 218.6900 Val_Loss: 640.7719  BEST VAL Loss: 640.7719\n",
            "\n",
            "Epoch 311: Validation loss decreased (640.771912 --> 636.543701).\n",
            "\t Train_Loss: 217.0471 Val_Loss: 636.5437  BEST VAL Loss: 636.5437\n",
            "\n",
            "Epoch 312: Validation loss decreased (636.543701 --> 632.367249).\n",
            "\t Train_Loss: 215.4348 Val_Loss: 632.3672  BEST VAL Loss: 632.3672\n",
            "\n",
            "Epoch 313: Validation loss decreased (632.367249 --> 628.241577).\n",
            "\t Train_Loss: 213.8524 Val_Loss: 628.2416  BEST VAL Loss: 628.2416\n",
            "\n",
            "Epoch 314: Validation loss decreased (628.241577 --> 624.166504).\n",
            "\t Train_Loss: 212.2994 Val_Loss: 624.1665  BEST VAL Loss: 624.1665\n",
            "\n",
            "Epoch 315: Validation loss decreased (624.166504 --> 620.141541).\n",
            "\t Train_Loss: 210.7754 Val_Loss: 620.1415  BEST VAL Loss: 620.1415\n",
            "\n",
            "Epoch 316: Validation loss decreased (620.141541 --> 616.165894).\n",
            "\t Train_Loss: 209.2799 Val_Loss: 616.1659  BEST VAL Loss: 616.1659\n",
            "\n",
            "Epoch 317: Validation loss decreased (616.165894 --> 612.238892).\n",
            "\t Train_Loss: 207.8124 Val_Loss: 612.2389  BEST VAL Loss: 612.2389\n",
            "\n",
            "Epoch 318: Validation loss decreased (612.238892 --> 608.360229).\n",
            "\t Train_Loss: 206.3725 Val_Loss: 608.3602  BEST VAL Loss: 608.3602\n",
            "\n",
            "Epoch 319: Validation loss decreased (608.360229 --> 604.528687).\n",
            "\t Train_Loss: 204.9597 Val_Loss: 604.5287  BEST VAL Loss: 604.5287\n",
            "\n",
            "Epoch 320: Validation loss decreased (604.528687 --> 600.744812).\n",
            "\t Train_Loss: 203.5734 Val_Loss: 600.7448  BEST VAL Loss: 600.7448\n",
            "\n",
            "Epoch 321: Validation loss decreased (600.744812 --> 597.007202).\n",
            "\t Train_Loss: 202.2136 Val_Loss: 597.0072  BEST VAL Loss: 597.0072\n",
            "\n",
            "Epoch 322: Validation loss decreased (597.007202 --> 593.315552).\n",
            "\t Train_Loss: 200.8794 Val_Loss: 593.3156  BEST VAL Loss: 593.3156\n",
            "\n",
            "Epoch 323: Validation loss decreased (593.315552 --> 589.669067).\n",
            "\t Train_Loss: 199.5705 Val_Loss: 589.6691  BEST VAL Loss: 589.6691\n",
            "\n",
            "Epoch 324: Validation loss decreased (589.669067 --> 586.067566).\n",
            "\t Train_Loss: 198.2866 Val_Loss: 586.0676  BEST VAL Loss: 586.0676\n",
            "\n",
            "Epoch 325: Validation loss decreased (586.067566 --> 582.510376).\n",
            "\t Train_Loss: 197.0272 Val_Loss: 582.5104  BEST VAL Loss: 582.5104\n",
            "\n",
            "Epoch 326: Validation loss decreased (582.510376 --> 578.997131).\n",
            "\t Train_Loss: 195.7919 Val_Loss: 578.9971  BEST VAL Loss: 578.9971\n",
            "\n",
            "Epoch 327: Validation loss decreased (578.997131 --> 575.526978).\n",
            "\t Train_Loss: 194.5802 Val_Loss: 575.5270  BEST VAL Loss: 575.5270\n",
            "\n",
            "Epoch 328: Validation loss decreased (575.526978 --> 572.099976).\n",
            "\t Train_Loss: 193.3919 Val_Loss: 572.1000  BEST VAL Loss: 572.1000\n",
            "\n",
            "Epoch 329: Validation loss decreased (572.099976 --> 568.715088).\n",
            "\t Train_Loss: 192.2265 Val_Loss: 568.7151  BEST VAL Loss: 568.7151\n",
            "\n",
            "Epoch 330: Validation loss decreased (568.715088 --> 565.371643).\n",
            "\t Train_Loss: 191.0836 Val_Loss: 565.3716  BEST VAL Loss: 565.3716\n",
            "\n",
            "Epoch 331: Validation loss decreased (565.371643 --> 562.069702).\n",
            "\t Train_Loss: 189.9627 Val_Loss: 562.0697  BEST VAL Loss: 562.0697\n",
            "\n",
            "Epoch 332: Validation loss decreased (562.069702 --> 558.808472).\n",
            "\t Train_Loss: 188.8636 Val_Loss: 558.8085  BEST VAL Loss: 558.8085\n",
            "\n",
            "Epoch 333: Validation loss decreased (558.808472 --> 555.587830).\n",
            "\t Train_Loss: 187.7859 Val_Loss: 555.5878  BEST VAL Loss: 555.5878\n",
            "\n",
            "Epoch 334: Validation loss decreased (555.587830 --> 552.406799).\n",
            "\t Train_Loss: 186.7293 Val_Loss: 552.4068  BEST VAL Loss: 552.4068\n",
            "\n",
            "Epoch 335: Validation loss decreased (552.406799 --> 549.264771).\n",
            "\t Train_Loss: 185.6932 Val_Loss: 549.2648  BEST VAL Loss: 549.2648\n",
            "\n",
            "Epoch 336: Validation loss decreased (549.264771 --> 546.161987).\n",
            "\t Train_Loss: 184.6774 Val_Loss: 546.1620  BEST VAL Loss: 546.1620\n",
            "\n",
            "Epoch 337: Validation loss decreased (546.161987 --> 543.097534).\n",
            "\t Train_Loss: 183.6815 Val_Loss: 543.0975  BEST VAL Loss: 543.0975\n",
            "\n",
            "Epoch 338: Validation loss decreased (543.097534 --> 540.070801).\n",
            "\t Train_Loss: 182.7053 Val_Loss: 540.0708  BEST VAL Loss: 540.0708\n",
            "\n",
            "Epoch 339: Validation loss decreased (540.070801 --> 537.081787).\n",
            "\t Train_Loss: 181.7482 Val_Loss: 537.0818  BEST VAL Loss: 537.0818\n",
            "\n",
            "Epoch 340: Validation loss decreased (537.081787 --> 534.130127).\n",
            "\t Train_Loss: 180.8101 Val_Loss: 534.1301  BEST VAL Loss: 534.1301\n",
            "\n",
            "Epoch 341: Validation loss decreased (534.130127 --> 531.214600).\n",
            "\t Train_Loss: 179.8907 Val_Loss: 531.2146  BEST VAL Loss: 531.2146\n",
            "\n",
            "Epoch 342: Validation loss decreased (531.214600 --> 528.335083).\n",
            "\t Train_Loss: 178.9893 Val_Loss: 528.3351  BEST VAL Loss: 528.3351\n",
            "\n",
            "Epoch 343: Validation loss decreased (528.335083 --> 525.491211).\n",
            "\t Train_Loss: 178.1059 Val_Loss: 525.4912  BEST VAL Loss: 525.4912\n",
            "\n",
            "Epoch 344: Validation loss decreased (525.491211 --> 522.683167).\n",
            "\t Train_Loss: 177.2400 Val_Loss: 522.6832  BEST VAL Loss: 522.6832\n",
            "\n",
            "Epoch 345: Validation loss decreased (522.683167 --> 519.910095).\n",
            "\t Train_Loss: 176.3916 Val_Loss: 519.9101  BEST VAL Loss: 519.9101\n",
            "\n",
            "Epoch 346: Validation loss decreased (519.910095 --> 517.171021).\n",
            "\t Train_Loss: 175.5602 Val_Loss: 517.1710  BEST VAL Loss: 517.1710\n",
            "\n",
            "Epoch 347: Validation loss decreased (517.171021 --> 514.465759).\n",
            "\t Train_Loss: 174.7453 Val_Loss: 514.4658  BEST VAL Loss: 514.4658\n",
            "\n",
            "Epoch 348: Validation loss decreased (514.465759 --> 511.794861).\n",
            "\t Train_Loss: 173.9468 Val_Loss: 511.7949  BEST VAL Loss: 511.7949\n",
            "\n",
            "Epoch 349: Validation loss decreased (511.794861 --> 509.156647).\n",
            "\t Train_Loss: 173.1646 Val_Loss: 509.1566  BEST VAL Loss: 509.1566\n",
            "\n",
            "Epoch 350: Validation loss decreased (509.156647 --> 506.551331).\n",
            "\t Train_Loss: 172.3980 Val_Loss: 506.5513  BEST VAL Loss: 506.5513\n",
            "\n",
            "Epoch 351: Validation loss decreased (506.551331 --> 503.978424).\n",
            "\t Train_Loss: 171.6470 Val_Loss: 503.9784  BEST VAL Loss: 503.9784\n",
            "\n",
            "Epoch 352: Validation loss decreased (503.978424 --> 501.437561).\n",
            "\t Train_Loss: 170.9111 Val_Loss: 501.4376  BEST VAL Loss: 501.4376\n",
            "\n",
            "Epoch 353: Validation loss decreased (501.437561 --> 498.928406).\n",
            "\t Train_Loss: 170.1903 Val_Loss: 498.9284  BEST VAL Loss: 498.9284\n",
            "\n",
            "Epoch 354: Validation loss decreased (498.928406 --> 496.450256).\n",
            "\t Train_Loss: 169.4842 Val_Loss: 496.4503  BEST VAL Loss: 496.4503\n",
            "\n",
            "Epoch 355: Validation loss decreased (496.450256 --> 494.003235).\n",
            "\t Train_Loss: 168.7924 Val_Loss: 494.0032  BEST VAL Loss: 494.0032\n",
            "\n",
            "Epoch 356: Validation loss decreased (494.003235 --> 491.586365).\n",
            "\t Train_Loss: 168.1149 Val_Loss: 491.5864  BEST VAL Loss: 491.5864\n",
            "\n",
            "Epoch 357: Validation loss decreased (491.586365 --> 489.200012).\n",
            "\t Train_Loss: 167.4510 Val_Loss: 489.2000  BEST VAL Loss: 489.2000\n",
            "\n",
            "Epoch 358: Validation loss decreased (489.200012 --> 486.843323).\n",
            "\t Train_Loss: 166.8010 Val_Loss: 486.8433  BEST VAL Loss: 486.8433\n",
            "\n",
            "Epoch 359: Validation loss decreased (486.843323 --> 484.515961).\n",
            "\t Train_Loss: 166.1643 Val_Loss: 484.5160  BEST VAL Loss: 484.5160\n",
            "\n",
            "Epoch 360: Validation loss decreased (484.515961 --> 482.217865).\n",
            "\t Train_Loss: 165.5408 Val_Loss: 482.2179  BEST VAL Loss: 482.2179\n",
            "\n",
            "Epoch 361: Validation loss decreased (482.217865 --> 479.948151).\n",
            "\t Train_Loss: 164.9303 Val_Loss: 479.9482  BEST VAL Loss: 479.9482\n",
            "\n",
            "Epoch 362: Validation loss decreased (479.948151 --> 477.707092).\n",
            "\t Train_Loss: 164.3322 Val_Loss: 477.7071  BEST VAL Loss: 477.7071\n",
            "\n",
            "Epoch 363: Validation loss decreased (477.707092 --> 475.493744).\n",
            "\t Train_Loss: 163.7467 Val_Loss: 475.4937  BEST VAL Loss: 475.4937\n",
            "\n",
            "Epoch 364: Validation loss decreased (475.493744 --> 473.308105).\n",
            "\t Train_Loss: 163.1733 Val_Loss: 473.3081  BEST VAL Loss: 473.3081\n",
            "\n",
            "Epoch 365: Validation loss decreased (473.308105 --> 471.150055).\n",
            "\t Train_Loss: 162.6118 Val_Loss: 471.1501  BEST VAL Loss: 471.1501\n",
            "\n",
            "Epoch 366: Validation loss decreased (471.150055 --> 469.018494).\n",
            "\t Train_Loss: 162.0622 Val_Loss: 469.0185  BEST VAL Loss: 469.0185\n",
            "\n",
            "Epoch 367: Validation loss decreased (469.018494 --> 466.913879).\n",
            "\t Train_Loss: 161.5239 Val_Loss: 466.9139  BEST VAL Loss: 466.9139\n",
            "\n",
            "Epoch 368: Validation loss decreased (466.913879 --> 464.836029).\n",
            "\t Train_Loss: 160.9971 Val_Loss: 464.8360  BEST VAL Loss: 464.8360\n",
            "\n",
            "Epoch 369: Validation loss decreased (464.836029 --> 462.783386).\n",
            "\t Train_Loss: 160.4814 Val_Loss: 462.7834  BEST VAL Loss: 462.7834\n",
            "\n",
            "Epoch 370: Validation loss decreased (462.783386 --> 460.757324).\n",
            "\t Train_Loss: 159.9763 Val_Loss: 460.7573  BEST VAL Loss: 460.7573\n",
            "\n",
            "Epoch 371: Validation loss decreased (460.757324 --> 458.755951).\n",
            "\t Train_Loss: 159.4822 Val_Loss: 458.7560  BEST VAL Loss: 458.7560\n",
            "\n",
            "Epoch 372: Validation loss decreased (458.755951 --> 456.780182).\n",
            "\t Train_Loss: 158.9984 Val_Loss: 456.7802  BEST VAL Loss: 456.7802\n",
            "\n",
            "Epoch 373: Validation loss decreased (456.780182 --> 454.828918).\n",
            "\t Train_Loss: 158.5249 Val_Loss: 454.8289  BEST VAL Loss: 454.8289\n",
            "\n",
            "Epoch 374: Validation loss decreased (454.828918 --> 452.901855).\n",
            "\t Train_Loss: 158.0614 Val_Loss: 452.9019  BEST VAL Loss: 452.9019\n",
            "\n",
            "Epoch 375: Validation loss decreased (452.901855 --> 450.999115).\n",
            "\t Train_Loss: 157.6077 Val_Loss: 450.9991  BEST VAL Loss: 450.9991\n",
            "\n",
            "Epoch 376: Validation loss decreased (450.999115 --> 449.120605).\n",
            "\t Train_Loss: 157.1638 Val_Loss: 449.1206  BEST VAL Loss: 449.1206\n",
            "\n",
            "Epoch 377: Validation loss decreased (449.120605 --> 447.265320).\n",
            "\t Train_Loss: 156.7294 Val_Loss: 447.2653  BEST VAL Loss: 447.2653\n",
            "\n",
            "Epoch 378: Validation loss decreased (447.265320 --> 445.433411).\n",
            "\t Train_Loss: 156.3043 Val_Loss: 445.4334  BEST VAL Loss: 445.4334\n",
            "\n",
            "Epoch 379: Validation loss decreased (445.433411 --> 443.624603).\n",
            "\t Train_Loss: 155.8883 Val_Loss: 443.6246  BEST VAL Loss: 443.6246\n",
            "\n",
            "Epoch 380: Validation loss decreased (443.624603 --> 441.838470).\n",
            "\t Train_Loss: 155.4812 Val_Loss: 441.8385  BEST VAL Loss: 441.8385\n",
            "\n",
            "Epoch 381: Validation loss decreased (441.838470 --> 440.074890).\n",
            "\t Train_Loss: 155.0830 Val_Loss: 440.0749  BEST VAL Loss: 440.0749\n",
            "\n",
            "Epoch 382: Validation loss decreased (440.074890 --> 438.333649).\n",
            "\t Train_Loss: 154.6933 Val_Loss: 438.3336  BEST VAL Loss: 438.3336\n",
            "\n",
            "Epoch 383: Validation loss decreased (438.333649 --> 436.613708).\n",
            "\t Train_Loss: 154.3122 Val_Loss: 436.6137  BEST VAL Loss: 436.6137\n",
            "\n",
            "Epoch 384: Validation loss decreased (436.613708 --> 434.915710).\n",
            "\t Train_Loss: 153.9392 Val_Loss: 434.9157  BEST VAL Loss: 434.9157\n",
            "\n",
            "Epoch 385: Validation loss decreased (434.915710 --> 433.239410).\n",
            "\t Train_Loss: 153.5743 Val_Loss: 433.2394  BEST VAL Loss: 433.2394\n",
            "\n",
            "Epoch 386: Validation loss decreased (433.239410 --> 431.584229).\n",
            "\t Train_Loss: 153.2175 Val_Loss: 431.5842  BEST VAL Loss: 431.5842\n",
            "\n",
            "Epoch 387: Validation loss decreased (431.584229 --> 429.949310).\n",
            "\t Train_Loss: 152.8685 Val_Loss: 429.9493  BEST VAL Loss: 429.9493\n",
            "\n",
            "Epoch 388: Validation loss decreased (429.949310 --> 428.335388).\n",
            "\t Train_Loss: 152.5269 Val_Loss: 428.3354  BEST VAL Loss: 428.3354\n",
            "\n",
            "Epoch 389: Validation loss decreased (428.335388 --> 426.741760).\n",
            "\t Train_Loss: 152.1929 Val_Loss: 426.7418  BEST VAL Loss: 426.7418\n",
            "\n",
            "Epoch 390: Validation loss decreased (426.741760 --> 425.168152).\n",
            "\t Train_Loss: 151.8663 Val_Loss: 425.1682  BEST VAL Loss: 425.1682\n",
            "\n",
            "Epoch 391: Validation loss decreased (425.168152 --> 423.614502).\n",
            "\t Train_Loss: 151.5468 Val_Loss: 423.6145  BEST VAL Loss: 423.6145\n",
            "\n",
            "Epoch 392: Validation loss decreased (423.614502 --> 422.080658).\n",
            "\t Train_Loss: 151.2344 Val_Loss: 422.0807  BEST VAL Loss: 422.0807\n",
            "\n",
            "Epoch 393: Validation loss decreased (422.080658 --> 420.565826).\n",
            "\t Train_Loss: 150.9289 Val_Loss: 420.5658  BEST VAL Loss: 420.5658\n",
            "\n",
            "Epoch 394: Validation loss decreased (420.565826 --> 419.070160).\n",
            "\t Train_Loss: 150.6301 Val_Loss: 419.0702  BEST VAL Loss: 419.0702\n",
            "\n",
            "Epoch 395: Validation loss decreased (419.070160 --> 417.593567).\n",
            "\t Train_Loss: 150.3380 Val_Loss: 417.5936  BEST VAL Loss: 417.5936\n",
            "\n",
            "Epoch 396: Validation loss decreased (417.593567 --> 416.135834).\n",
            "\t Train_Loss: 150.0523 Val_Loss: 416.1358  BEST VAL Loss: 416.1358\n",
            "\n",
            "Epoch 397: Validation loss decreased (416.135834 --> 414.695953).\n",
            "\t Train_Loss: 149.7731 Val_Loss: 414.6960  BEST VAL Loss: 414.6960\n",
            "\n",
            "Epoch 398: Validation loss decreased (414.695953 --> 413.274994).\n",
            "\t Train_Loss: 149.5000 Val_Loss: 413.2750  BEST VAL Loss: 413.2750\n",
            "\n",
            "Epoch 399: Validation loss decreased (413.274994 --> 411.871735).\n",
            "\t Train_Loss: 149.2332 Val_Loss: 411.8717  BEST VAL Loss: 411.8717\n",
            "\n",
            "Epoch 400: Validation loss decreased (411.871735 --> 410.486145).\n",
            "\t Train_Loss: 148.9722 Val_Loss: 410.4861  BEST VAL Loss: 410.4861\n",
            "\n",
            "Epoch 401: Validation loss decreased (410.486145 --> 409.118317).\n",
            "\t Train_Loss: 148.7171 Val_Loss: 409.1183  BEST VAL Loss: 409.1183\n",
            "\n",
            "Epoch 402: Validation loss decreased (409.118317 --> 407.767395).\n",
            "\t Train_Loss: 148.4678 Val_Loss: 407.7674  BEST VAL Loss: 407.7674\n",
            "\n",
            "Epoch 403: Validation loss decreased (407.767395 --> 406.434021).\n",
            "\t Train_Loss: 148.2239 Val_Loss: 406.4340  BEST VAL Loss: 406.4340\n",
            "\n",
            "Epoch 404: Validation loss decreased (406.434021 --> 405.117676).\n",
            "\t Train_Loss: 147.9857 Val_Loss: 405.1177  BEST VAL Loss: 405.1177\n",
            "\n",
            "Epoch 405: Validation loss decreased (405.117676 --> 403.817688).\n",
            "\t Train_Loss: 147.7529 Val_Loss: 403.8177  BEST VAL Loss: 403.8177\n",
            "\n",
            "Epoch 406: Validation loss decreased (403.817688 --> 402.533997).\n",
            "\t Train_Loss: 147.5253 Val_Loss: 402.5340  BEST VAL Loss: 402.5340\n",
            "\n",
            "Epoch 407: Validation loss decreased (402.533997 --> 401.266937).\n",
            "\t Train_Loss: 147.3028 Val_Loss: 401.2669  BEST VAL Loss: 401.2669\n",
            "\n",
            "Epoch 408: Validation loss decreased (401.266937 --> 400.015991).\n",
            "\t Train_Loss: 147.0855 Val_Loss: 400.0160  BEST VAL Loss: 400.0160\n",
            "\n",
            "Epoch 409: Validation loss decreased (400.015991 --> 398.780579).\n",
            "\t Train_Loss: 146.8731 Val_Loss: 398.7806  BEST VAL Loss: 398.7806\n",
            "\n",
            "Epoch 410: Validation loss decreased (398.780579 --> 397.561584).\n",
            "\t Train_Loss: 146.6655 Val_Loss: 397.5616  BEST VAL Loss: 397.5616\n",
            "\n",
            "Epoch 411: Validation loss decreased (397.561584 --> 396.357605).\n",
            "\t Train_Loss: 146.4628 Val_Loss: 396.3576  BEST VAL Loss: 396.3576\n",
            "\n",
            "Epoch 412: Validation loss decreased (396.357605 --> 395.169220).\n",
            "\t Train_Loss: 146.2646 Val_Loss: 395.1692  BEST VAL Loss: 395.1692\n",
            "\n",
            "Epoch 413: Validation loss decreased (395.169220 --> 393.995880).\n",
            "\t Train_Loss: 146.0711 Val_Loss: 393.9959  BEST VAL Loss: 393.9959\n",
            "\n",
            "Epoch 414: Validation loss decreased (393.995880 --> 392.837158).\n",
            "\t Train_Loss: 145.8819 Val_Loss: 392.8372  BEST VAL Loss: 392.8372\n",
            "\n",
            "Epoch 415: Validation loss decreased (392.837158 --> 391.693481).\n",
            "\t Train_Loss: 145.6971 Val_Loss: 391.6935  BEST VAL Loss: 391.6935\n",
            "\n",
            "Epoch 416: Validation loss decreased (391.693481 --> 390.564697).\n",
            "\t Train_Loss: 145.5166 Val_Loss: 390.5647  BEST VAL Loss: 390.5647\n",
            "\n",
            "Epoch 417: Validation loss decreased (390.564697 --> 389.449768).\n",
            "\t Train_Loss: 145.3403 Val_Loss: 389.4498  BEST VAL Loss: 389.4498\n",
            "\n",
            "Epoch 418: Validation loss decreased (389.449768 --> 388.349213).\n",
            "\t Train_Loss: 145.1680 Val_Loss: 388.3492  BEST VAL Loss: 388.3492\n",
            "\n",
            "Epoch 419: Validation loss decreased (388.349213 --> 387.262848).\n",
            "\t Train_Loss: 144.9998 Val_Loss: 387.2628  BEST VAL Loss: 387.2628\n",
            "\n",
            "Epoch 420: Validation loss decreased (387.262848 --> 386.190247).\n",
            "\t Train_Loss: 144.8354 Val_Loss: 386.1902  BEST VAL Loss: 386.1902\n",
            "\n",
            "Epoch 421: Validation loss decreased (386.190247 --> 385.131775).\n",
            "\t Train_Loss: 144.6749 Val_Loss: 385.1318  BEST VAL Loss: 385.1318\n",
            "\n",
            "Epoch 422: Validation loss decreased (385.131775 --> 384.086456).\n",
            "\t Train_Loss: 144.5183 Val_Loss: 384.0865  BEST VAL Loss: 384.0865\n",
            "\n",
            "Epoch 423: Validation loss decreased (384.086456 --> 383.054352).\n",
            "\t Train_Loss: 144.3652 Val_Loss: 383.0544  BEST VAL Loss: 383.0544\n",
            "\n",
            "Epoch 424: Validation loss decreased (383.054352 --> 382.035645).\n",
            "\t Train_Loss: 144.2157 Val_Loss: 382.0356  BEST VAL Loss: 382.0356\n",
            "\n",
            "Epoch 425: Validation loss decreased (382.035645 --> 381.030121).\n",
            "\t Train_Loss: 144.0697 Val_Loss: 381.0301  BEST VAL Loss: 381.0301\n",
            "\n",
            "Epoch 426: Validation loss decreased (381.030121 --> 380.037445).\n",
            "\t Train_Loss: 143.9271 Val_Loss: 380.0374  BEST VAL Loss: 380.0374\n",
            "\n",
            "Epoch 427: Validation loss decreased (380.037445 --> 379.057465).\n",
            "\t Train_Loss: 143.7880 Val_Loss: 379.0575  BEST VAL Loss: 379.0575\n",
            "\n",
            "Epoch 428: Validation loss decreased (379.057465 --> 378.090149).\n",
            "\t Train_Loss: 143.6521 Val_Loss: 378.0901  BEST VAL Loss: 378.0901\n",
            "\n",
            "Epoch 429: Validation loss decreased (378.090149 --> 377.135040).\n",
            "\t Train_Loss: 143.5195 Val_Loss: 377.1350  BEST VAL Loss: 377.1350\n",
            "\n",
            "Epoch 430: Validation loss decreased (377.135040 --> 376.192383).\n",
            "\t Train_Loss: 143.3899 Val_Loss: 376.1924  BEST VAL Loss: 376.1924\n",
            "\n",
            "Epoch 431: Validation loss decreased (376.192383 --> 375.261719).\n",
            "\t Train_Loss: 143.2635 Val_Loss: 375.2617  BEST VAL Loss: 375.2617\n",
            "\n",
            "Epoch 432: Validation loss decreased (375.261719 --> 374.343140).\n",
            "\t Train_Loss: 143.1400 Val_Loss: 374.3431  BEST VAL Loss: 374.3431\n",
            "\n",
            "Epoch 433: Validation loss decreased (374.343140 --> 373.436249).\n",
            "\t Train_Loss: 143.0196 Val_Loss: 373.4362  BEST VAL Loss: 373.4362\n",
            "\n",
            "Epoch 434: Validation loss decreased (373.436249 --> 372.541016).\n",
            "\t Train_Loss: 142.9019 Val_Loss: 372.5410  BEST VAL Loss: 372.5410\n",
            "\n",
            "Epoch 435: Validation loss decreased (372.541016 --> 371.657532).\n",
            "\t Train_Loss: 142.7871 Val_Loss: 371.6575  BEST VAL Loss: 371.6575\n",
            "\n",
            "Epoch 436: Validation loss decreased (371.657532 --> 370.785339).\n",
            "\t Train_Loss: 142.6751 Val_Loss: 370.7853  BEST VAL Loss: 370.7853\n",
            "\n",
            "Epoch 437: Validation loss decreased (370.785339 --> 369.924622).\n",
            "\t Train_Loss: 142.5658 Val_Loss: 369.9246  BEST VAL Loss: 369.9246\n",
            "\n",
            "Epoch 438: Validation loss decreased (369.924622 --> 369.074371).\n",
            "\t Train_Loss: 142.4591 Val_Loss: 369.0744  BEST VAL Loss: 369.0744\n",
            "\n",
            "Epoch 439: Validation loss decreased (369.074371 --> 368.235596).\n",
            "\t Train_Loss: 142.3549 Val_Loss: 368.2356  BEST VAL Loss: 368.2356\n",
            "\n",
            "Epoch 440: Validation loss decreased (368.235596 --> 367.407410).\n",
            "\t Train_Loss: 142.2533 Val_Loss: 367.4074  BEST VAL Loss: 367.4074\n",
            "\n",
            "Epoch 441: Validation loss decreased (367.407410 --> 366.590271).\n",
            "\t Train_Loss: 142.1540 Val_Loss: 366.5903  BEST VAL Loss: 366.5903\n",
            "\n",
            "Epoch 442: Validation loss decreased (366.590271 --> 365.783630).\n",
            "\t Train_Loss: 142.0573 Val_Loss: 365.7836  BEST VAL Loss: 365.7836\n",
            "\n",
            "Epoch 443: Validation loss decreased (365.783630 --> 364.987122).\n",
            "\t Train_Loss: 141.9629 Val_Loss: 364.9871  BEST VAL Loss: 364.9871\n",
            "\n",
            "Epoch 444: Validation loss decreased (364.987122 --> 364.201385).\n",
            "\t Train_Loss: 141.8707 Val_Loss: 364.2014  BEST VAL Loss: 364.2014\n",
            "\n",
            "Epoch 445: Validation loss decreased (364.201385 --> 363.425232).\n",
            "\t Train_Loss: 141.7809 Val_Loss: 363.4252  BEST VAL Loss: 363.4252\n",
            "\n",
            "Epoch 446: Validation loss decreased (363.425232 --> 362.659637).\n",
            "\t Train_Loss: 141.6932 Val_Loss: 362.6596  BEST VAL Loss: 362.6596\n",
            "\n",
            "Epoch 447: Validation loss decreased (362.659637 --> 361.903870).\n",
            "\t Train_Loss: 141.6076 Val_Loss: 361.9039  BEST VAL Loss: 361.9039\n",
            "\n",
            "Epoch 448: Validation loss decreased (361.903870 --> 361.157898).\n",
            "\t Train_Loss: 141.5242 Val_Loss: 361.1579  BEST VAL Loss: 361.1579\n",
            "\n",
            "Epoch 449: Validation loss decreased (361.157898 --> 360.421539).\n",
            "\t Train_Loss: 141.4428 Val_Loss: 360.4215  BEST VAL Loss: 360.4215\n",
            "\n",
            "Epoch 450: Validation loss decreased (360.421539 --> 359.694946).\n",
            "\t Train_Loss: 141.3634 Val_Loss: 359.6949  BEST VAL Loss: 359.6949\n",
            "\n",
            "Epoch 451: Validation loss decreased (359.694946 --> 358.977722).\n",
            "\t Train_Loss: 141.2860 Val_Loss: 358.9777  BEST VAL Loss: 358.9777\n",
            "\n",
            "Epoch 452: Validation loss decreased (358.977722 --> 358.270020).\n",
            "\t Train_Loss: 141.2105 Val_Loss: 358.2700  BEST VAL Loss: 358.2700\n",
            "\n",
            "Epoch 453: Validation loss decreased (358.270020 --> 357.571198).\n",
            "\t Train_Loss: 141.1369 Val_Loss: 357.5712  BEST VAL Loss: 357.5712\n",
            "\n",
            "Epoch 454: Validation loss decreased (357.571198 --> 356.881927).\n",
            "\t Train_Loss: 141.0650 Val_Loss: 356.8819  BEST VAL Loss: 356.8819\n",
            "\n",
            "Epoch 455: Validation loss decreased (356.881927 --> 356.200958).\n",
            "\t Train_Loss: 140.9950 Val_Loss: 356.2010  BEST VAL Loss: 356.2010\n",
            "\n",
            "Epoch 456: Validation loss decreased (356.200958 --> 355.529297).\n",
            "\t Train_Loss: 140.9266 Val_Loss: 355.5293  BEST VAL Loss: 355.5293\n",
            "\n",
            "Epoch 457: Validation loss decreased (355.529297 --> 354.866608).\n",
            "\t Train_Loss: 140.8600 Val_Loss: 354.8666  BEST VAL Loss: 354.8666\n",
            "\n",
            "Epoch 458: Validation loss decreased (354.866608 --> 354.212494).\n",
            "\t Train_Loss: 140.7951 Val_Loss: 354.2125  BEST VAL Loss: 354.2125\n",
            "\n",
            "Epoch 459: Validation loss decreased (354.212494 --> 353.566711).\n",
            "\t Train_Loss: 140.7318 Val_Loss: 353.5667  BEST VAL Loss: 353.5667\n",
            "\n",
            "Epoch 460: Validation loss decreased (353.566711 --> 352.929443).\n",
            "\t Train_Loss: 140.6700 Val_Loss: 352.9294  BEST VAL Loss: 352.9294\n",
            "\n",
            "Epoch 461: Validation loss decreased (352.929443 --> 352.300537).\n",
            "\t Train_Loss: 140.6099 Val_Loss: 352.3005  BEST VAL Loss: 352.3005\n",
            "\n",
            "Epoch 462: Validation loss decreased (352.300537 --> 351.679901).\n",
            "\t Train_Loss: 140.5512 Val_Loss: 351.6799  BEST VAL Loss: 351.6799\n",
            "\n",
            "Epoch 463: Validation loss decreased (351.679901 --> 351.067566).\n",
            "\t Train_Loss: 140.4940 Val_Loss: 351.0676  BEST VAL Loss: 351.0676\n",
            "\n",
            "Epoch 464: Validation loss decreased (351.067566 --> 350.462982).\n",
            "\t Train_Loss: 140.4382 Val_Loss: 350.4630  BEST VAL Loss: 350.4630\n",
            "\n",
            "Epoch 465: Validation loss decreased (350.462982 --> 349.866608).\n",
            "\t Train_Loss: 140.3838 Val_Loss: 349.8666  BEST VAL Loss: 349.8666\n",
            "\n",
            "Epoch 466: Validation loss decreased (349.866608 --> 349.277924).\n",
            "\t Train_Loss: 140.3308 Val_Loss: 349.2779  BEST VAL Loss: 349.2779\n",
            "\n",
            "Epoch 467: Validation loss decreased (349.277924 --> 348.697113).\n",
            "\t Train_Loss: 140.2792 Val_Loss: 348.6971  BEST VAL Loss: 348.6971\n",
            "\n",
            "Epoch 468: Validation loss decreased (348.697113 --> 348.124023).\n",
            "\t Train_Loss: 140.2289 Val_Loss: 348.1240  BEST VAL Loss: 348.1240\n",
            "\n",
            "Epoch 469: Validation loss decreased (348.124023 --> 347.558411).\n",
            "\t Train_Loss: 140.1799 Val_Loss: 347.5584  BEST VAL Loss: 347.5584\n",
            "\n",
            "Epoch 470: Validation loss decreased (347.558411 --> 347.000061).\n",
            "\t Train_Loss: 140.1320 Val_Loss: 347.0001  BEST VAL Loss: 347.0001\n",
            "\n",
            "Epoch 471: Validation loss decreased (347.000061 --> 346.449371).\n",
            "\t Train_Loss: 140.0854 Val_Loss: 346.4494  BEST VAL Loss: 346.4494\n",
            "\n",
            "Epoch 472: Validation loss decreased (346.449371 --> 345.905731).\n",
            "\t Train_Loss: 140.0401 Val_Loss: 345.9057  BEST VAL Loss: 345.9057\n",
            "\n",
            "Epoch 473: Validation loss decreased (345.905731 --> 345.369476).\n",
            "\t Train_Loss: 139.9959 Val_Loss: 345.3695  BEST VAL Loss: 345.3695\n",
            "\n",
            "Epoch 474: Validation loss decreased (345.369476 --> 344.840485).\n",
            "\t Train_Loss: 139.9528 Val_Loss: 344.8405  BEST VAL Loss: 344.8405\n",
            "\n",
            "Epoch 475: Validation loss decreased (344.840485 --> 344.318176).\n",
            "\t Train_Loss: 139.9108 Val_Loss: 344.3182  BEST VAL Loss: 344.3182\n",
            "\n",
            "Epoch 476: Validation loss decreased (344.318176 --> 343.802734).\n",
            "\t Train_Loss: 139.8699 Val_Loss: 343.8027  BEST VAL Loss: 343.8027\n",
            "\n",
            "Epoch 477: Validation loss decreased (343.802734 --> 343.294312).\n",
            "\t Train_Loss: 139.8300 Val_Loss: 343.2943  BEST VAL Loss: 343.2943\n",
            "\n",
            "Epoch 478: Validation loss decreased (343.294312 --> 342.792725).\n",
            "\t Train_Loss: 139.7912 Val_Loss: 342.7927  BEST VAL Loss: 342.7927\n",
            "\n",
            "Epoch 479: Validation loss decreased (342.792725 --> 342.297699).\n",
            "\t Train_Loss: 139.7534 Val_Loss: 342.2977  BEST VAL Loss: 342.2977\n",
            "\n",
            "Epoch 480: Validation loss decreased (342.297699 --> 341.809448).\n",
            "\t Train_Loss: 139.7165 Val_Loss: 341.8094  BEST VAL Loss: 341.8094\n",
            "\n",
            "Epoch 481: Validation loss decreased (341.809448 --> 341.327637).\n",
            "\t Train_Loss: 139.6807 Val_Loss: 341.3276  BEST VAL Loss: 341.3276\n",
            "\n",
            "Epoch 482: Validation loss decreased (341.327637 --> 340.851990).\n",
            "\t Train_Loss: 139.6457 Val_Loss: 340.8520  BEST VAL Loss: 340.8520\n",
            "\n",
            "Epoch 483: Validation loss decreased (340.851990 --> 340.382874).\n",
            "\t Train_Loss: 139.6117 Val_Loss: 340.3829  BEST VAL Loss: 340.3829\n",
            "\n",
            "Epoch 484: Validation loss decreased (340.382874 --> 339.920166).\n",
            "\t Train_Loss: 139.5785 Val_Loss: 339.9202  BEST VAL Loss: 339.9202\n",
            "\n",
            "Epoch 485: Validation loss decreased (339.920166 --> 339.463440).\n",
            "\t Train_Loss: 139.5463 Val_Loss: 339.4634  BEST VAL Loss: 339.4634\n",
            "\n",
            "Epoch 486: Validation loss decreased (339.463440 --> 339.012756).\n",
            "\t Train_Loss: 139.5148 Val_Loss: 339.0128  BEST VAL Loss: 339.0128\n",
            "\n",
            "Epoch 487: Validation loss decreased (339.012756 --> 338.568298).\n",
            "\t Train_Loss: 139.4842 Val_Loss: 338.5683  BEST VAL Loss: 338.5683\n",
            "\n",
            "Epoch 488: Validation loss decreased (338.568298 --> 338.129486).\n",
            "\t Train_Loss: 139.4544 Val_Loss: 338.1295  BEST VAL Loss: 338.1295\n",
            "\n",
            "Epoch 489: Validation loss decreased (338.129486 --> 337.697083).\n",
            "\t Train_Loss: 139.4253 Val_Loss: 337.6971  BEST VAL Loss: 337.6971\n",
            "\n",
            "Epoch 490: Validation loss decreased (337.697083 --> 337.270386).\n",
            "\t Train_Loss: 139.3971 Val_Loss: 337.2704  BEST VAL Loss: 337.2704\n",
            "\n",
            "Epoch 491: Validation loss decreased (337.270386 --> 336.849060).\n",
            "\t Train_Loss: 139.3696 Val_Loss: 336.8491  BEST VAL Loss: 336.8491\n",
            "\n",
            "Epoch 492: Validation loss decreased (336.849060 --> 336.434021).\n",
            "\t Train_Loss: 139.3428 Val_Loss: 336.4340  BEST VAL Loss: 336.4340\n",
            "\n",
            "Epoch 493: Validation loss decreased (336.434021 --> 336.023773).\n",
            "\t Train_Loss: 139.3168 Val_Loss: 336.0238  BEST VAL Loss: 336.0238\n",
            "\n",
            "Epoch 494: Validation loss decreased (336.023773 --> 335.619507).\n",
            "\t Train_Loss: 139.2913 Val_Loss: 335.6195  BEST VAL Loss: 335.6195\n",
            "\n",
            "Epoch 495: Validation loss decreased (335.619507 --> 335.220612).\n",
            "\t Train_Loss: 139.2666 Val_Loss: 335.2206  BEST VAL Loss: 335.2206\n",
            "\n",
            "Epoch 496: Validation loss decreased (335.220612 --> 334.827423).\n",
            "\t Train_Loss: 139.2425 Val_Loss: 334.8274  BEST VAL Loss: 334.8274\n",
            "\n",
            "Epoch 497: Validation loss decreased (334.827423 --> 334.438873).\n",
            "\t Train_Loss: 139.2192 Val_Loss: 334.4389  BEST VAL Loss: 334.4389\n",
            "\n",
            "Epoch 498: Validation loss decreased (334.438873 --> 334.056091).\n",
            "\t Train_Loss: 139.1963 Val_Loss: 334.0561  BEST VAL Loss: 334.0561\n",
            "\n",
            "Epoch 499: Validation loss decreased (334.056091 --> 333.678162).\n",
            "\t Train_Loss: 139.1741 Val_Loss: 333.6782  BEST VAL Loss: 333.6782\n",
            "\n",
            "Epoch 500: Validation loss decreased (333.678162 --> 333.305756).\n",
            "\t Train_Loss: 139.1525 Val_Loss: 333.3058  BEST VAL Loss: 333.3058\n",
            "\n",
            "Epoch 501: Validation loss decreased (333.305756 --> 332.938263).\n",
            "\t Train_Loss: 139.1315 Val_Loss: 332.9383  BEST VAL Loss: 332.9383\n",
            "\n",
            "Epoch 502: Validation loss decreased (332.938263 --> 332.575684).\n",
            "\t Train_Loss: 139.1111 Val_Loss: 332.5757  BEST VAL Loss: 332.5757\n",
            "\n",
            "Epoch 503: Validation loss decreased (332.575684 --> 332.218201).\n",
            "\t Train_Loss: 139.0912 Val_Loss: 332.2182  BEST VAL Loss: 332.2182\n",
            "\n",
            "Epoch 504: Validation loss decreased (332.218201 --> 331.865234).\n",
            "\t Train_Loss: 139.0718 Val_Loss: 331.8652  BEST VAL Loss: 331.8652\n",
            "\n",
            "Epoch 505: Validation loss decreased (331.865234 --> 331.517303).\n",
            "\t Train_Loss: 139.0530 Val_Loss: 331.5173  BEST VAL Loss: 331.5173\n",
            "\n",
            "Epoch 506: Validation loss decreased (331.517303 --> 331.174042).\n",
            "\t Train_Loss: 139.0347 Val_Loss: 331.1740  BEST VAL Loss: 331.1740\n",
            "\n",
            "Epoch 507: Validation loss decreased (331.174042 --> 330.835632).\n",
            "\t Train_Loss: 139.0168 Val_Loss: 330.8356  BEST VAL Loss: 330.8356\n",
            "\n",
            "Epoch 508: Validation loss decreased (330.835632 --> 330.501801).\n",
            "\t Train_Loss: 138.9995 Val_Loss: 330.5018  BEST VAL Loss: 330.5018\n",
            "\n",
            "Epoch 509: Validation loss decreased (330.501801 --> 330.172455).\n",
            "\t Train_Loss: 138.9826 Val_Loss: 330.1725  BEST VAL Loss: 330.1725\n",
            "\n",
            "Epoch 510: Validation loss decreased (330.172455 --> 329.847778).\n",
            "\t Train_Loss: 138.9662 Val_Loss: 329.8478  BEST VAL Loss: 329.8478\n",
            "\n",
            "Epoch 511: Validation loss decreased (329.847778 --> 329.527588).\n",
            "\t Train_Loss: 138.9502 Val_Loss: 329.5276  BEST VAL Loss: 329.5276\n",
            "\n",
            "Epoch 512: Validation loss decreased (329.527588 --> 329.211761).\n",
            "\t Train_Loss: 138.9347 Val_Loss: 329.2118  BEST VAL Loss: 329.2118\n",
            "\n",
            "Epoch 513: Validation loss decreased (329.211761 --> 328.900055).\n",
            "\t Train_Loss: 138.9196 Val_Loss: 328.9001  BEST VAL Loss: 328.9001\n",
            "\n",
            "Epoch 514: Validation loss decreased (328.900055 --> 328.592682).\n",
            "\t Train_Loss: 138.9049 Val_Loss: 328.5927  BEST VAL Loss: 328.5927\n",
            "\n",
            "Epoch 515: Validation loss decreased (328.592682 --> 328.289642).\n",
            "\t Train_Loss: 138.8906 Val_Loss: 328.2896  BEST VAL Loss: 328.2896\n",
            "\n",
            "Epoch 516: Validation loss decreased (328.289642 --> 327.990814).\n",
            "\t Train_Loss: 138.8767 Val_Loss: 327.9908  BEST VAL Loss: 327.9908\n",
            "\n",
            "Epoch 517: Validation loss decreased (327.990814 --> 327.695892).\n",
            "\t Train_Loss: 138.8632 Val_Loss: 327.6959  BEST VAL Loss: 327.6959\n",
            "\n",
            "Epoch 518: Validation loss decreased (327.695892 --> 327.405304).\n",
            "\t Train_Loss: 138.8501 Val_Loss: 327.4053  BEST VAL Loss: 327.4053\n",
            "\n",
            "Epoch 519: Validation loss decreased (327.405304 --> 327.118805).\n",
            "\t Train_Loss: 138.8372 Val_Loss: 327.1188  BEST VAL Loss: 327.1188\n",
            "\n",
            "Epoch 520: Validation loss decreased (327.118805 --> 326.836090).\n",
            "\t Train_Loss: 138.8249 Val_Loss: 326.8361  BEST VAL Loss: 326.8361\n",
            "\n",
            "Epoch 521: Validation loss decreased (326.836090 --> 326.557434).\n",
            "\t Train_Loss: 138.8128 Val_Loss: 326.5574  BEST VAL Loss: 326.5574\n",
            "\n",
            "Epoch 522: Validation loss decreased (326.557434 --> 326.282471).\n",
            "\t Train_Loss: 138.8011 Val_Loss: 326.2825  BEST VAL Loss: 326.2825\n",
            "\n",
            "Epoch 523: Validation loss decreased (326.282471 --> 326.011169).\n",
            "\t Train_Loss: 138.7896 Val_Loss: 326.0112  BEST VAL Loss: 326.0112\n",
            "\n",
            "Epoch 524: Validation loss decreased (326.011169 --> 325.743958).\n",
            "\t Train_Loss: 138.7785 Val_Loss: 325.7440  BEST VAL Loss: 325.7440\n",
            "\n",
            "Epoch 525: Validation loss decreased (325.743958 --> 325.480560).\n",
            "\t Train_Loss: 138.7677 Val_Loss: 325.4806  BEST VAL Loss: 325.4806\n",
            "\n",
            "Epoch 526: Validation loss decreased (325.480560 --> 325.220276).\n",
            "\t Train_Loss: 138.7572 Val_Loss: 325.2203  BEST VAL Loss: 325.2203\n",
            "\n",
            "Epoch 527: Validation loss decreased (325.220276 --> 324.963959).\n",
            "\t Train_Loss: 138.7470 Val_Loss: 324.9640  BEST VAL Loss: 324.9640\n",
            "\n",
            "Epoch 528: Validation loss decreased (324.963959 --> 324.711731).\n",
            "\t Train_Loss: 138.7370 Val_Loss: 324.7117  BEST VAL Loss: 324.7117\n",
            "\n",
            "Epoch 529: Validation loss decreased (324.711731 --> 324.462372).\n",
            "\t Train_Loss: 138.7275 Val_Loss: 324.4624  BEST VAL Loss: 324.4624\n",
            "\n",
            "Epoch 530: Validation loss decreased (324.462372 --> 324.216888).\n",
            "\t Train_Loss: 138.7181 Val_Loss: 324.2169  BEST VAL Loss: 324.2169\n",
            "\n",
            "Epoch 531: Validation loss decreased (324.216888 --> 323.974335).\n",
            "\t Train_Loss: 138.7090 Val_Loss: 323.9743  BEST VAL Loss: 323.9743\n",
            "\n",
            "Epoch 532: Validation loss decreased (323.974335 --> 323.735779).\n",
            "\t Train_Loss: 138.7001 Val_Loss: 323.7358  BEST VAL Loss: 323.7358\n",
            "\n",
            "Epoch 533: Validation loss decreased (323.735779 --> 323.500000).\n",
            "\t Train_Loss: 138.6916 Val_Loss: 323.5000  BEST VAL Loss: 323.5000\n",
            "\n",
            "Epoch 534: Validation loss decreased (323.500000 --> 323.267914).\n",
            "\t Train_Loss: 138.6832 Val_Loss: 323.2679  BEST VAL Loss: 323.2679\n",
            "\n",
            "Epoch 535: Validation loss decreased (323.267914 --> 323.039185).\n",
            "\t Train_Loss: 138.6751 Val_Loss: 323.0392  BEST VAL Loss: 323.0392\n",
            "\n",
            "Epoch 536: Validation loss decreased (323.039185 --> 322.813477).\n",
            "\t Train_Loss: 138.6672 Val_Loss: 322.8135  BEST VAL Loss: 322.8135\n",
            "\n",
            "Epoch 537: Validation loss decreased (322.813477 --> 322.590912).\n",
            "\t Train_Loss: 138.6595 Val_Loss: 322.5909  BEST VAL Loss: 322.5909\n",
            "\n",
            "Epoch 538: Validation loss decreased (322.590912 --> 322.371826).\n",
            "\t Train_Loss: 138.6521 Val_Loss: 322.3718  BEST VAL Loss: 322.3718\n",
            "\n",
            "Epoch 539: Validation loss decreased (322.371826 --> 322.155151).\n",
            "\t Train_Loss: 138.6449 Val_Loss: 322.1552  BEST VAL Loss: 322.1552\n",
            "\n",
            "Epoch 540: Validation loss decreased (322.155151 --> 321.942108).\n",
            "\t Train_Loss: 138.6378 Val_Loss: 321.9421  BEST VAL Loss: 321.9421\n",
            "\n",
            "Epoch 541: Validation loss decreased (321.942108 --> 321.731995).\n",
            "\t Train_Loss: 138.6310 Val_Loss: 321.7320  BEST VAL Loss: 321.7320\n",
            "\n",
            "Epoch 542: Validation loss decreased (321.731995 --> 321.524963).\n",
            "\t Train_Loss: 138.6243 Val_Loss: 321.5250  BEST VAL Loss: 321.5250\n",
            "\n",
            "Epoch 543: Validation loss decreased (321.524963 --> 321.320862).\n",
            "\t Train_Loss: 138.6180 Val_Loss: 321.3209  BEST VAL Loss: 321.3209\n",
            "\n",
            "Epoch 544: Validation loss decreased (321.320862 --> 321.119507).\n",
            "\t Train_Loss: 138.6118 Val_Loss: 321.1195  BEST VAL Loss: 321.1195\n",
            "\n",
            "Epoch 545: Validation loss decreased (321.119507 --> 320.920746).\n",
            "\t Train_Loss: 138.6056 Val_Loss: 320.9207  BEST VAL Loss: 320.9207\n",
            "\n",
            "Epoch 546: Validation loss decreased (320.920746 --> 320.725220).\n",
            "\t Train_Loss: 138.5997 Val_Loss: 320.7252  BEST VAL Loss: 320.7252\n",
            "\n",
            "Epoch 547: Validation loss decreased (320.725220 --> 320.532684).\n",
            "\t Train_Loss: 138.5940 Val_Loss: 320.5327  BEST VAL Loss: 320.5327\n",
            "\n",
            "Epoch 548: Validation loss decreased (320.532684 --> 320.342346).\n",
            "\t Train_Loss: 138.5885 Val_Loss: 320.3423  BEST VAL Loss: 320.3423\n",
            "\n",
            "Epoch 549: Validation loss decreased (320.342346 --> 320.155182).\n",
            "\t Train_Loss: 138.5830 Val_Loss: 320.1552  BEST VAL Loss: 320.1552\n",
            "\n",
            "Epoch 550: Validation loss decreased (320.155182 --> 319.970551).\n",
            "\t Train_Loss: 138.5778 Val_Loss: 319.9706  BEST VAL Loss: 319.9706\n",
            "\n",
            "Epoch 551: Validation loss decreased (319.970551 --> 319.788452).\n",
            "\t Train_Loss: 138.5727 Val_Loss: 319.7885  BEST VAL Loss: 319.7885\n",
            "\n",
            "Epoch 552: Validation loss decreased (319.788452 --> 319.609131).\n",
            "\t Train_Loss: 138.5677 Val_Loss: 319.6091  BEST VAL Loss: 319.6091\n",
            "\n",
            "Epoch 553: Validation loss decreased (319.609131 --> 319.432220).\n",
            "\t Train_Loss: 138.5630 Val_Loss: 319.4322  BEST VAL Loss: 319.4322\n",
            "\n",
            "Epoch 554: Validation loss decreased (319.432220 --> 319.258118).\n",
            "\t Train_Loss: 138.5583 Val_Loss: 319.2581  BEST VAL Loss: 319.2581\n",
            "\n",
            "Epoch 555: Validation loss decreased (319.258118 --> 319.086182).\n",
            "\t Train_Loss: 138.5538 Val_Loss: 319.0862  BEST VAL Loss: 319.0862\n",
            "\n",
            "Epoch 556: Validation loss decreased (319.086182 --> 318.916901).\n",
            "\t Train_Loss: 138.5493 Val_Loss: 318.9169  BEST VAL Loss: 318.9169\n",
            "\n",
            "Epoch 557: Validation loss decreased (318.916901 --> 318.750183).\n",
            "\t Train_Loss: 138.5451 Val_Loss: 318.7502  BEST VAL Loss: 318.7502\n",
            "\n",
            "Epoch 558: Validation loss decreased (318.750183 --> 318.585815).\n",
            "\t Train_Loss: 138.5409 Val_Loss: 318.5858  BEST VAL Loss: 318.5858\n",
            "\n",
            "Epoch 559: Validation loss decreased (318.585815 --> 318.423828).\n",
            "\t Train_Loss: 138.5370 Val_Loss: 318.4238  BEST VAL Loss: 318.4238\n",
            "\n",
            "Epoch 560: Validation loss decreased (318.423828 --> 318.264099).\n",
            "\t Train_Loss: 138.5330 Val_Loss: 318.2641  BEST VAL Loss: 318.2641\n",
            "\n",
            "Epoch 561: Validation loss decreased (318.264099 --> 318.106873).\n",
            "\t Train_Loss: 138.5292 Val_Loss: 318.1069  BEST VAL Loss: 318.1069\n",
            "\n",
            "Epoch 562: Validation loss decreased (318.106873 --> 317.951721).\n",
            "\t Train_Loss: 138.5256 Val_Loss: 317.9517  BEST VAL Loss: 317.9517\n",
            "\n",
            "Epoch 563: Validation loss decreased (317.951721 --> 317.799072).\n",
            "\t Train_Loss: 138.5220 Val_Loss: 317.7991  BEST VAL Loss: 317.7991\n",
            "\n",
            "Epoch 564: Validation loss decreased (317.799072 --> 317.648590).\n",
            "\t Train_Loss: 138.5186 Val_Loss: 317.6486  BEST VAL Loss: 317.6486\n",
            "\n",
            "Epoch 565: Validation loss decreased (317.648590 --> 317.500244).\n",
            "\t Train_Loss: 138.5152 Val_Loss: 317.5002  BEST VAL Loss: 317.5002\n",
            "\n",
            "Epoch 566: Validation loss decreased (317.500244 --> 317.354004).\n",
            "\t Train_Loss: 138.5120 Val_Loss: 317.3540  BEST VAL Loss: 317.3540\n",
            "\n",
            "Epoch 567: Validation loss decreased (317.354004 --> 317.209869).\n",
            "\t Train_Loss: 138.5088 Val_Loss: 317.2099  BEST VAL Loss: 317.2099\n",
            "\n",
            "Epoch 568: Validation loss decreased (317.209869 --> 317.067749).\n",
            "\t Train_Loss: 138.5057 Val_Loss: 317.0677  BEST VAL Loss: 317.0677\n",
            "\n",
            "Epoch 569: Validation loss decreased (317.067749 --> 316.928162).\n",
            "\t Train_Loss: 138.5027 Val_Loss: 316.9282  BEST VAL Loss: 316.9282\n",
            "\n",
            "Epoch 570: Validation loss decreased (316.928162 --> 316.790131).\n",
            "\t Train_Loss: 138.4998 Val_Loss: 316.7901  BEST VAL Loss: 316.7901\n",
            "\n",
            "Epoch 571: Validation loss decreased (316.790131 --> 316.654541).\n",
            "\t Train_Loss: 138.4971 Val_Loss: 316.6545  BEST VAL Loss: 316.6545\n",
            "\n",
            "Epoch 572: Validation loss decreased (316.654541 --> 316.520721).\n",
            "\t Train_Loss: 138.4943 Val_Loss: 316.5207  BEST VAL Loss: 316.5207\n",
            "\n",
            "Epoch 573: Validation loss decreased (316.520721 --> 316.388885).\n",
            "\t Train_Loss: 138.4917 Val_Loss: 316.3889  BEST VAL Loss: 316.3889\n",
            "\n",
            "Epoch 574: Validation loss decreased (316.388885 --> 316.259094).\n",
            "\t Train_Loss: 138.4892 Val_Loss: 316.2591  BEST VAL Loss: 316.2591\n",
            "\n",
            "Epoch 575: Validation loss decreased (316.259094 --> 316.131104).\n",
            "\t Train_Loss: 138.4867 Val_Loss: 316.1311  BEST VAL Loss: 316.1311\n",
            "\n",
            "Epoch 576: Validation loss decreased (316.131104 --> 316.005035).\n",
            "\t Train_Loss: 138.4842 Val_Loss: 316.0050  BEST VAL Loss: 316.0050\n",
            "\n",
            "Epoch 577: Validation loss decreased (316.005035 --> 315.880829).\n",
            "\t Train_Loss: 138.4819 Val_Loss: 315.8808  BEST VAL Loss: 315.8808\n",
            "\n",
            "Epoch 578: Validation loss decreased (315.880829 --> 315.758667).\n",
            "\t Train_Loss: 138.4797 Val_Loss: 315.7587  BEST VAL Loss: 315.7587\n",
            "\n",
            "Epoch 579: Validation loss decreased (315.758667 --> 315.637787).\n",
            "\t Train_Loss: 138.4775 Val_Loss: 315.6378  BEST VAL Loss: 315.6378\n",
            "\n",
            "Epoch 580: Validation loss decreased (315.637787 --> 315.519287).\n",
            "\t Train_Loss: 138.4753 Val_Loss: 315.5193  BEST VAL Loss: 315.5193\n",
            "\n",
            "Epoch 581: Validation loss decreased (315.519287 --> 315.402344).\n",
            "\t Train_Loss: 138.4733 Val_Loss: 315.4023  BEST VAL Loss: 315.4023\n",
            "\n",
            "Epoch 582: Validation loss decreased (315.402344 --> 315.287292).\n",
            "\t Train_Loss: 138.4713 Val_Loss: 315.2873  BEST VAL Loss: 315.2873\n",
            "\n",
            "Epoch 583: Validation loss decreased (315.287292 --> 315.173828).\n",
            "\t Train_Loss: 138.4694 Val_Loss: 315.1738  BEST VAL Loss: 315.1738\n",
            "\n",
            "Epoch 584: Validation loss decreased (315.173828 --> 315.061920).\n",
            "\t Train_Loss: 138.4675 Val_Loss: 315.0619  BEST VAL Loss: 315.0619\n",
            "\n",
            "Epoch 585: Validation loss decreased (315.061920 --> 314.951660).\n",
            "\t Train_Loss: 138.4656 Val_Loss: 314.9517  BEST VAL Loss: 314.9517\n",
            "\n",
            "Epoch 586: Validation loss decreased (314.951660 --> 314.843353).\n",
            "\t Train_Loss: 138.4638 Val_Loss: 314.8434  BEST VAL Loss: 314.8434\n",
            "\n",
            "Epoch 587: Validation loss decreased (314.843353 --> 314.736389).\n",
            "\t Train_Loss: 138.4622 Val_Loss: 314.7364  BEST VAL Loss: 314.7364\n",
            "\n",
            "Epoch 588: Validation loss decreased (314.736389 --> 314.631470).\n",
            "\t Train_Loss: 138.4605 Val_Loss: 314.6315  BEST VAL Loss: 314.6315\n",
            "\n",
            "Epoch 589: Validation loss decreased (314.631470 --> 314.527710).\n",
            "\t Train_Loss: 138.4589 Val_Loss: 314.5277  BEST VAL Loss: 314.5277\n",
            "\n",
            "Epoch 590: Validation loss decreased (314.527710 --> 314.425537).\n",
            "\t Train_Loss: 138.4574 Val_Loss: 314.4255  BEST VAL Loss: 314.4255\n",
            "\n",
            "Epoch 591: Validation loss decreased (314.425537 --> 314.324890).\n",
            "\t Train_Loss: 138.4558 Val_Loss: 314.3249  BEST VAL Loss: 314.3249\n",
            "\n",
            "Epoch 592: Validation loss decreased (314.324890 --> 314.226013).\n",
            "\t Train_Loss: 138.4543 Val_Loss: 314.2260  BEST VAL Loss: 314.2260\n",
            "\n",
            "Epoch 593: Validation loss decreased (314.226013 --> 314.128601).\n",
            "\t Train_Loss: 138.4529 Val_Loss: 314.1286  BEST VAL Loss: 314.1286\n",
            "\n",
            "Epoch 594: Validation loss decreased (314.128601 --> 314.032410).\n",
            "\t Train_Loss: 138.4516 Val_Loss: 314.0324  BEST VAL Loss: 314.0324\n",
            "\n",
            "Epoch 595: Validation loss decreased (314.032410 --> 313.937714).\n",
            "\t Train_Loss: 138.4503 Val_Loss: 313.9377  BEST VAL Loss: 313.9377\n",
            "\n",
            "Epoch 596: Validation loss decreased (313.937714 --> 313.844727).\n",
            "\t Train_Loss: 138.4489 Val_Loss: 313.8447  BEST VAL Loss: 313.8447\n",
            "\n",
            "Epoch 597: Validation loss decreased (313.844727 --> 313.753021).\n",
            "\t Train_Loss: 138.4477 Val_Loss: 313.7530  BEST VAL Loss: 313.7530\n",
            "\n",
            "Epoch 598: Validation loss decreased (313.753021 --> 313.662537).\n",
            "\t Train_Loss: 138.4465 Val_Loss: 313.6625  BEST VAL Loss: 313.6625\n",
            "\n",
            "Epoch 599: Validation loss decreased (313.662537 --> 313.573578).\n",
            "\t Train_Loss: 138.4453 Val_Loss: 313.5736  BEST VAL Loss: 313.5736\n",
            "\n",
            "Epoch 600: Validation loss decreased (313.573578 --> 313.485992).\n",
            "\t Train_Loss: 138.4442 Val_Loss: 313.4860  BEST VAL Loss: 313.4860\n",
            "\n",
            "Epoch 601: Validation loss decreased (313.485992 --> 313.399567).\n",
            "\t Train_Loss: 138.4431 Val_Loss: 313.3996  BEST VAL Loss: 313.3996\n",
            "\n",
            "Epoch 602: Validation loss decreased (313.399567 --> 313.314850).\n",
            "\t Train_Loss: 138.4420 Val_Loss: 313.3148  BEST VAL Loss: 313.3148\n",
            "\n",
            "Epoch 603: Validation loss decreased (313.314850 --> 313.231079).\n",
            "\t Train_Loss: 138.4410 Val_Loss: 313.2311  BEST VAL Loss: 313.2311\n",
            "\n",
            "Epoch 604: Validation loss decreased (313.231079 --> 313.148865).\n",
            "\t Train_Loss: 138.4399 Val_Loss: 313.1489  BEST VAL Loss: 313.1489\n",
            "\n",
            "Epoch 605: Validation loss decreased (313.148865 --> 313.067749).\n",
            "\t Train_Loss: 138.4390 Val_Loss: 313.0677  BEST VAL Loss: 313.0677\n",
            "\n",
            "Epoch 606: Validation loss decreased (313.067749 --> 312.987976).\n",
            "\t Train_Loss: 138.4380 Val_Loss: 312.9880  BEST VAL Loss: 312.9880\n",
            "\n",
            "Epoch 607: Validation loss decreased (312.987976 --> 312.909363).\n",
            "\t Train_Loss: 138.4371 Val_Loss: 312.9094  BEST VAL Loss: 312.9094\n",
            "\n",
            "Epoch 608: Validation loss decreased (312.909363 --> 312.832092).\n",
            "\t Train_Loss: 138.4362 Val_Loss: 312.8321  BEST VAL Loss: 312.8321\n",
            "\n",
            "Epoch 609: Validation loss decreased (312.832092 --> 312.755920).\n",
            "\t Train_Loss: 138.4354 Val_Loss: 312.7559  BEST VAL Loss: 312.7559\n",
            "\n",
            "Epoch 610: Validation loss decreased (312.755920 --> 312.680817).\n",
            "\t Train_Loss: 138.4346 Val_Loss: 312.6808  BEST VAL Loss: 312.6808\n",
            "\n",
            "Epoch 611: Validation loss decreased (312.680817 --> 312.606903).\n",
            "\t Train_Loss: 138.4338 Val_Loss: 312.6069  BEST VAL Loss: 312.6069\n",
            "\n",
            "Epoch 612: Validation loss decreased (312.606903 --> 312.534485).\n",
            "\t Train_Loss: 138.4330 Val_Loss: 312.5345  BEST VAL Loss: 312.5345\n",
            "\n",
            "Epoch 613: Validation loss decreased (312.534485 --> 312.463013).\n",
            "\t Train_Loss: 138.4323 Val_Loss: 312.4630  BEST VAL Loss: 312.4630\n",
            "\n",
            "Epoch 614: Validation loss decreased (312.463013 --> 312.392181).\n",
            "\t Train_Loss: 138.4315 Val_Loss: 312.3922  BEST VAL Loss: 312.3922\n",
            "\n",
            "Epoch 615: Validation loss decreased (312.392181 --> 312.322968).\n",
            "\t Train_Loss: 138.4308 Val_Loss: 312.3230  BEST VAL Loss: 312.3230\n",
            "\n",
            "Epoch 616: Validation loss decreased (312.322968 --> 312.254547).\n",
            "\t Train_Loss: 138.4301 Val_Loss: 312.2545  BEST VAL Loss: 312.2545\n",
            "\n",
            "Epoch 617: Validation loss decreased (312.254547 --> 312.187531).\n",
            "\t Train_Loss: 138.4295 Val_Loss: 312.1875  BEST VAL Loss: 312.1875\n",
            "\n",
            "Epoch 618: Validation loss decreased (312.187531 --> 312.121368).\n",
            "\t Train_Loss: 138.4289 Val_Loss: 312.1214  BEST VAL Loss: 312.1214\n",
            "\n",
            "Epoch 619: Validation loss decreased (312.121368 --> 312.056335).\n",
            "\t Train_Loss: 138.4283 Val_Loss: 312.0563  BEST VAL Loss: 312.0563\n",
            "\n",
            "Epoch 620: Validation loss decreased (312.056335 --> 311.992188).\n",
            "\t Train_Loss: 138.4276 Val_Loss: 311.9922  BEST VAL Loss: 311.9922\n",
            "\n",
            "Epoch 621: Validation loss decreased (311.992188 --> 311.928955).\n",
            "\t Train_Loss: 138.4270 Val_Loss: 311.9290  BEST VAL Loss: 311.9290\n",
            "\n",
            "Epoch 622: Validation loss decreased (311.928955 --> 311.866852).\n",
            "\t Train_Loss: 138.4265 Val_Loss: 311.8669  BEST VAL Loss: 311.8669\n",
            "\n",
            "Epoch 623: Validation loss decreased (311.866852 --> 311.805817).\n",
            "\t Train_Loss: 138.4259 Val_Loss: 311.8058  BEST VAL Loss: 311.8058\n",
            "\n",
            "Epoch 624: Validation loss decreased (311.805817 --> 311.745667).\n",
            "\t Train_Loss: 138.4254 Val_Loss: 311.7457  BEST VAL Loss: 311.7457\n",
            "\n",
            "Epoch 625: Validation loss decreased (311.745667 --> 311.686432).\n",
            "\t Train_Loss: 138.4249 Val_Loss: 311.6864  BEST VAL Loss: 311.6864\n",
            "\n",
            "Epoch 626: Validation loss decreased (311.686432 --> 311.628326).\n",
            "\t Train_Loss: 138.4244 Val_Loss: 311.6283  BEST VAL Loss: 311.6283\n",
            "\n",
            "Epoch 627: Validation loss decreased (311.628326 --> 311.571045).\n",
            "\t Train_Loss: 138.4240 Val_Loss: 311.5710  BEST VAL Loss: 311.5710\n",
            "\n",
            "Epoch 628: Validation loss decreased (311.571045 --> 311.514465).\n",
            "\t Train_Loss: 138.4235 Val_Loss: 311.5145  BEST VAL Loss: 311.5145\n",
            "\n",
            "Epoch 629: Validation loss decreased (311.514465 --> 311.459229).\n",
            "\t Train_Loss: 138.4230 Val_Loss: 311.4592  BEST VAL Loss: 311.4592\n",
            "\n",
            "Epoch 630: Validation loss decreased (311.459229 --> 311.404419).\n",
            "\t Train_Loss: 138.4227 Val_Loss: 311.4044  BEST VAL Loss: 311.4044\n",
            "\n",
            "Epoch 631: Validation loss decreased (311.404419 --> 311.350494).\n",
            "\t Train_Loss: 138.4222 Val_Loss: 311.3505  BEST VAL Loss: 311.3505\n",
            "\n",
            "Epoch 632: Validation loss decreased (311.350494 --> 311.297546).\n",
            "\t Train_Loss: 138.4218 Val_Loss: 311.2975  BEST VAL Loss: 311.2975\n",
            "\n",
            "Epoch 633: Validation loss decreased (311.297546 --> 311.245544).\n",
            "\t Train_Loss: 138.4214 Val_Loss: 311.2455  BEST VAL Loss: 311.2455\n",
            "\n",
            "Epoch 634: Validation loss decreased (311.245544 --> 311.194305).\n",
            "\t Train_Loss: 138.4210 Val_Loss: 311.1943  BEST VAL Loss: 311.1943\n",
            "\n",
            "Epoch 635: Validation loss decreased (311.194305 --> 311.143951).\n",
            "\t Train_Loss: 138.4207 Val_Loss: 311.1440  BEST VAL Loss: 311.1440\n",
            "\n",
            "Epoch 636: Validation loss decreased (311.143951 --> 311.094208).\n",
            "\t Train_Loss: 138.4203 Val_Loss: 311.0942  BEST VAL Loss: 311.0942\n",
            "\n",
            "Epoch 637: Validation loss decreased (311.094208 --> 311.045654).\n",
            "\t Train_Loss: 138.4200 Val_Loss: 311.0457  BEST VAL Loss: 311.0457\n",
            "\n",
            "Epoch 638: Validation loss decreased (311.045654 --> 310.997467).\n",
            "\t Train_Loss: 138.4196 Val_Loss: 310.9975  BEST VAL Loss: 310.9975\n",
            "\n",
            "Epoch 639: Validation loss decreased (310.997467 --> 310.950256).\n",
            "\t Train_Loss: 138.4193 Val_Loss: 310.9503  BEST VAL Loss: 310.9503\n",
            "\n",
            "Epoch 640: Validation loss decreased (310.950256 --> 310.903625).\n",
            "\t Train_Loss: 138.4190 Val_Loss: 310.9036  BEST VAL Loss: 310.9036\n",
            "\n",
            "Epoch 641: Validation loss decreased (310.903625 --> 310.857849).\n",
            "\t Train_Loss: 138.4187 Val_Loss: 310.8578  BEST VAL Loss: 310.8578\n",
            "\n",
            "Epoch 642: Validation loss decreased (310.857849 --> 310.812836).\n",
            "\t Train_Loss: 138.4184 Val_Loss: 310.8128  BEST VAL Loss: 310.8128\n",
            "\n",
            "Epoch 643: Validation loss decreased (310.812836 --> 310.768646).\n",
            "\t Train_Loss: 138.4181 Val_Loss: 310.7686  BEST VAL Loss: 310.7686\n",
            "\n",
            "Epoch 644: Validation loss decreased (310.768646 --> 310.725159).\n",
            "\t Train_Loss: 138.4179 Val_Loss: 310.7252  BEST VAL Loss: 310.7252\n",
            "\n",
            "Epoch 645: Validation loss decreased (310.725159 --> 310.682312).\n",
            "\t Train_Loss: 138.4176 Val_Loss: 310.6823  BEST VAL Loss: 310.6823\n",
            "\n",
            "Epoch 646: Validation loss decreased (310.682312 --> 310.639954).\n",
            "\t Train_Loss: 138.4174 Val_Loss: 310.6400  BEST VAL Loss: 310.6400\n",
            "\n",
            "Epoch 647: Validation loss decreased (310.639954 --> 310.598419).\n",
            "\t Train_Loss: 138.4171 Val_Loss: 310.5984  BEST VAL Loss: 310.5984\n",
            "\n",
            "Epoch 648: Validation loss decreased (310.598419 --> 310.557800).\n",
            "\t Train_Loss: 138.4169 Val_Loss: 310.5578  BEST VAL Loss: 310.5578\n",
            "\n",
            "Epoch 649: Validation loss decreased (310.557800 --> 310.517487).\n",
            "\t Train_Loss: 138.4166 Val_Loss: 310.5175  BEST VAL Loss: 310.5175\n",
            "\n",
            "Epoch 650: Validation loss decreased (310.517487 --> 310.478088).\n",
            "\t Train_Loss: 138.4164 Val_Loss: 310.4781  BEST VAL Loss: 310.4781\n",
            "\n",
            "Epoch 651: Validation loss decreased (310.478088 --> 310.439240).\n",
            "\t Train_Loss: 138.4162 Val_Loss: 310.4392  BEST VAL Loss: 310.4392\n",
            "\n",
            "Epoch 652: Validation loss decreased (310.439240 --> 310.400970).\n",
            "\t Train_Loss: 138.4160 Val_Loss: 310.4010  BEST VAL Loss: 310.4010\n",
            "\n",
            "Epoch 653: Validation loss decreased (310.400970 --> 310.363342).\n",
            "\t Train_Loss: 138.4158 Val_Loss: 310.3633  BEST VAL Loss: 310.3633\n",
            "\n",
            "Epoch 654: Validation loss decreased (310.363342 --> 310.326569).\n",
            "\t Train_Loss: 138.4156 Val_Loss: 310.3266  BEST VAL Loss: 310.3266\n",
            "\n",
            "Epoch 655: Validation loss decreased (310.326569 --> 310.290344).\n",
            "\t Train_Loss: 138.4154 Val_Loss: 310.2903  BEST VAL Loss: 310.2903\n",
            "\n",
            "Epoch 656: Validation loss decreased (310.290344 --> 310.254456).\n",
            "\t Train_Loss: 138.4153 Val_Loss: 310.2545  BEST VAL Loss: 310.2545\n",
            "\n",
            "Epoch 657: Validation loss decreased (310.254456 --> 310.219299).\n",
            "\t Train_Loss: 138.4151 Val_Loss: 310.2193  BEST VAL Loss: 310.2193\n",
            "\n",
            "Epoch 658: Validation loss decreased (310.219299 --> 310.184784).\n",
            "\t Train_Loss: 138.4149 Val_Loss: 310.1848  BEST VAL Loss: 310.1848\n",
            "\n",
            "Epoch 659: Validation loss decreased (310.184784 --> 310.150574).\n",
            "\t Train_Loss: 138.4147 Val_Loss: 310.1506  BEST VAL Loss: 310.1506\n",
            "\n",
            "Epoch 660: Validation loss decreased (310.150574 --> 310.117645).\n",
            "\t Train_Loss: 138.4146 Val_Loss: 310.1176  BEST VAL Loss: 310.1176\n",
            "\n",
            "Epoch 661: Validation loss decreased (310.117645 --> 310.084534).\n",
            "\t Train_Loss: 138.4145 Val_Loss: 310.0845  BEST VAL Loss: 310.0845\n",
            "\n",
            "Epoch 662: Validation loss decreased (310.084534 --> 310.052185).\n",
            "\t Train_Loss: 138.4143 Val_Loss: 310.0522  BEST VAL Loss: 310.0522\n",
            "\n",
            "Epoch 663: Validation loss decreased (310.052185 --> 310.020294).\n",
            "\t Train_Loss: 138.4142 Val_Loss: 310.0203  BEST VAL Loss: 310.0203\n",
            "\n",
            "Epoch 664: Validation loss decreased (310.020294 --> 309.989105).\n",
            "\t Train_Loss: 138.4140 Val_Loss: 309.9891  BEST VAL Loss: 309.9891\n",
            "\n",
            "Epoch 665: Validation loss decreased (309.989105 --> 309.958191).\n",
            "\t Train_Loss: 138.4139 Val_Loss: 309.9582  BEST VAL Loss: 309.9582\n",
            "\n",
            "Epoch 666: Validation loss decreased (309.958191 --> 309.928162).\n",
            "\t Train_Loss: 138.4137 Val_Loss: 309.9282  BEST VAL Loss: 309.9282\n",
            "\n",
            "Epoch 667: Validation loss decreased (309.928162 --> 309.898376).\n",
            "\t Train_Loss: 138.4136 Val_Loss: 309.8984  BEST VAL Loss: 309.8984\n",
            "\n",
            "Epoch 668: Validation loss decreased (309.898376 --> 309.869019).\n",
            "\t Train_Loss: 138.4135 Val_Loss: 309.8690  BEST VAL Loss: 309.8690\n",
            "\n",
            "Epoch 669: Validation loss decreased (309.869019 --> 309.840271).\n",
            "\t Train_Loss: 138.4134 Val_Loss: 309.8403  BEST VAL Loss: 309.8403\n",
            "\n",
            "Epoch 670: Validation loss decreased (309.840271 --> 309.811951).\n",
            "\t Train_Loss: 138.4133 Val_Loss: 309.8120  BEST VAL Loss: 309.8120\n",
            "\n",
            "Epoch 671: Validation loss decreased (309.811951 --> 309.784302).\n",
            "\t Train_Loss: 138.4132 Val_Loss: 309.7843  BEST VAL Loss: 309.7843\n",
            "\n",
            "Epoch 672: Validation loss decreased (309.784302 --> 309.756897).\n",
            "\t Train_Loss: 138.4131 Val_Loss: 309.7569  BEST VAL Loss: 309.7569\n",
            "\n",
            "Epoch 673: Validation loss decreased (309.756897 --> 309.730164).\n",
            "\t Train_Loss: 138.4130 Val_Loss: 309.7302  BEST VAL Loss: 309.7302\n",
            "\n",
            "Epoch 674: Validation loss decreased (309.730164 --> 309.703857).\n",
            "\t Train_Loss: 138.4129 Val_Loss: 309.7039  BEST VAL Loss: 309.7039\n",
            "\n",
            "Epoch 675: Validation loss decreased (309.703857 --> 309.677795).\n",
            "\t Train_Loss: 138.4128 Val_Loss: 309.6778  BEST VAL Loss: 309.6778\n",
            "\n",
            "Epoch 676: Validation loss decreased (309.677795 --> 309.652344).\n",
            "\t Train_Loss: 138.4127 Val_Loss: 309.6523  BEST VAL Loss: 309.6523\n",
            "\n",
            "Epoch 677: Validation loss decreased (309.652344 --> 309.627228).\n",
            "\t Train_Loss: 138.4126 Val_Loss: 309.6272  BEST VAL Loss: 309.6272\n",
            "\n",
            "Epoch 678: Validation loss decreased (309.627228 --> 309.602478).\n",
            "\t Train_Loss: 138.4125 Val_Loss: 309.6025  BEST VAL Loss: 309.6025\n",
            "\n",
            "Epoch 679: Validation loss decreased (309.602478 --> 309.578369).\n",
            "\t Train_Loss: 138.4123 Val_Loss: 309.5784  BEST VAL Loss: 309.5784\n",
            "\n",
            "Epoch 680: Validation loss decreased (309.578369 --> 309.554413).\n",
            "\t Train_Loss: 138.4122 Val_Loss: 309.5544  BEST VAL Loss: 309.5544\n",
            "\n",
            "Epoch 681: Validation loss decreased (309.554413 --> 309.531708).\n",
            "\t Train_Loss: 138.4117 Val_Loss: 309.5317  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 682: Validation loss did not decrease\n",
            "\t Train_Loss: 138.4010 Val_Loss: 309.7062  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 683: Validation loss did not decrease\n",
            "\t Train_Loss: 137.3384 Val_Loss: 335.1846  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 684: Validation loss did not decrease\n",
            "\t Train_Loss: 129.4582 Val_Loss: 310.5068  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 685: Validation loss did not decrease\n",
            "\t Train_Loss: 134.5087 Val_Loss: 311.6078  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 686: Validation loss did not decrease\n",
            "\t Train_Loss: 131.8023 Val_Loss: 351.0223  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 687: Validation loss did not decrease\n",
            "\t Train_Loss: 132.1111 Val_Loss: 321.0367  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 688: Validation loss did not decrease\n",
            "\t Train_Loss: 126.1610 Val_Loss: 312.1932  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 689: Validation loss did not decrease\n",
            "\t Train_Loss: 128.4103 Val_Loss: 315.1803  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 690: Validation loss did not decrease\n",
            "\t Train_Loss: 125.5913 Val_Loss: 333.5014  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 691: Validation loss did not decrease\n",
            "\t Train_Loss: 126.5575 Val_Loss: 323.5240  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 692: Validation loss did not decrease\n",
            "\t Train_Loss: 124.0071 Val_Loss: 311.9704  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 693: Validation loss did not decrease\n",
            "\t Train_Loss: 124.2776 Val_Loss: 311.2675  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 694: Validation loss did not decrease\n",
            "\t Train_Loss: 123.6927 Val_Loss: 317.6198  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 695: Validation loss did not decrease\n",
            "\t Train_Loss: 121.9101 Val_Loss: 323.3091  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 696: Validation loss did not decrease\n",
            "\t Train_Loss: 122.7770 Val_Loss: 314.6602  BEST VAL Loss: 309.5317\n",
            "\n",
            "Epoch 697: Validation loss decreased (309.531708 --> 309.005219).\n",
            "\t Train_Loss: 120.8504 Val_Loss: 309.0052  BEST VAL Loss: 309.0052\n",
            "\n",
            "Epoch 698: Validation loss decreased (309.005219 --> 308.622192).\n",
            "\t Train_Loss: 121.2409 Val_Loss: 308.6222  BEST VAL Loss: 308.6222\n",
            "\n",
            "Epoch 699: Validation loss did not decrease\n",
            "\t Train_Loss: 120.6107 Val_Loss: 312.1094  BEST VAL Loss: 308.6222\n",
            "\n",
            "Epoch 700: Validation loss did not decrease\n",
            "\t Train_Loss: 119.6882 Val_Loss: 314.9064  BEST VAL Loss: 308.6222\n",
            "\n",
            "Epoch 701: Validation loss did not decrease\n",
            "\t Train_Loss: 120.0797 Val_Loss: 310.4911  BEST VAL Loss: 308.6222\n",
            "\n",
            "Epoch 702: Validation loss decreased (308.622192 --> 306.184479).\n",
            "\t Train_Loss: 119.0855 Val_Loss: 306.1845  BEST VAL Loss: 306.1845\n",
            "\n",
            "Epoch 703: Validation loss decreased (306.184479 --> 305.012268).\n",
            "\t Train_Loss: 119.0017 Val_Loss: 305.0123  BEST VAL Loss: 305.0123\n",
            "\n",
            "Epoch 704: Validation loss did not decrease\n",
            "\t Train_Loss: 118.9399 Val_Loss: 306.0399  BEST VAL Loss: 305.0123\n",
            "\n",
            "Epoch 705: Validation loss did not decrease\n",
            "\t Train_Loss: 118.2190 Val_Loss: 308.0782  BEST VAL Loss: 305.0123\n",
            "\n",
            "Epoch 706: Validation loss did not decrease\n",
            "\t Train_Loss: 118.3105 Val_Loss: 307.0070  BEST VAL Loss: 305.0123\n",
            "\n",
            "Epoch 707: Validation loss decreased (305.012268 --> 303.761902).\n",
            "\t Train_Loss: 118.0646 Val_Loss: 303.7619  BEST VAL Loss: 303.7619\n",
            "\n",
            "Epoch 708: Validation loss decreased (303.761902 --> 301.861328).\n",
            "\t Train_Loss: 117.6130 Val_Loss: 301.8613  BEST VAL Loss: 301.8613\n",
            "\n",
            "Epoch 709: Validation loss decreased (301.861328 --> 301.465637).\n",
            "\t Train_Loss: 117.7054 Val_Loss: 301.4656  BEST VAL Loss: 301.4656\n",
            "\n",
            "Epoch 710: Validation loss did not decrease\n",
            "\t Train_Loss: 117.4268 Val_Loss: 302.2048  BEST VAL Loss: 301.4656\n",
            "\n",
            "Epoch 711: Validation loss did not decrease\n",
            "\t Train_Loss: 117.1306 Val_Loss: 302.7852  BEST VAL Loss: 301.4656\n",
            "\n",
            "Epoch 712: Validation loss decreased (301.465637 --> 301.446106).\n",
            "\t Train_Loss: 117.1823 Val_Loss: 301.4461  BEST VAL Loss: 301.4461\n",
            "\n",
            "Epoch 713: Validation loss decreased (301.446106 --> 299.425171).\n",
            "\t Train_Loss: 116.9278 Val_Loss: 299.4252  BEST VAL Loss: 299.4252\n",
            "\n",
            "Epoch 714: Validation loss decreased (299.425171 --> 298.221130).\n",
            "\t Train_Loss: 116.7305 Val_Loss: 298.2211  BEST VAL Loss: 298.2211\n",
            "\n",
            "Epoch 715: Validation loss decreased (298.221130 --> 297.890991).\n",
            "\t Train_Loss: 116.7399 Val_Loss: 297.8910  BEST VAL Loss: 297.8910\n",
            "\n",
            "Epoch 716: Validation loss did not decrease\n",
            "\t Train_Loss: 116.5362 Val_Loss: 298.1835  BEST VAL Loss: 297.8910\n",
            "\n",
            "Epoch 717: Validation loss did not decrease\n",
            "\t Train_Loss: 116.3734 Val_Loss: 298.2593  BEST VAL Loss: 297.8910\n",
            "\n",
            "Epoch 718: Validation loss decreased (297.890991 --> 297.268799).\n",
            "\t Train_Loss: 116.3625 Val_Loss: 297.2688  BEST VAL Loss: 297.2688\n",
            "\n",
            "Epoch 719: Validation loss decreased (297.268799 --> 295.896912).\n",
            "\t Train_Loss: 116.1931 Val_Loss: 295.8969  BEST VAL Loss: 295.8969\n",
            "\n",
            "Epoch 720: Validation loss did not decrease\n",
            "\t Train_Loss: 115.8501 Val_Loss: 302.4540  BEST VAL Loss: 295.8969\n",
            "\n",
            "Epoch 721: Validation loss did not decrease\n",
            "\t Train_Loss: 109.1604 Val_Loss: 423.7699  BEST VAL Loss: 295.8969\n",
            "\n",
            "Epoch 722: Validation loss did not decrease\n",
            "\t Train_Loss: 136.3052 Val_Loss: 403.8139  BEST VAL Loss: 295.8969\n",
            "\n",
            "Epoch 723: Validation loss did not decrease\n",
            "\t Train_Loss: 133.5207 Val_Loss: 327.8952  BEST VAL Loss: 295.8969\n",
            "\n",
            "Epoch 724: Validation loss decreased (295.896912 --> 291.647064).\n",
            "\t Train_Loss: 113.1086 Val_Loss: 291.6471  BEST VAL Loss: 291.6471\n",
            "\n",
            "Epoch 725: Validation loss decreased (291.647064 --> 291.311218).\n",
            "\t Train_Loss: 114.2059 Val_Loss: 291.3112  BEST VAL Loss: 291.3112\n",
            "\n",
            "Epoch 726: Validation loss did not decrease\n",
            "\t Train_Loss: 115.4014 Val_Loss: 291.5642  BEST VAL Loss: 291.3112\n",
            "\n",
            "Epoch 727: Validation loss decreased (291.311218 --> 291.060822).\n",
            "\t Train_Loss: 115.4522 Val_Loss: 291.0608  BEST VAL Loss: 291.0608\n",
            "\n",
            "Epoch 728: Validation loss decreased (291.060822 --> 289.502502).\n",
            "\t Train_Loss: 115.4232 Val_Loss: 289.5025  BEST VAL Loss: 289.5025\n",
            "\n",
            "Epoch 729: Validation loss decreased (289.502502 --> 288.020416).\n",
            "\t Train_Loss: 115.1915 Val_Loss: 288.0204  BEST VAL Loss: 288.0204\n",
            "\n",
            "Epoch 730: Validation loss decreased (288.020416 --> 287.136322).\n",
            "\t Train_Loss: 115.1434 Val_Loss: 287.1363  BEST VAL Loss: 287.1363\n",
            "\n",
            "Epoch 731: Validation loss decreased (287.136322 --> 286.814636).\n",
            "\t Train_Loss: 115.1348 Val_Loss: 286.8146  BEST VAL Loss: 286.8146\n",
            "\n",
            "Epoch 732: Validation loss did not decrease\n",
            "\t Train_Loss: 114.9688 Val_Loss: 286.8958  BEST VAL Loss: 286.8146\n",
            "\n",
            "Epoch 733: Validation loss decreased (286.814636 --> 286.799255).\n",
            "\t Train_Loss: 114.8775 Val_Loss: 286.7993  BEST VAL Loss: 286.7993\n",
            "\n",
            "Epoch 734: Validation loss decreased (286.799255 --> 285.983215).\n",
            "\t Train_Loss: 114.8763 Val_Loss: 285.9832  BEST VAL Loss: 285.9832\n",
            "\n",
            "Epoch 735: Validation loss decreased (285.983215 --> 284.837311).\n",
            "\t Train_Loss: 114.7630 Val_Loss: 284.8373  BEST VAL Loss: 284.8373\n",
            "\n",
            "Epoch 736: Validation loss decreased (284.837311 --> 283.953583).\n",
            "\t Train_Loss: 114.6577 Val_Loss: 283.9536  BEST VAL Loss: 283.9536\n",
            "\n",
            "Epoch 737: Validation loss decreased (283.953583 --> 283.490875).\n",
            "\t Train_Loss: 114.6415 Val_Loss: 283.4909  BEST VAL Loss: 283.4909\n",
            "\n",
            "Epoch 738: Validation loss decreased (283.490875 --> 283.392426).\n",
            "\t Train_Loss: 114.5721 Val_Loss: 283.3924  BEST VAL Loss: 283.3924\n",
            "\n",
            "Epoch 739: Validation loss did not decrease\n",
            "\t Train_Loss: 114.4669 Val_Loss: 283.4093  BEST VAL Loss: 283.3924\n",
            "\n",
            "Epoch 740: Validation loss decreased (283.392426 --> 283.110657).\n",
            "\t Train_Loss: 114.4281 Val_Loss: 283.1107  BEST VAL Loss: 283.1107\n",
            "\n",
            "Epoch 741: Validation loss decreased (283.110657 --> 282.382843).\n",
            "\t Train_Loss: 114.3855 Val_Loss: 282.3828  BEST VAL Loss: 282.3828\n",
            "\n",
            "Epoch 742: Validation loss decreased (282.382843 --> 281.575562).\n",
            "\t Train_Loss: 114.2951 Val_Loss: 281.5756  BEST VAL Loss: 281.5756\n",
            "\n",
            "Epoch 743: Validation loss decreased (281.575562 --> 280.996002).\n",
            "\t Train_Loss: 114.2372 Val_Loss: 280.9960  BEST VAL Loss: 280.9960\n",
            "\n",
            "Epoch 744: Validation loss decreased (280.996002 --> 280.716644).\n",
            "\t Train_Loss: 114.2025 Val_Loss: 280.7166  BEST VAL Loss: 280.7166\n",
            "\n",
            "Epoch 745: Validation loss decreased (280.716644 --> 280.658508).\n",
            "\t Train_Loss: 114.1334 Val_Loss: 280.6585  BEST VAL Loss: 280.6585\n",
            "\n",
            "Epoch 746: Validation loss decreased (280.658508 --> 280.596832).\n",
            "\t Train_Loss: 114.0641 Val_Loss: 280.5968  BEST VAL Loss: 280.5968\n",
            "\n",
            "Epoch 747: Validation loss decreased (280.596832 --> 280.280273).\n",
            "\t Train_Loss: 114.0244 Val_Loss: 280.2803  BEST VAL Loss: 280.2803\n",
            "\n",
            "Epoch 748: Validation loss decreased (280.280273 --> 279.709198).\n",
            "\t Train_Loss: 113.9727 Val_Loss: 279.7092  BEST VAL Loss: 279.7092\n",
            "\n",
            "Epoch 749: Validation loss decreased (279.709198 --> 279.114105).\n",
            "\t Train_Loss: 113.9045 Val_Loss: 279.1141  BEST VAL Loss: 279.1141\n",
            "\n",
            "Epoch 750: Validation loss decreased (279.114105 --> 278.684875).\n",
            "\t Train_Loss: 113.8544 Val_Loss: 278.6849  BEST VAL Loss: 278.6849\n",
            "\n",
            "Epoch 751: Validation loss decreased (278.684875 --> 278.468964).\n",
            "\t Train_Loss: 113.8108 Val_Loss: 278.4690  BEST VAL Loss: 278.4690\n",
            "\n",
            "Epoch 752: Validation loss decreased (278.468964 --> 278.398438).\n",
            "\t Train_Loss: 113.7511 Val_Loss: 278.3984  BEST VAL Loss: 278.3984\n",
            "\n",
            "Epoch 753: Validation loss decreased (278.398438 --> 278.311005).\n",
            "\t Train_Loss: 113.6932 Val_Loss: 278.3110  BEST VAL Loss: 278.3110\n",
            "\n",
            "Epoch 754: Validation loss decreased (278.311005 --> 278.052979).\n",
            "\t Train_Loss: 113.6479 Val_Loss: 278.0530  BEST VAL Loss: 278.0530\n",
            "\n",
            "Epoch 755: Validation loss decreased (278.052979 --> 277.623383).\n",
            "\t Train_Loss: 113.5972 Val_Loss: 277.6234  BEST VAL Loss: 277.6234\n",
            "\n",
            "Epoch 756: Validation loss decreased (277.623383 --> 277.162415).\n",
            "\t Train_Loss: 113.5387 Val_Loss: 277.1624  BEST VAL Loss: 277.1624\n",
            "\n",
            "Epoch 757: Validation loss decreased (277.162415 --> 276.804596).\n",
            "\t Train_Loss: 113.4875 Val_Loss: 276.8046  BEST VAL Loss: 276.8046\n",
            "\n",
            "Epoch 758: Validation loss decreased (276.804596 --> 276.598938).\n",
            "\t Train_Loss: 113.4402 Val_Loss: 276.5989  BEST VAL Loss: 276.5989\n",
            "\n",
            "Epoch 759: Validation loss decreased (276.598938 --> 276.506165).\n",
            "\t Train_Loss: 113.3860 Val_Loss: 276.5062  BEST VAL Loss: 276.5062\n",
            "\n",
            "Epoch 760: Validation loss decreased (276.506165 --> 276.422455).\n",
            "\t Train_Loss: 113.3307 Val_Loss: 276.4225  BEST VAL Loss: 276.4225\n",
            "\n",
            "Epoch 761: Validation loss decreased (276.422455 --> 276.240204).\n",
            "\t Train_Loss: 113.2809 Val_Loss: 276.2402  BEST VAL Loss: 276.2402\n",
            "\n",
            "Epoch 762: Validation loss decreased (276.240204 --> 275.932800).\n",
            "\t Train_Loss: 113.2304 Val_Loss: 275.9328  BEST VAL Loss: 275.9328\n",
            "\n",
            "Epoch 763: Validation loss decreased (275.932800 --> 275.571136).\n",
            "\t Train_Loss: 113.1753 Val_Loss: 275.5711  BEST VAL Loss: 275.5711\n",
            "\n",
            "Epoch 764: Validation loss decreased (275.571136 --> 275.253510).\n",
            "\t Train_Loss: 113.1215 Val_Loss: 275.2535  BEST VAL Loss: 275.2535\n",
            "\n",
            "Epoch 765: Validation loss decreased (275.253510 --> 275.036041).\n",
            "\t Train_Loss: 113.0707 Val_Loss: 275.0360  BEST VAL Loss: 275.0360\n",
            "\n",
            "Epoch 766: Validation loss decreased (275.036041 --> 274.914886).\n",
            "\t Train_Loss: 113.0177 Val_Loss: 274.9149  BEST VAL Loss: 274.9149\n",
            "\n",
            "Epoch 767: Validation loss decreased (274.914886 --> 274.832611).\n",
            "\t Train_Loss: 112.9623 Val_Loss: 274.8326  BEST VAL Loss: 274.8326\n",
            "\n",
            "Epoch 768: Validation loss decreased (274.832611 --> 274.713715).\n",
            "\t Train_Loss: 112.9083 Val_Loss: 274.7137  BEST VAL Loss: 274.7137\n",
            "\n",
            "Epoch 769: Validation loss decreased (274.713715 --> 274.511841).\n",
            "\t Train_Loss: 112.8554 Val_Loss: 274.5118  BEST VAL Loss: 274.5118\n",
            "\n",
            "Epoch 770: Validation loss decreased (274.511841 --> 274.243103).\n",
            "\t Train_Loss: 112.8005 Val_Loss: 274.2431  BEST VAL Loss: 274.2431\n",
            "\n",
            "Epoch 771: Validation loss decreased (274.243103 --> 273.965820).\n",
            "\t Train_Loss: 112.7444 Val_Loss: 273.9658  BEST VAL Loss: 273.9658\n",
            "\n",
            "Epoch 772: Validation loss decreased (273.965820 --> 273.736572).\n",
            "\t Train_Loss: 112.6892 Val_Loss: 273.7366  BEST VAL Loss: 273.7366\n",
            "\n",
            "Epoch 773: Validation loss decreased (273.736572 --> 273.579041).\n",
            "\t Train_Loss: 112.6342 Val_Loss: 273.5790  BEST VAL Loss: 273.5790\n",
            "\n",
            "Epoch 774: Validation loss decreased (273.579041 --> 273.477112).\n",
            "\t Train_Loss: 112.5776 Val_Loss: 273.4771  BEST VAL Loss: 273.4771\n",
            "\n",
            "Epoch 775: Validation loss decreased (273.477112 --> 273.386353).\n",
            "\t Train_Loss: 112.5203 Val_Loss: 273.3864  BEST VAL Loss: 273.3864\n",
            "\n",
            "Epoch 776: Validation loss decreased (273.386353 --> 273.261078).\n",
            "\t Train_Loss: 112.4634 Val_Loss: 273.2611  BEST VAL Loss: 273.2611\n",
            "\n",
            "Epoch 777: Validation loss decreased (273.261078 --> 273.080841).\n",
            "\t Train_Loss: 112.4064 Val_Loss: 273.0808  BEST VAL Loss: 273.0808\n",
            "\n",
            "Epoch 778: Validation loss decreased (273.080841 --> 272.861542).\n",
            "\t Train_Loss: 112.3483 Val_Loss: 272.8615  BEST VAL Loss: 272.8615\n",
            "\n",
            "Epoch 779: Validation loss decreased (272.861542 --> 272.641113).\n",
            "\t Train_Loss: 112.2895 Val_Loss: 272.6411  BEST VAL Loss: 272.6411\n",
            "\n",
            "Epoch 780: Validation loss decreased (272.641113 --> 272.453278).\n",
            "\t Train_Loss: 112.2310 Val_Loss: 272.4533  BEST VAL Loss: 272.4533\n",
            "\n",
            "Epoch 781: Validation loss decreased (272.453278 --> 272.311432).\n",
            "\t Train_Loss: 112.1723 Val_Loss: 272.3114  BEST VAL Loss: 272.3114\n",
            "\n",
            "Epoch 782: Validation loss decreased (272.311432 --> 272.204254).\n",
            "\t Train_Loss: 112.1128 Val_Loss: 272.2043  BEST VAL Loss: 272.2043\n",
            "\n",
            "Epoch 783: Validation loss decreased (272.204254 --> 272.104736).\n",
            "\t Train_Loss: 112.0529 Val_Loss: 272.1047  BEST VAL Loss: 272.1047\n",
            "\n",
            "Epoch 784: Validation loss decreased (272.104736 --> 271.984039).\n",
            "\t Train_Loss: 111.9930 Val_Loss: 271.9840  BEST VAL Loss: 271.9840\n",
            "\n",
            "Epoch 785: Validation loss decreased (271.984039 --> 271.828949).\n",
            "\t Train_Loss: 111.9331 Val_Loss: 271.8289  BEST VAL Loss: 271.8289\n",
            "\n",
            "Epoch 786: Validation loss decreased (271.828949 --> 271.646088).\n",
            "\t Train_Loss: 111.8727 Val_Loss: 271.6461  BEST VAL Loss: 271.6461\n",
            "\n",
            "Epoch 787: Validation loss decreased (271.646088 --> 271.456329).\n",
            "\t Train_Loss: 111.8121 Val_Loss: 271.4563  BEST VAL Loss: 271.4563\n",
            "\n",
            "Epoch 788: Validation loss decreased (271.456329 --> 271.281433).\n",
            "\t Train_Loss: 111.7515 Val_Loss: 271.2814  BEST VAL Loss: 271.2814\n",
            "\n",
            "Epoch 789: Validation loss decreased (271.281433 --> 271.133118).\n",
            "\t Train_Loss: 111.6911 Val_Loss: 271.1331  BEST VAL Loss: 271.1331\n",
            "\n",
            "Epoch 790: Validation loss decreased (271.133118 --> 271.008453).\n",
            "\t Train_Loss: 111.6306 Val_Loss: 271.0085  BEST VAL Loss: 271.0085\n",
            "\n",
            "Epoch 791: Validation loss decreased (271.008453 --> 270.893738).\n",
            "\t Train_Loss: 111.5701 Val_Loss: 270.8937  BEST VAL Loss: 270.8937\n",
            "\n",
            "Epoch 792: Validation loss decreased (270.893738 --> 270.771576).\n",
            "\t Train_Loss: 111.5098 Val_Loss: 270.7716  BEST VAL Loss: 270.7716\n",
            "\n",
            "Epoch 793: Validation loss decreased (270.771576 --> 270.630066).\n",
            "\t Train_Loss: 111.4498 Val_Loss: 270.6301  BEST VAL Loss: 270.6301\n",
            "\n",
            "Epoch 794: Validation loss decreased (270.630066 --> 270.467926).\n",
            "\t Train_Loss: 111.3900 Val_Loss: 270.4679  BEST VAL Loss: 270.4679\n",
            "\n",
            "Epoch 795: Validation loss decreased (270.467926 --> 270.293854).\n",
            "\t Train_Loss: 111.3305 Val_Loss: 270.2939  BEST VAL Loss: 270.2939\n",
            "\n",
            "Epoch 796: Validation loss decreased (270.293854 --> 270.120880).\n",
            "\t Train_Loss: 111.2714 Val_Loss: 270.1209  BEST VAL Loss: 270.1209\n",
            "\n",
            "Epoch 797: Validation loss decreased (270.120880 --> 269.959106).\n",
            "\t Train_Loss: 111.2128 Val_Loss: 269.9591  BEST VAL Loss: 269.9591\n",
            "\n",
            "Epoch 798: Validation loss decreased (269.959106 --> 269.812561).\n",
            "\t Train_Loss: 111.1546 Val_Loss: 269.8126  BEST VAL Loss: 269.8126\n",
            "\n",
            "Epoch 799: Validation loss decreased (269.812561 --> 269.677063).\n",
            "\t Train_Loss: 111.0970 Val_Loss: 269.6771  BEST VAL Loss: 269.6771\n",
            "\n",
            "Epoch 800: Validation loss decreased (269.677063 --> 269.543701).\n",
            "\t Train_Loss: 111.0400 Val_Loss: 269.5437  BEST VAL Loss: 269.5437\n",
            "\n",
            "Epoch 801: Validation loss decreased (269.543701 --> 269.403564).\n",
            "\t Train_Loss: 110.9835 Val_Loss: 269.4036  BEST VAL Loss: 269.4036\n",
            "\n",
            "Epoch 802: Validation loss decreased (269.403564 --> 269.251282).\n",
            "\t Train_Loss: 110.9278 Val_Loss: 269.2513  BEST VAL Loss: 269.2513\n",
            "\n",
            "Epoch 803: Validation loss decreased (269.251282 --> 269.087708).\n",
            "\t Train_Loss: 110.8727 Val_Loss: 269.0877  BEST VAL Loss: 269.0877\n",
            "\n",
            "Epoch 804: Validation loss decreased (269.087708 --> 268.918152).\n",
            "\t Train_Loss: 110.8182 Val_Loss: 268.9182  BEST VAL Loss: 268.9182\n",
            "\n",
            "Epoch 805: Validation loss decreased (268.918152 --> 268.749359).\n",
            "\t Train_Loss: 110.7645 Val_Loss: 268.7494  BEST VAL Loss: 268.7494\n",
            "\n",
            "Epoch 806: Validation loss decreased (268.749359 --> 268.587463).\n",
            "\t Train_Loss: 110.7114 Val_Loss: 268.5875  BEST VAL Loss: 268.5875\n",
            "\n",
            "Epoch 807: Validation loss decreased (268.587463 --> 268.433777).\n",
            "\t Train_Loss: 110.6590 Val_Loss: 268.4338  BEST VAL Loss: 268.4338\n",
            "\n",
            "Epoch 808: Validation loss decreased (268.433777 --> 268.286865).\n",
            "\t Train_Loss: 110.6073 Val_Loss: 268.2869  BEST VAL Loss: 268.2869\n",
            "\n",
            "Epoch 809: Validation loss decreased (268.286865 --> 268.141388).\n",
            "\t Train_Loss: 110.5563 Val_Loss: 268.1414  BEST VAL Loss: 268.1414\n",
            "\n",
            "Epoch 810: Validation loss decreased (268.141388 --> 267.992828).\n",
            "\t Train_Loss: 110.5059 Val_Loss: 267.9928  BEST VAL Loss: 267.9928\n",
            "\n",
            "Epoch 811: Validation loss decreased (267.992828 --> 267.837830).\n",
            "\t Train_Loss: 110.4561 Val_Loss: 267.8378  BEST VAL Loss: 267.8378\n",
            "\n",
            "Epoch 812: Validation loss decreased (267.837830 --> 267.676514).\n",
            "\t Train_Loss: 110.4069 Val_Loss: 267.6765  BEST VAL Loss: 267.6765\n",
            "\n",
            "Epoch 813: Validation loss decreased (267.676514 --> 267.511444).\n",
            "\t Train_Loss: 110.3583 Val_Loss: 267.5114  BEST VAL Loss: 267.5114\n",
            "\n",
            "Epoch 814: Validation loss decreased (267.511444 --> 267.346741).\n",
            "\t Train_Loss: 110.3102 Val_Loss: 267.3467  BEST VAL Loss: 267.3467\n",
            "\n",
            "Epoch 815: Validation loss decreased (267.346741 --> 267.185455).\n",
            "\t Train_Loss: 110.2626 Val_Loss: 267.1855  BEST VAL Loss: 267.1855\n",
            "\n",
            "Epoch 816: Validation loss decreased (267.185455 --> 267.029572).\n",
            "\t Train_Loss: 110.2154 Val_Loss: 267.0296  BEST VAL Loss: 267.0296\n",
            "\n",
            "Epoch 817: Validation loss decreased (267.029572 --> 266.878296).\n",
            "\t Train_Loss: 110.1687 Val_Loss: 266.8783  BEST VAL Loss: 266.8783\n",
            "\n",
            "Epoch 818: Validation loss decreased (266.878296 --> 266.729431).\n",
            "\t Train_Loss: 110.1223 Val_Loss: 266.7294  BEST VAL Loss: 266.7294\n",
            "\n",
            "Epoch 819: Validation loss decreased (266.729431 --> 266.579590).\n",
            "\t Train_Loss: 110.0763 Val_Loss: 266.5796  BEST VAL Loss: 266.5796\n",
            "\n",
            "Epoch 820: Validation loss decreased (266.579590 --> 266.427185).\n",
            "\t Train_Loss: 110.0306 Val_Loss: 266.4272  BEST VAL Loss: 266.4272\n",
            "\n",
            "Epoch 821: Validation loss decreased (266.427185 --> 266.271576).\n",
            "\t Train_Loss: 109.9852 Val_Loss: 266.2716  BEST VAL Loss: 266.2716\n",
            "\n",
            "Epoch 822: Validation loss decreased (266.271576 --> 266.113647).\n",
            "\t Train_Loss: 109.9400 Val_Loss: 266.1136  BEST VAL Loss: 266.1136\n",
            "\n",
            "Epoch 823: Validation loss decreased (266.113647 --> 265.955170).\n",
            "\t Train_Loss: 109.8951 Val_Loss: 265.9552  BEST VAL Loss: 265.9552\n",
            "\n",
            "Epoch 824: Validation loss decreased (265.955170 --> 265.798798).\n",
            "\t Train_Loss: 109.8504 Val_Loss: 265.7988  BEST VAL Loss: 265.7988\n",
            "\n",
            "Epoch 825: Validation loss decreased (265.798798 --> 265.645691).\n",
            "\t Train_Loss: 109.8059 Val_Loss: 265.6457  BEST VAL Loss: 265.6457\n",
            "\n",
            "Epoch 826: Validation loss decreased (265.645691 --> 265.496033).\n",
            "\t Train_Loss: 109.7616 Val_Loss: 265.4960  BEST VAL Loss: 265.4960\n",
            "\n",
            "Epoch 827: Validation loss decreased (265.496033 --> 265.348755).\n",
            "\t Train_Loss: 109.7175 Val_Loss: 265.3488  BEST VAL Loss: 265.3488\n",
            "\n",
            "Epoch 828: Validation loss decreased (265.348755 --> 265.202667).\n",
            "\t Train_Loss: 109.6735 Val_Loss: 265.2027  BEST VAL Loss: 265.2027\n",
            "\n",
            "Epoch 829: Validation loss decreased (265.202667 --> 265.055817).\n",
            "\t Train_Loss: 109.6297 Val_Loss: 265.0558  BEST VAL Loss: 265.0558\n",
            "\n",
            "Epoch 830: Validation loss decreased (265.055817 --> 264.908051).\n",
            "\t Train_Loss: 109.5860 Val_Loss: 264.9081  BEST VAL Loss: 264.9081\n",
            "\n",
            "Epoch 831: Validation loss decreased (264.908051 --> 264.758972).\n",
            "\t Train_Loss: 109.5425 Val_Loss: 264.7590  BEST VAL Loss: 264.7590\n",
            "\n",
            "Epoch 832: Validation loss decreased (264.758972 --> 264.609436).\n",
            "\t Train_Loss: 109.4990 Val_Loss: 264.6094  BEST VAL Loss: 264.6094\n",
            "\n",
            "Epoch 833: Validation loss decreased (264.609436 --> 264.460999).\n",
            "\t Train_Loss: 109.4557 Val_Loss: 264.4610  BEST VAL Loss: 264.4610\n",
            "\n",
            "Epoch 834: Validation loss decreased (264.460999 --> 264.314514).\n",
            "\t Train_Loss: 109.4126 Val_Loss: 264.3145  BEST VAL Loss: 264.3145\n",
            "\n",
            "Epoch 835: Validation loss decreased (264.314514 --> 264.170807).\n",
            "\t Train_Loss: 109.3695 Val_Loss: 264.1708  BEST VAL Loss: 264.1708\n",
            "\n",
            "Epoch 836: Validation loss decreased (264.170807 --> 264.029358).\n",
            "\t Train_Loss: 109.3267 Val_Loss: 264.0294  BEST VAL Loss: 264.0294\n",
            "\n",
            "Epoch 837: Validation loss decreased (264.029358 --> 263.889923).\n",
            "\t Train_Loss: 109.2839 Val_Loss: 263.8899  BEST VAL Loss: 263.8899\n",
            "\n",
            "Epoch 838: Validation loss decreased (263.889923 --> 263.751312).\n",
            "\t Train_Loss: 109.2412 Val_Loss: 263.7513  BEST VAL Loss: 263.7513\n",
            "\n",
            "Epoch 839: Validation loss decreased (263.751312 --> 263.612701).\n",
            "\t Train_Loss: 109.1987 Val_Loss: 263.6127  BEST VAL Loss: 263.6127\n",
            "\n",
            "Epoch 840: Validation loss decreased (263.612701 --> 263.473907).\n",
            "\t Train_Loss: 109.1564 Val_Loss: 263.4739  BEST VAL Loss: 263.4739\n",
            "\n",
            "Epoch 841: Validation loss decreased (263.473907 --> 263.335144).\n",
            "\t Train_Loss: 109.1141 Val_Loss: 263.3351  BEST VAL Loss: 263.3351\n",
            "\n",
            "Epoch 842: Validation loss decreased (263.335144 --> 263.197021).\n",
            "\t Train_Loss: 109.0720 Val_Loss: 263.1970  BEST VAL Loss: 263.1970\n",
            "\n",
            "Epoch 843: Validation loss decreased (263.197021 --> 263.060211).\n",
            "\t Train_Loss: 109.0300 Val_Loss: 263.0602  BEST VAL Loss: 263.0602\n",
            "\n",
            "Epoch 844: Validation loss decreased (263.060211 --> 262.925446).\n",
            "\t Train_Loss: 108.9881 Val_Loss: 262.9254  BEST VAL Loss: 262.9254\n",
            "\n",
            "Epoch 845: Validation loss decreased (262.925446 --> 262.792877).\n",
            "\t Train_Loss: 108.9464 Val_Loss: 262.7929  BEST VAL Loss: 262.7929\n",
            "\n",
            "Epoch 846: Validation loss decreased (262.792877 --> 262.661926).\n",
            "\t Train_Loss: 108.9048 Val_Loss: 262.6619  BEST VAL Loss: 262.6619\n",
            "\n",
            "Epoch 847: Validation loss decreased (262.661926 --> 262.532562).\n",
            "\t Train_Loss: 108.8633 Val_Loss: 262.5326  BEST VAL Loss: 262.5326\n",
            "\n",
            "Epoch 848: Validation loss decreased (262.532562 --> 262.404175).\n",
            "\t Train_Loss: 108.8220 Val_Loss: 262.4042  BEST VAL Loss: 262.4042\n",
            "\n",
            "Epoch 849: Validation loss decreased (262.404175 --> 262.276245).\n",
            "\t Train_Loss: 108.7808 Val_Loss: 262.2762  BEST VAL Loss: 262.2762\n",
            "\n",
            "Epoch 850: Validation loss decreased (262.276245 --> 262.148773).\n",
            "\t Train_Loss: 108.7397 Val_Loss: 262.1488  BEST VAL Loss: 262.1488\n",
            "\n",
            "Epoch 851: Validation loss decreased (262.148773 --> 262.022156).\n",
            "\t Train_Loss: 108.6987 Val_Loss: 262.0222  BEST VAL Loss: 262.0222\n",
            "\n",
            "Epoch 852: Validation loss decreased (262.022156 --> 261.896240).\n",
            "\t Train_Loss: 108.6578 Val_Loss: 261.8962  BEST VAL Loss: 261.8962\n",
            "\n",
            "Epoch 853: Validation loss decreased (261.896240 --> 261.771667).\n",
            "\t Train_Loss: 108.6171 Val_Loss: 261.7717  BEST VAL Loss: 261.7717\n",
            "\n",
            "Epoch 854: Validation loss decreased (261.771667 --> 261.648987).\n",
            "\t Train_Loss: 108.5764 Val_Loss: 261.6490  BEST VAL Loss: 261.6490\n",
            "\n",
            "Epoch 855: Validation loss decreased (261.648987 --> 261.527771).\n",
            "\t Train_Loss: 108.5359 Val_Loss: 261.5278  BEST VAL Loss: 261.5278\n",
            "\n",
            "Epoch 856: Validation loss decreased (261.527771 --> 261.407898).\n",
            "\t Train_Loss: 108.4954 Val_Loss: 261.4079  BEST VAL Loss: 261.4079\n",
            "\n",
            "Epoch 857: Validation loss decreased (261.407898 --> 261.289490).\n",
            "\t Train_Loss: 108.4551 Val_Loss: 261.2895  BEST VAL Loss: 261.2895\n",
            "\n",
            "Epoch 858: Validation loss decreased (261.289490 --> 261.172058).\n",
            "\t Train_Loss: 108.4149 Val_Loss: 261.1721  BEST VAL Loss: 261.1721\n",
            "\n",
            "Epoch 859: Validation loss decreased (261.172058 --> 261.055267).\n",
            "\t Train_Loss: 108.3748 Val_Loss: 261.0553  BEST VAL Loss: 261.0553\n",
            "\n",
            "Epoch 860: Validation loss decreased (261.055267 --> 260.939392).\n",
            "\t Train_Loss: 108.3347 Val_Loss: 260.9394  BEST VAL Loss: 260.9394\n",
            "\n",
            "Epoch 861: Validation loss decreased (260.939392 --> 260.823883).\n",
            "\t Train_Loss: 108.2948 Val_Loss: 260.8239  BEST VAL Loss: 260.8239\n",
            "\n",
            "Epoch 862: Validation loss decreased (260.823883 --> 260.709473).\n",
            "\t Train_Loss: 108.2549 Val_Loss: 260.7095  BEST VAL Loss: 260.7095\n",
            "\n",
            "Epoch 863: Validation loss decreased (260.709473 --> 260.596191).\n",
            "\t Train_Loss: 108.2152 Val_Loss: 260.5962  BEST VAL Loss: 260.5962\n",
            "\n",
            "Epoch 864: Validation loss decreased (260.596191 --> 260.484131).\n",
            "\t Train_Loss: 108.1755 Val_Loss: 260.4841  BEST VAL Loss: 260.4841\n",
            "\n",
            "Epoch 865: Validation loss decreased (260.484131 --> 260.373566).\n",
            "\t Train_Loss: 108.1359 Val_Loss: 260.3736  BEST VAL Loss: 260.3736\n",
            "\n",
            "Epoch 866: Validation loss decreased (260.373566 --> 260.263733).\n",
            "\t Train_Loss: 108.0964 Val_Loss: 260.2637  BEST VAL Loss: 260.2637\n",
            "\n",
            "Epoch 867: Validation loss decreased (260.263733 --> 260.155426).\n",
            "\t Train_Loss: 108.0570 Val_Loss: 260.1554  BEST VAL Loss: 260.1554\n",
            "\n",
            "Epoch 868: Validation loss decreased (260.155426 --> 260.047668).\n",
            "\t Train_Loss: 108.0177 Val_Loss: 260.0477  BEST VAL Loss: 260.0477\n",
            "\n",
            "Epoch 869: Validation loss decreased (260.047668 --> 259.940735).\n",
            "\t Train_Loss: 107.9784 Val_Loss: 259.9407  BEST VAL Loss: 259.9407\n",
            "\n",
            "Epoch 870: Validation loss decreased (259.940735 --> 259.834351).\n",
            "\t Train_Loss: 107.9392 Val_Loss: 259.8344  BEST VAL Loss: 259.8344\n",
            "\n",
            "Epoch 871: Validation loss decreased (259.834351 --> 259.728577).\n",
            "\t Train_Loss: 107.9001 Val_Loss: 259.7286  BEST VAL Loss: 259.7286\n",
            "\n",
            "Epoch 872: Validation loss decreased (259.728577 --> 259.623688).\n",
            "\t Train_Loss: 107.8610 Val_Loss: 259.6237  BEST VAL Loss: 259.6237\n",
            "\n",
            "Epoch 873: Validation loss decreased (259.623688 --> 259.519867).\n",
            "\t Train_Loss: 107.8219 Val_Loss: 259.5199  BEST VAL Loss: 259.5199\n",
            "\n",
            "Epoch 874: Validation loss decreased (259.519867 --> 259.416901).\n",
            "\t Train_Loss: 107.7829 Val_Loss: 259.4169  BEST VAL Loss: 259.4169\n",
            "\n",
            "Epoch 875: Validation loss decreased (259.416901 --> 259.314758).\n",
            "\t Train_Loss: 107.7439 Val_Loss: 259.3148  BEST VAL Loss: 259.3148\n",
            "\n",
            "Epoch 876: Validation loss decreased (259.314758 --> 259.213867).\n",
            "\t Train_Loss: 107.7048 Val_Loss: 259.2139  BEST VAL Loss: 259.2139\n",
            "\n",
            "Epoch 877: Validation loss decreased (259.213867 --> 259.113922).\n",
            "\t Train_Loss: 107.6653 Val_Loss: 259.1139  BEST VAL Loss: 259.1139\n",
            "\n",
            "Epoch 878: Validation loss decreased (259.113922 --> 259.017334).\n",
            "\t Train_Loss: 107.6236 Val_Loss: 259.0173  BEST VAL Loss: 259.0173\n",
            "\n",
            "Epoch 879: Validation loss did not decrease\n",
            "\t Train_Loss: 107.5590 Val_Loss: 259.9097  BEST VAL Loss: 259.0173\n",
            "\n",
            "Epoch 880: Validation loss did not decrease\n",
            "\t Train_Loss: 104.9307 Val_Loss: 329.9615  BEST VAL Loss: 259.0173\n",
            "\n",
            "Epoch 881: Validation loss did not decrease\n",
            "\t Train_Loss: 111.9039 Val_Loss: 264.2263  BEST VAL Loss: 259.0173\n",
            "\n",
            "Epoch 882: Validation loss decreased (259.017334 --> 258.513428).\n",
            "\t Train_Loss: 100.2754 Val_Loss: 258.5134  BEST VAL Loss: 258.5134\n",
            "\n",
            "Epoch 883: Validation loss did not decrease\n",
            "\t Train_Loss: 103.2396 Val_Loss: 259.4981  BEST VAL Loss: 258.5134\n",
            "\n",
            "Epoch 884: Validation loss did not decrease\n",
            "\t Train_Loss: 100.8545 Val_Loss: 277.7357  BEST VAL Loss: 258.5134\n",
            "\n",
            "Epoch 885: Validation loss did not decrease\n",
            "\t Train_Loss: 98.5625 Val_Loss: 280.4360  BEST VAL Loss: 258.5134\n",
            "\n",
            "Epoch 886: Validation loss did not decrease\n",
            "\t Train_Loss: 98.6891 Val_Loss: 261.7402  BEST VAL Loss: 258.5134\n",
            "\n",
            "Epoch 887: Validation loss decreased (258.513428 --> 258.408875).\n",
            "\t Train_Loss: 96.5576 Val_Loss: 258.4089  BEST VAL Loss: 258.4089\n",
            "\n",
            "Epoch 888: Validation loss did not decrease\n",
            "\t Train_Loss: 97.3082 Val_Loss: 260.9019  BEST VAL Loss: 258.4089\n",
            "\n",
            "Epoch 889: Validation loss did not decrease\n",
            "\t Train_Loss: 95.1900 Val_Loss: 269.4254  BEST VAL Loss: 258.4089\n",
            "\n",
            "Epoch 890: Validation loss did not decrease\n",
            "\t Train_Loss: 94.9277 Val_Loss: 270.6264  BEST VAL Loss: 258.4089\n",
            "\n",
            "Epoch 891: Validation loss did not decrease\n",
            "\t Train_Loss: 94.9451 Val_Loss: 262.1964  BEST VAL Loss: 258.4089\n",
            "\n",
            "Epoch 892: Validation loss decreased (258.408875 --> 256.609589).\n",
            "\t Train_Loss: 93.4026 Val_Loss: 256.6096  BEST VAL Loss: 256.6096\n",
            "\n",
            "Epoch 893: Validation loss decreased (256.609589 --> 255.334381).\n",
            "\t Train_Loss: 93.5220 Val_Loss: 255.3344  BEST VAL Loss: 255.3344\n",
            "\n",
            "Epoch 894: Validation loss did not decrease\n",
            "\t Train_Loss: 93.4189 Val_Loss: 256.8971  BEST VAL Loss: 255.3344\n",
            "\n",
            "Epoch 895: Validation loss did not decrease\n",
            "\t Train_Loss: 92.4845 Val_Loss: 260.5176  BEST VAL Loss: 255.3344\n",
            "\n",
            "Epoch 896: Validation loss did not decrease\n",
            "\t Train_Loss: 92.2755 Val_Loss: 262.3632  BEST VAL Loss: 255.3344\n",
            "\n",
            "Epoch 897: Validation loss did not decrease\n",
            "\t Train_Loss: 92.4032 Val_Loss: 260.0174  BEST VAL Loss: 255.3344\n",
            "\n",
            "Epoch 898: Validation loss did not decrease\n",
            "\t Train_Loss: 91.9442 Val_Loss: 255.8057  BEST VAL Loss: 255.3344\n",
            "\n",
            "Epoch 899: Validation loss decreased (255.334381 --> 252.886917).\n",
            "\t Train_Loss: 91.4687 Val_Loss: 252.8869  BEST VAL Loss: 252.8869\n",
            "\n",
            "Epoch 900: Validation loss decreased (252.886917 --> 251.923309).\n",
            "\t Train_Loss: 91.4660 Val_Loss: 251.9233  BEST VAL Loss: 251.9233\n",
            "\n",
            "Epoch 901: Validation loss did not decrease\n",
            "\t Train_Loss: 91.4009 Val_Loss: 252.5341  BEST VAL Loss: 251.9233\n",
            "\n",
            "Epoch 902: Validation loss did not decrease\n",
            "\t Train_Loss: 91.0066 Val_Loss: 254.2788  BEST VAL Loss: 251.9233\n",
            "\n",
            "Epoch 903: Validation loss did not decrease\n",
            "\t Train_Loss: 90.7545 Val_Loss: 255.7822  BEST VAL Loss: 251.9233\n",
            "\n",
            "Epoch 904: Validation loss did not decrease\n",
            "\t Train_Loss: 90.7440 Val_Loss: 255.5011  BEST VAL Loss: 251.9233\n",
            "\n",
            "Epoch 905: Validation loss did not decrease\n",
            "\t Train_Loss: 90.6154 Val_Loss: 253.4657  BEST VAL Loss: 251.9233\n",
            "\n",
            "Epoch 906: Validation loss decreased (251.923309 --> 251.053101).\n",
            "\t Train_Loss: 90.3178 Val_Loss: 251.0531  BEST VAL Loss: 251.0531\n",
            "\n",
            "Epoch 907: Validation loss decreased (251.053101 --> 249.411102).\n",
            "\t Train_Loss: 90.1269 Val_Loss: 249.4111  BEST VAL Loss: 249.4111\n",
            "\n",
            "Epoch 908: Validation loss decreased (249.411102 --> 248.809967).\n",
            "\t Train_Loss: 90.0786 Val_Loss: 248.8100  BEST VAL Loss: 248.8100\n",
            "\n",
            "Epoch 909: Validation loss did not decrease\n",
            "\t Train_Loss: 89.9425 Val_Loss: 249.1355  BEST VAL Loss: 248.8100\n",
            "\n",
            "Epoch 910: Validation loss did not decrease\n",
            "\t Train_Loss: 89.7070 Val_Loss: 250.0026  BEST VAL Loss: 248.8100\n",
            "\n",
            "Epoch 911: Validation loss did not decrease\n",
            "\t Train_Loss: 89.5516 Val_Loss: 250.6047  BEST VAL Loss: 248.8100\n",
            "\n",
            "Epoch 912: Validation loss did not decrease\n",
            "\t Train_Loss: 89.4769 Val_Loss: 250.2218  BEST VAL Loss: 248.8100\n",
            "\n",
            "Epoch 913: Validation loss did not decrease\n",
            "\t Train_Loss: 89.3483 Val_Loss: 248.9072  BEST VAL Loss: 248.8100\n",
            "\n",
            "Epoch 914: Validation loss decreased (248.809967 --> 247.353729).\n",
            "\t Train_Loss: 89.1573 Val_Loss: 247.3537  BEST VAL Loss: 247.3537\n",
            "\n",
            "Epoch 915: Validation loss decreased (247.353729 --> 246.198639).\n",
            "\t Train_Loss: 89.0111 Val_Loss: 246.1986  BEST VAL Loss: 246.1986\n",
            "\n",
            "Epoch 916: Validation loss decreased (246.198639 --> 245.675812).\n",
            "\t Train_Loss: 88.9240 Val_Loss: 245.6758  BEST VAL Loss: 245.6758\n",
            "\n",
            "Epoch 917: Validation loss did not decrease\n",
            "\t Train_Loss: 88.8070 Val_Loss: 245.7317  BEST VAL Loss: 245.6758\n",
            "\n",
            "Epoch 918: Validation loss did not decrease\n",
            "\t Train_Loss: 88.6454 Val_Loss: 246.1029  BEST VAL Loss: 245.6758\n",
            "\n",
            "Epoch 919: Validation loss did not decrease\n",
            "\t Train_Loss: 88.5111 Val_Loss: 246.3242  BEST VAL Loss: 245.6758\n",
            "\n",
            "Epoch 920: Validation loss did not decrease\n",
            "\t Train_Loss: 88.4170 Val_Loss: 245.9806  BEST VAL Loss: 245.6758\n",
            "\n",
            "Epoch 921: Validation loss decreased (245.675812 --> 245.050262).\n",
            "\t Train_Loss: 88.3070 Val_Loss: 245.0503  BEST VAL Loss: 245.0503\n",
            "\n",
            "Epoch 922: Validation loss decreased (245.050262 --> 243.896332).\n",
            "\t Train_Loss: 88.1675 Val_Loss: 243.8963  BEST VAL Loss: 243.8963\n",
            "\n",
            "Epoch 923: Validation loss decreased (243.896332 --> 242.933746).\n",
            "\t Train_Loss: 88.0427 Val_Loss: 242.9337  BEST VAL Loss: 242.9337\n",
            "\n",
            "Epoch 924: Validation loss decreased (242.933746 --> 242.378204).\n",
            "\t Train_Loss: 87.9461 Val_Loss: 242.3782  BEST VAL Loss: 242.3782\n",
            "\n",
            "Epoch 925: Validation loss decreased (242.378204 --> 242.229691).\n",
            "\t Train_Loss: 87.8423 Val_Loss: 242.2297  BEST VAL Loss: 242.2297\n",
            "\n",
            "Epoch 926: Validation loss did not decrease\n",
            "\t Train_Loss: 87.7182 Val_Loss: 242.3190  BEST VAL Loss: 242.2297\n",
            "\n",
            "Epoch 927: Validation loss did not decrease\n",
            "\t Train_Loss: 87.6017 Val_Loss: 242.3535  BEST VAL Loss: 242.2297\n",
            "\n",
            "Epoch 928: Validation loss decreased (242.229691 --> 242.066452).\n",
            "\t Train_Loss: 87.5048 Val_Loss: 242.0665  BEST VAL Loss: 242.0665\n",
            "\n",
            "Epoch 929: Validation loss decreased (242.066452 --> 241.405670).\n",
            "\t Train_Loss: 87.4054 Val_Loss: 241.4057  BEST VAL Loss: 241.4057\n",
            "\n",
            "Epoch 930: Validation loss decreased (241.405670 --> 240.554932).\n",
            "\t Train_Loss: 87.2925 Val_Loss: 240.5549  BEST VAL Loss: 240.5549\n",
            "\n",
            "Epoch 931: Validation loss decreased (240.554932 --> 239.770706).\n",
            "\t Train_Loss: 87.1834 Val_Loss: 239.7707  BEST VAL Loss: 239.7707\n",
            "\n",
            "Epoch 932: Validation loss decreased (239.770706 --> 239.218552).\n",
            "\t Train_Loss: 87.0873 Val_Loss: 239.2186  BEST VAL Loss: 239.2186\n",
            "\n",
            "Epoch 933: Validation loss decreased (239.218552 --> 238.929153).\n",
            "\t Train_Loss: 86.9905 Val_Loss: 238.9292  BEST VAL Loss: 238.9292\n",
            "\n",
            "Epoch 934: Validation loss decreased (238.929153 --> 238.810135).\n",
            "\t Train_Loss: 86.8854 Val_Loss: 238.8101  BEST VAL Loss: 238.8101\n",
            "\n",
            "Epoch 935: Validation loss decreased (238.810135 --> 238.686356).\n",
            "\t Train_Loss: 86.7826 Val_Loss: 238.6864  BEST VAL Loss: 238.6864\n",
            "\n",
            "Epoch 936: Validation loss decreased (238.686356 --> 238.392670).\n",
            "\t Train_Loss: 86.6883 Val_Loss: 238.3927  BEST VAL Loss: 238.3927\n",
            "\n",
            "Epoch 937: Validation loss decreased (238.392670 --> 237.884369).\n",
            "\t Train_Loss: 86.5938 Val_Loss: 237.8844  BEST VAL Loss: 237.8844\n",
            "\n",
            "Epoch 938: Validation loss decreased (237.884369 --> 237.256393).\n",
            "\t Train_Loss: 86.4940 Val_Loss: 237.2564  BEST VAL Loss: 237.2564\n",
            "\n",
            "Epoch 939: Validation loss decreased (237.256393 --> 236.654694).\n",
            "\t Train_Loss: 86.3962 Val_Loss: 236.6547  BEST VAL Loss: 236.6547\n",
            "\n",
            "Epoch 940: Validation loss decreased (236.654694 --> 236.182373).\n",
            "\t Train_Loss: 86.3042 Val_Loss: 236.1824  BEST VAL Loss: 236.1824\n",
            "\n",
            "Epoch 941: Validation loss decreased (236.182373 --> 235.861328).\n",
            "\t Train_Loss: 86.2120 Val_Loss: 235.8613  BEST VAL Loss: 235.8613\n",
            "\n",
            "Epoch 942: Validation loss decreased (235.861328 --> 235.637894).\n",
            "\t Train_Loss: 86.1164 Val_Loss: 235.6379  BEST VAL Loss: 235.6379\n",
            "\n",
            "Epoch 943: Validation loss decreased (235.637894 --> 235.410156).\n",
            "\t Train_Loss: 86.0225 Val_Loss: 235.4102  BEST VAL Loss: 235.4102\n",
            "\n",
            "Epoch 944: Validation loss decreased (235.410156 --> 235.086349).\n",
            "\t Train_Loss: 85.9327 Val_Loss: 235.0863  BEST VAL Loss: 235.0863\n",
            "\n",
            "Epoch 945: Validation loss decreased (235.086349 --> 234.646042).\n",
            "\t Train_Loss: 85.8430 Val_Loss: 234.6460  BEST VAL Loss: 234.6460\n",
            "\n",
            "Epoch 946: Validation loss decreased (234.646042 --> 234.147903).\n",
            "\t Train_Loss: 85.7510 Val_Loss: 234.1479  BEST VAL Loss: 234.1479\n",
            "\n",
            "Epoch 947: Validation loss decreased (234.147903 --> 233.677734).\n",
            "\t Train_Loss: 85.6605 Val_Loss: 233.6777  BEST VAL Loss: 233.6777\n",
            "\n",
            "Epoch 948: Validation loss decreased (233.677734 --> 233.293304).\n",
            "\t Train_Loss: 85.5730 Val_Loss: 233.2933  BEST VAL Loss: 233.2933\n",
            "\n",
            "Epoch 949: Validation loss decreased (233.293304 --> 233.000000).\n",
            "\t Train_Loss: 85.4856 Val_Loss: 233.0000  BEST VAL Loss: 233.0000\n",
            "\n",
            "Epoch 950: Validation loss decreased (233.000000 --> 232.756546).\n",
            "\t Train_Loss: 85.3969 Val_Loss: 232.7565  BEST VAL Loss: 232.7565\n",
            "\n",
            "Epoch 951: Validation loss decreased (232.756546 --> 232.497162).\n",
            "\t Train_Loss: 85.3094 Val_Loss: 232.4972  BEST VAL Loss: 232.4972\n",
            "\n",
            "Epoch 952: Validation loss decreased (232.497162 --> 232.171097).\n",
            "\t Train_Loss: 85.2241 Val_Loss: 232.1711  BEST VAL Loss: 232.1711\n",
            "\n",
            "Epoch 953: Validation loss decreased (232.171097 --> 231.774948).\n",
            "\t Train_Loss: 85.1390 Val_Loss: 231.7749  BEST VAL Loss: 231.7749\n",
            "\n",
            "Epoch 954: Validation loss decreased (231.774948 --> 231.351608).\n",
            "\t Train_Loss: 85.0533 Val_Loss: 231.3516  BEST VAL Loss: 231.3516\n",
            "\n",
            "Epoch 955: Validation loss decreased (231.351608 --> 230.957611).\n",
            "\t Train_Loss: 84.9686 Val_Loss: 230.9576  BEST VAL Loss: 230.9576\n",
            "\n",
            "Epoch 956: Validation loss decreased (230.957611 --> 230.627853).\n",
            "\t Train_Loss: 84.8855 Val_Loss: 230.6279  BEST VAL Loss: 230.6279\n",
            "\n",
            "Epoch 957: Validation loss decreased (230.627853 --> 230.360596).\n",
            "\t Train_Loss: 84.8027 Val_Loss: 230.3606  BEST VAL Loss: 230.3606\n",
            "\n",
            "Epoch 958: Validation loss decreased (230.360596 --> 230.122971).\n",
            "\t Train_Loss: 84.7198 Val_Loss: 230.1230  BEST VAL Loss: 230.1230\n",
            "\n",
            "Epoch 959: Validation loss decreased (230.122971 --> 229.869720).\n",
            "\t Train_Loss: 84.6377 Val_Loss: 229.8697  BEST VAL Loss: 229.8697\n",
            "\n",
            "Epoch 960: Validation loss decreased (229.869720 --> 229.569214).\n",
            "\t Train_Loss: 84.5569 Val_Loss: 229.5692  BEST VAL Loss: 229.5692\n",
            "\n",
            "Epoch 961: Validation loss decreased (229.569214 --> 229.222321).\n",
            "\t Train_Loss: 84.4765 Val_Loss: 229.2223  BEST VAL Loss: 229.2223\n",
            "\n",
            "Epoch 962: Validation loss decreased (229.222321 --> 228.858932).\n",
            "\t Train_Loss: 84.3961 Val_Loss: 228.8589  BEST VAL Loss: 228.8589\n",
            "\n",
            "Epoch 963: Validation loss decreased (228.858932 --> 228.516144).\n",
            "\t Train_Loss: 84.3167 Val_Loss: 228.5161  BEST VAL Loss: 228.5161\n",
            "\n",
            "Epoch 964: Validation loss decreased (228.516144 --> 228.216263).\n",
            "\t Train_Loss: 84.2382 Val_Loss: 228.2163  BEST VAL Loss: 228.2163\n",
            "\n",
            "Epoch 965: Validation loss decreased (228.216263 --> 227.957809).\n",
            "\t Train_Loss: 84.1602 Val_Loss: 227.9578  BEST VAL Loss: 227.9578\n",
            "\n",
            "Epoch 966: Validation loss decreased (227.957809 --> 227.719574).\n",
            "\t Train_Loss: 84.0825 Val_Loss: 227.7196  BEST VAL Loss: 227.7196\n",
            "\n",
            "Epoch 967: Validation loss decreased (227.719574 --> 227.472610).\n",
            "\t Train_Loss: 84.0056 Val_Loss: 227.4726  BEST VAL Loss: 227.4726\n",
            "\n",
            "Epoch 968: Validation loss decreased (227.472610 --> 227.198318).\n",
            "\t Train_Loss: 83.9296 Val_Loss: 227.1983  BEST VAL Loss: 227.1983\n",
            "\n",
            "Epoch 969: Validation loss decreased (227.198318 --> 226.897186).\n",
            "\t Train_Loss: 83.8540 Val_Loss: 226.8972  BEST VAL Loss: 226.8972\n",
            "\n",
            "Epoch 970: Validation loss decreased (226.897186 --> 226.586426).\n",
            "\t Train_Loss: 83.7789 Val_Loss: 226.5864  BEST VAL Loss: 226.5864\n",
            "\n",
            "Epoch 971: Validation loss decreased (226.586426 --> 226.286911).\n",
            "\t Train_Loss: 83.7047 Val_Loss: 226.2869  BEST VAL Loss: 226.2869\n",
            "\n",
            "Epoch 972: Validation loss decreased (226.286911 --> 226.011261).\n",
            "\t Train_Loss: 83.6311 Val_Loss: 226.0113  BEST VAL Loss: 226.0113\n",
            "\n",
            "Epoch 973: Validation loss decreased (226.011261 --> 225.758545).\n",
            "\t Train_Loss: 83.5581 Val_Loss: 225.7585  BEST VAL Loss: 225.7585\n",
            "\n",
            "Epoch 974: Validation loss decreased (225.758545 --> 225.516754).\n",
            "\t Train_Loss: 83.4857 Val_Loss: 225.5168  BEST VAL Loss: 225.5168\n",
            "\n",
            "Epoch 975: Validation loss decreased (225.516754 --> 225.270660).\n",
            "\t Train_Loss: 83.4140 Val_Loss: 225.2707  BEST VAL Loss: 225.2707\n",
            "\n",
            "Epoch 976: Validation loss decreased (225.270660 --> 225.011200).\n",
            "\t Train_Loss: 83.3430 Val_Loss: 225.0112  BEST VAL Loss: 225.0112\n",
            "\n",
            "Epoch 977: Validation loss decreased (225.011200 --> 224.739334).\n",
            "\t Train_Loss: 83.2726 Val_Loss: 224.7393  BEST VAL Loss: 224.7393\n",
            "\n",
            "Epoch 978: Validation loss decreased (224.739334 --> 224.464600).\n",
            "\t Train_Loss: 83.2027 Val_Loss: 224.4646  BEST VAL Loss: 224.4646\n",
            "\n",
            "Epoch 979: Validation loss decreased (224.464600 --> 224.197433).\n",
            "\t Train_Loss: 83.1336 Val_Loss: 224.1974  BEST VAL Loss: 224.1974\n",
            "\n",
            "Epoch 980: Validation loss decreased (224.197433 --> 223.943649).\n",
            "\t Train_Loss: 83.0651 Val_Loss: 223.9436  BEST VAL Loss: 223.9436\n",
            "\n",
            "Epoch 981: Validation loss decreased (223.943649 --> 223.701782).\n",
            "\t Train_Loss: 82.9971 Val_Loss: 223.7018  BEST VAL Loss: 223.7018\n",
            "\n",
            "Epoch 982: Validation loss decreased (223.701782 --> 223.464645).\n",
            "\t Train_Loss: 82.9298 Val_Loss: 223.4646  BEST VAL Loss: 223.4646\n",
            "\n",
            "Epoch 983: Validation loss decreased (223.464645 --> 223.224213).\n",
            "\t Train_Loss: 82.8630 Val_Loss: 223.2242  BEST VAL Loss: 223.2242\n",
            "\n",
            "Epoch 984: Validation loss decreased (223.224213 --> 222.976227).\n",
            "\t Train_Loss: 82.7969 Val_Loss: 222.9762  BEST VAL Loss: 222.9762\n",
            "\n",
            "Epoch 985: Validation loss decreased (222.976227 --> 222.721924).\n",
            "\t Train_Loss: 82.7313 Val_Loss: 222.7219  BEST VAL Loss: 222.7219\n",
            "\n",
            "Epoch 986: Validation loss decreased (222.721924 --> 222.467651).\n",
            "\t Train_Loss: 82.6662 Val_Loss: 222.4677  BEST VAL Loss: 222.4677\n",
            "\n",
            "Epoch 987: Validation loss decreased (222.467651 --> 222.219559).\n",
            "\t Train_Loss: 82.6016 Val_Loss: 222.2196  BEST VAL Loss: 222.2196\n",
            "\n",
            "Epoch 988: Validation loss decreased (222.219559 --> 221.980911).\n",
            "\t Train_Loss: 82.5377 Val_Loss: 221.9809  BEST VAL Loss: 221.9809\n",
            "\n",
            "Epoch 989: Validation loss decreased (221.980911 --> 221.750610).\n",
            "\t Train_Loss: 82.4742 Val_Loss: 221.7506  BEST VAL Loss: 221.7506\n",
            "\n",
            "Epoch 990: Validation loss decreased (221.750610 --> 221.524017).\n",
            "\t Train_Loss: 82.4112 Val_Loss: 221.5240  BEST VAL Loss: 221.5240\n",
            "\n",
            "Epoch 991: Validation loss decreased (221.524017 --> 221.296066).\n",
            "\t Train_Loss: 82.3487 Val_Loss: 221.2961  BEST VAL Loss: 221.2961\n",
            "\n",
            "Epoch 992: Validation loss decreased (221.296066 --> 221.063278).\n",
            "\t Train_Loss: 82.2867 Val_Loss: 221.0633  BEST VAL Loss: 221.0633\n",
            "\n",
            "Epoch 993: Validation loss decreased (221.063278 --> 220.826126).\n",
            "\t Train_Loss: 82.2251 Val_Loss: 220.8261  BEST VAL Loss: 220.8261\n",
            "\n",
            "Epoch 994: Validation loss decreased (220.826126 --> 220.588181).\n",
            "\t Train_Loss: 82.1640 Val_Loss: 220.5882  BEST VAL Loss: 220.5882\n",
            "\n",
            "Epoch 995: Validation loss decreased (220.588181 --> 220.353546).\n",
            "\t Train_Loss: 82.1032 Val_Loss: 220.3535  BEST VAL Loss: 220.3535\n",
            "\n",
            "Epoch 996: Validation loss decreased (220.353546 --> 220.125687).\n",
            "\t Train_Loss: 82.0429 Val_Loss: 220.1257  BEST VAL Loss: 220.1257\n",
            "\n",
            "Epoch 997: Validation loss decreased (220.125687 --> 219.904831).\n",
            "\t Train_Loss: 81.9830 Val_Loss: 219.9048  BEST VAL Loss: 219.9048\n",
            "\n",
            "Epoch 998: Validation loss decreased (219.904831 --> 219.688766).\n",
            "\t Train_Loss: 81.9233 Val_Loss: 219.6888  BEST VAL Loss: 219.6888\n",
            "\n",
            "Epoch 999: Validation loss decreased (219.688766 --> 219.474274).\n",
            "\t Train_Loss: 81.8639 Val_Loss: 219.4743  BEST VAL Loss: 219.4743\n",
            "\n",
            "Epoch 1000: Validation loss decreased (219.474274 --> 219.258133).\n",
            "\t Train_Loss: 81.8048 Val_Loss: 219.2581  BEST VAL Loss: 219.2581\n",
            "\n",
            "Epoch 1001: Validation loss decreased (219.258133 --> 219.039841).\n",
            "\t Train_Loss: 81.7458 Val_Loss: 219.0398  BEST VAL Loss: 219.0398\n",
            "\n",
            "Epoch 1002: Validation loss decreased (219.039841 --> 218.820236).\n",
            "\t Train_Loss: 81.6869 Val_Loss: 218.8202  BEST VAL Loss: 218.8202\n",
            "\n",
            "Epoch 1003: Validation loss decreased (218.820236 --> 218.602005).\n",
            "\t Train_Loss: 81.6277 Val_Loss: 218.6020  BEST VAL Loss: 218.6020\n",
            "\n",
            "Epoch 1004: Validation loss decreased (218.602005 --> 218.387207).\n",
            "\t Train_Loss: 81.5679 Val_Loss: 218.3872  BEST VAL Loss: 218.3872\n",
            "\n",
            "Epoch 1005: Validation loss decreased (218.387207 --> 218.178055).\n",
            "\t Train_Loss: 81.5066 Val_Loss: 218.1781  BEST VAL Loss: 218.1781\n",
            "\n",
            "Epoch 1006: Validation loss decreased (218.178055 --> 217.975342).\n",
            "\t Train_Loss: 81.4420 Val_Loss: 217.9753  BEST VAL Loss: 217.9753\n",
            "\n",
            "Epoch 1007: Validation loss decreased (217.975342 --> 217.782135).\n",
            "\t Train_Loss: 81.3691 Val_Loss: 217.7821  BEST VAL Loss: 217.7821\n",
            "\n",
            "Epoch 1008: Validation loss decreased (217.782135 --> 217.628387).\n",
            "\t Train_Loss: 81.2694 Val_Loss: 217.6284  BEST VAL Loss: 217.6284\n",
            "\n",
            "Epoch 1009: Validation loss did not decrease\n",
            "\t Train_Loss: 81.0346 Val_Loss: 218.3907  BEST VAL Loss: 217.6284\n",
            "\n",
            "Epoch 1010: Validation loss did not decrease\n",
            "\t Train_Loss: 79.0760 Val_Loss: 289.4124  BEST VAL Loss: 217.6284\n",
            "\n",
            "Epoch 1011: Validation loss did not decrease\n",
            "\t Train_Loss: 88.8002 Val_Loss: 232.0151  BEST VAL Loss: 217.6284\n",
            "\n",
            "Epoch 1012: Validation loss decreased (217.628387 --> 214.023880).\n",
            "\t Train_Loss: 75.7132 Val_Loss: 214.0239  BEST VAL Loss: 214.0239\n",
            "\n",
            "Epoch 1013: Validation loss decreased (214.023880 --> 213.175003).\n",
            "\t Train_Loss: 80.1388 Val_Loss: 213.1750  BEST VAL Loss: 213.1750\n",
            "\n",
            "Epoch 1014: Validation loss did not decrease\n",
            "\t Train_Loss: 81.3077 Val_Loss: 213.4962  BEST VAL Loss: 213.1750\n",
            "\n",
            "Epoch 1015: Validation loss did not decrease\n",
            "\t Train_Loss: 81.2377 Val_Loss: 214.5805  BEST VAL Loss: 213.1750\n",
            "\n",
            "Epoch 1016: Validation loss did not decrease\n",
            "\t Train_Loss: 80.9771 Val_Loss: 215.9330  BEST VAL Loss: 213.1750\n",
            "\n",
            "Epoch 1017: Validation loss did not decrease\n",
            "\t Train_Loss: 80.8695 Val_Loss: 216.9757  BEST VAL Loss: 213.1750\n",
            "\n",
            "Epoch 1018: Validation loss did not decrease\n",
            "\t Train_Loss: 80.9512 Val_Loss: 217.2466  BEST VAL Loss: 213.1750\n",
            "\n",
            "Epoch 1019: Validation loss did not decrease\n",
            "\t Train_Loss: 81.0129 Val_Loss: 216.5829  BEST VAL Loss: 213.1750\n",
            "\n",
            "Epoch 1020: Validation loss did not decrease\n",
            "\t Train_Loss: 80.8951 Val_Loss: 215.2862  BEST VAL Loss: 213.1750\n",
            "\n",
            "Epoch 1021: Validation loss did not decrease\n",
            "\t Train_Loss: 80.6961 Val_Loss: 213.8715  BEST VAL Loss: 213.1750\n",
            "\n",
            "Epoch 1022: Validation loss decreased (213.175003 --> 212.736984).\n",
            "\t Train_Loss: 80.5957 Val_Loss: 212.7370  BEST VAL Loss: 212.7370\n",
            "\n",
            "Epoch 1023: Validation loss decreased (212.736984 --> 212.111160).\n",
            "\t Train_Loss: 80.6135 Val_Loss: 212.1112  BEST VAL Loss: 212.1112\n",
            "\n",
            "Epoch 1024: Validation loss decreased (212.111160 --> 212.053421).\n",
            "\t Train_Loss: 80.6336 Val_Loss: 212.0534  BEST VAL Loss: 212.0534\n",
            "\n",
            "Epoch 1025: Validation loss did not decrease\n",
            "\t Train_Loss: 80.5695 Val_Loss: 212.4580  BEST VAL Loss: 212.0534\n",
            "\n",
            "Epoch 1026: Validation loss did not decrease\n",
            "\t Train_Loss: 80.4424 Val_Loss: 213.0905  BEST VAL Loss: 212.0534\n",
            "\n",
            "Epoch 1027: Validation loss did not decrease\n",
            "\t Train_Loss: 80.3371 Val_Loss: 213.6735  BEST VAL Loss: 212.0534\n",
            "\n",
            "Epoch 1028: Validation loss did not decrease\n",
            "\t Train_Loss: 80.3050 Val_Loss: 213.9656  BEST VAL Loss: 212.0534\n",
            "\n",
            "Epoch 1029: Validation loss did not decrease\n",
            "\t Train_Loss: 80.3076 Val_Loss: 213.8157  BEST VAL Loss: 212.0534\n",
            "\n",
            "Epoch 1030: Validation loss did not decrease\n",
            "\t Train_Loss: 80.2674 Val_Loss: 213.2529  BEST VAL Loss: 212.0534\n",
            "\n",
            "Epoch 1031: Validation loss did not decrease\n",
            "\t Train_Loss: 80.1732 Val_Loss: 212.4740  BEST VAL Loss: 212.0534\n",
            "\n",
            "Epoch 1032: Validation loss decreased (212.053421 --> 211.710541).\n",
            "\t Train_Loss: 80.0851 Val_Loss: 211.7105  BEST VAL Loss: 211.7105\n",
            "\n",
            "Epoch 1033: Validation loss decreased (211.710541 --> 211.140472).\n",
            "\t Train_Loss: 80.0430 Val_Loss: 211.1405  BEST VAL Loss: 211.1405\n",
            "\n",
            "Epoch 1034: Validation loss decreased (211.140472 --> 210.862793).\n",
            "\t Train_Loss: 80.0243 Val_Loss: 210.8628  BEST VAL Loss: 210.8628\n",
            "\n",
            "Epoch 1035: Validation loss did not decrease\n",
            "\t Train_Loss: 79.9864 Val_Loss: 210.8816  BEST VAL Loss: 210.8628\n",
            "\n",
            "Epoch 1036: Validation loss did not decrease\n",
            "\t Train_Loss: 79.9178 Val_Loss: 211.1157  BEST VAL Loss: 210.8628\n",
            "\n",
            "Epoch 1037: Validation loss did not decrease\n",
            "\t Train_Loss: 79.8434 Val_Loss: 211.4273  BEST VAL Loss: 210.8628\n",
            "\n",
            "Epoch 1038: Validation loss did not decrease\n",
            "\t Train_Loss: 79.7911 Val_Loss: 211.6606  BEST VAL Loss: 210.8628\n",
            "\n",
            "Epoch 1039: Validation loss did not decrease\n",
            "\t Train_Loss: 79.7593 Val_Loss: 211.6884  BEST VAL Loss: 210.8628\n",
            "\n",
            "Epoch 1040: Validation loss did not decrease\n",
            "\t Train_Loss: 79.7221 Val_Loss: 211.4648  BEST VAL Loss: 210.8628\n",
            "\n",
            "Epoch 1041: Validation loss did not decrease\n",
            "\t Train_Loss: 79.6657 Val_Loss: 211.0406  BEST VAL Loss: 210.8628\n",
            "\n",
            "Epoch 1042: Validation loss decreased (210.862793 --> 210.528442).\n",
            "\t Train_Loss: 79.6026 Val_Loss: 210.5284  BEST VAL Loss: 210.5284\n",
            "\n",
            "Epoch 1043: Validation loss decreased (210.528442 --> 210.054901).\n",
            "\t Train_Loss: 79.5505 Val_Loss: 210.0549  BEST VAL Loss: 210.0549\n",
            "\n",
            "Epoch 1044: Validation loss decreased (210.054901 --> 209.721237).\n",
            "\t Train_Loss: 79.5105 Val_Loss: 209.7212  BEST VAL Loss: 209.7212\n",
            "\n",
            "Epoch 1045: Validation loss decreased (209.721237 --> 209.575150).\n",
            "\t Train_Loss: 79.4703 Val_Loss: 209.5751  BEST VAL Loss: 209.5751\n",
            "\n",
            "Epoch 1046: Validation loss did not decrease\n",
            "\t Train_Loss: 79.4211 Val_Loss: 209.6012  BEST VAL Loss: 209.5751\n",
            "\n",
            "Epoch 1047: Validation loss did not decrease\n",
            "\t Train_Loss: 79.3660 Val_Loss: 209.7315  BEST VAL Loss: 209.5751\n",
            "\n",
            "Epoch 1048: Validation loss did not decrease\n",
            "\t Train_Loss: 79.3141 Val_Loss: 209.8697  BEST VAL Loss: 209.5751\n",
            "\n",
            "Epoch 1049: Validation loss did not decrease\n",
            "\t Train_Loss: 79.2696 Val_Loss: 209.9230  BEST VAL Loss: 209.5751\n",
            "\n",
            "Epoch 1050: Validation loss did not decrease\n",
            "\t Train_Loss: 79.2276 Val_Loss: 209.8333  BEST VAL Loss: 209.5751\n",
            "\n",
            "Epoch 1051: Validation loss did not decrease\n",
            "\t Train_Loss: 79.1817 Val_Loss: 209.5953  BEST VAL Loss: 209.5751\n",
            "\n",
            "Epoch 1052: Validation loss decreased (209.575150 --> 209.257156).\n",
            "\t Train_Loss: 79.1314 Val_Loss: 209.2572  BEST VAL Loss: 209.2572\n",
            "\n",
            "Epoch 1053: Validation loss decreased (209.257156 --> 208.896698).\n",
            "\t Train_Loss: 79.0813 Val_Loss: 208.8967  BEST VAL Loss: 208.8967\n",
            "\n",
            "Epoch 1054: Validation loss decreased (208.896698 --> 208.592377).\n",
            "\t Train_Loss: 79.0351 Val_Loss: 208.5924  BEST VAL Loss: 208.5924\n",
            "\n",
            "Epoch 1055: Validation loss decreased (208.592377 --> 208.395096).\n",
            "\t Train_Loss: 78.9917 Val_Loss: 208.3951  BEST VAL Loss: 208.3951\n",
            "\n",
            "Epoch 1056: Validation loss decreased (208.395096 --> 208.315308).\n",
            "\t Train_Loss: 78.9471 Val_Loss: 208.3153  BEST VAL Loss: 208.3153\n",
            "\n",
            "Epoch 1057: Validation loss did not decrease\n",
            "\t Train_Loss: 78.8997 Val_Loss: 208.3250  BEST VAL Loss: 208.3153\n",
            "\n",
            "Epoch 1058: Validation loss did not decrease\n",
            "\t Train_Loss: 78.8513 Val_Loss: 208.3713  BEST VAL Loss: 208.3153\n",
            "\n",
            "Epoch 1059: Validation loss did not decrease\n",
            "\t Train_Loss: 78.8048 Val_Loss: 208.3932  BEST VAL Loss: 208.3153\n",
            "\n",
            "Epoch 1060: Validation loss did not decrease\n",
            "\t Train_Loss: 78.7605 Val_Loss: 208.3423  BEST VAL Loss: 208.3153\n",
            "\n",
            "Epoch 1061: Validation loss decreased (208.315308 --> 208.198196).\n",
            "\t Train_Loss: 78.7165 Val_Loss: 208.1982  BEST VAL Loss: 208.1982\n",
            "\n",
            "Epoch 1062: Validation loss decreased (208.198196 --> 207.975616).\n",
            "\t Train_Loss: 78.6707 Val_Loss: 207.9756  BEST VAL Loss: 207.9756\n",
            "\n",
            "Epoch 1063: Validation loss decreased (207.975616 --> 207.715118).\n",
            "\t Train_Loss: 78.6238 Val_Loss: 207.7151  BEST VAL Loss: 207.7151\n",
            "\n",
            "Epoch 1064: Validation loss decreased (207.715118 --> 207.466476).\n",
            "\t Train_Loss: 78.5776 Val_Loss: 207.4665  BEST VAL Loss: 207.4665\n",
            "\n",
            "Epoch 1065: Validation loss decreased (207.466476 --> 207.269318).\n",
            "\t Train_Loss: 78.5331 Val_Loss: 207.2693  BEST VAL Loss: 207.2693\n",
            "\n",
            "Epoch 1066: Validation loss decreased (207.269318 --> 207.141647).\n",
            "\t Train_Loss: 78.4891 Val_Loss: 207.1416  BEST VAL Loss: 207.1416\n",
            "\n",
            "Epoch 1067: Validation loss decreased (207.141647 --> 207.077759).\n",
            "\t Train_Loss: 78.4443 Val_Loss: 207.0778  BEST VAL Loss: 207.0778\n",
            "\n",
            "Epoch 1068: Validation loss decreased (207.077759 --> 207.052567).\n",
            "\t Train_Loss: 78.3986 Val_Loss: 207.0526  BEST VAL Loss: 207.0526\n",
            "\n",
            "Epoch 1069: Validation loss decreased (207.052567 --> 207.031158).\n",
            "\t Train_Loss: 78.3531 Val_Loss: 207.0312  BEST VAL Loss: 207.0312\n",
            "\n",
            "Epoch 1070: Validation loss decreased (207.031158 --> 206.979645).\n",
            "\t Train_Loss: 78.3085 Val_Loss: 206.9796  BEST VAL Loss: 206.9796\n",
            "\n",
            "Epoch 1071: Validation loss decreased (206.979645 --> 206.878052).\n",
            "\t Train_Loss: 78.2646 Val_Loss: 206.8781  BEST VAL Loss: 206.8781\n",
            "\n",
            "Epoch 1072: Validation loss decreased (206.878052 --> 206.725586).\n",
            "\t Train_Loss: 78.2203 Val_Loss: 206.7256  BEST VAL Loss: 206.7256\n",
            "\n",
            "Epoch 1073: Validation loss decreased (206.725586 --> 206.538498).\n",
            "\t Train_Loss: 78.1755 Val_Loss: 206.5385  BEST VAL Loss: 206.5385\n",
            "\n",
            "Epoch 1074: Validation loss decreased (206.538498 --> 206.343384).\n",
            "\t Train_Loss: 78.1307 Val_Loss: 206.3434  BEST VAL Loss: 206.3434\n",
            "\n",
            "Epoch 1075: Validation loss decreased (206.343384 --> 206.166168).\n",
            "\t Train_Loss: 78.0864 Val_Loss: 206.1662  BEST VAL Loss: 206.1662\n",
            "\n",
            "Epoch 1076: Validation loss decreased (206.166168 --> 206.023834).\n",
            "\t Train_Loss: 78.0425 Val_Loss: 206.0238  BEST VAL Loss: 206.0238\n",
            "\n",
            "Epoch 1077: Validation loss decreased (206.023834 --> 205.920929).\n",
            "\t Train_Loss: 77.9987 Val_Loss: 205.9209  BEST VAL Loss: 205.9209\n",
            "\n",
            "Epoch 1078: Validation loss decreased (205.920929 --> 205.848846).\n",
            "\t Train_Loss: 77.9545 Val_Loss: 205.8488  BEST VAL Loss: 205.8488\n",
            "\n",
            "Epoch 1079: Validation loss decreased (205.848846 --> 205.790405).\n",
            "\t Train_Loss: 77.9103 Val_Loss: 205.7904  BEST VAL Loss: 205.7904\n",
            "\n",
            "Epoch 1080: Validation loss decreased (205.790405 --> 205.725739).\n",
            "\t Train_Loss: 77.8663 Val_Loss: 205.7257  BEST VAL Loss: 205.7257\n",
            "\n",
            "Epoch 1081: Validation loss decreased (205.725739 --> 205.639084).\n",
            "\t Train_Loss: 77.8226 Val_Loss: 205.6391  BEST VAL Loss: 205.6391\n",
            "\n",
            "Epoch 1082: Validation loss decreased (205.639084 --> 205.523895).\n",
            "\t Train_Loss: 77.7791 Val_Loss: 205.5239  BEST VAL Loss: 205.5239\n",
            "\n",
            "Epoch 1083: Validation loss decreased (205.523895 --> 205.383713).\n",
            "\t Train_Loss: 77.7354 Val_Loss: 205.3837  BEST VAL Loss: 205.3837\n",
            "\n",
            "Epoch 1084: Validation loss decreased (205.383713 --> 205.229889).\n",
            "\t Train_Loss: 77.6917 Val_Loss: 205.2299  BEST VAL Loss: 205.2299\n",
            "\n",
            "Epoch 1085: Validation loss decreased (205.229889 --> 205.076904).\n",
            "\t Train_Loss: 77.6481 Val_Loss: 205.0769  BEST VAL Loss: 205.0769\n",
            "\n",
            "Epoch 1086: Validation loss decreased (205.076904 --> 204.937531).\n",
            "\t Train_Loss: 77.6047 Val_Loss: 204.9375  BEST VAL Loss: 204.9375\n",
            "\n",
            "Epoch 1087: Validation loss decreased (204.937531 --> 204.819244).\n",
            "\t Train_Loss: 77.5614 Val_Loss: 204.8192  BEST VAL Loss: 204.8192\n",
            "\n",
            "Epoch 1088: Validation loss decreased (204.819244 --> 204.721466).\n",
            "\t Train_Loss: 77.5181 Val_Loss: 204.7215  BEST VAL Loss: 204.7215\n",
            "\n",
            "Epoch 1089: Validation loss decreased (204.721466 --> 204.638260).\n",
            "\t Train_Loss: 77.4748 Val_Loss: 204.6383  BEST VAL Loss: 204.6383\n",
            "\n",
            "Epoch 1090: Validation loss decreased (204.638260 --> 204.559097).\n",
            "\t Train_Loss: 77.4315 Val_Loss: 204.5591  BEST VAL Loss: 204.5591\n",
            "\n",
            "Epoch 1091: Validation loss decreased (204.559097 --> 204.474121).\n",
            "\t Train_Loss: 77.3884 Val_Loss: 204.4741  BEST VAL Loss: 204.4741\n",
            "\n",
            "Epoch 1092: Validation loss decreased (204.474121 --> 204.375717).\n",
            "\t Train_Loss: 77.3454 Val_Loss: 204.3757  BEST VAL Loss: 204.3757\n",
            "\n",
            "Epoch 1093: Validation loss decreased (204.375717 --> 204.261871).\n",
            "\t Train_Loss: 77.3024 Val_Loss: 204.2619  BEST VAL Loss: 204.2619\n",
            "\n",
            "Epoch 1094: Validation loss decreased (204.261871 --> 204.135956).\n",
            "\t Train_Loss: 77.2595 Val_Loss: 204.1360  BEST VAL Loss: 204.1360\n",
            "\n",
            "Epoch 1095: Validation loss decreased (204.135956 --> 204.004562).\n",
            "\t Train_Loss: 77.2165 Val_Loss: 204.0046  BEST VAL Loss: 204.0046\n",
            "\n",
            "Epoch 1096: Validation loss decreased (204.004562 --> 203.875702).\n",
            "\t Train_Loss: 77.1737 Val_Loss: 203.8757  BEST VAL Loss: 203.8757\n",
            "\n",
            "Epoch 1097: Validation loss decreased (203.875702 --> 203.755615).\n",
            "\t Train_Loss: 77.1310 Val_Loss: 203.7556  BEST VAL Loss: 203.7556\n",
            "\n",
            "Epoch 1098: Validation loss decreased (203.755615 --> 203.647659).\n",
            "\t Train_Loss: 77.0883 Val_Loss: 203.6477  BEST VAL Loss: 203.6477\n",
            "\n",
            "Epoch 1099: Validation loss decreased (203.647659 --> 203.550934).\n",
            "\t Train_Loss: 77.0456 Val_Loss: 203.5509  BEST VAL Loss: 203.5509\n",
            "\n",
            "Epoch 1100: Validation loss decreased (203.550934 --> 203.461273).\n",
            "\t Train_Loss: 77.0030 Val_Loss: 203.4613  BEST VAL Loss: 203.4613\n",
            "\n",
            "Epoch 1101: Validation loss decreased (203.461273 --> 203.372818).\n",
            "\t Train_Loss: 76.9604 Val_Loss: 203.3728  BEST VAL Loss: 203.3728\n",
            "\n",
            "Epoch 1102: Validation loss decreased (203.372818 --> 203.279877).\n",
            "\t Train_Loss: 76.9179 Val_Loss: 203.2799  BEST VAL Loss: 203.2799\n",
            "\n",
            "Epoch 1103: Validation loss decreased (203.279877 --> 203.179230).\n",
            "\t Train_Loss: 76.8755 Val_Loss: 203.1792  BEST VAL Loss: 203.1792\n",
            "\n",
            "Epoch 1104: Validation loss decreased (203.179230 --> 203.070160).\n",
            "\t Train_Loss: 76.8331 Val_Loss: 203.0702  BEST VAL Loss: 203.0702\n",
            "\n",
            "Epoch 1105: Validation loss decreased (203.070160 --> 202.954788).\n",
            "\t Train_Loss: 76.7908 Val_Loss: 202.9548  BEST VAL Loss: 202.9548\n",
            "\n",
            "Epoch 1106: Validation loss decreased (202.954788 --> 202.837418).\n",
            "\t Train_Loss: 76.7485 Val_Loss: 202.8374  BEST VAL Loss: 202.8374\n",
            "\n",
            "Epoch 1107: Validation loss decreased (202.837418 --> 202.722488).\n",
            "\t Train_Loss: 76.7062 Val_Loss: 202.7225  BEST VAL Loss: 202.7225\n",
            "\n",
            "Epoch 1108: Validation loss decreased (202.722488 --> 202.613342).\n",
            "\t Train_Loss: 76.6640 Val_Loss: 202.6133  BEST VAL Loss: 202.6133\n",
            "\n",
            "Epoch 1109: Validation loss decreased (202.613342 --> 202.511444).\n",
            "\t Train_Loss: 76.6219 Val_Loss: 202.5114  BEST VAL Loss: 202.5114\n",
            "\n",
            "Epoch 1110: Validation loss decreased (202.511444 --> 202.415771).\n",
            "\t Train_Loss: 76.5798 Val_Loss: 202.4158  BEST VAL Loss: 202.4158\n",
            "\n",
            "Epoch 1111: Validation loss decreased (202.415771 --> 202.323685).\n",
            "\t Train_Loss: 76.5378 Val_Loss: 202.3237  BEST VAL Loss: 202.3237\n",
            "\n",
            "Epoch 1112: Validation loss decreased (202.323685 --> 202.231308).\n",
            "\t Train_Loss: 76.4957 Val_Loss: 202.2313  BEST VAL Loss: 202.2313\n",
            "\n",
            "Epoch 1113: Validation loss decreased (202.231308 --> 202.136139).\n",
            "\t Train_Loss: 76.4538 Val_Loss: 202.1361  BEST VAL Loss: 202.1361\n",
            "\n",
            "Epoch 1114: Validation loss decreased (202.136139 --> 202.036255).\n",
            "\t Train_Loss: 76.4119 Val_Loss: 202.0363  BEST VAL Loss: 202.0363\n",
            "\n",
            "Epoch 1115: Validation loss decreased (202.036255 --> 201.931671).\n",
            "\t Train_Loss: 76.3700 Val_Loss: 201.9317  BEST VAL Loss: 201.9317\n",
            "\n",
            "Epoch 1116: Validation loss decreased (201.931671 --> 201.823883).\n",
            "\t Train_Loss: 76.3281 Val_Loss: 201.8239  BEST VAL Loss: 201.8239\n",
            "\n",
            "Epoch 1117: Validation loss decreased (201.823883 --> 201.715866).\n",
            "\t Train_Loss: 76.2863 Val_Loss: 201.7159  BEST VAL Loss: 201.7159\n",
            "\n",
            "Epoch 1118: Validation loss decreased (201.715866 --> 201.610016).\n",
            "\t Train_Loss: 76.2446 Val_Loss: 201.6100  BEST VAL Loss: 201.6100\n",
            "\n",
            "Epoch 1119: Validation loss decreased (201.610016 --> 201.508041).\n",
            "\t Train_Loss: 76.2028 Val_Loss: 201.5080  BEST VAL Loss: 201.5080\n",
            "\n",
            "Epoch 1120: Validation loss decreased (201.508041 --> 201.410248).\n",
            "\t Train_Loss: 76.1612 Val_Loss: 201.4102  BEST VAL Loss: 201.4102\n",
            "\n",
            "Epoch 1121: Validation loss decreased (201.410248 --> 201.315826).\n",
            "\t Train_Loss: 76.1195 Val_Loss: 201.3158  BEST VAL Loss: 201.3158\n",
            "\n",
            "Epoch 1122: Validation loss decreased (201.315826 --> 201.223022).\n",
            "\t Train_Loss: 76.0779 Val_Loss: 201.2230  BEST VAL Loss: 201.2230\n",
            "\n",
            "Epoch 1123: Validation loss decreased (201.223022 --> 201.129791).\n",
            "\t Train_Loss: 76.0363 Val_Loss: 201.1298  BEST VAL Loss: 201.1298\n",
            "\n",
            "Epoch 1124: Validation loss decreased (201.129791 --> 201.034470).\n",
            "\t Train_Loss: 75.9948 Val_Loss: 201.0345  BEST VAL Loss: 201.0345\n",
            "\n",
            "Epoch 1125: Validation loss decreased (201.034470 --> 200.936310).\n",
            "\t Train_Loss: 75.9533 Val_Loss: 200.9363  BEST VAL Loss: 200.9363\n",
            "\n",
            "Epoch 1126: Validation loss decreased (200.936310 --> 200.835831).\n",
            "\t Train_Loss: 75.9118 Val_Loss: 200.8358  BEST VAL Loss: 200.8358\n",
            "\n",
            "Epoch 1127: Validation loss decreased (200.835831 --> 200.734283).\n",
            "\t Train_Loss: 75.8703 Val_Loss: 200.7343  BEST VAL Loss: 200.7343\n",
            "\n",
            "Epoch 1128: Validation loss decreased (200.734283 --> 200.633072).\n",
            "\t Train_Loss: 75.8289 Val_Loss: 200.6331  BEST VAL Loss: 200.6331\n",
            "\n",
            "Epoch 1129: Validation loss decreased (200.633072 --> 200.533417).\n",
            "\t Train_Loss: 75.7875 Val_Loss: 200.5334  BEST VAL Loss: 200.5334\n",
            "\n",
            "Epoch 1130: Validation loss decreased (200.533417 --> 200.436310).\n",
            "\t Train_Loss: 75.7462 Val_Loss: 200.4363  BEST VAL Loss: 200.4363\n",
            "\n",
            "Epoch 1131: Validation loss decreased (200.436310 --> 200.341278).\n",
            "\t Train_Loss: 75.7048 Val_Loss: 200.3413  BEST VAL Loss: 200.3413\n",
            "\n",
            "Epoch 1132: Validation loss decreased (200.341278 --> 200.248199).\n",
            "\t Train_Loss: 75.6635 Val_Loss: 200.2482  BEST VAL Loss: 200.2482\n",
            "\n",
            "Epoch 1133: Validation loss decreased (200.248199 --> 200.155548).\n",
            "\t Train_Loss: 75.6223 Val_Loss: 200.1555  BEST VAL Loss: 200.1555\n",
            "\n",
            "Epoch 1134: Validation loss decreased (200.155548 --> 200.062653).\n",
            "\t Train_Loss: 75.5810 Val_Loss: 200.0627  BEST VAL Loss: 200.0627\n",
            "\n",
            "Epoch 1135: Validation loss decreased (200.062653 --> 199.968384).\n",
            "\t Train_Loss: 75.5398 Val_Loss: 199.9684  BEST VAL Loss: 199.9684\n",
            "\n",
            "Epoch 1136: Validation loss decreased (199.968384 --> 199.873062).\n",
            "\t Train_Loss: 75.4986 Val_Loss: 199.8731  BEST VAL Loss: 199.8731\n",
            "\n",
            "Epoch 1137: Validation loss decreased (199.873062 --> 199.776657).\n",
            "\t Train_Loss: 75.4574 Val_Loss: 199.7767  BEST VAL Loss: 199.7767\n",
            "\n",
            "Epoch 1138: Validation loss decreased (199.776657 --> 199.679840).\n",
            "\t Train_Loss: 75.4162 Val_Loss: 199.6798  BEST VAL Loss: 199.6798\n",
            "\n",
            "Epoch 1139: Validation loss decreased (199.679840 --> 199.583237).\n",
            "\t Train_Loss: 75.3751 Val_Loss: 199.5832  BEST VAL Loss: 199.5832\n",
            "\n",
            "Epoch 1140: Validation loss decreased (199.583237 --> 199.487823).\n",
            "\t Train_Loss: 75.3339 Val_Loss: 199.4878  BEST VAL Loss: 199.4878\n",
            "\n",
            "Epoch 1141: Validation loss decreased (199.487823 --> 199.393890).\n",
            "\t Train_Loss: 75.2928 Val_Loss: 199.3939  BEST VAL Loss: 199.3939\n",
            "\n",
            "Epoch 1142: Validation loss decreased (199.393890 --> 199.301193).\n",
            "\t Train_Loss: 75.2517 Val_Loss: 199.3012  BEST VAL Loss: 199.3012\n",
            "\n",
            "Epoch 1143: Validation loss decreased (199.301193 --> 199.209549).\n",
            "\t Train_Loss: 75.2106 Val_Loss: 199.2095  BEST VAL Loss: 199.2095\n",
            "\n",
            "Epoch 1144: Validation loss decreased (199.209549 --> 199.118149).\n",
            "\t Train_Loss: 75.1696 Val_Loss: 199.1181  BEST VAL Loss: 199.1181\n",
            "\n",
            "Epoch 1145: Validation loss decreased (199.118149 --> 199.026627).\n",
            "\t Train_Loss: 75.1285 Val_Loss: 199.0266  BEST VAL Loss: 199.0266\n",
            "\n",
            "Epoch 1146: Validation loss decreased (199.026627 --> 198.934433).\n",
            "\t Train_Loss: 75.0875 Val_Loss: 198.9344  BEST VAL Loss: 198.9344\n",
            "\n",
            "Epoch 1147: Validation loss decreased (198.934433 --> 198.841599).\n",
            "\t Train_Loss: 75.0464 Val_Loss: 198.8416  BEST VAL Loss: 198.8416\n",
            "\n",
            "Epoch 1148: Validation loss decreased (198.841599 --> 198.748322).\n",
            "\t Train_Loss: 75.0054 Val_Loss: 198.7483  BEST VAL Loss: 198.7483\n",
            "\n",
            "Epoch 1149: Validation loss decreased (198.748322 --> 198.655075).\n",
            "\t Train_Loss: 74.9644 Val_Loss: 198.6551  BEST VAL Loss: 198.6551\n",
            "\n",
            "Epoch 1150: Validation loss decreased (198.655075 --> 198.561920).\n",
            "\t Train_Loss: 74.9234 Val_Loss: 198.5619  BEST VAL Loss: 198.5619\n",
            "\n",
            "Epoch 1151: Validation loss decreased (198.561920 --> 198.469620).\n",
            "\t Train_Loss: 74.8824 Val_Loss: 198.4696  BEST VAL Loss: 198.4696\n",
            "\n",
            "Epoch 1152: Validation loss decreased (198.469620 --> 198.378220).\n",
            "\t Train_Loss: 74.8414 Val_Loss: 198.3782  BEST VAL Loss: 198.3782\n",
            "\n",
            "Epoch 1153: Validation loss decreased (198.378220 --> 198.287888).\n",
            "\t Train_Loss: 74.8004 Val_Loss: 198.2879  BEST VAL Loss: 198.2879\n",
            "\n",
            "Epoch 1154: Validation loss decreased (198.287888 --> 198.197906).\n",
            "\t Train_Loss: 74.7594 Val_Loss: 198.1979  BEST VAL Loss: 198.1979\n",
            "\n",
            "Epoch 1155: Validation loss decreased (198.197906 --> 198.108231).\n",
            "\t Train_Loss: 74.7184 Val_Loss: 198.1082  BEST VAL Loss: 198.1082\n",
            "\n",
            "Epoch 1156: Validation loss decreased (198.108231 --> 198.018250).\n",
            "\t Train_Loss: 74.6774 Val_Loss: 198.0182  BEST VAL Loss: 198.0182\n",
            "\n",
            "Epoch 1157: Validation loss decreased (198.018250 --> 197.928146).\n",
            "\t Train_Loss: 74.6363 Val_Loss: 197.9281  BEST VAL Loss: 197.9281\n",
            "\n",
            "Epoch 1158: Validation loss decreased (197.928146 --> 197.837585).\n",
            "\t Train_Loss: 74.5953 Val_Loss: 197.8376  BEST VAL Loss: 197.8376\n",
            "\n",
            "Epoch 1159: Validation loss decreased (197.837585 --> 197.747070).\n",
            "\t Train_Loss: 74.5543 Val_Loss: 197.7471  BEST VAL Loss: 197.7471\n",
            "\n",
            "Epoch 1160: Validation loss decreased (197.747070 --> 197.656494).\n",
            "\t Train_Loss: 74.5133 Val_Loss: 197.6565  BEST VAL Loss: 197.6565\n",
            "\n",
            "Epoch 1161: Validation loss decreased (197.656494 --> 197.566254).\n",
            "\t Train_Loss: 74.4722 Val_Loss: 197.5663  BEST VAL Loss: 197.5663\n",
            "\n",
            "Epoch 1162: Validation loss decreased (197.566254 --> 197.476715).\n",
            "\t Train_Loss: 74.4312 Val_Loss: 197.4767  BEST VAL Loss: 197.4767\n",
            "\n",
            "Epoch 1163: Validation loss decreased (197.476715 --> 197.387802).\n",
            "\t Train_Loss: 74.3901 Val_Loss: 197.3878  BEST VAL Loss: 197.3878\n",
            "\n",
            "Epoch 1164: Validation loss decreased (197.387802 --> 197.299347).\n",
            "\t Train_Loss: 74.3490 Val_Loss: 197.2993  BEST VAL Loss: 197.2993\n",
            "\n",
            "Epoch 1165: Validation loss decreased (197.299347 --> 197.211075).\n",
            "\t Train_Loss: 74.3079 Val_Loss: 197.2111  BEST VAL Loss: 197.2111\n",
            "\n",
            "Epoch 1166: Validation loss decreased (197.211075 --> 197.123062).\n",
            "\t Train_Loss: 74.2668 Val_Loss: 197.1231  BEST VAL Loss: 197.1231\n",
            "\n",
            "Epoch 1167: Validation loss decreased (197.123062 --> 197.035187).\n",
            "\t Train_Loss: 74.2257 Val_Loss: 197.0352  BEST VAL Loss: 197.0352\n",
            "\n",
            "Epoch 1168: Validation loss decreased (197.035187 --> 196.946976).\n",
            "\t Train_Loss: 74.1845 Val_Loss: 196.9470  BEST VAL Loss: 196.9470\n",
            "\n",
            "Epoch 1169: Validation loss decreased (196.946976 --> 196.858917).\n",
            "\t Train_Loss: 74.1433 Val_Loss: 196.8589  BEST VAL Loss: 196.8589\n",
            "\n",
            "Epoch 1170: Validation loss decreased (196.858917 --> 196.770844).\n",
            "\t Train_Loss: 74.1021 Val_Loss: 196.7708  BEST VAL Loss: 196.7708\n",
            "\n",
            "Epoch 1171: Validation loss decreased (196.770844 --> 196.682953).\n",
            "\t Train_Loss: 74.0609 Val_Loss: 196.6830  BEST VAL Loss: 196.6830\n",
            "\n",
            "Epoch 1172: Validation loss decreased (196.682953 --> 196.595352).\n",
            "\t Train_Loss: 74.0196 Val_Loss: 196.5954  BEST VAL Loss: 196.5954\n",
            "\n",
            "Epoch 1173: Validation loss decreased (196.595352 --> 196.508087).\n",
            "\t Train_Loss: 73.9783 Val_Loss: 196.5081  BEST VAL Loss: 196.5081\n",
            "\n",
            "Epoch 1174: Validation loss decreased (196.508087 --> 196.421509).\n",
            "\t Train_Loss: 73.9370 Val_Loss: 196.4215  BEST VAL Loss: 196.4215\n",
            "\n",
            "Epoch 1175: Validation loss decreased (196.421509 --> 196.335144).\n",
            "\t Train_Loss: 73.8956 Val_Loss: 196.3351  BEST VAL Loss: 196.3351\n",
            "\n",
            "Epoch 1176: Validation loss decreased (196.335144 --> 196.249023).\n",
            "\t Train_Loss: 73.8542 Val_Loss: 196.2490  BEST VAL Loss: 196.2490\n",
            "\n",
            "Epoch 1177: Validation loss decreased (196.249023 --> 196.163239).\n",
            "\t Train_Loss: 73.8128 Val_Loss: 196.1632  BEST VAL Loss: 196.1632\n",
            "\n",
            "Epoch 1178: Validation loss decreased (196.163239 --> 196.077301).\n",
            "\t Train_Loss: 73.7713 Val_Loss: 196.0773  BEST VAL Loss: 196.0773\n",
            "\n",
            "Epoch 1179: Validation loss decreased (196.077301 --> 195.991623).\n",
            "\t Train_Loss: 73.7298 Val_Loss: 195.9916  BEST VAL Loss: 195.9916\n",
            "\n",
            "Epoch 1180: Validation loss decreased (195.991623 --> 195.905914).\n",
            "\t Train_Loss: 73.6883 Val_Loss: 195.9059  BEST VAL Loss: 195.9059\n",
            "\n",
            "Epoch 1181: Validation loss decreased (195.905914 --> 195.820465).\n",
            "\t Train_Loss: 73.6467 Val_Loss: 195.8205  BEST VAL Loss: 195.8205\n",
            "\n",
            "Epoch 1182: Validation loss decreased (195.820465 --> 195.735321).\n",
            "\t Train_Loss: 73.6050 Val_Loss: 195.7353  BEST VAL Loss: 195.7353\n",
            "\n",
            "Epoch 1183: Validation loss decreased (195.735321 --> 195.650543).\n",
            "\t Train_Loss: 73.5633 Val_Loss: 195.6505  BEST VAL Loss: 195.6505\n",
            "\n",
            "Epoch 1184: Validation loss decreased (195.650543 --> 195.565918).\n",
            "\t Train_Loss: 73.5215 Val_Loss: 195.5659  BEST VAL Loss: 195.5659\n",
            "\n",
            "Epoch 1185: Validation loss decreased (195.565918 --> 195.481964).\n",
            "\t Train_Loss: 73.4797 Val_Loss: 195.4820  BEST VAL Loss: 195.4820\n",
            "\n",
            "Epoch 1186: Validation loss decreased (195.481964 --> 195.398209).\n",
            "\t Train_Loss: 73.4378 Val_Loss: 195.3982  BEST VAL Loss: 195.3982\n",
            "\n",
            "Epoch 1187: Validation loss decreased (195.398209 --> 195.314728).\n",
            "\t Train_Loss: 73.3958 Val_Loss: 195.3147  BEST VAL Loss: 195.3147\n",
            "\n",
            "Epoch 1188: Validation loss decreased (195.314728 --> 195.231659).\n",
            "\t Train_Loss: 73.3537 Val_Loss: 195.2317  BEST VAL Loss: 195.2317\n",
            "\n",
            "Epoch 1189: Validation loss decreased (195.231659 --> 195.148804).\n",
            "\t Train_Loss: 73.3111 Val_Loss: 195.1488  BEST VAL Loss: 195.1488\n",
            "\n",
            "Epoch 1190: Validation loss decreased (195.148804 --> 195.066925).\n",
            "\t Train_Loss: 73.2673 Val_Loss: 195.0669  BEST VAL Loss: 195.0669\n",
            "\n",
            "Epoch 1191: Validation loss did not decrease\n",
            "\t Train_Loss: 73.2136 Val_Loss: 195.1201  BEST VAL Loss: 195.0669\n",
            "\n",
            "Epoch 1192: Validation loss did not decrease\n",
            "\t Train_Loss: 72.3644 Val_Loss: 229.7469  BEST VAL Loss: 195.0669\n",
            "\n",
            "Epoch 1193: Validation loss decreased (195.066925 --> 193.665726).\n",
            "\t Train_Loss: 70.8199 Val_Loss: 193.6657  BEST VAL Loss: 193.6657\n",
            "\n",
            "Epoch 1194: Validation loss decreased (193.665726 --> 192.403610).\n",
            "\t Train_Loss: 71.1114 Val_Loss: 192.4036  BEST VAL Loss: 192.4036\n",
            "\n",
            "Epoch 1195: Validation loss decreased (192.403610 --> 192.256271).\n",
            "\t Train_Loss: 73.0403 Val_Loss: 192.2563  BEST VAL Loss: 192.2563\n",
            "\n",
            "Epoch 1196: Validation loss did not decrease\n",
            "\t Train_Loss: 73.2513 Val_Loss: 192.8362  BEST VAL Loss: 192.2563\n",
            "\n",
            "Epoch 1197: Validation loss did not decrease\n",
            "\t Train_Loss: 73.0947 Val_Loss: 193.8595  BEST VAL Loss: 192.2563\n",
            "\n",
            "Epoch 1198: Validation loss did not decrease\n",
            "\t Train_Loss: 72.9348 Val_Loss: 194.9610  BEST VAL Loss: 192.2563\n",
            "\n",
            "Epoch 1199: Validation loss did not decrease\n",
            "\t Train_Loss: 72.9291 Val_Loss: 195.7257  BEST VAL Loss: 192.2563\n",
            "\n",
            "Epoch 1200: Validation loss did not decrease\n",
            "\t Train_Loss: 73.0022 Val_Loss: 195.8086  BEST VAL Loss: 192.2563\n",
            "\n",
            "Epoch 1201: Validation loss did not decrease\n",
            "\t Train_Loss: 72.9918 Val_Loss: 195.1800  BEST VAL Loss: 192.2563\n",
            "\n",
            "Epoch 1202: Validation loss did not decrease\n",
            "\t Train_Loss: 72.8648 Val_Loss: 194.1436  BEST VAL Loss: 192.2563\n",
            "\n",
            "Epoch 1203: Validation loss did not decrease\n",
            "\t Train_Loss: 72.7332 Val_Loss: 193.1008  BEST VAL Loss: 192.2563\n",
            "\n",
            "Epoch 1204: Validation loss did not decrease\n",
            "\t Train_Loss: 72.6923 Val_Loss: 192.3570  BEST VAL Loss: 192.2563\n",
            "\n",
            "Epoch 1205: Validation loss decreased (192.256271 --> 192.065262).\n",
            "\t Train_Loss: 72.7149 Val_Loss: 192.0653  BEST VAL Loss: 192.0653\n",
            "\n",
            "Epoch 1206: Validation loss did not decrease\n",
            "\t Train_Loss: 72.7047 Val_Loss: 192.2339  BEST VAL Loss: 192.0653\n",
            "\n",
            "Epoch 1207: Validation loss did not decrease\n",
            "\t Train_Loss: 72.6232 Val_Loss: 192.7422  BEST VAL Loss: 192.0653\n",
            "\n",
            "Epoch 1208: Validation loss did not decrease\n",
            "\t Train_Loss: 72.5236 Val_Loss: 193.3719  BEST VAL Loss: 192.0653\n",
            "\n",
            "Epoch 1209: Validation loss did not decrease\n",
            "\t Train_Loss: 72.4694 Val_Loss: 193.8744  BEST VAL Loss: 192.0653\n",
            "\n",
            "Epoch 1210: Validation loss did not decrease\n",
            "\t Train_Loss: 72.4612 Val_Loss: 194.0478  BEST VAL Loss: 192.0653\n",
            "\n",
            "Epoch 1211: Validation loss did not decrease\n",
            "\t Train_Loss: 72.4453 Val_Loss: 193.8202  BEST VAL Loss: 192.0653\n",
            "\n",
            "Epoch 1212: Validation loss did not decrease\n",
            "\t Train_Loss: 72.3861 Val_Loss: 193.2917  BEST VAL Loss: 192.0653\n",
            "\n",
            "Epoch 1213: Validation loss did not decrease\n",
            "\t Train_Loss: 72.3081 Val_Loss: 192.6613  BEST VAL Loss: 192.0653\n",
            "\n",
            "Epoch 1214: Validation loss did not decrease\n",
            "\t Train_Loss: 72.2535 Val_Loss: 192.1310  BEST VAL Loss: 192.0653\n",
            "\n",
            "Epoch 1215: Validation loss decreased (192.065262 --> 191.840897).\n",
            "\t Train_Loss: 72.2284 Val_Loss: 191.8409  BEST VAL Loss: 191.8409\n",
            "\n",
            "Epoch 1216: Validation loss decreased (191.840897 --> 191.834747).\n",
            "\t Train_Loss: 72.2041 Val_Loss: 191.8347  BEST VAL Loss: 191.8347\n",
            "\n",
            "Epoch 1217: Validation loss did not decrease\n",
            "\t Train_Loss: 72.1554 Val_Loss: 192.0639  BEST VAL Loss: 191.8347\n",
            "\n",
            "Epoch 1218: Validation loss did not decrease\n",
            "\t Train_Loss: 72.0916 Val_Loss: 192.4091  BEST VAL Loss: 191.8347\n",
            "\n",
            "Epoch 1219: Validation loss did not decrease\n",
            "\t Train_Loss: 72.0391 Val_Loss: 192.7155  BEST VAL Loss: 191.8347\n",
            "\n",
            "Epoch 1220: Validation loss did not decrease\n",
            "\t Train_Loss: 72.0053 Val_Loss: 192.8515  BEST VAL Loss: 191.8347\n",
            "\n",
            "Epoch 1221: Validation loss did not decrease\n",
            "\t Train_Loss: 71.9744 Val_Loss: 192.7577  BEST VAL Loss: 191.8347\n",
            "\n",
            "Epoch 1222: Validation loss did not decrease\n",
            "\t Train_Loss: 71.9299 Val_Loss: 192.4679  BEST VAL Loss: 191.8347\n",
            "\n",
            "Epoch 1223: Validation loss did not decrease\n",
            "\t Train_Loss: 71.8749 Val_Loss: 192.0865  BEST VAL Loss: 191.8347\n",
            "\n",
            "Epoch 1224: Validation loss decreased (191.834747 --> 191.736176).\n",
            "\t Train_Loss: 71.8253 Val_Loss: 191.7362  BEST VAL Loss: 191.7362\n",
            "\n",
            "Epoch 1225: Validation loss decreased (191.736176 --> 191.513046).\n",
            "\t Train_Loss: 71.7873 Val_Loss: 191.5130  BEST VAL Loss: 191.5130\n",
            "\n",
            "Epoch 1226: Validation loss decreased (191.513046 --> 191.459198).\n",
            "\t Train_Loss: 71.7520 Val_Loss: 191.4592  BEST VAL Loss: 191.4592\n",
            "\n",
            "Epoch 1227: Validation loss did not decrease\n",
            "\t Train_Loss: 71.7090 Val_Loss: 191.5558  BEST VAL Loss: 191.4592\n",
            "\n",
            "Epoch 1228: Validation loss did not decrease\n",
            "\t Train_Loss: 71.6593 Val_Loss: 191.7351  BEST VAL Loss: 191.4592\n",
            "\n",
            "Epoch 1229: Validation loss did not decrease\n",
            "\t Train_Loss: 71.6122 Val_Loss: 191.9049  BEST VAL Loss: 191.4592\n",
            "\n",
            "Epoch 1230: Validation loss did not decrease\n",
            "\t Train_Loss: 71.5720 Val_Loss: 191.9823  BEST VAL Loss: 191.4592\n",
            "\n",
            "Epoch 1231: Validation loss did not decrease\n",
            "\t Train_Loss: 71.5339 Val_Loss: 191.9258  BEST VAL Loss: 191.4592\n",
            "\n",
            "Epoch 1232: Validation loss did not decrease\n",
            "\t Train_Loss: 71.4915 Val_Loss: 191.7482  BEST VAL Loss: 191.4592\n",
            "\n",
            "Epoch 1233: Validation loss did not decrease\n",
            "\t Train_Loss: 71.4448 Val_Loss: 191.5074  BEST VAL Loss: 191.4592\n",
            "\n",
            "Epoch 1234: Validation loss decreased (191.459198 --> 191.277298).\n",
            "\t Train_Loss: 71.3996 Val_Loss: 191.2773  BEST VAL Loss: 191.2773\n",
            "\n",
            "Epoch 1235: Validation loss decreased (191.277298 --> 191.119583).\n",
            "\t Train_Loss: 71.3585 Val_Loss: 191.1196  BEST VAL Loss: 191.1196\n",
            "\n",
            "Epoch 1236: Validation loss decreased (191.119583 --> 191.062714).\n",
            "\t Train_Loss: 71.3187 Val_Loss: 191.0627  BEST VAL Loss: 191.0627\n",
            "\n",
            "Epoch 1237: Validation loss did not decrease\n",
            "\t Train_Loss: 71.2764 Val_Loss: 191.0975  BEST VAL Loss: 191.0627\n",
            "\n",
            "Epoch 1238: Validation loss did not decrease\n",
            "\t Train_Loss: 71.2316 Val_Loss: 191.1835  BEST VAL Loss: 191.0627\n",
            "\n",
            "Epoch 1239: Validation loss did not decrease\n",
            "\t Train_Loss: 71.1874 Val_Loss: 191.2653  BEST VAL Loss: 191.0627\n",
            "\n",
            "Epoch 1240: Validation loss did not decrease\n",
            "\t Train_Loss: 71.1458 Val_Loss: 191.2930  BEST VAL Loss: 191.0627\n",
            "\n",
            "Epoch 1241: Validation loss did not decrease\n",
            "\t Train_Loss: 71.1050 Val_Loss: 191.2411  BEST VAL Loss: 191.0627\n",
            "\n",
            "Epoch 1242: Validation loss did not decrease\n",
            "\t Train_Loss: 71.0625 Val_Loss: 191.1167  BEST VAL Loss: 191.0627\n",
            "\n",
            "Epoch 1243: Validation loss decreased (191.062714 --> 190.954102).\n",
            "\t Train_Loss: 71.0185 Val_Loss: 190.9541  BEST VAL Loss: 190.9541\n",
            "\n",
            "Epoch 1244: Validation loss decreased (190.954102 --> 190.798157).\n",
            "\t Train_Loss: 70.9748 Val_Loss: 190.7982  BEST VAL Loss: 190.7982\n",
            "\n",
            "Epoch 1245: Validation loss decreased (190.798157 --> 190.685699).\n",
            "\t Train_Loss: 70.9326 Val_Loss: 190.6857  BEST VAL Loss: 190.6857\n",
            "\n",
            "Epoch 1246: Validation loss decreased (190.685699 --> 190.633621).\n",
            "\t Train_Loss: 70.8906 Val_Loss: 190.6336  BEST VAL Loss: 190.6336\n",
            "\n",
            "Epoch 1247: Validation loss did not decrease\n",
            "\t Train_Loss: 70.8474 Val_Loss: 190.6357  BEST VAL Loss: 190.6336\n",
            "\n",
            "Epoch 1248: Validation loss did not decrease\n",
            "\t Train_Loss: 70.8029 Val_Loss: 190.6669  BEST VAL Loss: 190.6336\n",
            "\n",
            "Epoch 1249: Validation loss did not decrease\n",
            "\t Train_Loss: 70.7584 Val_Loss: 190.6937  BEST VAL Loss: 190.6336\n",
            "\n",
            "Epoch 1250: Validation loss did not decrease\n",
            "\t Train_Loss: 70.7141 Val_Loss: 190.6866  BEST VAL Loss: 190.6336\n",
            "\n",
            "Epoch 1251: Validation loss decreased (190.633621 --> 190.631561).\n",
            "\t Train_Loss: 70.6691 Val_Loss: 190.6316  BEST VAL Loss: 190.6316\n",
            "\n",
            "Epoch 1252: Validation loss decreased (190.631561 --> 190.534393).\n",
            "\t Train_Loss: 70.6222 Val_Loss: 190.5344  BEST VAL Loss: 190.5344\n",
            "\n",
            "Epoch 1253: Validation loss decreased (190.534393 --> 190.417114).\n",
            "\t Train_Loss: 70.5727 Val_Loss: 190.4171  BEST VAL Loss: 190.4171\n",
            "\n",
            "Epoch 1254: Validation loss decreased (190.417114 --> 190.306549).\n",
            "\t Train_Loss: 70.5201 Val_Loss: 190.3065  BEST VAL Loss: 190.3065\n",
            "\n",
            "Epoch 1255: Validation loss decreased (190.306549 --> 190.224838).\n",
            "\t Train_Loss: 70.4625 Val_Loss: 190.2248  BEST VAL Loss: 190.2248\n",
            "\n",
            "Epoch 1256: Validation loss decreased (190.224838 --> 190.183060).\n",
            "\t Train_Loss: 70.3948 Val_Loss: 190.1831  BEST VAL Loss: 190.1831\n",
            "\n",
            "Epoch 1257: Validation loss decreased (190.183060 --> 190.182968).\n",
            "\t Train_Loss: 70.3053 Val_Loss: 190.1830  BEST VAL Loss: 190.1830\n",
            "\n",
            "Epoch 1258: Validation loss did not decrease\n",
            "\t Train_Loss: 70.1636 Val_Loss: 190.2361  BEST VAL Loss: 190.1830\n",
            "\n",
            "Epoch 1259: Validation loss did not decrease\n",
            "\t Train_Loss: 69.8573 Val_Loss: 190.5314  BEST VAL Loss: 190.1830\n",
            "\n",
            "Epoch 1260: Validation loss did not decrease\n",
            "\t Train_Loss: 68.7638 Val_Loss: 196.4868  BEST VAL Loss: 190.1830\n",
            "\n",
            "Epoch 1261: Validation loss did not decrease\n",
            "\t Train_Loss: 63.9763 Val_Loss: 250.7231  BEST VAL Loss: 190.1830\n",
            "\n",
            "Epoch 1262: Validation loss did not decrease\n",
            "\t Train_Loss: 74.1631 Val_Loss: 210.1336  BEST VAL Loss: 190.1830\n",
            "\n",
            "Epoch 1263: Validation loss decreased (190.182968 --> 188.467194).\n",
            "\t Train_Loss: 64.6840 Val_Loss: 188.4672  BEST VAL Loss: 188.4672\n",
            "\n",
            "Epoch 1264: Validation loss decreased (188.467194 --> 187.769073).\n",
            "\t Train_Loss: 66.9801 Val_Loss: 187.7691  BEST VAL Loss: 187.7691\n",
            "\n",
            "Epoch 1265: Validation loss did not decrease\n",
            "\t Train_Loss: 69.1983 Val_Loss: 188.0723  BEST VAL Loss: 187.7691\n",
            "\n",
            "Epoch 1266: Validation loss did not decrease\n",
            "\t Train_Loss: 69.4796 Val_Loss: 188.7974  BEST VAL Loss: 187.7691\n",
            "\n",
            "Epoch 1267: Validation loss did not decrease\n",
            "\t Train_Loss: 69.3757 Val_Loss: 189.6521  BEST VAL Loss: 187.7691\n",
            "\n",
            "Epoch 1268: Validation loss did not decrease\n",
            "\t Train_Loss: 69.1346 Val_Loss: 190.1903  BEST VAL Loss: 187.7691\n",
            "\n",
            "Epoch 1269: Validation loss did not decrease\n",
            "\t Train_Loss: 68.1957 Val_Loss: 190.3810  BEST VAL Loss: 187.7691\n",
            "\n",
            "Epoch 1270: Validation loss did not decrease\n",
            "\t Train_Loss: 64.8325 Val_Loss: 194.7289  BEST VAL Loss: 187.7691\n",
            "\n",
            "Epoch 1271: Validation loss did not decrease\n",
            "\t Train_Loss: 60.7471 Val_Loss: 207.5416  BEST VAL Loss: 187.7691\n",
            "\n",
            "Epoch 1272: Validation loss did not decrease\n",
            "\t Train_Loss: 62.7948 Val_Loss: 211.6656  BEST VAL Loss: 187.7691\n",
            "\n",
            "Epoch 1273: Validation loss did not decrease\n",
            "\t Train_Loss: 64.1176 Val_Loss: 199.0235  BEST VAL Loss: 187.7691\n",
            "\n",
            "Epoch 1274: Validation loss did not decrease\n",
            "\t Train_Loss: 61.5277 Val_Loss: 188.8813  BEST VAL Loss: 187.7691\n",
            "\n",
            "Epoch 1275: Validation loss decreased (187.769073 --> 185.289490).\n",
            "\t Train_Loss: 61.0178 Val_Loss: 185.2895  BEST VAL Loss: 185.2895\n",
            "\n",
            "Epoch 1276: Validation loss did not decrease\n",
            "\t Train_Loss: 61.3621 Val_Loss: 185.7985  BEST VAL Loss: 185.2895\n",
            "\n",
            "Epoch 1277: Validation loss did not decrease\n",
            "\t Train_Loss: 60.7437 Val_Loss: 189.4025  BEST VAL Loss: 185.2895\n",
            "\n",
            "Epoch 1278: Validation loss did not decrease\n",
            "\t Train_Loss: 60.4343 Val_Loss: 192.9254  BEST VAL Loss: 185.2895\n",
            "\n",
            "Epoch 1279: Validation loss did not decrease\n",
            "\t Train_Loss: 60.3365 Val_Loss: 194.3473  BEST VAL Loss: 185.2895\n",
            "\n",
            "Epoch 1280: Validation loss did not decrease\n",
            "\t Train_Loss: 60.6606 Val_Loss: 193.4389  BEST VAL Loss: 185.2895\n",
            "\n",
            "Epoch 1281: Validation loss did not decrease\n",
            "\t Train_Loss: 60.2789 Val_Loss: 190.5593  BEST VAL Loss: 185.2895\n",
            "\n",
            "Epoch 1282: Validation loss did not decrease\n",
            "\t Train_Loss: 59.2562 Val_Loss: 187.3308  BEST VAL Loss: 185.2895\n",
            "\n",
            "Epoch 1283: Validation loss decreased (185.289490 --> 184.348175).\n",
            "\t Train_Loss: 59.1957 Val_Loss: 184.3482  BEST VAL Loss: 184.3482\n",
            "\n",
            "Epoch 1284: Validation loss decreased (184.348175 --> 183.332794).\n",
            "\t Train_Loss: 59.5544 Val_Loss: 183.3328  BEST VAL Loss: 183.3328\n",
            "\n",
            "Epoch 1285: Validation loss did not decrease\n",
            "\t Train_Loss: 59.6049 Val_Loss: 184.3461  BEST VAL Loss: 183.3328\n",
            "\n",
            "Epoch 1286: Validation loss did not decrease\n",
            "\t Train_Loss: 59.1042 Val_Loss: 186.9106  BEST VAL Loss: 183.3328\n",
            "\n",
            "Epoch 1287: Validation loss did not decrease\n",
            "\t Train_Loss: 58.6005 Val_Loss: 189.7067  BEST VAL Loss: 183.3328\n",
            "\n",
            "Epoch 1288: Validation loss did not decrease\n",
            "\t Train_Loss: 58.6750 Val_Loss: 190.4015  BEST VAL Loss: 183.3328\n",
            "\n",
            "Epoch 1289: Validation loss did not decrease\n",
            "\t Train_Loss: 58.7385 Val_Loss: 188.4677  BEST VAL Loss: 183.3328\n",
            "\n",
            "Epoch 1290: Validation loss did not decrease\n",
            "\t Train_Loss: 58.4396 Val_Loss: 185.5459  BEST VAL Loss: 183.3328\n",
            "\n",
            "Epoch 1291: Validation loss decreased (183.332794 --> 183.286407).\n",
            "\t Train_Loss: 58.0735 Val_Loss: 183.2864  BEST VAL Loss: 183.2864\n",
            "\n",
            "Epoch 1292: Validation loss decreased (183.286407 --> 182.257446).\n",
            "\t Train_Loss: 57.9923 Val_Loss: 182.2574  BEST VAL Loss: 182.2574\n",
            "\n",
            "Epoch 1293: Validation loss decreased (182.257446 --> 182.072388).\n",
            "\t Train_Loss: 58.1062 Val_Loss: 182.0724  BEST VAL Loss: 182.0724\n",
            "\n",
            "Epoch 1294: Validation loss did not decrease\n",
            "\t Train_Loss: 57.9020 Val_Loss: 182.5058  BEST VAL Loss: 182.0724\n",
            "\n",
            "Epoch 1295: Validation loss did not decrease\n",
            "\t Train_Loss: 57.5220 Val_Loss: 183.5576  BEST VAL Loss: 182.0724\n",
            "\n",
            "Epoch 1296: Validation loss did not decrease\n",
            "\t Train_Loss: 57.4188 Val_Loss: 184.7243  BEST VAL Loss: 182.0724\n",
            "\n",
            "Epoch 1297: Validation loss did not decrease\n",
            "\t Train_Loss: 57.4109 Val_Loss: 184.9841  BEST VAL Loss: 182.0724\n",
            "\n",
            "Epoch 1298: Validation loss did not decrease\n",
            "\t Train_Loss: 57.3579 Val_Loss: 183.5846  BEST VAL Loss: 182.0724\n",
            "\n",
            "Epoch 1299: Validation loss decreased (182.072388 --> 181.464798).\n",
            "\t Train_Loss: 57.1568 Val_Loss: 181.4648  BEST VAL Loss: 181.4648\n",
            "\n",
            "Epoch 1300: Validation loss decreased (181.464798 --> 179.991501).\n",
            "\t Train_Loss: 57.0048 Val_Loss: 179.9915  BEST VAL Loss: 179.9915\n",
            "\n",
            "Epoch 1301: Validation loss decreased (179.991501 --> 179.431061).\n",
            "\t Train_Loss: 56.9174 Val_Loss: 179.4311  BEST VAL Loss: 179.4311\n",
            "\n",
            "Epoch 1302: Validation loss decreased (179.431061 --> 179.223297).\n",
            "\t Train_Loss: 56.8515 Val_Loss: 179.2233  BEST VAL Loss: 179.2233\n",
            "\n",
            "Epoch 1303: Validation loss did not decrease\n",
            "\t Train_Loss: 56.7012 Val_Loss: 179.4304  BEST VAL Loss: 179.2233\n",
            "\n",
            "Epoch 1304: Validation loss did not decrease\n",
            "\t Train_Loss: 56.5768 Val_Loss: 180.1962  BEST VAL Loss: 179.2233\n",
            "\n",
            "Epoch 1305: Validation loss did not decrease\n",
            "\t Train_Loss: 56.5014 Val_Loss: 180.7195  BEST VAL Loss: 179.2233\n",
            "\n",
            "Epoch 1306: Validation loss did not decrease\n",
            "\t Train_Loss: 56.4909 Val_Loss: 180.1496  BEST VAL Loss: 179.2233\n",
            "\n",
            "Epoch 1307: Validation loss decreased (179.223297 --> 179.031555).\n",
            "\t Train_Loss: 56.3993 Val_Loss: 179.0316  BEST VAL Loss: 179.0316\n",
            "\n",
            "Epoch 1308: Validation loss decreased (179.031555 --> 178.070847).\n",
            "\t Train_Loss: 56.2849 Val_Loss: 178.0708  BEST VAL Loss: 178.0708\n",
            "\n",
            "Epoch 1309: Validation loss decreased (178.070847 --> 177.244537).\n",
            "\t Train_Loss: 56.1859 Val_Loss: 177.2445  BEST VAL Loss: 177.2445\n",
            "\n",
            "Epoch 1310: Validation loss decreased (177.244537 --> 176.648712).\n",
            "\t Train_Loss: 56.1428 Val_Loss: 176.6487  BEST VAL Loss: 176.6487\n",
            "\n",
            "Epoch 1311: Validation loss did not decrease\n",
            "\t Train_Loss: 56.0789 Val_Loss: 176.7179  BEST VAL Loss: 176.6487\n",
            "\n",
            "Epoch 1312: Validation loss did not decrease\n",
            "\t Train_Loss: 55.9927 Val_Loss: 177.2056  BEST VAL Loss: 176.6487\n",
            "\n",
            "Epoch 1313: Validation loss did not decrease\n",
            "\t Train_Loss: 55.9208 Val_Loss: 177.4015  BEST VAL Loss: 176.6487\n",
            "\n",
            "Epoch 1314: Validation loss did not decrease\n",
            "\t Train_Loss: 55.8675 Val_Loss: 177.1980  BEST VAL Loss: 176.6487\n",
            "\n",
            "Epoch 1315: Validation loss did not decrease\n",
            "\t Train_Loss: 55.8140 Val_Loss: 176.7487  BEST VAL Loss: 176.6487\n",
            "\n",
            "Epoch 1316: Validation loss decreased (176.648712 --> 175.969345).\n",
            "\t Train_Loss: 55.7253 Val_Loss: 175.9693  BEST VAL Loss: 175.9693\n",
            "\n",
            "Epoch 1317: Validation loss decreased (175.969345 --> 175.078445).\n",
            "\t Train_Loss: 55.6426 Val_Loss: 175.0784  BEST VAL Loss: 175.0784\n",
            "\n",
            "Epoch 1318: Validation loss decreased (175.078445 --> 174.607788).\n",
            "\t Train_Loss: 55.5799 Val_Loss: 174.6078  BEST VAL Loss: 174.6078\n",
            "\n",
            "Epoch 1319: Validation loss decreased (174.607788 --> 174.560013).\n",
            "\t Train_Loss: 55.5233 Val_Loss: 174.5600  BEST VAL Loss: 174.5600\n",
            "\n",
            "Epoch 1320: Validation loss did not decrease\n",
            "\t Train_Loss: 55.4549 Val_Loss: 174.5806  BEST VAL Loss: 174.5600\n",
            "\n",
            "Epoch 1321: Validation loss did not decrease\n",
            "\t Train_Loss: 55.3770 Val_Loss: 174.6299  BEST VAL Loss: 174.5600\n",
            "\n",
            "Epoch 1322: Validation loss did not decrease\n",
            "\t Train_Loss: 55.3152 Val_Loss: 174.6554  BEST VAL Loss: 174.5600\n",
            "\n",
            "Epoch 1323: Validation loss decreased (174.560013 --> 174.326569).\n",
            "\t Train_Loss: 55.2530 Val_Loss: 174.3266  BEST VAL Loss: 174.3266\n",
            "\n",
            "Epoch 1324: Validation loss decreased (174.326569 --> 173.638367).\n",
            "\t Train_Loss: 55.1836 Val_Loss: 173.6384  BEST VAL Loss: 173.6384\n",
            "\n",
            "Epoch 1325: Validation loss decreased (173.638367 --> 173.000198).\n",
            "\t Train_Loss: 55.1085 Val_Loss: 173.0002  BEST VAL Loss: 173.0002\n",
            "\n",
            "Epoch 1326: Validation loss decreased (173.000198 --> 172.563156).\n",
            "\t Train_Loss: 55.0434 Val_Loss: 172.5632  BEST VAL Loss: 172.5632\n",
            "\n",
            "Epoch 1327: Validation loss decreased (172.563156 --> 172.234589).\n",
            "\t Train_Loss: 54.9860 Val_Loss: 172.2346  BEST VAL Loss: 172.2346\n",
            "\n",
            "Epoch 1328: Validation loss decreased (172.234589 --> 172.085785).\n",
            "\t Train_Loss: 54.9223 Val_Loss: 172.0858  BEST VAL Loss: 172.0858\n",
            "\n",
            "Epoch 1329: Validation loss did not decrease\n",
            "\t Train_Loss: 54.8555 Val_Loss: 172.1350  BEST VAL Loss: 172.0858\n",
            "\n",
            "Epoch 1330: Validation loss did not decrease\n",
            "\t Train_Loss: 54.7898 Val_Loss: 172.1128  BEST VAL Loss: 172.0858\n",
            "\n",
            "Epoch 1331: Validation loss decreased (172.085785 --> 171.831924).\n",
            "\t Train_Loss: 54.7307 Val_Loss: 171.8319  BEST VAL Loss: 171.8319\n",
            "\n",
            "Epoch 1332: Validation loss decreased (171.831924 --> 171.425797).\n",
            "\t Train_Loss: 54.6689 Val_Loss: 171.4258  BEST VAL Loss: 171.4258\n",
            "\n",
            "Epoch 1333: Validation loss decreased (171.425797 --> 171.005295).\n",
            "\t Train_Loss: 54.6052 Val_Loss: 171.0053  BEST VAL Loss: 171.0053\n",
            "\n",
            "Epoch 1334: Validation loss decreased (171.005295 --> 170.562988).\n",
            "\t Train_Loss: 54.5434 Val_Loss: 170.5630  BEST VAL Loss: 170.5630\n",
            "\n",
            "Epoch 1335: Validation loss decreased (170.562988 --> 170.197998).\n",
            "\t Train_Loss: 54.4858 Val_Loss: 170.1980  BEST VAL Loss: 170.1980\n",
            "\n",
            "Epoch 1336: Validation loss decreased (170.197998 --> 170.029572).\n",
            "\t Train_Loss: 54.4277 Val_Loss: 170.0296  BEST VAL Loss: 170.0296\n",
            "\n",
            "Epoch 1337: Validation loss decreased (170.029572 --> 169.966324).\n",
            "\t Train_Loss: 54.3661 Val_Loss: 169.9663  BEST VAL Loss: 169.9663\n",
            "\n",
            "Epoch 1338: Validation loss decreased (169.966324 --> 169.838455).\n",
            "\t Train_Loss: 54.3053 Val_Loss: 169.8385  BEST VAL Loss: 169.8385\n",
            "\n",
            "Epoch 1339: Validation loss decreased (169.838455 --> 169.627197).\n",
            "\t Train_Loss: 54.2468 Val_Loss: 169.6272  BEST VAL Loss: 169.6272\n",
            "\n",
            "Epoch 1340: Validation loss decreased (169.627197 --> 169.360840).\n",
            "\t Train_Loss: 54.1899 Val_Loss: 169.3608  BEST VAL Loss: 169.3608\n",
            "\n",
            "Epoch 1341: Validation loss decreased (169.360840 --> 169.005280).\n",
            "\t Train_Loss: 54.1311 Val_Loss: 169.0053  BEST VAL Loss: 169.0053\n",
            "\n",
            "Epoch 1342: Validation loss decreased (169.005280 --> 168.603271).\n",
            "\t Train_Loss: 54.0726 Val_Loss: 168.6033  BEST VAL Loss: 168.6033\n",
            "\n",
            "Epoch 1343: Validation loss decreased (168.603271 --> 168.292206).\n",
            "\t Train_Loss: 54.0152 Val_Loss: 168.2922  BEST VAL Loss: 168.2922\n",
            "\n",
            "Epoch 1344: Validation loss decreased (168.292206 --> 168.108551).\n",
            "\t Train_Loss: 53.9585 Val_Loss: 168.1086  BEST VAL Loss: 168.1086\n",
            "\n",
            "Epoch 1345: Validation loss decreased (168.108551 --> 167.969315).\n",
            "\t Train_Loss: 53.9010 Val_Loss: 167.9693  BEST VAL Loss: 167.9693\n",
            "\n",
            "Epoch 1346: Validation loss decreased (167.969315 --> 167.830368).\n",
            "\t Train_Loss: 53.8433 Val_Loss: 167.8304  BEST VAL Loss: 167.8304\n",
            "\n",
            "Epoch 1347: Validation loss decreased (167.830368 --> 167.688080).\n",
            "\t Train_Loss: 53.7870 Val_Loss: 167.6881  BEST VAL Loss: 167.6881\n",
            "\n",
            "Epoch 1348: Validation loss decreased (167.688080 --> 167.485428).\n",
            "\t Train_Loss: 53.7315 Val_Loss: 167.4854  BEST VAL Loss: 167.4854\n",
            "\n",
            "Epoch 1349: Validation loss decreased (167.485428 --> 167.184860).\n",
            "\t Train_Loss: 53.6758 Val_Loss: 167.1849  BEST VAL Loss: 167.1849\n",
            "\n",
            "Epoch 1350: Validation loss decreased (167.184860 --> 166.858734).\n",
            "\t Train_Loss: 53.6194 Val_Loss: 166.8587  BEST VAL Loss: 166.8587\n",
            "\n",
            "Epoch 1351: Validation loss decreased (166.858734 --> 166.584335).\n",
            "\t Train_Loss: 53.5639 Val_Loss: 166.5843  BEST VAL Loss: 166.5843\n",
            "\n",
            "Epoch 1352: Validation loss decreased (166.584335 --> 166.355988).\n",
            "\t Train_Loss: 53.5090 Val_Loss: 166.3560  BEST VAL Loss: 166.3560\n",
            "\n",
            "Epoch 1353: Validation loss decreased (166.355988 --> 166.159424).\n",
            "\t Train_Loss: 53.4544 Val_Loss: 166.1594  BEST VAL Loss: 166.1594\n",
            "\n",
            "Epoch 1354: Validation loss decreased (166.159424 --> 166.006973).\n",
            "\t Train_Loss: 53.3996 Val_Loss: 166.0070  BEST VAL Loss: 166.0070\n",
            "\n",
            "Epoch 1355: Validation loss decreased (166.006973 --> 165.864746).\n",
            "\t Train_Loss: 53.3453 Val_Loss: 165.8647  BEST VAL Loss: 165.8647\n",
            "\n",
            "Epoch 1356: Validation loss decreased (165.864746 --> 165.669235).\n",
            "\t Train_Loss: 53.2915 Val_Loss: 165.6692  BEST VAL Loss: 165.6692\n",
            "\n",
            "Epoch 1357: Validation loss decreased (165.669235 --> 165.422745).\n",
            "\t Train_Loss: 53.2378 Val_Loss: 165.4227  BEST VAL Loss: 165.4227\n",
            "\n",
            "Epoch 1358: Validation loss decreased (165.422745 --> 165.171600).\n",
            "\t Train_Loss: 53.1841 Val_Loss: 165.1716  BEST VAL Loss: 165.1716\n",
            "\n",
            "Epoch 1359: Validation loss decreased (165.171600 --> 164.928940).\n",
            "\t Train_Loss: 53.1306 Val_Loss: 164.9289  BEST VAL Loss: 164.9289\n",
            "\n",
            "Epoch 1360: Validation loss decreased (164.928940 --> 164.697083).\n",
            "\t Train_Loss: 53.0778 Val_Loss: 164.6971  BEST VAL Loss: 164.6971\n",
            "\n",
            "Epoch 1361: Validation loss decreased (164.697083 --> 164.502197).\n",
            "\t Train_Loss: 53.0251 Val_Loss: 164.5022  BEST VAL Loss: 164.5022\n",
            "\n",
            "Epoch 1362: Validation loss decreased (164.502197 --> 164.344070).\n",
            "\t Train_Loss: 52.9724 Val_Loss: 164.3441  BEST VAL Loss: 164.3441\n",
            "\n",
            "Epoch 1363: Validation loss decreased (164.344070 --> 164.179337).\n",
            "\t Train_Loss: 52.9199 Val_Loss: 164.1793  BEST VAL Loss: 164.1793\n",
            "\n",
            "Epoch 1364: Validation loss decreased (164.179337 --> 163.984634).\n",
            "\t Train_Loss: 52.8678 Val_Loss: 163.9846  BEST VAL Loss: 163.9846\n",
            "\n",
            "Epoch 1365: Validation loss decreased (163.984634 --> 163.773560).\n",
            "\t Train_Loss: 52.8159 Val_Loss: 163.7736  BEST VAL Loss: 163.7736\n",
            "\n",
            "Epoch 1366: Validation loss decreased (163.773560 --> 163.551468).\n",
            "\t Train_Loss: 52.7641 Val_Loss: 163.5515  BEST VAL Loss: 163.5515\n",
            "\n",
            "Epoch 1367: Validation loss decreased (163.551468 --> 163.319916).\n",
            "\t Train_Loss: 52.7125 Val_Loss: 163.3199  BEST VAL Loss: 163.3199\n",
            "\n",
            "Epoch 1368: Validation loss decreased (163.319916 --> 163.105133).\n",
            "\t Train_Loss: 52.6612 Val_Loss: 163.1051  BEST VAL Loss: 163.1051\n",
            "\n",
            "Epoch 1369: Validation loss decreased (163.105133 --> 162.925919).\n",
            "\t Train_Loss: 52.6101 Val_Loss: 162.9259  BEST VAL Loss: 162.9259\n",
            "\n",
            "Epoch 1370: Validation loss decreased (162.925919 --> 162.764862).\n",
            "\t Train_Loss: 52.5591 Val_Loss: 162.7649  BEST VAL Loss: 162.7649\n",
            "\n",
            "Epoch 1371: Validation loss decreased (162.764862 --> 162.600784).\n",
            "\t Train_Loss: 52.5083 Val_Loss: 162.6008  BEST VAL Loss: 162.6008\n",
            "\n",
            "Epoch 1372: Validation loss decreased (162.600784 --> 162.431198).\n",
            "\t Train_Loss: 52.4578 Val_Loss: 162.4312  BEST VAL Loss: 162.4312\n",
            "\n",
            "Epoch 1373: Validation loss decreased (162.431198 --> 162.249390).\n",
            "\t Train_Loss: 52.4075 Val_Loss: 162.2494  BEST VAL Loss: 162.2494\n",
            "\n",
            "Epoch 1374: Validation loss decreased (162.249390 --> 162.045944).\n",
            "\t Train_Loss: 52.3573 Val_Loss: 162.0459  BEST VAL Loss: 162.0459\n",
            "\n",
            "Epoch 1375: Validation loss decreased (162.045944 --> 161.835266).\n",
            "\t Train_Loss: 52.3074 Val_Loss: 161.8353  BEST VAL Loss: 161.8353\n",
            "\n",
            "Epoch 1376: Validation loss decreased (161.835266 --> 161.639496).\n",
            "\t Train_Loss: 52.2576 Val_Loss: 161.6395  BEST VAL Loss: 161.6395\n",
            "\n",
            "Epoch 1377: Validation loss decreased (161.639496 --> 161.460785).\n",
            "\t Train_Loss: 52.2081 Val_Loss: 161.4608  BEST VAL Loss: 161.4608\n",
            "\n",
            "Epoch 1378: Validation loss decreased (161.460785 --> 161.292969).\n",
            "\t Train_Loss: 52.1588 Val_Loss: 161.2930  BEST VAL Loss: 161.2930\n",
            "\n",
            "Epoch 1379: Validation loss decreased (161.292969 --> 161.136261).\n",
            "\t Train_Loss: 52.1096 Val_Loss: 161.1363  BEST VAL Loss: 161.1363\n",
            "\n",
            "Epoch 1380: Validation loss decreased (161.136261 --> 160.983078).\n",
            "\t Train_Loss: 52.0606 Val_Loss: 160.9831  BEST VAL Loss: 160.9831\n",
            "\n",
            "Epoch 1381: Validation loss decreased (160.983078 --> 160.818344).\n",
            "\t Train_Loss: 52.0115 Val_Loss: 160.8183  BEST VAL Loss: 160.8183\n",
            "\n",
            "Epoch 1382: Validation loss decreased (160.818344 --> 160.641678).\n",
            "\t Train_Loss: 51.9614 Val_Loss: 160.6417  BEST VAL Loss: 160.6417\n",
            "\n",
            "Epoch 1383: Validation loss did not decrease\n",
            "\t Train_Loss: 51.8931 Val_Loss: 161.6375  BEST VAL Loss: 160.6417\n",
            "\n",
            "Epoch 1384: Validation loss did not decrease\n",
            "\t Train_Loss: 48.9477 Val_Loss: 220.2613  BEST VAL Loss: 160.6417\n",
            "\n",
            "Epoch 1385: Validation loss did not decrease\n",
            "\t Train_Loss: 59.5140 Val_Loss: 171.1053  BEST VAL Loss: 160.6417\n",
            "\n",
            "Epoch 1386: Validation loss decreased (160.641678 --> 158.540741).\n",
            "\t Train_Loss: 48.0050 Val_Loss: 158.5407  BEST VAL Loss: 158.5407\n",
            "\n",
            "Epoch 1387: Validation loss did not decrease\n",
            "\t Train_Loss: 50.8460 Val_Loss: 159.7089  BEST VAL Loss: 158.5407\n",
            "\n",
            "Epoch 1388: Validation loss did not decrease\n",
            "\t Train_Loss: 52.6934 Val_Loss: 158.7722  BEST VAL Loss: 158.5407\n",
            "\n",
            "Epoch 1389: Validation loss did not decrease\n",
            "\t Train_Loss: 52.0247 Val_Loss: 158.8930  BEST VAL Loss: 158.5407\n",
            "\n",
            "Epoch 1390: Validation loss did not decrease\n",
            "\t Train_Loss: 52.5784 Val_Loss: 158.9478  BEST VAL Loss: 158.5407\n",
            "\n",
            "Epoch 1391: Validation loss did not decrease\n",
            "\t Train_Loss: 51.5764 Val_Loss: 161.1010  BEST VAL Loss: 158.5407\n",
            "\n",
            "Epoch 1392: Validation loss did not decrease\n",
            "\t Train_Loss: 52.3246 Val_Loss: 159.7619  BEST VAL Loss: 158.5407\n",
            "\n",
            "Epoch 1393: Validation loss decreased (158.540741 --> 158.460648).\n",
            "\t Train_Loss: 51.7591 Val_Loss: 158.4606  BEST VAL Loss: 158.4606\n",
            "\n",
            "Epoch 1394: Validation loss decreased (158.460648 --> 157.753754).\n",
            "\t Train_Loss: 52.2135 Val_Loss: 157.7538  BEST VAL Loss: 157.7538\n",
            "\n",
            "Epoch 1395: Validation loss did not decrease\n",
            "\t Train_Loss: 51.4959 Val_Loss: 158.6827  BEST VAL Loss: 157.7538\n",
            "\n",
            "Epoch 1396: Validation loss decreased (157.753754 --> 157.562500).\n",
            "\t Train_Loss: 51.8497 Val_Loss: 157.5625  BEST VAL Loss: 157.5625\n",
            "\n",
            "Epoch 1397: Validation loss decreased (157.562500 --> 156.709549).\n",
            "\t Train_Loss: 51.4936 Val_Loss: 156.7095  BEST VAL Loss: 156.7095\n",
            "\n",
            "Epoch 1398: Validation loss decreased (156.709549 --> 156.578049).\n",
            "\t Train_Loss: 51.7502 Val_Loss: 156.5780  BEST VAL Loss: 156.5780\n",
            "\n",
            "Epoch 1399: Validation loss did not decrease\n",
            "\t Train_Loss: 51.3784 Val_Loss: 157.7310  BEST VAL Loss: 156.5780\n",
            "\n",
            "Epoch 1400: Validation loss did not decrease\n",
            "\t Train_Loss: 51.5563 Val_Loss: 157.3004  BEST VAL Loss: 156.5780\n",
            "\n",
            "Epoch 1401: Validation loss decreased (156.578049 --> 156.455536).\n",
            "\t Train_Loss: 51.2670 Val_Loss: 156.4555  BEST VAL Loss: 156.4555\n",
            "\n",
            "Epoch 1402: Validation loss did not decrease\n",
            "\t Train_Loss: 51.3203 Val_Loss: 156.4920  BEST VAL Loss: 156.4555\n",
            "\n",
            "Epoch 1403: Validation loss did not decrease\n",
            "\t Train_Loss: 51.2065 Val_Loss: 157.3506  BEST VAL Loss: 156.4555\n",
            "\n",
            "Epoch 1404: Validation loss did not decrease\n",
            "\t Train_Loss: 51.2139 Val_Loss: 157.0661  BEST VAL Loss: 156.4555\n",
            "\n",
            "Epoch 1405: Validation loss decreased (156.455536 --> 155.834427).\n",
            "\t Train_Loss: 51.1372 Val_Loss: 155.8344  BEST VAL Loss: 155.8344\n",
            "\n",
            "Epoch 1406: Validation loss decreased (155.834427 --> 155.491379).\n",
            "\t Train_Loss: 50.9817 Val_Loss: 155.4914  BEST VAL Loss: 155.4914\n",
            "\n",
            "Epoch 1407: Validation loss did not decrease\n",
            "\t Train_Loss: 51.0067 Val_Loss: 155.7426  BEST VAL Loss: 155.4914\n",
            "\n",
            "Epoch 1408: Validation loss did not decrease\n",
            "\t Train_Loss: 50.9206 Val_Loss: 155.6491  BEST VAL Loss: 155.4914\n",
            "\n",
            "Epoch 1409: Validation loss decreased (155.491379 --> 154.924316).\n",
            "\t Train_Loss: 50.9359 Val_Loss: 154.9243  BEST VAL Loss: 154.9243\n",
            "\n",
            "Epoch 1410: Validation loss decreased (154.924316 --> 154.851288).\n",
            "\t Train_Loss: 50.7939 Val_Loss: 154.8513  BEST VAL Loss: 154.8513\n",
            "\n",
            "Epoch 1411: Validation loss did not decrease\n",
            "\t Train_Loss: 50.7879 Val_Loss: 155.3448  BEST VAL Loss: 154.8513\n",
            "\n",
            "Epoch 1412: Validation loss did not decrease\n",
            "\t Train_Loss: 50.6914 Val_Loss: 155.5629  BEST VAL Loss: 154.8513\n",
            "\n",
            "Epoch 1413: Validation loss did not decrease\n",
            "\t Train_Loss: 50.7067 Val_Loss: 155.0462  BEST VAL Loss: 154.8513\n",
            "\n",
            "Epoch 1414: Validation loss did not decrease\n",
            "\t Train_Loss: 50.6053 Val_Loss: 154.8546  BEST VAL Loss: 154.8513\n",
            "\n",
            "Epoch 1415: Validation loss did not decrease\n",
            "\t Train_Loss: 50.6051 Val_Loss: 154.9501  BEST VAL Loss: 154.8513\n",
            "\n",
            "Epoch 1416: Validation loss decreased (154.851288 --> 154.758209).\n",
            "\t Train_Loss: 50.5025 Val_Loss: 154.7582  BEST VAL Loss: 154.7582\n",
            "\n",
            "Epoch 1417: Validation loss decreased (154.758209 --> 154.122833).\n",
            "\t Train_Loss: 50.4987 Val_Loss: 154.1228  BEST VAL Loss: 154.1228\n",
            "\n",
            "Epoch 1418: Validation loss decreased (154.122833 --> 153.869049).\n",
            "\t Train_Loss: 50.4230 Val_Loss: 153.8690  BEST VAL Loss: 153.8690\n",
            "\n",
            "Epoch 1419: Validation loss did not decrease\n",
            "\t Train_Loss: 50.4098 Val_Loss: 153.9769  BEST VAL Loss: 153.8690\n",
            "\n",
            "Epoch 1420: Validation loss did not decrease\n",
            "\t Train_Loss: 50.3478 Val_Loss: 153.9943  BEST VAL Loss: 153.8690\n",
            "\n",
            "Epoch 1421: Validation loss decreased (153.869049 --> 153.832596).\n",
            "\t Train_Loss: 50.3063 Val_Loss: 153.8326  BEST VAL Loss: 153.8326\n",
            "\n",
            "Epoch 1422: Validation loss did not decrease\n",
            "\t Train_Loss: 50.2608 Val_Loss: 153.9259  BEST VAL Loss: 153.8326\n",
            "\n",
            "Epoch 1423: Validation loss did not decrease\n",
            "\t Train_Loss: 50.2190 Val_Loss: 154.1551  BEST VAL Loss: 153.8326\n",
            "\n",
            "Epoch 1424: Validation loss did not decrease\n",
            "\t Train_Loss: 50.1900 Val_Loss: 153.9764  BEST VAL Loss: 153.8326\n",
            "\n",
            "Epoch 1425: Validation loss decreased (153.832596 --> 153.575165).\n",
            "\t Train_Loss: 50.1344 Val_Loss: 153.5752  BEST VAL Loss: 153.5752\n",
            "\n",
            "Epoch 1426: Validation loss decreased (153.575165 --> 153.349014).\n",
            "\t Train_Loss: 50.1053 Val_Loss: 153.3490  BEST VAL Loss: 153.3490\n",
            "\n",
            "Epoch 1427: Validation loss decreased (153.349014 --> 153.259842).\n",
            "\t Train_Loss: 50.0455 Val_Loss: 153.2598  BEST VAL Loss: 153.2598\n",
            "\n",
            "Epoch 1428: Validation loss decreased (153.259842 --> 153.006439).\n",
            "\t Train_Loss: 50.0300 Val_Loss: 153.0064  BEST VAL Loss: 153.0064\n",
            "\n",
            "Epoch 1429: Validation loss decreased (153.006439 --> 152.870193).\n",
            "\t Train_Loss: 49.9702 Val_Loss: 152.8702  BEST VAL Loss: 152.8702\n",
            "\n",
            "Epoch 1430: Validation loss did not decrease\n",
            "\t Train_Loss: 49.9507 Val_Loss: 152.9770  BEST VAL Loss: 152.8702\n",
            "\n",
            "Epoch 1431: Validation loss did not decrease\n",
            "\t Train_Loss: 49.8887 Val_Loss: 153.1233  BEST VAL Loss: 152.8702\n",
            "\n",
            "Epoch 1432: Validation loss did not decrease\n",
            "\t Train_Loss: 49.8673 Val_Loss: 153.0134  BEST VAL Loss: 152.8702\n",
            "\n",
            "Epoch 1433: Validation loss did not decrease\n",
            "\t Train_Loss: 49.8161 Val_Loss: 152.8965  BEST VAL Loss: 152.8702\n",
            "\n",
            "Epoch 1434: Validation loss decreased (152.870193 --> 152.836258).\n",
            "\t Train_Loss: 49.7897 Val_Loss: 152.8363  BEST VAL Loss: 152.8363\n",
            "\n",
            "Epoch 1435: Validation loss decreased (152.836258 --> 152.648300).\n",
            "\t Train_Loss: 49.7414 Val_Loss: 152.6483  BEST VAL Loss: 152.6483\n",
            "\n",
            "Epoch 1436: Validation loss decreased (152.648300 --> 152.340881).\n",
            "\t Train_Loss: 49.7071 Val_Loss: 152.3409  BEST VAL Loss: 152.3409\n",
            "\n",
            "Epoch 1437: Validation loss decreased (152.340881 --> 152.189468).\n",
            "\t Train_Loss: 49.6672 Val_Loss: 152.1895  BEST VAL Loss: 152.1895\n",
            "\n",
            "Epoch 1438: Validation loss did not decrease\n",
            "\t Train_Loss: 49.6301 Val_Loss: 152.1928  BEST VAL Loss: 152.1895\n",
            "\n",
            "Epoch 1439: Validation loss decreased (152.189468 --> 152.143127).\n",
            "\t Train_Loss: 49.5949 Val_Loss: 152.1431  BEST VAL Loss: 152.1431\n",
            "\n",
            "Epoch 1440: Validation loss decreased (152.143127 --> 152.078186).\n",
            "\t Train_Loss: 49.5521 Val_Loss: 152.0782  BEST VAL Loss: 152.0782\n",
            "\n",
            "Epoch 1441: Validation loss did not decrease\n",
            "\t Train_Loss: 49.5195 Val_Loss: 152.1017  BEST VAL Loss: 152.0782\n",
            "\n",
            "Epoch 1442: Validation loss did not decrease\n",
            "\t Train_Loss: 49.4771 Val_Loss: 152.1022  BEST VAL Loss: 152.0782\n",
            "\n",
            "Epoch 1443: Validation loss decreased (152.078186 --> 151.926239).\n",
            "\t Train_Loss: 49.4461 Val_Loss: 151.9262  BEST VAL Loss: 151.9262\n",
            "\n",
            "Epoch 1444: Validation loss decreased (151.926239 --> 151.731903).\n",
            "\t Train_Loss: 49.4037 Val_Loss: 151.7319  BEST VAL Loss: 151.7319\n",
            "\n",
            "Epoch 1445: Validation loss decreased (151.731903 --> 151.622955).\n",
            "\t Train_Loss: 49.3709 Val_Loss: 151.6230  BEST VAL Loss: 151.6230\n",
            "\n",
            "Epoch 1446: Validation loss decreased (151.622955 --> 151.511551).\n",
            "\t Train_Loss: 49.3305 Val_Loss: 151.5116  BEST VAL Loss: 151.5116\n",
            "\n",
            "Epoch 1447: Validation loss decreased (151.511551 --> 151.362885).\n",
            "\t Train_Loss: 49.2970 Val_Loss: 151.3629  BEST VAL Loss: 151.3629\n",
            "\n",
            "Epoch 1448: Validation loss decreased (151.362885 --> 151.304276).\n",
            "\t Train_Loss: 49.2591 Val_Loss: 151.3043  BEST VAL Loss: 151.3043\n",
            "\n",
            "Epoch 1449: Validation loss did not decrease\n",
            "\t Train_Loss: 49.2234 Val_Loss: 151.3230  BEST VAL Loss: 151.3043\n",
            "\n",
            "Epoch 1450: Validation loss decreased (151.304276 --> 151.276398).\n",
            "\t Train_Loss: 49.1870 Val_Loss: 151.2764  BEST VAL Loss: 151.2764\n",
            "\n",
            "Epoch 1451: Validation loss decreased (151.276398 --> 151.167801).\n",
            "\t Train_Loss: 49.1503 Val_Loss: 151.1678  BEST VAL Loss: 151.1678\n",
            "\n",
            "Epoch 1452: Validation loss decreased (151.167801 --> 151.090439).\n",
            "\t Train_Loss: 49.1158 Val_Loss: 151.0904  BEST VAL Loss: 151.0904\n",
            "\n",
            "Epoch 1453: Validation loss decreased (151.090439 --> 151.009705).\n",
            "\t Train_Loss: 49.0786 Val_Loss: 151.0097  BEST VAL Loss: 151.0097\n",
            "\n",
            "Epoch 1454: Validation loss decreased (151.009705 --> 150.856033).\n",
            "\t Train_Loss: 49.0443 Val_Loss: 150.8560  BEST VAL Loss: 150.8560\n",
            "\n",
            "Epoch 1455: Validation loss decreased (150.856033 --> 150.716248).\n",
            "\t Train_Loss: 49.0070 Val_Loss: 150.7162  BEST VAL Loss: 150.7162\n",
            "\n",
            "Epoch 1456: Validation loss decreased (150.716248 --> 150.652390).\n",
            "\t Train_Loss: 48.9731 Val_Loss: 150.6524  BEST VAL Loss: 150.6524\n",
            "\n",
            "Epoch 1457: Validation loss decreased (150.652390 --> 150.597412).\n",
            "\t Train_Loss: 48.9366 Val_Loss: 150.5974  BEST VAL Loss: 150.5974\n",
            "\n",
            "Epoch 1458: Validation loss decreased (150.597412 --> 150.507355).\n",
            "\t Train_Loss: 48.9022 Val_Loss: 150.5074  BEST VAL Loss: 150.5074\n",
            "\n",
            "Epoch 1459: Validation loss decreased (150.507355 --> 150.443527).\n",
            "\t Train_Loss: 48.8662 Val_Loss: 150.4435  BEST VAL Loss: 150.4435\n",
            "\n",
            "Epoch 1460: Validation loss decreased (150.443527 --> 150.404037).\n",
            "\t Train_Loss: 48.8315 Val_Loss: 150.4040  BEST VAL Loss: 150.4040\n",
            "\n",
            "Epoch 1461: Validation loss decreased (150.404037 --> 150.315094).\n",
            "\t Train_Loss: 48.7965 Val_Loss: 150.3151  BEST VAL Loss: 150.3151\n",
            "\n",
            "Epoch 1462: Validation loss decreased (150.315094 --> 150.189651).\n",
            "\t Train_Loss: 48.7615 Val_Loss: 150.1897  BEST VAL Loss: 150.1897\n",
            "\n",
            "Epoch 1463: Validation loss decreased (150.189651 --> 150.094574).\n",
            "\t Train_Loss: 48.7270 Val_Loss: 150.0946  BEST VAL Loss: 150.0946\n",
            "\n",
            "Epoch 1464: Validation loss decreased (150.094574 --> 150.014450).\n",
            "\t Train_Loss: 48.6917 Val_Loss: 150.0145  BEST VAL Loss: 150.0145\n",
            "\n",
            "Epoch 1465: Validation loss decreased (150.014450 --> 149.908051).\n",
            "\t Train_Loss: 48.6576 Val_Loss: 149.9081  BEST VAL Loss: 149.9081\n",
            "\n",
            "Epoch 1466: Validation loss decreased (149.908051 --> 149.813873).\n",
            "\t Train_Loss: 48.6226 Val_Loss: 149.8139  BEST VAL Loss: 149.8139\n",
            "\n",
            "Epoch 1467: Validation loss decreased (149.813873 --> 149.758011).\n",
            "\t Train_Loss: 48.5886 Val_Loss: 149.7580  BEST VAL Loss: 149.7580\n",
            "\n",
            "Epoch 1468: Validation loss decreased (149.758011 --> 149.694656).\n",
            "\t Train_Loss: 48.5538 Val_Loss: 149.6947  BEST VAL Loss: 149.6947\n",
            "\n",
            "Epoch 1469: Validation loss decreased (149.694656 --> 149.601349).\n",
            "\t Train_Loss: 48.5198 Val_Loss: 149.6013  BEST VAL Loss: 149.6013\n",
            "\n",
            "Epoch 1470: Validation loss decreased (149.601349 --> 149.517334).\n",
            "\t Train_Loss: 48.4854 Val_Loss: 149.5173  BEST VAL Loss: 149.5173\n",
            "\n",
            "Epoch 1471: Validation loss decreased (149.517334 --> 149.445038).\n",
            "\t Train_Loss: 48.4514 Val_Loss: 149.4450  BEST VAL Loss: 149.4450\n",
            "\n",
            "Epoch 1472: Validation loss decreased (149.445038 --> 149.349152).\n",
            "\t Train_Loss: 48.4174 Val_Loss: 149.3492  BEST VAL Loss: 149.3492\n",
            "\n",
            "Epoch 1473: Validation loss decreased (149.349152 --> 149.243317).\n",
            "\t Train_Loss: 48.3833 Val_Loss: 149.2433  BEST VAL Loss: 149.2433\n",
            "\n",
            "Epoch 1474: Validation loss decreased (149.243317 --> 149.162155).\n",
            "\t Train_Loss: 48.3495 Val_Loss: 149.1622  BEST VAL Loss: 149.1622\n",
            "\n",
            "Epoch 1475: Validation loss decreased (149.162155 --> 149.089447).\n",
            "\t Train_Loss: 48.3155 Val_Loss: 149.0894  BEST VAL Loss: 149.0894\n",
            "\n",
            "Epoch 1476: Validation loss decreased (149.089447 --> 149.000824).\n",
            "\t Train_Loss: 48.2820 Val_Loss: 149.0008  BEST VAL Loss: 149.0008\n",
            "\n",
            "Epoch 1477: Validation loss decreased (149.000824 --> 148.917450).\n",
            "\t Train_Loss: 48.2481 Val_Loss: 148.9174  BEST VAL Loss: 148.9174\n",
            "\n",
            "Epoch 1478: Validation loss decreased (148.917450 --> 148.850327).\n",
            "\t Train_Loss: 48.2146 Val_Loss: 148.8503  BEST VAL Loss: 148.8503\n",
            "\n",
            "Epoch 1479: Validation loss decreased (148.850327 --> 148.772369).\n",
            "\t Train_Loss: 48.1810 Val_Loss: 148.7724  BEST VAL Loss: 148.7724\n",
            "\n",
            "Epoch 1480: Validation loss decreased (148.772369 --> 148.678787).\n",
            "\t Train_Loss: 48.1475 Val_Loss: 148.6788  BEST VAL Loss: 148.6788\n",
            "\n",
            "Epoch 1481: Validation loss decreased (148.678787 --> 148.594223).\n",
            "\t Train_Loss: 48.1141 Val_Loss: 148.5942  BEST VAL Loss: 148.5942\n",
            "\n",
            "Epoch 1482: Validation loss decreased (148.594223 --> 148.516922).\n",
            "\t Train_Loss: 48.0807 Val_Loss: 148.5169  BEST VAL Loss: 148.5169\n",
            "\n",
            "Epoch 1483: Validation loss decreased (148.516922 --> 148.428055).\n",
            "\t Train_Loss: 48.0474 Val_Loss: 148.4281  BEST VAL Loss: 148.4281\n",
            "\n",
            "Epoch 1484: Validation loss decreased (148.428055 --> 148.338104).\n",
            "\t Train_Loss: 48.0141 Val_Loss: 148.3381  BEST VAL Loss: 148.3381\n",
            "\n",
            "Epoch 1485: Validation loss decreased (148.338104 --> 148.262665).\n",
            "\t Train_Loss: 47.9810 Val_Loss: 148.2627  BEST VAL Loss: 148.2627\n",
            "\n",
            "Epoch 1486: Validation loss decreased (148.262665 --> 148.188019).\n",
            "\t Train_Loss: 47.9477 Val_Loss: 148.1880  BEST VAL Loss: 148.1880\n",
            "\n",
            "Epoch 1487: Validation loss decreased (148.188019 --> 148.102921).\n",
            "\t Train_Loss: 47.9146 Val_Loss: 148.1029  BEST VAL Loss: 148.1029\n",
            "\n",
            "Epoch 1488: Validation loss decreased (148.102921 --> 148.021637).\n",
            "\t Train_Loss: 47.8815 Val_Loss: 148.0216  BEST VAL Loss: 148.0216\n",
            "\n",
            "Epoch 1489: Validation loss decreased (148.021637 --> 147.947449).\n",
            "\t Train_Loss: 47.8484 Val_Loss: 147.9474  BEST VAL Loss: 147.9474\n",
            "\n",
            "Epoch 1490: Validation loss decreased (147.947449 --> 147.865204).\n",
            "\t Train_Loss: 47.8153 Val_Loss: 147.8652  BEST VAL Loss: 147.8652\n",
            "\n",
            "Epoch 1491: Validation loss decreased (147.865204 --> 147.776566).\n",
            "\t Train_Loss: 47.7821 Val_Loss: 147.7766  BEST VAL Loss: 147.7766\n",
            "\n",
            "Epoch 1492: Validation loss decreased (147.776566 --> 147.695404).\n",
            "\t Train_Loss: 47.7489 Val_Loss: 147.6954  BEST VAL Loss: 147.6954\n",
            "\n",
            "Epoch 1493: Validation loss decreased (147.695404 --> 147.617767).\n",
            "\t Train_Loss: 47.7154 Val_Loss: 147.6178  BEST VAL Loss: 147.6178\n",
            "\n",
            "Epoch 1494: Validation loss decreased (147.617767 --> 147.533646).\n",
            "\t Train_Loss: 47.6818 Val_Loss: 147.5336  BEST VAL Loss: 147.5336\n",
            "\n",
            "Epoch 1495: Validation loss decreased (147.533646 --> 147.451340).\n",
            "\t Train_Loss: 47.6477 Val_Loss: 147.4513  BEST VAL Loss: 147.4513\n",
            "\n",
            "Epoch 1496: Validation loss decreased (147.451340 --> 147.376846).\n",
            "\t Train_Loss: 47.6129 Val_Loss: 147.3768  BEST VAL Loss: 147.3768\n",
            "\n",
            "Epoch 1497: Validation loss decreased (147.376846 --> 147.300583).\n",
            "\t Train_Loss: 47.5766 Val_Loss: 147.3006  BEST VAL Loss: 147.3006\n",
            "\n",
            "Epoch 1498: Validation loss decreased (147.300583 --> 147.219223).\n",
            "\t Train_Loss: 47.5376 Val_Loss: 147.2192  BEST VAL Loss: 147.2192\n",
            "\n",
            "Epoch 1499: Validation loss decreased (147.219223 --> 147.143555).\n",
            "\t Train_Loss: 47.4918 Val_Loss: 147.1436  BEST VAL Loss: 147.1436\n",
            "\n",
            "Epoch 1500: Validation loss decreased (147.143555 --> 147.084061).\n",
            "\t Train_Loss: 47.4261 Val_Loss: 147.0841  BEST VAL Loss: 147.0841\n",
            "\n",
            "Epoch 1501: Validation loss did not decrease\n",
            "\t Train_Loss: 47.2690 Val_Loss: 147.2343  BEST VAL Loss: 147.0841\n",
            "\n",
            "Epoch 1502: Validation loss did not decrease\n",
            "\t Train_Loss: 46.1551 Val_Loss: 184.0529  BEST VAL Loss: 147.0841\n",
            "\n",
            "Epoch 1503: Validation loss did not decrease\n",
            "\t Train_Loss: 49.5138 Val_Loss: 147.4053  BEST VAL Loss: 147.0841\n",
            "\n",
            "Epoch 1504: Validation loss decreased (147.084061 --> 145.648560).\n",
            "\t Train_Loss: 43.9162 Val_Loss: 145.6486  BEST VAL Loss: 145.6486\n",
            "\n",
            "Epoch 1505: Validation loss decreased (145.648560 --> 145.486511).\n",
            "\t Train_Loss: 45.9186 Val_Loss: 145.4865  BEST VAL Loss: 145.4865\n",
            "\n",
            "Epoch 1506: Validation loss did not decrease\n",
            "\t Train_Loss: 46.0114 Val_Loss: 146.1786  BEST VAL Loss: 145.4865\n",
            "\n",
            "Epoch 1507: Validation loss did not decrease\n",
            "\t Train_Loss: 44.7464 Val_Loss: 148.7688  BEST VAL Loss: 145.4865\n",
            "\n",
            "Epoch 1508: Validation loss did not decrease\n",
            "\t Train_Loss: 42.6404 Val_Loss: 156.8518  BEST VAL Loss: 145.4865\n",
            "\n",
            "Epoch 1509: Validation loss did not decrease\n",
            "\t Train_Loss: 43.4254 Val_Loss: 158.0050  BEST VAL Loss: 145.4865\n",
            "\n",
            "Epoch 1510: Validation loss did not decrease\n",
            "\t Train_Loss: 43.8823 Val_Loss: 150.8931  BEST VAL Loss: 145.4865\n",
            "\n",
            "Epoch 1511: Validation loss decreased (145.486511 --> 144.990479).\n",
            "\t Train_Loss: 42.5986 Val_Loss: 144.9905  BEST VAL Loss: 144.9905\n",
            "\n",
            "Epoch 1512: Validation loss decreased (144.990479 --> 143.342957).\n",
            "\t Train_Loss: 42.0468 Val_Loss: 143.3430  BEST VAL Loss: 143.3430\n",
            "\n",
            "Epoch 1513: Validation loss did not decrease\n",
            "\t Train_Loss: 42.7256 Val_Loss: 144.0858  BEST VAL Loss: 143.3430\n",
            "\n",
            "Epoch 1514: Validation loss did not decrease\n",
            "\t Train_Loss: 42.2256 Val_Loss: 146.2368  BEST VAL Loss: 143.3430\n",
            "\n",
            "Epoch 1515: Validation loss did not decrease\n",
            "\t Train_Loss: 41.1670 Val_Loss: 148.8967  BEST VAL Loss: 143.3430\n",
            "\n",
            "Epoch 1516: Validation loss did not decrease\n",
            "\t Train_Loss: 41.5626 Val_Loss: 150.0344  BEST VAL Loss: 143.3430\n",
            "\n",
            "Epoch 1517: Validation loss did not decrease\n",
            "\t Train_Loss: 41.6888 Val_Loss: 148.1215  BEST VAL Loss: 143.3430\n",
            "\n",
            "Epoch 1518: Validation loss did not decrease\n",
            "\t Train_Loss: 41.0448 Val_Loss: 143.9945  BEST VAL Loss: 143.3430\n",
            "\n",
            "Epoch 1519: Validation loss decreased (143.342957 --> 141.751892).\n",
            "\t Train_Loss: 40.4444 Val_Loss: 141.7519  BEST VAL Loss: 141.7519\n",
            "\n",
            "Epoch 1520: Validation loss did not decrease\n",
            "\t Train_Loss: 40.8944 Val_Loss: 142.6413  BEST VAL Loss: 141.7519\n",
            "\n",
            "Epoch 1521: Validation loss did not decrease\n",
            "\t Train_Loss: 40.8291 Val_Loss: 143.0658  BEST VAL Loss: 141.7519\n",
            "\n",
            "Epoch 1522: Validation loss did not decrease\n",
            "\t Train_Loss: 40.1881 Val_Loss: 143.9407  BEST VAL Loss: 141.7519\n",
            "\n",
            "Epoch 1523: Validation loss did not decrease\n",
            "\t Train_Loss: 40.6464 Val_Loss: 146.4487  BEST VAL Loss: 141.7519\n",
            "\n",
            "Epoch 1524: Validation loss did not decrease\n",
            "\t Train_Loss: 40.5022 Val_Loss: 145.2999  BEST VAL Loss: 141.7519\n",
            "\n",
            "Epoch 1525: Validation loss did not decrease\n",
            "\t Train_Loss: 40.1443 Val_Loss: 142.9367  BEST VAL Loss: 141.7519\n",
            "\n",
            "Epoch 1526: Validation loss did not decrease\n",
            "\t Train_Loss: 40.9187 Val_Loss: 143.5584  BEST VAL Loss: 141.7519\n",
            "\n",
            "Epoch 1527: Validation loss did not decrease\n",
            "\t Train_Loss: 40.0974 Val_Loss: 142.9372  BEST VAL Loss: 141.7519\n",
            "\n",
            "Epoch 1528: Validation loss decreased (141.751892 --> 141.153839).\n",
            "\t Train_Loss: 39.9997 Val_Loss: 141.1538  BEST VAL Loss: 141.1538\n",
            "\n",
            "Epoch 1529: Validation loss did not decrease\n",
            "\t Train_Loss: 40.1974 Val_Loss: 142.0765  BEST VAL Loss: 141.1538\n",
            "\n",
            "Epoch 1530: Validation loss did not decrease\n",
            "\t Train_Loss: 39.7890 Val_Loss: 142.3149  BEST VAL Loss: 141.1538\n",
            "\n",
            "Epoch 1531: Validation loss decreased (141.153839 --> 140.849335).\n",
            "\t Train_Loss: 39.8104 Val_Loss: 140.8493  BEST VAL Loss: 140.8493\n",
            "\n",
            "Epoch 1532: Validation loss did not decrease\n",
            "\t Train_Loss: 39.6067 Val_Loss: 141.1346  BEST VAL Loss: 140.8493\n",
            "\n",
            "Epoch 1533: Validation loss did not decrease\n",
            "\t Train_Loss: 39.4038 Val_Loss: 141.9270  BEST VAL Loss: 140.8493\n",
            "\n",
            "Epoch 1534: Validation loss decreased (140.849335 --> 140.754578).\n",
            "\t Train_Loss: 39.5299 Val_Loss: 140.7546  BEST VAL Loss: 140.7546\n",
            "\n",
            "Epoch 1535: Validation loss decreased (140.754578 --> 140.348755).\n",
            "\t Train_Loss: 39.3257 Val_Loss: 140.3488  BEST VAL Loss: 140.3488\n",
            "\n",
            "Epoch 1536: Validation loss did not decrease\n",
            "\t Train_Loss: 39.2482 Val_Loss: 140.5668  BEST VAL Loss: 140.3488\n",
            "\n",
            "Epoch 1537: Validation loss decreased (140.348755 --> 139.509979).\n",
            "\t Train_Loss: 39.2460 Val_Loss: 139.5100  BEST VAL Loss: 139.5100\n",
            "\n",
            "Epoch 1538: Validation loss decreased (139.509979 --> 138.503098).\n",
            "\t Train_Loss: 39.1319 Val_Loss: 138.5031  BEST VAL Loss: 138.5031\n",
            "\n",
            "Epoch 1539: Validation loss did not decrease\n",
            "\t Train_Loss: 39.1647 Val_Loss: 138.7005  BEST VAL Loss: 138.5031\n",
            "\n",
            "Epoch 1540: Validation loss did not decrease\n",
            "\t Train_Loss: 39.0628 Val_Loss: 138.5713  BEST VAL Loss: 138.5031\n",
            "\n",
            "Epoch 1541: Validation loss decreased (138.503098 --> 138.057510).\n",
            "\t Train_Loss: 39.0146 Val_Loss: 138.0575  BEST VAL Loss: 138.0575\n",
            "\n",
            "Epoch 1542: Validation loss did not decrease\n",
            "\t Train_Loss: 38.9968 Val_Loss: 138.4964  BEST VAL Loss: 138.0575\n",
            "\n",
            "Epoch 1543: Validation loss did not decrease\n",
            "\t Train_Loss: 38.8954 Val_Loss: 138.6126  BEST VAL Loss: 138.0575\n",
            "\n",
            "Epoch 1544: Validation loss decreased (138.057510 --> 137.794586).\n",
            "\t Train_Loss: 38.8845 Val_Loss: 137.7946  BEST VAL Loss: 137.7946\n",
            "\n",
            "Epoch 1545: Validation loss decreased (137.794586 --> 137.305573).\n",
            "\t Train_Loss: 38.8155 Val_Loss: 137.3056  BEST VAL Loss: 137.3056\n",
            "\n",
            "Epoch 1546: Validation loss decreased (137.305573 --> 137.122055).\n",
            "\t Train_Loss: 38.7531 Val_Loss: 137.1221  BEST VAL Loss: 137.1221\n",
            "\n",
            "Epoch 1547: Validation loss decreased (137.122055 --> 136.530334).\n",
            "\t Train_Loss: 38.7237 Val_Loss: 136.5303  BEST VAL Loss: 136.5303\n",
            "\n",
            "Epoch 1548: Validation loss decreased (136.530334 --> 136.142975).\n",
            "\t Train_Loss: 38.6576 Val_Loss: 136.1430  BEST VAL Loss: 136.1430\n",
            "\n",
            "Epoch 1549: Validation loss did not decrease\n",
            "\t Train_Loss: 38.6332 Val_Loss: 136.4463  BEST VAL Loss: 136.1430\n",
            "\n",
            "Epoch 1550: Validation loss did not decrease\n",
            "\t Train_Loss: 38.5674 Val_Loss: 136.4656  BEST VAL Loss: 136.1430\n",
            "\n",
            "Epoch 1551: Validation loss decreased (136.142975 --> 136.043457).\n",
            "\t Train_Loss: 38.5281 Val_Loss: 136.0435  BEST VAL Loss: 136.0435\n",
            "\n",
            "Epoch 1552: Validation loss decreased (136.043457 --> 135.914856).\n",
            "\t Train_Loss: 38.4960 Val_Loss: 135.9149  BEST VAL Loss: 135.9149\n",
            "\n",
            "Epoch 1553: Validation loss decreased (135.914856 --> 135.633667).\n",
            "\t Train_Loss: 38.4342 Val_Loss: 135.6337  BEST VAL Loss: 135.6337\n",
            "\n",
            "Epoch 1554: Validation loss decreased (135.633667 --> 134.994293).\n",
            "\t Train_Loss: 38.4034 Val_Loss: 134.9943  BEST VAL Loss: 134.9943\n",
            "\n",
            "Epoch 1555: Validation loss decreased (134.994293 --> 134.676773).\n",
            "\t Train_Loss: 38.3569 Val_Loss: 134.6768  BEST VAL Loss: 134.6768\n",
            "\n",
            "Epoch 1556: Validation loss decreased (134.676773 --> 134.652832).\n",
            "\t Train_Loss: 38.3143 Val_Loss: 134.6528  BEST VAL Loss: 134.6528\n",
            "\n",
            "Epoch 1557: Validation loss decreased (134.652832 --> 134.382431).\n",
            "\t Train_Loss: 38.2758 Val_Loss: 134.3824  BEST VAL Loss: 134.3824\n",
            "\n",
            "Epoch 1558: Validation loss decreased (134.382431 --> 134.145584).\n",
            "\t Train_Loss: 38.2246 Val_Loss: 134.1456  BEST VAL Loss: 134.1456\n",
            "\n",
            "Epoch 1559: Validation loss decreased (134.145584 --> 134.102020).\n",
            "\t Train_Loss: 38.1939 Val_Loss: 134.1020  BEST VAL Loss: 134.1020\n",
            "\n",
            "Epoch 1560: Validation loss decreased (134.102020 --> 133.720627).\n",
            "\t Train_Loss: 38.1517 Val_Loss: 133.7206  BEST VAL Loss: 133.7206\n",
            "\n",
            "Epoch 1561: Validation loss decreased (133.720627 --> 133.275574).\n",
            "\t Train_Loss: 38.1033 Val_Loss: 133.2756  BEST VAL Loss: 133.2756\n",
            "\n",
            "Epoch 1562: Validation loss decreased (133.275574 --> 133.112686).\n",
            "\t Train_Loss: 38.0704 Val_Loss: 133.1127  BEST VAL Loss: 133.1127\n",
            "\n",
            "Epoch 1563: Validation loss decreased (133.112686 --> 132.871521).\n",
            "\t Train_Loss: 38.0284 Val_Loss: 132.8715  BEST VAL Loss: 132.8715\n",
            "\n",
            "Epoch 1564: Validation loss decreased (132.871521 --> 132.572983).\n",
            "\t Train_Loss: 37.9892 Val_Loss: 132.5730  BEST VAL Loss: 132.5730\n",
            "\n",
            "Epoch 1565: Validation loss decreased (132.572983 --> 132.503220).\n",
            "\t Train_Loss: 37.9525 Val_Loss: 132.5032  BEST VAL Loss: 132.5032\n",
            "\n",
            "Epoch 1566: Validation loss decreased (132.503220 --> 132.345673).\n",
            "\t Train_Loss: 37.9090 Val_Loss: 132.3457  BEST VAL Loss: 132.3457\n",
            "\n",
            "Epoch 1567: Validation loss decreased (132.345673 --> 131.983566).\n",
            "\t Train_Loss: 37.8747 Val_Loss: 131.9836  BEST VAL Loss: 131.9836\n",
            "\n",
            "Epoch 1568: Validation loss decreased (131.983566 --> 131.760101).\n",
            "\t Train_Loss: 37.8375 Val_Loss: 131.7601  BEST VAL Loss: 131.7601\n",
            "\n",
            "Epoch 1569: Validation loss decreased (131.760101 --> 131.544998).\n",
            "\t Train_Loss: 37.7958 Val_Loss: 131.5450  BEST VAL Loss: 131.5450\n",
            "\n",
            "Epoch 1570: Validation loss decreased (131.544998 --> 131.238678).\n",
            "\t Train_Loss: 37.7614 Val_Loss: 131.2387  BEST VAL Loss: 131.2387\n",
            "\n",
            "Epoch 1571: Validation loss decreased (131.238678 --> 131.098892).\n",
            "\t Train_Loss: 37.7241 Val_Loss: 131.0989  BEST VAL Loss: 131.0989\n",
            "\n",
            "Epoch 1572: Validation loss decreased (131.098892 --> 131.036591).\n",
            "\t Train_Loss: 37.6864 Val_Loss: 131.0366  BEST VAL Loss: 131.0366\n",
            "\n",
            "Epoch 1573: Validation loss decreased (131.036591 --> 130.827835).\n",
            "\t Train_Loss: 37.6516 Val_Loss: 130.8278  BEST VAL Loss: 130.8278\n",
            "\n",
            "Epoch 1574: Validation loss decreased (130.827835 --> 130.622025).\n",
            "\t Train_Loss: 37.6144 Val_Loss: 130.6220  BEST VAL Loss: 130.6220\n",
            "\n",
            "Epoch 1575: Validation loss decreased (130.622025 --> 130.449982).\n",
            "\t Train_Loss: 37.5798 Val_Loss: 130.4500  BEST VAL Loss: 130.4500\n",
            "\n",
            "Epoch 1576: Validation loss decreased (130.449982 --> 130.157883).\n",
            "\t Train_Loss: 37.5443 Val_Loss: 130.1579  BEST VAL Loss: 130.1579\n",
            "\n",
            "Epoch 1577: Validation loss decreased (130.157883 --> 129.888260).\n",
            "\t Train_Loss: 37.5076 Val_Loss: 129.8883  BEST VAL Loss: 129.8883\n",
            "\n",
            "Epoch 1578: Validation loss decreased (129.888260 --> 129.753235).\n",
            "\t Train_Loss: 37.4739 Val_Loss: 129.7532  BEST VAL Loss: 129.7532\n",
            "\n",
            "Epoch 1579: Validation loss decreased (129.753235 --> 129.603317).\n",
            "\t Train_Loss: 37.4382 Val_Loss: 129.6033  BEST VAL Loss: 129.6033\n",
            "\n",
            "Epoch 1580: Validation loss decreased (129.603317 --> 129.427399).\n",
            "\t Train_Loss: 37.4026 Val_Loss: 129.4274  BEST VAL Loss: 129.4274\n",
            "\n",
            "Epoch 1581: Validation loss decreased (129.427399 --> 129.310272).\n",
            "\t Train_Loss: 37.3682 Val_Loss: 129.3103  BEST VAL Loss: 129.3103\n",
            "\n",
            "Epoch 1582: Validation loss decreased (129.310272 --> 129.151962).\n",
            "\t Train_Loss: 37.3327 Val_Loss: 129.1520  BEST VAL Loss: 129.1520\n",
            "\n",
            "Epoch 1583: Validation loss decreased (129.151962 --> 128.908127).\n",
            "\t Train_Loss: 37.2985 Val_Loss: 128.9081  BEST VAL Loss: 128.9081\n",
            "\n",
            "Epoch 1584: Validation loss decreased (128.908127 --> 128.701157).\n",
            "\t Train_Loss: 37.2634 Val_Loss: 128.7012  BEST VAL Loss: 128.7012\n",
            "\n",
            "Epoch 1585: Validation loss decreased (128.701157 --> 128.541626).\n",
            "\t Train_Loss: 37.2288 Val_Loss: 128.5416  BEST VAL Loss: 128.5416\n",
            "\n",
            "Epoch 1586: Validation loss decreased (128.541626 --> 128.360565).\n",
            "\t Train_Loss: 37.1948 Val_Loss: 128.3606  BEST VAL Loss: 128.3606\n",
            "\n",
            "Epoch 1587: Validation loss decreased (128.360565 --> 128.201141).\n",
            "\t Train_Loss: 37.1600 Val_Loss: 128.2011  BEST VAL Loss: 128.2011\n",
            "\n",
            "Epoch 1588: Validation loss decreased (128.201141 --> 128.090576).\n",
            "\t Train_Loss: 37.1260 Val_Loss: 128.0906  BEST VAL Loss: 128.0906\n",
            "\n",
            "Epoch 1589: Validation loss decreased (128.090576 --> 127.950943).\n",
            "\t Train_Loss: 37.0916 Val_Loss: 127.9509  BEST VAL Loss: 127.9509\n",
            "\n",
            "Epoch 1590: Validation loss decreased (127.950943 --> 127.768654).\n",
            "\t Train_Loss: 37.0575 Val_Loss: 127.7687  BEST VAL Loss: 127.7687\n",
            "\n",
            "Epoch 1591: Validation loss decreased (127.768654 --> 127.610130).\n",
            "\t Train_Loss: 37.0232 Val_Loss: 127.6101  BEST VAL Loss: 127.6101\n",
            "\n",
            "Epoch 1592: Validation loss decreased (127.610130 --> 127.470840).\n",
            "\t Train_Loss: 36.9888 Val_Loss: 127.4708  BEST VAL Loss: 127.4708\n",
            "\n",
            "Epoch 1593: Validation loss decreased (127.470840 --> 127.313477).\n",
            "\t Train_Loss: 36.9548 Val_Loss: 127.3135  BEST VAL Loss: 127.3135\n",
            "\n",
            "Epoch 1594: Validation loss decreased (127.313477 --> 127.166771).\n",
            "\t Train_Loss: 36.9203 Val_Loss: 127.1668  BEST VAL Loss: 127.1668\n",
            "\n",
            "Epoch 1595: Validation loss decreased (127.166771 --> 127.049538).\n",
            "\t Train_Loss: 36.8861 Val_Loss: 127.0495  BEST VAL Loss: 127.0495\n",
            "\n",
            "Epoch 1596: Validation loss decreased (127.049538 --> 126.918114).\n",
            "\t Train_Loss: 36.8515 Val_Loss: 126.9181  BEST VAL Loss: 126.9181\n",
            "\n",
            "Epoch 1597: Validation loss decreased (126.918114 --> 126.756020).\n",
            "\t Train_Loss: 36.8172 Val_Loss: 126.7560  BEST VAL Loss: 126.7560\n",
            "\n",
            "Epoch 1598: Validation loss decreased (126.756020 --> 126.603470).\n",
            "\t Train_Loss: 36.7825 Val_Loss: 126.6035  BEST VAL Loss: 126.6035\n",
            "\n",
            "Epoch 1599: Validation loss decreased (126.603470 --> 126.471031).\n",
            "\t Train_Loss: 36.7478 Val_Loss: 126.4710  BEST VAL Loss: 126.4710\n",
            "\n",
            "Epoch 1600: Validation loss decreased (126.471031 --> 126.334251).\n",
            "\t Train_Loss: 36.7131 Val_Loss: 126.3343  BEST VAL Loss: 126.3343\n",
            "\n",
            "Epoch 1601: Validation loss decreased (126.334251 --> 126.198105).\n",
            "\t Train_Loss: 36.6781 Val_Loss: 126.1981  BEST VAL Loss: 126.1981\n",
            "\n",
            "Epoch 1602: Validation loss decreased (126.198105 --> 126.080727).\n",
            "\t Train_Loss: 36.6431 Val_Loss: 126.0807  BEST VAL Loss: 126.0807\n",
            "\n",
            "Epoch 1603: Validation loss decreased (126.080727 --> 125.964050).\n",
            "\t Train_Loss: 36.6078 Val_Loss: 125.9641  BEST VAL Loss: 125.9641\n",
            "\n",
            "Epoch 1604: Validation loss decreased (125.964050 --> 125.823746).\n",
            "\t Train_Loss: 36.5725 Val_Loss: 125.8237  BEST VAL Loss: 125.8237\n",
            "\n",
            "Epoch 1605: Validation loss decreased (125.823746 --> 125.675034).\n",
            "\t Train_Loss: 36.5368 Val_Loss: 125.6750  BEST VAL Loss: 125.6750\n",
            "\n",
            "Epoch 1606: Validation loss decreased (125.675034 --> 125.539940).\n",
            "\t Train_Loss: 36.5011 Val_Loss: 125.5399  BEST VAL Loss: 125.5399\n",
            "\n",
            "Epoch 1607: Validation loss decreased (125.539940 --> 125.411667).\n",
            "\t Train_Loss: 36.4650 Val_Loss: 125.4117  BEST VAL Loss: 125.4117\n",
            "\n",
            "Epoch 1608: Validation loss decreased (125.411667 --> 125.279251).\n",
            "\t Train_Loss: 36.4287 Val_Loss: 125.2793  BEST VAL Loss: 125.2793\n",
            "\n",
            "Epoch 1609: Validation loss decreased (125.279251 --> 125.152611).\n",
            "\t Train_Loss: 36.3920 Val_Loss: 125.1526  BEST VAL Loss: 125.1526\n",
            "\n",
            "Epoch 1610: Validation loss decreased (125.152611 --> 125.036720).\n",
            "\t Train_Loss: 36.3546 Val_Loss: 125.0367  BEST VAL Loss: 125.0367\n",
            "\n",
            "Epoch 1611: Validation loss decreased (125.036720 --> 124.931419).\n",
            "\t Train_Loss: 36.3140 Val_Loss: 124.9314  BEST VAL Loss: 124.9314\n",
            "\n",
            "Epoch 1612: Validation loss did not decrease\n",
            "\t Train_Loss: 36.1509 Val_Loss: 135.4353  BEST VAL Loss: 124.9314\n",
            "\n",
            "Epoch 1613: Validation loss decreased (124.931419 --> 123.793777).\n",
            "\t Train_Loss: 35.4197 Val_Loss: 123.7938  BEST VAL Loss: 123.7938\n",
            "\n",
            "Epoch 1614: Validation loss decreased (123.793777 --> 123.599876).\n",
            "\t Train_Loss: 36.2050 Val_Loss: 123.5999  BEST VAL Loss: 123.5999\n",
            "\n",
            "Epoch 1615: Validation loss did not decrease\n",
            "\t Train_Loss: 36.2119 Val_Loss: 124.2556  BEST VAL Loss: 123.5999\n",
            "\n",
            "Epoch 1616: Validation loss did not decrease\n",
            "\t Train_Loss: 36.3738 Val_Loss: 124.0421  BEST VAL Loss: 123.5999\n",
            "\n",
            "Epoch 1617: Validation loss did not decrease\n",
            "\t Train_Loss: 36.1226 Val_Loss: 123.9766  BEST VAL Loss: 123.5999\n",
            "\n",
            "Epoch 1618: Validation loss did not decrease\n",
            "\t Train_Loss: 36.2266 Val_Loss: 124.2405  BEST VAL Loss: 123.5999\n",
            "\n",
            "Epoch 1619: Validation loss did not decrease\n",
            "\t Train_Loss: 36.0533 Val_Loss: 124.6115  BEST VAL Loss: 123.5999\n",
            "\n",
            "Epoch 1620: Validation loss did not decrease\n",
            "\t Train_Loss: 36.1160 Val_Loss: 124.1464  BEST VAL Loss: 123.5999\n",
            "\n",
            "Epoch 1621: Validation loss decreased (123.599876 --> 123.386154).\n",
            "\t Train_Loss: 35.9908 Val_Loss: 123.3862  BEST VAL Loss: 123.3862\n",
            "\n",
            "Epoch 1622: Validation loss decreased (123.386154 --> 123.068626).\n",
            "\t Train_Loss: 35.9846 Val_Loss: 123.0686  BEST VAL Loss: 123.0686\n",
            "\n",
            "Epoch 1623: Validation loss did not decrease\n",
            "\t Train_Loss: 35.9045 Val_Loss: 123.2362  BEST VAL Loss: 123.0686\n",
            "\n",
            "Epoch 1624: Validation loss did not decrease\n",
            "\t Train_Loss: 35.8644 Val_Loss: 123.1257  BEST VAL Loss: 123.0686\n",
            "\n",
            "Epoch 1625: Validation loss decreased (123.068626 --> 122.653641).\n",
            "\t Train_Loss: 35.8405 Val_Loss: 122.6536  BEST VAL Loss: 122.6536\n",
            "\n",
            "Epoch 1626: Validation loss decreased (122.653641 --> 122.582382).\n",
            "\t Train_Loss: 35.7528 Val_Loss: 122.5824  BEST VAL Loss: 122.5824\n",
            "\n",
            "Epoch 1627: Validation loss did not decrease\n",
            "\t Train_Loss: 35.7516 Val_Loss: 122.8551  BEST VAL Loss: 122.5824\n",
            "\n",
            "Epoch 1628: Validation loss did not decrease\n",
            "\t Train_Loss: 35.6431 Val_Loss: 123.0874  BEST VAL Loss: 122.5824\n",
            "\n",
            "Epoch 1629: Validation loss did not decrease\n",
            "\t Train_Loss: 35.6555 Val_Loss: 122.7884  BEST VAL Loss: 122.5824\n",
            "\n",
            "Epoch 1630: Validation loss decreased (122.582382 --> 122.397850).\n",
            "\t Train_Loss: 35.5659 Val_Loss: 122.3979  BEST VAL Loss: 122.3979\n",
            "\n",
            "Epoch 1631: Validation loss decreased (122.397850 --> 122.203125).\n",
            "\t Train_Loss: 35.5572 Val_Loss: 122.2031  BEST VAL Loss: 122.2031\n",
            "\n",
            "Epoch 1632: Validation loss decreased (122.203125 --> 122.176559).\n",
            "\t Train_Loss: 35.4691 Val_Loss: 122.1766  BEST VAL Loss: 122.1766\n",
            "\n",
            "Epoch 1633: Validation loss decreased (122.176559 --> 121.948792).\n",
            "\t Train_Loss: 35.4503 Val_Loss: 121.9488  BEST VAL Loss: 121.9488\n",
            "\n",
            "Epoch 1634: Validation loss decreased (121.948792 --> 121.638268).\n",
            "\t Train_Loss: 35.3974 Val_Loss: 121.6383  BEST VAL Loss: 121.6383\n",
            "\n",
            "Epoch 1635: Validation loss decreased (121.638268 --> 121.564346).\n",
            "\t Train_Loss: 35.3467 Val_Loss: 121.5643  BEST VAL Loss: 121.5643\n",
            "\n",
            "Epoch 1636: Validation loss did not decrease\n",
            "\t Train_Loss: 35.3070 Val_Loss: 121.6936  BEST VAL Loss: 121.5643\n",
            "\n",
            "Epoch 1637: Validation loss did not decrease\n",
            "\t Train_Loss: 35.2428 Val_Loss: 121.7402  BEST VAL Loss: 121.5643\n",
            "\n",
            "Epoch 1638: Validation loss decreased (121.564346 --> 121.506432).\n",
            "\t Train_Loss: 35.2183 Val_Loss: 121.5064  BEST VAL Loss: 121.5064\n",
            "\n",
            "Epoch 1639: Validation loss decreased (121.506432 --> 121.258812).\n",
            "\t Train_Loss: 35.1504 Val_Loss: 121.2588  BEST VAL Loss: 121.2588\n",
            "\n",
            "Epoch 1640: Validation loss decreased (121.258812 --> 121.138588).\n",
            "\t Train_Loss: 35.1169 Val_Loss: 121.1386  BEST VAL Loss: 121.1386\n",
            "\n",
            "Epoch 1641: Validation loss decreased (121.138588 --> 121.065247).\n",
            "\t Train_Loss: 35.0576 Val_Loss: 121.0652  BEST VAL Loss: 121.0652\n",
            "\n",
            "Epoch 1642: Validation loss decreased (121.065247 --> 120.841675).\n",
            "\t Train_Loss: 35.0154 Val_Loss: 120.8417  BEST VAL Loss: 120.8417\n",
            "\n",
            "Epoch 1643: Validation loss decreased (120.841675 --> 120.544907).\n",
            "\t Train_Loss: 34.9652 Val_Loss: 120.5449  BEST VAL Loss: 120.5449\n",
            "\n",
            "Epoch 1644: Validation loss decreased (120.544907 --> 120.419617).\n",
            "\t Train_Loss: 34.9128 Val_Loss: 120.4196  BEST VAL Loss: 120.4196\n",
            "\n",
            "Epoch 1645: Validation loss did not decrease\n",
            "\t Train_Loss: 34.8702 Val_Loss: 120.4801  BEST VAL Loss: 120.4196\n",
            "\n",
            "Epoch 1646: Validation loss did not decrease\n",
            "\t Train_Loss: 34.8101 Val_Loss: 120.5189  BEST VAL Loss: 120.4196\n",
            "\n",
            "Epoch 1647: Validation loss decreased (120.419617 --> 120.344162).\n",
            "\t Train_Loss: 34.7687 Val_Loss: 120.3442  BEST VAL Loss: 120.3442\n",
            "\n",
            "Epoch 1648: Validation loss decreased (120.344162 --> 120.063316).\n",
            "\t Train_Loss: 34.7127 Val_Loss: 120.0633  BEST VAL Loss: 120.0633\n",
            "\n",
            "Epoch 1649: Validation loss decreased (120.063316 --> 119.857956).\n",
            "\t Train_Loss: 34.6641 Val_Loss: 119.8580  BEST VAL Loss: 119.8580\n",
            "\n",
            "Epoch 1650: Validation loss decreased (119.857956 --> 119.763855).\n",
            "\t Train_Loss: 34.6111 Val_Loss: 119.7639  BEST VAL Loss: 119.7639\n",
            "\n",
            "Epoch 1651: Validation loss decreased (119.763855 --> 119.658913).\n",
            "\t Train_Loss: 34.5578 Val_Loss: 119.6589  BEST VAL Loss: 119.6589\n",
            "\n",
            "Epoch 1652: Validation loss decreased (119.658913 --> 119.473312).\n",
            "\t Train_Loss: 34.5093 Val_Loss: 119.4733  BEST VAL Loss: 119.4733\n",
            "\n",
            "Epoch 1653: Validation loss decreased (119.473312 --> 119.307373).\n",
            "\t Train_Loss: 34.4520 Val_Loss: 119.3074  BEST VAL Loss: 119.3074\n",
            "\n",
            "Epoch 1654: Validation loss decreased (119.307373 --> 119.233559).\n",
            "\t Train_Loss: 34.4016 Val_Loss: 119.2336  BEST VAL Loss: 119.2336\n",
            "\n",
            "Epoch 1655: Validation loss decreased (119.233559 --> 119.197838).\n",
            "\t Train_Loss: 34.3463 Val_Loss: 119.1978  BEST VAL Loss: 119.1978\n",
            "\n",
            "Epoch 1656: Validation loss decreased (119.197838 --> 119.081200).\n",
            "\t Train_Loss: 34.2932 Val_Loss: 119.0812  BEST VAL Loss: 119.0812\n",
            "\n",
            "Epoch 1657: Validation loss decreased (119.081200 --> 118.863785).\n",
            "\t Train_Loss: 34.2387 Val_Loss: 118.8638  BEST VAL Loss: 118.8638\n",
            "\n",
            "Epoch 1658: Validation loss decreased (118.863785 --> 118.646606).\n",
            "\t Train_Loss: 34.1829 Val_Loss: 118.6466  BEST VAL Loss: 118.6466\n",
            "\n",
            "Epoch 1659: Validation loss decreased (118.646606 --> 118.507950).\n",
            "\t Train_Loss: 34.1288 Val_Loss: 118.5079  BEST VAL Loss: 118.5079\n",
            "\n",
            "Epoch 1660: Validation loss decreased (118.507950 --> 118.421768).\n",
            "\t Train_Loss: 34.0718 Val_Loss: 118.4218  BEST VAL Loss: 118.4218\n",
            "\n",
            "Epoch 1661: Validation loss decreased (118.421768 --> 118.315224).\n",
            "\t Train_Loss: 34.0172 Val_Loss: 118.3152  BEST VAL Loss: 118.3152\n",
            "\n",
            "Epoch 1662: Validation loss decreased (118.315224 --> 118.175514).\n",
            "\t Train_Loss: 33.9598 Val_Loss: 118.1755  BEST VAL Loss: 118.1755\n",
            "\n",
            "Epoch 1663: Validation loss decreased (118.175514 --> 118.041847).\n",
            "\t Train_Loss: 33.9028 Val_Loss: 118.0418  BEST VAL Loss: 118.0418\n",
            "\n",
            "Epoch 1664: Validation loss decreased (118.041847 --> 117.935013).\n",
            "\t Train_Loss: 33.8458 Val_Loss: 117.9350  BEST VAL Loss: 117.9350\n",
            "\n",
            "Epoch 1665: Validation loss decreased (117.935013 --> 117.822830).\n",
            "\t Train_Loss: 33.7876 Val_Loss: 117.8228  BEST VAL Loss: 117.8228\n",
            "\n",
            "Epoch 1666: Validation loss decreased (117.822830 --> 117.669594).\n",
            "\t Train_Loss: 33.7287 Val_Loss: 117.6696  BEST VAL Loss: 117.6696\n",
            "\n",
            "Epoch 1667: Validation loss decreased (117.669594 --> 117.492355).\n",
            "\t Train_Loss: 33.6691 Val_Loss: 117.4924  BEST VAL Loss: 117.4924\n",
            "\n",
            "Epoch 1668: Validation loss decreased (117.492355 --> 117.341354).\n",
            "\t Train_Loss: 33.6085 Val_Loss: 117.3414  BEST VAL Loss: 117.3414\n",
            "\n",
            "Epoch 1669: Validation loss decreased (117.341354 --> 117.241257).\n",
            "\t Train_Loss: 33.5464 Val_Loss: 117.2413  BEST VAL Loss: 117.2413\n",
            "\n",
            "Epoch 1670: Validation loss decreased (117.241257 --> 117.164444).\n",
            "\t Train_Loss: 33.4827 Val_Loss: 117.1644  BEST VAL Loss: 117.1644\n",
            "\n",
            "Epoch 1671: Validation loss decreased (117.164444 --> 117.067543).\n",
            "\t Train_Loss: 33.4162 Val_Loss: 117.0675  BEST VAL Loss: 117.0675\n",
            "\n",
            "Epoch 1672: Validation loss decreased (117.067543 --> 116.936523).\n",
            "\t Train_Loss: 33.3471 Val_Loss: 116.9365  BEST VAL Loss: 116.9365\n",
            "\n",
            "Epoch 1673: Validation loss decreased (116.936523 --> 116.793900).\n",
            "\t Train_Loss: 33.2732 Val_Loss: 116.7939  BEST VAL Loss: 116.7939\n",
            "\n",
            "Epoch 1674: Validation loss decreased (116.793900 --> 116.661583).\n",
            "\t Train_Loss: 33.1947 Val_Loss: 116.6616  BEST VAL Loss: 116.6616\n",
            "\n",
            "Epoch 1675: Validation loss decreased (116.661583 --> 116.540260).\n",
            "\t Train_Loss: 33.1098 Val_Loss: 116.5403  BEST VAL Loss: 116.5403\n",
            "\n",
            "Epoch 1676: Validation loss decreased (116.540260 --> 116.419876).\n",
            "\t Train_Loss: 33.0185 Val_Loss: 116.4199  BEST VAL Loss: 116.4199\n",
            "\n",
            "Epoch 1677: Validation loss decreased (116.419876 --> 116.299477).\n",
            "\t Train_Loss: 32.9210 Val_Loss: 116.2995  BEST VAL Loss: 116.2995\n",
            "\n",
            "Epoch 1678: Validation loss decreased (116.299477 --> 116.186180).\n",
            "\t Train_Loss: 32.8174 Val_Loss: 116.1862  BEST VAL Loss: 116.1862\n",
            "\n",
            "Epoch 1679: Validation loss decreased (116.186180 --> 116.075050).\n",
            "\t Train_Loss: 32.7096 Val_Loss: 116.0751  BEST VAL Loss: 116.0751\n",
            "\n",
            "Epoch 1680: Validation loss decreased (116.075050 --> 115.956100).\n",
            "\t Train_Loss: 32.5995 Val_Loss: 115.9561  BEST VAL Loss: 115.9561\n",
            "\n",
            "Epoch 1681: Validation loss decreased (115.956100 --> 115.836708).\n",
            "\t Train_Loss: 32.4894 Val_Loss: 115.8367  BEST VAL Loss: 115.8367\n",
            "\n",
            "Epoch 1682: Validation loss decreased (115.836708 --> 115.714676).\n",
            "\t Train_Loss: 32.3807 Val_Loss: 115.7147  BEST VAL Loss: 115.7147\n",
            "\n",
            "Epoch 1683: Validation loss did not decrease\n",
            "\t Train_Loss: 32.2564 Val_Loss: 115.9443  BEST VAL Loss: 115.7147\n",
            "\n",
            "Epoch 1684: Validation loss did not decrease\n",
            "\t Train_Loss: 29.9094 Val_Loss: 161.0099  BEST VAL Loss: 115.7147\n",
            "\n",
            "Epoch 1685: Validation loss did not decrease\n",
            "\t Train_Loss: 38.8582 Val_Loss: 122.0045  BEST VAL Loss: 115.7147\n",
            "\n",
            "Epoch 1686: Validation loss did not decrease\n",
            "\t Train_Loss: 29.8065 Val_Loss: 116.3115  BEST VAL Loss: 115.7147\n",
            "\n",
            "Epoch 1687: Validation loss decreased (115.714676 --> 114.844139).\n",
            "\t Train_Loss: 31.4864 Val_Loss: 114.8441  BEST VAL Loss: 114.8441\n",
            "\n",
            "Epoch 1688: Validation loss decreased (114.844139 --> 114.275124).\n",
            "\t Train_Loss: 31.8714 Val_Loss: 114.2751  BEST VAL Loss: 114.2751\n",
            "\n",
            "Epoch 1689: Validation loss decreased (114.275124 --> 114.166916).\n",
            "\t Train_Loss: 32.1461 Val_Loss: 114.1669  BEST VAL Loss: 114.1669\n",
            "\n",
            "Epoch 1690: Validation loss did not decrease\n",
            "\t Train_Loss: 31.8070 Val_Loss: 114.5048  BEST VAL Loss: 114.1669\n",
            "\n",
            "Epoch 1691: Validation loss did not decrease\n",
            "\t Train_Loss: 31.8003 Val_Loss: 114.5352  BEST VAL Loss: 114.1669\n",
            "\n",
            "Epoch 1692: Validation loss did not decrease\n",
            "\t Train_Loss: 31.5932 Val_Loss: 114.3017  BEST VAL Loss: 114.1669\n",
            "\n",
            "Epoch 1693: Validation loss decreased (114.166916 --> 113.735306).\n",
            "\t Train_Loss: 31.5905 Val_Loss: 113.7353  BEST VAL Loss: 113.7353\n",
            "\n",
            "Epoch 1694: Validation loss decreased (113.735306 --> 112.890991).\n",
            "\t Train_Loss: 31.4353 Val_Loss: 112.8910  BEST VAL Loss: 112.8910\n",
            "\n",
            "Epoch 1695: Validation loss decreased (112.890991 --> 112.828026).\n",
            "\t Train_Loss: 31.6877 Val_Loss: 112.8280  BEST VAL Loss: 112.8280\n",
            "\n",
            "Epoch 1696: Validation loss did not decrease\n",
            "\t Train_Loss: 32.4886 Val_Loss: 113.3983  BEST VAL Loss: 112.8280\n",
            "\n",
            "Epoch 1697: Validation loss did not decrease\n",
            "\t Train_Loss: 31.1422 Val_Loss: 113.5923  BEST VAL Loss: 112.8280\n",
            "\n",
            "Epoch 1698: Validation loss did not decrease\n",
            "\t Train_Loss: 31.3606 Val_Loss: 113.0910  BEST VAL Loss: 112.8280\n",
            "\n",
            "Epoch 1699: Validation loss did not decrease\n",
            "\t Train_Loss: 31.5860 Val_Loss: 113.0395  BEST VAL Loss: 112.8280\n",
            "\n",
            "Epoch 1700: Validation loss did not decrease\n",
            "\t Train_Loss: 30.9181 Val_Loss: 113.8372  BEST VAL Loss: 112.8280\n",
            "\n",
            "Epoch 1701: Validation loss decreased (112.828026 --> 111.616249).\n",
            "\t Train_Loss: 33.7287 Val_Loss: 111.6162  BEST VAL Loss: 111.6162\n",
            "\n",
            "Epoch 1702: Validation loss decreased (111.616249 --> 111.263016).\n",
            "\t Train_Loss: 31.1575 Val_Loss: 111.2630  BEST VAL Loss: 111.2630\n",
            "\n",
            "Epoch 1703: Validation loss did not decrease\n",
            "\t Train_Loss: 32.4602 Val_Loss: 111.3346  BEST VAL Loss: 111.2630\n",
            "\n",
            "Epoch 1704: Validation loss did not decrease\n",
            "\t Train_Loss: 31.4461 Val_Loss: 124.7602  BEST VAL Loss: 111.2630\n",
            "\n",
            "Epoch 1705: Validation loss did not decrease\n",
            "\t Train_Loss: 44.0818 Val_Loss: 112.9215  BEST VAL Loss: 111.2630\n",
            "\n",
            "Epoch 1706: Validation loss did not decrease\n",
            "\t Train_Loss: 32.3655 Val_Loss: 112.2343  BEST VAL Loss: 111.2630\n",
            "\n",
            "Epoch 1707: Validation loss decreased (111.263016 --> 111.224525).\n",
            "\t Train_Loss: 43.5216 Val_Loss: 111.2245  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1708: Validation loss did not decrease\n",
            "\t Train_Loss: 45.0887 Val_Loss: 113.0687  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1709: Validation loss did not decrease\n",
            "\t Train_Loss: 45.9689 Val_Loss: 113.2132  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1710: Validation loss did not decrease\n",
            "\t Train_Loss: 45.5540 Val_Loss: 113.6710  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1711: Validation loss did not decrease\n",
            "\t Train_Loss: 45.5992 Val_Loss: 114.5886  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1712: Validation loss did not decrease\n",
            "\t Train_Loss: 45.8704 Val_Loss: 113.7931  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1713: Validation loss did not decrease\n",
            "\t Train_Loss: 45.5543 Val_Loss: 112.4300  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1714: Validation loss did not decrease\n",
            "\t Train_Loss: 45.0446 Val_Loss: 112.0536  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1715: Validation loss did not decrease\n",
            "\t Train_Loss: 45.1380 Val_Loss: 111.8184  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1716: Validation loss did not decrease\n",
            "\t Train_Loss: 45.1891 Val_Loss: 112.4086  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1717: Validation loss did not decrease\n",
            "\t Train_Loss: 44.7154 Val_Loss: 113.3641  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1718: Validation loss did not decrease\n",
            "\t Train_Loss: 44.7976 Val_Loss: 113.8494  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1719: Validation loss did not decrease\n",
            "\t Train_Loss: 44.6318 Val_Loss: 114.0926  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1720: Validation loss did not decrease\n",
            "\t Train_Loss: 44.4214 Val_Loss: 114.4913  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1721: Validation loss did not decrease\n",
            "\t Train_Loss: 44.5514 Val_Loss: 114.3446  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1722: Validation loss did not decrease\n",
            "\t Train_Loss: 44.1816 Val_Loss: 114.4014  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1723: Validation loss did not decrease\n",
            "\t Train_Loss: 44.1026 Val_Loss: 114.4010  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1724: Validation loss did not decrease\n",
            "\t Train_Loss: 44.1557 Val_Loss: 114.5560  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1725: Validation loss did not decrease\n",
            "\t Train_Loss: 43.9097 Val_Loss: 115.0866  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1726: Validation loss did not decrease\n",
            "\t Train_Loss: 43.9215 Val_Loss: 115.7472  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1727: Validation loss did not decrease\n",
            "\t Train_Loss: 43.6679 Val_Loss: 116.5325  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1728: Validation loss did not decrease\n",
            "\t Train_Loss: 43.7088 Val_Loss: 116.9341  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1729: Validation loss did not decrease\n",
            "\t Train_Loss: 43.6391 Val_Loss: 116.9282  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1730: Validation loss did not decrease\n",
            "\t Train_Loss: 43.4558 Val_Loss: 116.9392  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1731: Validation loss did not decrease\n",
            "\t Train_Loss: 43.4405 Val_Loss: 117.0466  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1732: Validation loss did not decrease\n",
            "\t Train_Loss: 43.2924 Val_Loss: 117.3414  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1733: Validation loss did not decrease\n",
            "\t Train_Loss: 43.3237 Val_Loss: 117.7231  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1734: Validation loss did not decrease\n",
            "\t Train_Loss: 43.1458 Val_Loss: 118.2100  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1735: Validation loss did not decrease\n",
            "\t Train_Loss: 43.1231 Val_Loss: 118.7425  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1736: Validation loss did not decrease\n",
            "\t Train_Loss: 43.0136 Val_Loss: 119.1988  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1737: Validation loss did not decrease\n",
            "\t Train_Loss: 43.0025 Val_Loss: 119.2919  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1738: Validation loss did not decrease\n",
            "\t Train_Loss: 42.8737 Val_Loss: 119.2777  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1739: Validation loss did not decrease\n",
            "\t Train_Loss: 42.8314 Val_Loss: 119.4179  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1740: Validation loss did not decrease\n",
            "\t Train_Loss: 42.7509 Val_Loss: 119.7498  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1741: Validation loss did not decrease\n",
            "\t Train_Loss: 42.7085 Val_Loss: 120.1295  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1742: Validation loss did not decrease\n",
            "\t Train_Loss: 42.6090 Val_Loss: 120.4921  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1743: Validation loss did not decrease\n",
            "\t Train_Loss: 42.5613 Val_Loss: 120.8705  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1744: Validation loss did not decrease\n",
            "\t Train_Loss: 42.4943 Val_Loss: 121.1661  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1745: Validation loss did not decrease\n",
            "\t Train_Loss: 42.4381 Val_Loss: 121.2215  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1746: Validation loss did not decrease\n",
            "\t Train_Loss: 42.3598 Val_Loss: 121.2534  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1747: Validation loss did not decrease\n",
            "\t Train_Loss: 42.3161 Val_Loss: 121.4790  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1748: Validation loss did not decrease\n",
            "\t Train_Loss: 42.2531 Val_Loss: 121.8808  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1749: Validation loss did not decrease\n",
            "\t Train_Loss: 42.1967 Val_Loss: 122.2289  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1750: Validation loss did not decrease\n",
            "\t Train_Loss: 42.1360 Val_Loss: 122.4344  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1751: Validation loss did not decrease\n",
            "\t Train_Loss: 42.0916 Val_Loss: 122.6357  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1752: Validation loss did not decrease\n",
            "\t Train_Loss: 42.0331 Val_Loss: 122.8355  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1753: Validation loss did not decrease\n",
            "\t Train_Loss: 41.9817 Val_Loss: 122.9426  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1754: Validation loss did not decrease\n",
            "\t Train_Loss: 41.9309 Val_Loss: 123.0615  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1755: Validation loss did not decrease\n",
            "\t Train_Loss: 41.8874 Val_Loss: 123.3371  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1756: Validation loss did not decrease\n",
            "\t Train_Loss: 41.8316 Val_Loss: 123.7062  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1757: Validation loss did not decrease\n",
            "\t Train_Loss: 41.7891 Val_Loss: 123.9430  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1758: Validation loss did not decrease\n",
            "\t Train_Loss: 41.7413 Val_Loss: 124.0445  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1759: Validation loss did not decrease\n",
            "\t Train_Loss: 41.6993 Val_Loss: 124.1831  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1760: Validation loss did not decrease\n",
            "\t Train_Loss: 41.6488 Val_Loss: 124.3632  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1761: Validation loss did not decrease\n",
            "\t Train_Loss: 41.6120 Val_Loss: 124.5144  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1762: Validation loss did not decrease\n",
            "\t Train_Loss: 41.5650 Val_Loss: 124.7049  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1763: Validation loss did not decrease\n",
            "\t Train_Loss: 41.5257 Val_Loss: 124.9919  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1764: Validation loss did not decrease\n",
            "\t Train_Loss: 41.4809 Val_Loss: 125.2348  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1765: Validation loss did not decrease\n",
            "\t Train_Loss: 41.4451 Val_Loss: 125.3157  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1766: Validation loss did not decrease\n",
            "\t Train_Loss: 41.4002 Val_Loss: 125.3865  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1767: Validation loss did not decrease\n",
            "\t Train_Loss: 41.3635 Val_Loss: 125.5629  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1768: Validation loss did not decrease\n",
            "\t Train_Loss: 41.3227 Val_Loss: 125.7611  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1769: Validation loss did not decrease\n",
            "\t Train_Loss: 41.2860 Val_Loss: 125.9086  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1770: Validation loss did not decrease\n",
            "\t Train_Loss: 41.2453 Val_Loss: 126.0737  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1771: Validation loss did not decrease\n",
            "\t Train_Loss: 41.2101 Val_Loss: 126.2662  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1772: Validation loss did not decrease\n",
            "\t Train_Loss: 41.1717 Val_Loss: 126.3773  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1773: Validation loss did not decrease\n",
            "\t Train_Loss: 41.1355 Val_Loss: 126.4193  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1774: Validation loss did not decrease\n",
            "\t Train_Loss: 41.0989 Val_Loss: 126.5279  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1775: Validation loss did not decrease\n",
            "\t Train_Loss: 41.0639 Val_Loss: 126.7170  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1776: Validation loss did not decrease\n",
            "\t Train_Loss: 41.0279 Val_Loss: 126.8754  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1777: Validation loss did not decrease\n",
            "\t Train_Loss: 40.9932 Val_Loss: 126.9640  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1778: Validation loss did not decrease\n",
            "\t Train_Loss: 40.9590 Val_Loss: 127.0561  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1779: Validation loss did not decrease\n",
            "\t Train_Loss: 40.9245 Val_Loss: 127.1610  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1780: Validation loss did not decrease\n",
            "\t Train_Loss: 40.8909 Val_Loss: 127.2363  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1781: Validation loss did not decrease\n",
            "\t Train_Loss: 40.8575 Val_Loss: 127.3117  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1782: Validation loss did not decrease\n",
            "\t Train_Loss: 40.8248 Val_Loss: 127.4366  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1783: Validation loss did not decrease\n",
            "\t Train_Loss: 40.7916 Val_Loss: 127.5702  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1784: Validation loss did not decrease\n",
            "\t Train_Loss: 40.7599 Val_Loss: 127.6428  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1785: Validation loss did not decrease\n",
            "\t Train_Loss: 40.7275 Val_Loss: 127.6820  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1786: Validation loss did not decrease\n",
            "\t Train_Loss: 40.6961 Val_Loss: 127.7500  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1787: Validation loss did not decrease\n",
            "\t Train_Loss: 40.6645 Val_Loss: 127.8382  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1788: Validation loss did not decrease\n",
            "\t Train_Loss: 40.6338 Val_Loss: 127.9138  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1789: Validation loss did not decrease\n",
            "\t Train_Loss: 40.6025 Val_Loss: 127.9876  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1790: Validation loss did not decrease\n",
            "\t Train_Loss: 40.5723 Val_Loss: 128.0695  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1791: Validation loss did not decrease\n",
            "\t Train_Loss: 40.5418 Val_Loss: 128.1281  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1792: Validation loss did not decrease\n",
            "\t Train_Loss: 40.5120 Val_Loss: 128.1562  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1793: Validation loss did not decrease\n",
            "\t Train_Loss: 40.4820 Val_Loss: 128.1990  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1794: Validation loss did not decrease\n",
            "\t Train_Loss: 40.4527 Val_Loss: 128.2743  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1795: Validation loss did not decrease\n",
            "\t Train_Loss: 40.4232 Val_Loss: 128.3440  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1796: Validation loss did not decrease\n",
            "\t Train_Loss: 40.3943 Val_Loss: 128.3838  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1797: Validation loss did not decrease\n",
            "\t Train_Loss: 40.3654 Val_Loss: 128.4171  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1798: Validation loss did not decrease\n",
            "\t Train_Loss: 40.3369 Val_Loss: 128.4585  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1799: Validation loss did not decrease\n",
            "\t Train_Loss: 40.3084 Val_Loss: 128.4933  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1800: Validation loss did not decrease\n",
            "\t Train_Loss: 40.2804 Val_Loss: 128.5220  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1801: Validation loss did not decrease\n",
            "\t Train_Loss: 40.2523 Val_Loss: 128.5637  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1802: Validation loss did not decrease\n",
            "\t Train_Loss: 40.2246 Val_Loss: 128.6113  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1803: Validation loss did not decrease\n",
            "\t Train_Loss: 40.1971 Val_Loss: 128.6363  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1804: Validation loss did not decrease\n",
            "\t Train_Loss: 40.1697 Val_Loss: 128.6421  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1805: Validation loss did not decrease\n",
            "\t Train_Loss: 40.1425 Val_Loss: 128.6588  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1806: Validation loss did not decrease\n",
            "\t Train_Loss: 40.1155 Val_Loss: 128.6909  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1807: Validation loss did not decrease\n",
            "\t Train_Loss: 40.0886 Val_Loss: 128.7161  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1808: Validation loss did not decrease\n",
            "\t Train_Loss: 40.0619 Val_Loss: 128.7283  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1809: Validation loss did not decrease\n",
            "\t Train_Loss: 40.0354 Val_Loss: 128.7404  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1810: Validation loss did not decrease\n",
            "\t Train_Loss: 40.0090 Val_Loss: 128.7528  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1811: Validation loss did not decrease\n",
            "\t Train_Loss: 39.9828 Val_Loss: 128.7566  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1812: Validation loss did not decrease\n",
            "\t Train_Loss: 39.9567 Val_Loss: 128.7591  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1813: Validation loss did not decrease\n",
            "\t Train_Loss: 39.9308 Val_Loss: 128.7711  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1814: Validation loss did not decrease\n",
            "\t Train_Loss: 39.9050 Val_Loss: 128.7842  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1815: Validation loss did not decrease\n",
            "\t Train_Loss: 39.8794 Val_Loss: 128.7834  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1816: Validation loss did not decrease\n",
            "\t Train_Loss: 39.8538 Val_Loss: 128.7747  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1817: Validation loss did not decrease\n",
            "\t Train_Loss: 39.8284 Val_Loss: 128.7719  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1818: Validation loss did not decrease\n",
            "\t Train_Loss: 39.8032 Val_Loss: 128.7737  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1819: Validation loss did not decrease\n",
            "\t Train_Loss: 39.7780 Val_Loss: 128.7716  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1820: Validation loss did not decrease\n",
            "\t Train_Loss: 39.7530 Val_Loss: 128.7656  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1821: Validation loss did not decrease\n",
            "\t Train_Loss: 39.7281 Val_Loss: 128.7595  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1822: Validation loss did not decrease\n",
            "\t Train_Loss: 39.7032 Val_Loss: 128.7502  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1823: Validation loss did not decrease\n",
            "\t Train_Loss: 39.6784 Val_Loss: 128.7360  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1824: Validation loss did not decrease\n",
            "\t Train_Loss: 39.6536 Val_Loss: 128.7240  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1825: Validation loss did not decrease\n",
            "\t Train_Loss: 39.6272 Val_Loss: 128.7255  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1826: Validation loss did not decrease\n",
            "\t Train_Loss: 39.2888 Val_Loss: 137.6659  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1827: Validation loss did not decrease\n",
            "\t Train_Loss: 36.6384 Val_Loss: 128.7815  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1828: Validation loss did not decrease\n",
            "\t Train_Loss: 38.9587 Val_Loss: 128.5523  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1829: Validation loss did not decrease\n",
            "\t Train_Loss: 39.4191 Val_Loss: 129.1107  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1830: Validation loss did not decrease\n",
            "\t Train_Loss: 39.6359 Val_Loss: 128.7106  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1831: Validation loss did not decrease\n",
            "\t Train_Loss: 39.5782 Val_Loss: 128.1287  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1832: Validation loss did not decrease\n",
            "\t Train_Loss: 39.5236 Val_Loss: 128.1532  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1833: Validation loss did not decrease\n",
            "\t Train_Loss: 39.5647 Val_Loss: 128.3637  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1834: Validation loss did not decrease\n",
            "\t Train_Loss: 39.4381 Val_Loss: 128.6057  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1835: Validation loss did not decrease\n",
            "\t Train_Loss: 39.5119 Val_Loss: 128.1783  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1836: Validation loss did not decrease\n",
            "\t Train_Loss: 39.3836 Val_Loss: 127.9873  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1837: Validation loss did not decrease\n",
            "\t Train_Loss: 39.4412 Val_Loss: 127.9222  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1838: Validation loss did not decrease\n",
            "\t Train_Loss: 39.3497 Val_Loss: 128.1831  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1839: Validation loss did not decrease\n",
            "\t Train_Loss: 39.3594 Val_Loss: 128.1984  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1840: Validation loss did not decrease\n",
            "\t Train_Loss: 39.3243 Val_Loss: 127.9471  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1841: Validation loss did not decrease\n",
            "\t Train_Loss: 39.2786 Val_Loss: 127.8912  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1842: Validation loss did not decrease\n",
            "\t Train_Loss: 39.2846 Val_Loss: 127.9454  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1843: Validation loss did not decrease\n",
            "\t Train_Loss: 39.2173 Val_Loss: 128.0815  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1844: Validation loss did not decrease\n",
            "\t Train_Loss: 39.2351 Val_Loss: 127.8591  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1845: Validation loss did not decrease\n",
            "\t Train_Loss: 39.1668 Val_Loss: 127.7928  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1846: Validation loss did not decrease\n",
            "\t Train_Loss: 39.1814 Val_Loss: 127.8346  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1847: Validation loss did not decrease\n",
            "\t Train_Loss: 39.1237 Val_Loss: 128.0023  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1848: Validation loss did not decrease\n",
            "\t Train_Loss: 39.1253 Val_Loss: 127.8410  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1849: Validation loss did not decrease\n",
            "\t Train_Loss: 39.0832 Val_Loss: 127.6660  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1850: Validation loss did not decrease\n",
            "\t Train_Loss: 39.0700 Val_Loss: 127.6665  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1851: Validation loss did not decrease\n",
            "\t Train_Loss: 39.0413 Val_Loss: 127.7969  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1852: Validation loss did not decrease\n",
            "\t Train_Loss: 39.0166 Val_Loss: 127.7727  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1853: Validation loss did not decrease\n",
            "\t Train_Loss: 38.9984 Val_Loss: 127.6011  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1854: Validation loss did not decrease\n",
            "\t Train_Loss: 38.9655 Val_Loss: 127.5410  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1855: Validation loss did not decrease\n",
            "\t Train_Loss: 38.9532 Val_Loss: 127.5622  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1856: Validation loss did not decrease\n",
            "\t Train_Loss: 38.9179 Val_Loss: 127.5859  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1857: Validation loss did not decrease\n",
            "\t Train_Loss: 38.9068 Val_Loss: 127.4920  BEST VAL Loss: 111.2245\n",
            "\n",
            "Epoch 1858: Validation loss did not decrease\n",
            "Early stopped at epoch : 1858\n"
          ]
        }
      ],
      "source": [
        "SimpleRNN_best_model, train_losses, val_losses = trainer(SimpleRNN_model, X_train, y_train, X_val, y_val, optimizer, criterion, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "8x-goeR4Ef0o",
        "outputId": "a473ae28-ff79-471f-a73f-3160f05b0fcc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_losses, label = 'Train_loss')\n",
        "plt.plot(val_losses, label = 'validation_loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-qi4WfFZQF-"
      },
      "source": [
        "---\n",
        "### 4.4 Evaluate model on validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VCb4QQCPRrzm"
      },
      "outputs": [],
      "source": [
        "val_predict_RNN = SimpleRNN_best_model(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "kjQclrpURuOf",
        "outputId": "d53d774e-183b-4c27-fc4f-7a6ffd222b3a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(df[-len(y_val):].index, y_val.cpu(), label=\"actual\", marker=\"o\")\n",
        "plt.plot(df[-len(y_val):].index, val_predict_RNN.detach().cpu(), label=\"predicted\", marker=\"o\")\n",
        "plt.title(\"Electric production IP prediction by Simple RNN model\", fontsize=25)\n",
        "plt.ylabel(\"ylabel\")\n",
        "plt.legend(title_fontsize=14, fontsize=13, fancybox=True, shadow=True, frameon=True)\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utvDPP4kXEI-"
      },
      "source": [
        "---\n",
        "---\n",
        "## 5 GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkIg9lbrXiKZ"
      },
      "source": [
        "---\n",
        "### 5.1 Define single GRU cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "EDjVZTlBXIFj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GRUCell(nn.Module):\n",
        "    def __init__(self, input_length=10, hidden_size=20, bias=True):\n",
        "        super(GRUCell, self).__init__()\n",
        "\n",
        "        self.input_length = input_length\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Define the layers\n",
        "        self.reset_gate = nn.Linear(input_length + hidden_size, hidden_size, bias=bias)\n",
        "        self.update_gate = nn.Linear(input_length + hidden_size, hidden_size, bias=bias)\n",
        "        self.output_gate = nn.Linear(input_length + hidden_size, hidden_size, bias=bias)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        std = 1.0 / np.sqrt(self.hidden_size)\n",
        "        for w in self.parameters():\n",
        "            w.data.uniform_(-std, std)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        # Concatenate the input and hidden state\n",
        "        combined = torch.cat((x, h), 1)\n",
        "\n",
        "        r = torch.sigmoid(self.reset_gate(combined))\n",
        "\n",
        "        z = torch.sigmoid(self.update_gate(combined))\n",
        "\n",
        "        n_t = torch.tanh(self.output_gate(torch.cat((x, r * h), 1)))\n",
        "\n",
        "        h_new = (1 - z) * n_t + z * h\n",
        "\n",
        "        return h_new\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SlbDcQ-XuYx"
      },
      "source": [
        "---\n",
        "### 5.2 GRU model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "g6frzQdtXyWW"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, bias, output_size):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        # Define the GRU layer\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, bias=bias, batch_first=True)\n",
        "\n",
        "        # Define the fully connected layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hx=None):\n",
        "        # Pass the input through the GRU layer\n",
        "        out, _ = self.gru(input, hx)\n",
        "\n",
        "        # Only take the output from the final timestep\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Pass the output of the last time step through the fully connected layer\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIIm3f8yX9XF"
      },
      "source": [
        "---\n",
        "### 5.3 Train GRU model and plot losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TTE5topYD_j",
        "outputId": "82715ee9-4252-4ff5-fa77-69a1c6646840"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GRU(\n",
              "  (gru): GRU(1, 50, batch_first=True)\n",
              "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "GRU_model = GRU(input_size=1, hidden_size=50, num_layers=1, bias=True, output_size=1)\n",
        "GRU_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "SdCfe-xRYKtx"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.008\n",
        "n_epochs = 2000\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(GRU_model.parameters(), lr = learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1xTqKgoYNNM",
        "outputId": "168545f1-79d8-41f8-f424-855c60c3d37e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 43: Validation loss decreased (7575.485840 --> 7510.373535).\n",
            "\t Train_Loss: 5340.7842 Val_Loss: 7510.3735  BEST VAL Loss: 7510.3735\n",
            "\n",
            "Epoch 44: Validation loss decreased (7510.373535 --> 7445.662598).\n",
            "\t Train_Loss: 5286.4780 Val_Loss: 7445.6626  BEST VAL Loss: 7445.6626\n",
            "\n",
            "Epoch 45: Validation loss decreased (7445.662598 --> 7381.367188).\n",
            "\t Train_Loss: 5232.5527 Val_Loss: 7381.3672  BEST VAL Loss: 7381.3672\n",
            "\n",
            "Epoch 46: Validation loss decreased (7381.367188 --> 7317.502441).\n",
            "\t Train_Loss: 5179.0210 Val_Loss: 7317.5024  BEST VAL Loss: 7317.5024\n",
            "\n",
            "Epoch 47: Validation loss decreased (7317.502441 --> 7254.078125).\n",
            "\t Train_Loss: 5125.8950 Val_Loss: 7254.0781  BEST VAL Loss: 7254.0781\n",
            "\n",
            "Epoch 48: Validation loss decreased (7254.078125 --> 7191.103027).\n",
            "\t Train_Loss: 5073.1826 Val_Loss: 7191.1030  BEST VAL Loss: 7191.1030\n",
            "\n",
            "Epoch 49: Validation loss decreased (7191.103027 --> 7128.583496).\n",
            "\t Train_Loss: 5020.8896 Val_Loss: 7128.5835  BEST VAL Loss: 7128.5835\n",
            "\n",
            "Epoch 50: Validation loss decreased (7128.583496 --> 7066.523438).\n",
            "\t Train_Loss: 4969.0225 Val_Loss: 7066.5234  BEST VAL Loss: 7066.5234\n",
            "\n",
            "Epoch 51: Validation loss decreased (7066.523438 --> 7004.930664).\n",
            "\t Train_Loss: 4917.5850 Val_Loss: 7004.9307  BEST VAL Loss: 7004.9307\n",
            "\n",
            "Epoch 52: Validation loss decreased (7004.930664 --> 6943.803711).\n",
            "\t Train_Loss: 4866.5781 Val_Loss: 6943.8037  BEST VAL Loss: 6943.8037\n",
            "\n",
            "Epoch 53: Validation loss decreased (6943.803711 --> 6883.146973).\n",
            "\t Train_Loss: 4816.0049 Val_Loss: 6883.1470  BEST VAL Loss: 6883.1470\n",
            "\n",
            "Epoch 54: Validation loss decreased (6883.146973 --> 6822.959473).\n",
            "\t Train_Loss: 4765.8628 Val_Loss: 6822.9595  BEST VAL Loss: 6822.9595\n",
            "\n",
            "Epoch 55: Validation loss decreased (6822.959473 --> 6763.242188).\n",
            "\t Train_Loss: 4716.1519 Val_Loss: 6763.2422  BEST VAL Loss: 6763.2422\n",
            "\n",
            "Epoch 56: Validation loss decreased (6763.242188 --> 6703.991211).\n",
            "\t Train_Loss: 4666.8564 Val_Loss: 6703.9912  BEST VAL Loss: 6703.9912\n",
            "\n",
            "Epoch 57: Validation loss decreased (6703.991211 --> 6645.196777).\n",
            "\t Train_Loss: 4617.9302 Val_Loss: 6645.1968  BEST VAL Loss: 6645.1968\n",
            "\n",
            "Epoch 58: Validation loss decreased (6645.196777 --> 6586.823242).\n",
            "\t Train_Loss: 4569.2461 Val_Loss: 6586.8232  BEST VAL Loss: 6586.8232\n",
            "\n",
            "Epoch 59: Validation loss decreased (6586.823242 --> 6528.743164).\n",
            "\t Train_Loss: 4520.5176 Val_Loss: 6528.7432  BEST VAL Loss: 6528.7432\n",
            "\n",
            "Epoch 60: Validation loss decreased (6528.743164 --> 6470.458008).\n",
            "\t Train_Loss: 4471.1318 Val_Loss: 6470.4580  BEST VAL Loss: 6470.4580\n",
            "\n",
            "Epoch 61: Validation loss decreased (6470.458008 --> 6409.942383).\n",
            "\t Train_Loss: 4420.2754 Val_Loss: 6409.9424  BEST VAL Loss: 6409.9424\n",
            "\n",
            "Epoch 62: Validation loss decreased (6409.942383 --> 6341.849609).\n",
            "\t Train_Loss: 4367.7285 Val_Loss: 6341.8496  BEST VAL Loss: 6341.8496\n",
            "\n",
            "Epoch 63: Validation loss decreased (6341.849609 --> 6276.186523).\n",
            "\t Train_Loss: 4315.1587 Val_Loss: 6276.1865  BEST VAL Loss: 6276.1865\n",
            "\n",
            "Epoch 64: Validation loss decreased (6276.186523 --> 6218.933594).\n",
            "\t Train_Loss: 4266.8311 Val_Loss: 6218.9336  BEST VAL Loss: 6218.9336\n",
            "\n",
            "Epoch 65: Validation loss decreased (6218.933594 --> 6162.109863).\n",
            "\t Train_Loss: 4220.0923 Val_Loss: 6162.1099  BEST VAL Loss: 6162.1099\n",
            "\n",
            "Epoch 66: Validation loss decreased (6162.109863 --> 6105.657227).\n",
            "\t Train_Loss: 4173.6958 Val_Loss: 6105.6572  BEST VAL Loss: 6105.6572\n",
            "\n",
            "Epoch 67: Validation loss decreased (6105.657227 --> 6049.619141).\n",
            "\t Train_Loss: 4127.6582 Val_Loss: 6049.6191  BEST VAL Loss: 6049.6191\n",
            "\n",
            "Epoch 68: Validation loss decreased (6049.619141 --> 5993.997559).\n",
            "\t Train_Loss: 4081.9993 Val_Loss: 5993.9976  BEST VAL Loss: 5993.9976\n",
            "\n",
            "Epoch 69: Validation loss decreased (5993.997559 --> 5938.802246).\n",
            "\t Train_Loss: 4036.7268 Val_Loss: 5938.8022  BEST VAL Loss: 5938.8022\n",
            "\n",
            "Epoch 70: Validation loss decreased (5938.802246 --> 5884.041992).\n",
            "\t Train_Loss: 3991.8496 Val_Loss: 5884.0420  BEST VAL Loss: 5884.0420\n",
            "\n",
            "Epoch 71: Validation loss decreased (5884.041992 --> 5829.719727).\n",
            "\t Train_Loss: 3947.3735 Val_Loss: 5829.7197  BEST VAL Loss: 5829.7197\n",
            "\n",
            "Epoch 72: Validation loss decreased (5829.719727 --> 5775.840820).\n",
            "\t Train_Loss: 3903.3030 Val_Loss: 5775.8408  BEST VAL Loss: 5775.8408\n",
            "\n",
            "Epoch 73: Validation loss decreased (5775.840820 --> 5722.409180).\n",
            "\t Train_Loss: 3859.6401 Val_Loss: 5722.4092  BEST VAL Loss: 5722.4092\n",
            "\n",
            "Epoch 74: Validation loss decreased (5722.409180 --> 5669.424805).\n",
            "\t Train_Loss: 3816.3867 Val_Loss: 5669.4248  BEST VAL Loss: 5669.4248\n",
            "\n",
            "Epoch 75: Validation loss decreased (5669.424805 --> 5616.889648).\n",
            "\t Train_Loss: 3773.5442 Val_Loss: 5616.8896  BEST VAL Loss: 5616.8896\n",
            "\n",
            "Epoch 76: Validation loss decreased (5616.889648 --> 5564.803223).\n",
            "\t Train_Loss: 3731.1118 Val_Loss: 5564.8032  BEST VAL Loss: 5564.8032\n",
            "\n",
            "Epoch 77: Validation loss decreased (5564.803223 --> 5513.164062).\n",
            "\t Train_Loss: 3689.0898 Val_Loss: 5513.1641  BEST VAL Loss: 5513.1641\n",
            "\n",
            "Epoch 78: Validation loss decreased (5513.164062 --> 5461.971680).\n",
            "\t Train_Loss: 3647.4763 Val_Loss: 5461.9717  BEST VAL Loss: 5461.9717\n",
            "\n",
            "Epoch 79: Validation loss decreased (5461.971680 --> 5411.223633).\n",
            "\t Train_Loss: 3606.2698 Val_Loss: 5411.2236  BEST VAL Loss: 5411.2236\n",
            "\n",
            "Epoch 80: Validation loss decreased (5411.223633 --> 5360.918945).\n",
            "\t Train_Loss: 3565.4695 Val_Loss: 5360.9189  BEST VAL Loss: 5360.9189\n",
            "\n",
            "Epoch 81: Validation loss decreased (5360.918945 --> 5311.054199).\n",
            "\t Train_Loss: 3525.0706 Val_Loss: 5311.0542  BEST VAL Loss: 5311.0542\n",
            "\n",
            "Epoch 82: Validation loss decreased (5311.054199 --> 5261.627930).\n",
            "\t Train_Loss: 3485.0730 Val_Loss: 5261.6279  BEST VAL Loss: 5261.6279\n",
            "\n",
            "Epoch 83: Validation loss decreased (5261.627930 --> 5212.637695).\n",
            "\t Train_Loss: 3445.4741 Val_Loss: 5212.6377  BEST VAL Loss: 5212.6377\n",
            "\n",
            "Epoch 84: Validation loss decreased (5212.637695 --> 5164.078125).\n",
            "\t Train_Loss: 3406.2695 Val_Loss: 5164.0781  BEST VAL Loss: 5164.0781\n",
            "\n",
            "Epoch 85: Validation loss decreased (5164.078125 --> 5115.948242).\n",
            "\t Train_Loss: 3367.4570 Val_Loss: 5115.9482  BEST VAL Loss: 5115.9482\n",
            "\n",
            "Epoch 86: Validation loss decreased (5115.948242 --> 5068.246094).\n",
            "\t Train_Loss: 3329.0334 Val_Loss: 5068.2461  BEST VAL Loss: 5068.2461\n",
            "\n",
            "Epoch 87: Validation loss decreased (5068.246094 --> 5020.965332).\n",
            "\t Train_Loss: 3290.9937 Val_Loss: 5020.9653  BEST VAL Loss: 5020.9653\n",
            "\n",
            "Epoch 88: Validation loss decreased (5020.965332 --> 4974.101562).\n",
            "\t Train_Loss: 3253.3279 Val_Loss: 4974.1016  BEST VAL Loss: 4974.1016\n",
            "\n",
            "Epoch 89: Validation loss decreased (4974.101562 --> 4927.647461).\n",
            "\t Train_Loss: 3215.9993 Val_Loss: 4927.6475  BEST VAL Loss: 4927.6475\n",
            "\n",
            "Epoch 90: Validation loss decreased (4927.647461 --> 4881.567383).\n",
            "\t Train_Loss: 3178.9131 Val_Loss: 4881.5674  BEST VAL Loss: 4881.5674\n",
            "\n",
            "Epoch 91: Validation loss decreased (4881.567383 --> 4835.724121).\n",
            "\t Train_Loss: 3141.7961 Val_Loss: 4835.7241  BEST VAL Loss: 4835.7241\n",
            "\n",
            "Epoch 92: Validation loss decreased (4835.724121 --> 4789.435059).\n",
            "\t Train_Loss: 3104.0122 Val_Loss: 4789.4351  BEST VAL Loss: 4789.4351\n",
            "\n",
            "Epoch 93: Validation loss decreased (4789.435059 --> 4739.476074).\n",
            "\t Train_Loss: 3064.7683 Val_Loss: 4739.4761  BEST VAL Loss: 4739.4761\n",
            "\n",
            "Epoch 94: Validation loss decreased (4739.476074 --> 4683.372070).\n",
            "\t Train_Loss: 3024.0837 Val_Loss: 4683.3721  BEST VAL Loss: 4683.3721\n",
            "\n",
            "Epoch 95: Validation loss decreased (4683.372070 --> 4636.651367).\n",
            "\t Train_Loss: 2985.1091 Val_Loss: 4636.6514  BEST VAL Loss: 4636.6514\n",
            "\n",
            "Epoch 96: Validation loss decreased (4636.651367 --> 4591.286621).\n",
            "\t Train_Loss: 2949.0754 Val_Loss: 4591.2866  BEST VAL Loss: 4591.2866\n",
            "\n",
            "Epoch 97: Validation loss decreased (4591.286621 --> 4546.226074).\n",
            "\t Train_Loss: 2913.3789 Val_Loss: 4546.2261  BEST VAL Loss: 4546.2261\n",
            "\n",
            "Epoch 98: Validation loss decreased (4546.226074 --> 4501.494629).\n",
            "\t Train_Loss: 2877.9709 Val_Loss: 4501.4946  BEST VAL Loss: 4501.4946\n",
            "\n",
            "Epoch 99: Validation loss decreased (4501.494629 --> 4457.109375).\n",
            "\t Train_Loss: 2842.8691 Val_Loss: 4457.1094  BEST VAL Loss: 4457.1094\n",
            "\n",
            "Epoch 100: Validation loss decreased (4457.109375 --> 4413.084961).\n",
            "\t Train_Loss: 2808.0881 Val_Loss: 4413.0850  BEST VAL Loss: 4413.0850\n",
            "\n",
            "Epoch 101: Validation loss decreased (4413.084961 --> 4369.431641).\n",
            "\t Train_Loss: 2773.6387 Val_Loss: 4369.4316  BEST VAL Loss: 4369.4316\n",
            "\n",
            "Epoch 102: Validation loss decreased (4369.431641 --> 4326.158691).\n",
            "\t Train_Loss: 2739.5273 Val_Loss: 4326.1587  BEST VAL Loss: 4326.1587\n",
            "\n",
            "Epoch 103: Validation loss decreased (4326.158691 --> 4283.270508).\n",
            "\t Train_Loss: 2705.7620 Val_Loss: 4283.2705  BEST VAL Loss: 4283.2705\n",
            "\n",
            "Epoch 104: Validation loss decreased (4283.270508 --> 4240.771973).\n",
            "\t Train_Loss: 2672.3450 Val_Loss: 4240.7720  BEST VAL Loss: 4240.7720\n",
            "\n",
            "Epoch 105: Validation loss decreased (4240.771973 --> 4198.664062).\n",
            "\t Train_Loss: 2639.2791 Val_Loss: 4198.6641  BEST VAL Loss: 4198.6641\n",
            "\n",
            "Epoch 106: Validation loss decreased (4198.664062 --> 4156.950195).\n",
            "\t Train_Loss: 2606.5659 Val_Loss: 4156.9502  BEST VAL Loss: 4156.9502\n",
            "\n",
            "Epoch 107: Validation loss decreased (4156.950195 --> 4115.631348).\n",
            "\t Train_Loss: 2574.2063 Val_Loss: 4115.6313  BEST VAL Loss: 4115.6313\n",
            "\n",
            "Epoch 108: Validation loss decreased (4115.631348 --> 4074.705078).\n",
            "\t Train_Loss: 2542.2000 Val_Loss: 4074.7051  BEST VAL Loss: 4074.7051\n",
            "\n",
            "Epoch 109: Validation loss decreased (4074.705078 --> 4034.172607).\n",
            "\t Train_Loss: 2510.5464 Val_Loss: 4034.1726  BEST VAL Loss: 4034.1726\n",
            "\n",
            "Epoch 110: Validation loss decreased (4034.172607 --> 3994.032715).\n",
            "\t Train_Loss: 2479.2437 Val_Loss: 3994.0327  BEST VAL Loss: 3994.0327\n",
            "\n",
            "Epoch 111: Validation loss decreased (3994.032715 --> 3954.282471).\n",
            "\t Train_Loss: 2448.2917 Val_Loss: 3954.2825  BEST VAL Loss: 3954.2825\n",
            "\n",
            "Epoch 112: Validation loss decreased (3954.282471 --> 3914.921387).\n",
            "\t Train_Loss: 2417.6868 Val_Loss: 3914.9214  BEST VAL Loss: 3914.9214\n",
            "\n",
            "Epoch 113: Validation loss decreased (3914.921387 --> 3875.945801).\n",
            "\t Train_Loss: 2387.4277 Val_Loss: 3875.9458  BEST VAL Loss: 3875.9458\n",
            "\n",
            "Epoch 114: Validation loss decreased (3875.945801 --> 3837.354004).\n",
            "\t Train_Loss: 2357.5122 Val_Loss: 3837.3540  BEST VAL Loss: 3837.3540\n",
            "\n",
            "Epoch 115: Validation loss decreased (3837.354004 --> 3799.143799).\n",
            "\t Train_Loss: 2327.9370 Val_Loss: 3799.1438  BEST VAL Loss: 3799.1438\n",
            "\n",
            "Epoch 116: Validation loss decreased (3799.143799 --> 3761.311768).\n",
            "\t Train_Loss: 2298.7002 Val_Loss: 3761.3118  BEST VAL Loss: 3761.3118\n",
            "\n",
            "Epoch 117: Validation loss decreased (3761.311768 --> 3723.854736).\n",
            "\t Train_Loss: 2269.7988 Val_Loss: 3723.8547  BEST VAL Loss: 3723.8547\n",
            "\n",
            "Epoch 118: Validation loss decreased (3723.854736 --> 3686.769043).\n",
            "\t Train_Loss: 2241.2295 Val_Loss: 3686.7690  BEST VAL Loss: 3686.7690\n",
            "\n",
            "Epoch 119: Validation loss decreased (3686.769043 --> 3650.053955).\n",
            "\t Train_Loss: 2212.9890 Val_Loss: 3650.0540  BEST VAL Loss: 3650.0540\n",
            "\n",
            "Epoch 120: Validation loss decreased (3650.053955 --> 3613.704346).\n",
            "\t Train_Loss: 2185.0750 Val_Loss: 3613.7043  BEST VAL Loss: 3613.7043\n",
            "\n",
            "Epoch 121: Validation loss decreased (3613.704346 --> 3577.717285).\n",
            "\t Train_Loss: 2157.4849 Val_Loss: 3577.7173  BEST VAL Loss: 3577.7173\n",
            "\n",
            "Epoch 122: Validation loss decreased (3577.717285 --> 3542.089355).\n",
            "\t Train_Loss: 2130.2144 Val_Loss: 3542.0894  BEST VAL Loss: 3542.0894\n",
            "\n",
            "Epoch 123: Validation loss decreased (3542.089355 --> 3506.818848).\n",
            "\t Train_Loss: 2103.2607 Val_Loss: 3506.8188  BEST VAL Loss: 3506.8188\n",
            "\n",
            "Epoch 124: Validation loss decreased (3506.818848 --> 3471.899902).\n",
            "\t Train_Loss: 2076.6213 Val_Loss: 3471.8999  BEST VAL Loss: 3471.8999\n",
            "\n",
            "Epoch 125: Validation loss decreased (3471.899902 --> 3437.330811).\n",
            "\t Train_Loss: 2050.2925 Val_Loss: 3437.3308  BEST VAL Loss: 3437.3308\n",
            "\n",
            "Epoch 126: Validation loss decreased (3437.330811 --> 3403.108643).\n",
            "\t Train_Loss: 2024.2709 Val_Loss: 3403.1086  BEST VAL Loss: 3403.1086\n",
            "\n",
            "Epoch 127: Validation loss decreased (3403.108643 --> 3369.229980).\n",
            "\t Train_Loss: 1998.5542 Val_Loss: 3369.2300  BEST VAL Loss: 3369.2300\n",
            "\n",
            "Epoch 128: Validation loss decreased (3369.229980 --> 3335.690918).\n",
            "\t Train_Loss: 1973.1389 Val_Loss: 3335.6909  BEST VAL Loss: 3335.6909\n",
            "\n",
            "Epoch 129: Validation loss decreased (3335.690918 --> 3302.488281).\n",
            "\t Train_Loss: 1948.0223 Val_Loss: 3302.4883  BEST VAL Loss: 3302.4883\n",
            "\n",
            "Epoch 130: Validation loss decreased (3302.488281 --> 3269.619629).\n",
            "\t Train_Loss: 1923.2007 Val_Loss: 3269.6196  BEST VAL Loss: 3269.6196\n",
            "\n",
            "Epoch 131: Validation loss decreased (3269.619629 --> 3237.080566).\n",
            "\t Train_Loss: 1898.6711 Val_Loss: 3237.0806  BEST VAL Loss: 3237.0806\n",
            "\n",
            "Epoch 132: Validation loss decreased (3237.080566 --> 3204.869629).\n",
            "\t Train_Loss: 1874.4312 Val_Loss: 3204.8696  BEST VAL Loss: 3204.8696\n",
            "\n",
            "Epoch 133: Validation loss decreased (3204.869629 --> 3172.981689).\n",
            "\t Train_Loss: 1850.4775 Val_Loss: 3172.9817  BEST VAL Loss: 3172.9817\n",
            "\n",
            "Epoch 134: Validation loss decreased (3172.981689 --> 3141.415527).\n",
            "\t Train_Loss: 1826.8073 Val_Loss: 3141.4155  BEST VAL Loss: 3141.4155\n",
            "\n",
            "Epoch 135: Validation loss decreased (3141.415527 --> 3110.166992).\n",
            "\t Train_Loss: 1803.4172 Val_Loss: 3110.1670  BEST VAL Loss: 3110.1670\n",
            "\n",
            "Epoch 136: Validation loss decreased (3110.166992 --> 3079.233643).\n",
            "\t Train_Loss: 1780.3046 Val_Loss: 3079.2336  BEST VAL Loss: 3079.2336\n",
            "\n",
            "Epoch 137: Validation loss decreased (3079.233643 --> 3048.612061).\n",
            "\t Train_Loss: 1757.4668 Val_Loss: 3048.6121  BEST VAL Loss: 3048.6121\n",
            "\n",
            "Epoch 138: Validation loss decreased (3048.612061 --> 3018.299805).\n",
            "\t Train_Loss: 1734.9009 Val_Loss: 3018.2998  BEST VAL Loss: 3018.2998\n",
            "\n",
            "Epoch 139: Validation loss decreased (3018.299805 --> 2988.293457).\n",
            "\t Train_Loss: 1712.6041 Val_Loss: 2988.2935  BEST VAL Loss: 2988.2935\n",
            "\n",
            "Epoch 140: Validation loss decreased (2988.293457 --> 2958.590332).\n",
            "\t Train_Loss: 1690.5736 Val_Loss: 2958.5903  BEST VAL Loss: 2958.5903\n",
            "\n",
            "Epoch 141: Validation loss decreased (2958.590332 --> 2929.187500).\n",
            "\t Train_Loss: 1668.8065 Val_Loss: 2929.1875  BEST VAL Loss: 2929.1875\n",
            "\n",
            "Epoch 142: Validation loss decreased (2929.187500 --> 2900.081543).\n",
            "\t Train_Loss: 1647.3004 Val_Loss: 2900.0815  BEST VAL Loss: 2900.0815\n",
            "\n",
            "Epoch 143: Validation loss decreased (2900.081543 --> 2871.270996).\n",
            "\t Train_Loss: 1626.0524 Val_Loss: 2871.2710  BEST VAL Loss: 2871.2710\n",
            "\n",
            "Epoch 144: Validation loss decreased (2871.270996 --> 2842.751465).\n",
            "\t Train_Loss: 1605.0598 Val_Loss: 2842.7515  BEST VAL Loss: 2842.7515\n",
            "\n",
            "Epoch 145: Validation loss decreased (2842.751465 --> 2814.521973).\n",
            "\t Train_Loss: 1584.3198 Val_Loss: 2814.5220  BEST VAL Loss: 2814.5220\n",
            "\n",
            "Epoch 146: Validation loss decreased (2814.521973 --> 2786.579346).\n",
            "\t Train_Loss: 1563.8306 Val_Loss: 2786.5793  BEST VAL Loss: 2786.5793\n",
            "\n",
            "Epoch 147: Validation loss decreased (2786.579346 --> 2758.919922).\n",
            "\t Train_Loss: 1543.5892 Val_Loss: 2758.9199  BEST VAL Loss: 2758.9199\n",
            "\n",
            "Epoch 148: Validation loss decreased (2758.919922 --> 2731.541748).\n",
            "\t Train_Loss: 1523.5927 Val_Loss: 2731.5417  BEST VAL Loss: 2731.5417\n",
            "\n",
            "Epoch 149: Validation loss decreased (2731.541748 --> 2704.442139).\n",
            "\t Train_Loss: 1503.8391 Val_Loss: 2704.4421  BEST VAL Loss: 2704.4421\n",
            "\n",
            "Epoch 150: Validation loss decreased (2704.442139 --> 2677.619141).\n",
            "\t Train_Loss: 1484.3257 Val_Loss: 2677.6191  BEST VAL Loss: 2677.6191\n",
            "\n",
            "Epoch 151: Validation loss decreased (2677.619141 --> 2651.068848).\n",
            "\t Train_Loss: 1465.0503 Val_Loss: 2651.0688  BEST VAL Loss: 2651.0688\n",
            "\n",
            "Epoch 152: Validation loss decreased (2651.068848 --> 2624.790283).\n",
            "\t Train_Loss: 1446.0096 Val_Loss: 2624.7903  BEST VAL Loss: 2624.7903\n",
            "\n",
            "Epoch 153: Validation loss decreased (2624.790283 --> 2598.779785).\n",
            "\t Train_Loss: 1427.2024 Val_Loss: 2598.7798  BEST VAL Loss: 2598.7798\n",
            "\n",
            "Epoch 154: Validation loss decreased (2598.779785 --> 2573.034668).\n",
            "\t Train_Loss: 1408.6255 Val_Loss: 2573.0347  BEST VAL Loss: 2573.0347\n",
            "\n",
            "Epoch 155: Validation loss decreased (2573.034668 --> 2547.553711).\n",
            "\t Train_Loss: 1390.2767 Val_Loss: 2547.5537  BEST VAL Loss: 2547.5537\n",
            "\n",
            "Epoch 156: Validation loss decreased (2547.553711 --> 2522.333496).\n",
            "\t Train_Loss: 1372.1542 Val_Loss: 2522.3335  BEST VAL Loss: 2522.3335\n",
            "\n",
            "Epoch 157: Validation loss decreased (2522.333496 --> 2497.372559).\n",
            "\t Train_Loss: 1354.2550 Val_Loss: 2497.3726  BEST VAL Loss: 2497.3726\n",
            "\n",
            "Epoch 158: Validation loss decreased (2497.372559 --> 2472.667480).\n",
            "\t Train_Loss: 1336.5770 Val_Loss: 2472.6675  BEST VAL Loss: 2472.6675\n",
            "\n",
            "Epoch 159: Validation loss decreased (2472.667480 --> 2448.216309).\n",
            "\t Train_Loss: 1319.1180 Val_Loss: 2448.2163  BEST VAL Loss: 2448.2163\n",
            "\n",
            "Epoch 160: Validation loss decreased (2448.216309 --> 2424.017090).\n",
            "\t Train_Loss: 1301.8760 Val_Loss: 2424.0171  BEST VAL Loss: 2424.0171\n",
            "\n",
            "Epoch 161: Validation loss decreased (2424.017090 --> 2400.067383).\n",
            "\t Train_Loss: 1284.8484 Val_Loss: 2400.0674  BEST VAL Loss: 2400.0674\n",
            "\n",
            "Epoch 162: Validation loss decreased (2400.067383 --> 2376.364746).\n",
            "\t Train_Loss: 1268.0332 Val_Loss: 2376.3647  BEST VAL Loss: 2376.3647\n",
            "\n",
            "Epoch 163: Validation loss decreased (2376.364746 --> 2352.906494).\n",
            "\t Train_Loss: 1251.4282 Val_Loss: 2352.9065  BEST VAL Loss: 2352.9065\n",
            "\n",
            "Epoch 164: Validation loss decreased (2352.906494 --> 2329.690918).\n",
            "\t Train_Loss: 1235.0314 Val_Loss: 2329.6909  BEST VAL Loss: 2329.6909\n",
            "\n",
            "Epoch 165: Validation loss decreased (2329.690918 --> 2306.716309).\n",
            "\t Train_Loss: 1218.8405 Val_Loss: 2306.7163  BEST VAL Loss: 2306.7163\n",
            "\n",
            "Epoch 166: Validation loss decreased (2306.716309 --> 2283.979004).\n",
            "\t Train_Loss: 1202.8533 Val_Loss: 2283.9790  BEST VAL Loss: 2283.9790\n",
            "\n",
            "Epoch 167: Validation loss decreased (2283.979004 --> 2261.478516).\n",
            "\t Train_Loss: 1187.0677 Val_Loss: 2261.4785  BEST VAL Loss: 2261.4785\n",
            "\n",
            "Epoch 168: Validation loss decreased (2261.478516 --> 2239.211670).\n",
            "\t Train_Loss: 1171.4821 Val_Loss: 2239.2117  BEST VAL Loss: 2239.2117\n",
            "\n",
            "Epoch 169: Validation loss decreased (2239.211670 --> 2217.176270).\n",
            "\t Train_Loss: 1156.0938 Val_Loss: 2217.1763  BEST VAL Loss: 2217.1763\n",
            "\n",
            "Epoch 170: Validation loss decreased (2217.176270 --> 2195.371094).\n",
            "\t Train_Loss: 1140.9011 Val_Loss: 2195.3711  BEST VAL Loss: 2195.3711\n",
            "\n",
            "Epoch 171: Validation loss decreased (2195.371094 --> 2173.792725).\n",
            "\t Train_Loss: 1125.9016 Val_Loss: 2173.7927  BEST VAL Loss: 2173.7927\n",
            "\n",
            "Epoch 172: Validation loss decreased (2173.792725 --> 2152.439941).\n",
            "\t Train_Loss: 1111.0939 Val_Loss: 2152.4399  BEST VAL Loss: 2152.4399\n",
            "\n",
            "Epoch 173: Validation loss decreased (2152.439941 --> 2131.311279).\n",
            "\t Train_Loss: 1096.4758 Val_Loss: 2131.3113  BEST VAL Loss: 2131.3113\n",
            "\n",
            "Epoch 174: Validation loss decreased (2131.311279 --> 2110.403320).\n",
            "\t Train_Loss: 1082.0452 Val_Loss: 2110.4033  BEST VAL Loss: 2110.4033\n",
            "\n",
            "Epoch 175: Validation loss decreased (2110.403320 --> 2089.714844).\n",
            "\t Train_Loss: 1067.8002 Val_Loss: 2089.7148  BEST VAL Loss: 2089.7148\n",
            "\n",
            "Epoch 176: Validation loss decreased (2089.714844 --> 2069.243652).\n",
            "\t Train_Loss: 1053.7389 Val_Loss: 2069.2437  BEST VAL Loss: 2069.2437\n",
            "\n",
            "Epoch 177: Validation loss decreased (2069.243652 --> 2048.987793).\n",
            "\t Train_Loss: 1039.8594 Val_Loss: 2048.9878  BEST VAL Loss: 2048.9878\n",
            "\n",
            "Epoch 178: Validation loss decreased (2048.987793 --> 2028.945557).\n",
            "\t Train_Loss: 1026.1597 Val_Loss: 2028.9456  BEST VAL Loss: 2028.9456\n",
            "\n",
            "Epoch 179: Validation loss decreased (2028.945557 --> 2009.114258).\n",
            "\t Train_Loss: 1012.6379 Val_Loss: 2009.1143  BEST VAL Loss: 2009.1143\n",
            "\n",
            "Epoch 180: Validation loss decreased (2009.114258 --> 1989.492554).\n",
            "\t Train_Loss: 999.2922 Val_Loss: 1989.4926  BEST VAL Loss: 1989.4926\n",
            "\n",
            "Epoch 181: Validation loss decreased (1989.492554 --> 1970.078735).\n",
            "\t Train_Loss: 986.1208 Val_Loss: 1970.0787  BEST VAL Loss: 1970.0787\n",
            "\n",
            "Epoch 182: Validation loss decreased (1970.078735 --> 1950.870117).\n",
            "\t Train_Loss: 973.1219 Val_Loss: 1950.8701  BEST VAL Loss: 1950.8701\n",
            "\n",
            "Epoch 183: Validation loss decreased (1950.870117 --> 1931.865234).\n",
            "\t Train_Loss: 960.2933 Val_Loss: 1931.8652  BEST VAL Loss: 1931.8652\n",
            "\n",
            "Epoch 184: Validation loss decreased (1931.865234 --> 1913.062256).\n",
            "\t Train_Loss: 947.6338 Val_Loss: 1913.0623  BEST VAL Loss: 1913.0623\n",
            "\n",
            "Epoch 185: Validation loss decreased (1913.062256 --> 1894.458984).\n",
            "\t Train_Loss: 935.1409 Val_Loss: 1894.4590  BEST VAL Loss: 1894.4590\n",
            "\n",
            "Epoch 186: Validation loss decreased (1894.458984 --> 1876.054321).\n",
            "\t Train_Loss: 922.8135 Val_Loss: 1876.0543  BEST VAL Loss: 1876.0543\n",
            "\n",
            "Epoch 187: Validation loss decreased (1876.054321 --> 1857.845947).\n",
            "\t Train_Loss: 910.6494 Val_Loss: 1857.8459  BEST VAL Loss: 1857.8459\n",
            "\n",
            "Epoch 188: Validation loss decreased (1857.845947 --> 1839.832031).\n",
            "\t Train_Loss: 898.6470 Val_Loss: 1839.8320  BEST VAL Loss: 1839.8320\n",
            "\n",
            "Epoch 189: Validation loss decreased (1839.832031 --> 1822.010376).\n",
            "\t Train_Loss: 886.8047 Val_Loss: 1822.0104  BEST VAL Loss: 1822.0104\n",
            "\n",
            "Epoch 190: Validation loss decreased (1822.010376 --> 1804.380249).\n",
            "\t Train_Loss: 875.1202 Val_Loss: 1804.3802  BEST VAL Loss: 1804.3802\n",
            "\n",
            "Epoch 191: Validation loss decreased (1804.380249 --> 1786.938721).\n",
            "\t Train_Loss: 863.5928 Val_Loss: 1786.9387  BEST VAL Loss: 1786.9387\n",
            "\n",
            "Epoch 192: Validation loss decreased (1786.938721 --> 1769.684937).\n",
            "\t Train_Loss: 852.2198 Val_Loss: 1769.6849  BEST VAL Loss: 1769.6849\n",
            "\n",
            "Epoch 193: Validation loss decreased (1769.684937 --> 1752.616577).\n",
            "\t Train_Loss: 841.0002 Val_Loss: 1752.6166  BEST VAL Loss: 1752.6166\n",
            "\n",
            "Epoch 194: Validation loss decreased (1752.616577 --> 1735.732056).\n",
            "\t Train_Loss: 829.9318 Val_Loss: 1735.7321  BEST VAL Loss: 1735.7321\n",
            "\n",
            "Epoch 195: Validation loss decreased (1735.732056 --> 1719.029297).\n",
            "\t Train_Loss: 819.0132 Val_Loss: 1719.0293  BEST VAL Loss: 1719.0293\n",
            "\n",
            "Epoch 196: Validation loss decreased (1719.029297 --> 1702.507446).\n",
            "\t Train_Loss: 808.2427 Val_Loss: 1702.5074  BEST VAL Loss: 1702.5074\n",
            "\n",
            "Epoch 197: Validation loss decreased (1702.507446 --> 1686.164062).\n",
            "\t Train_Loss: 797.6188 Val_Loss: 1686.1641  BEST VAL Loss: 1686.1641\n",
            "\n",
            "Epoch 198: Validation loss decreased (1686.164062 --> 1669.997803).\n",
            "\t Train_Loss: 787.1398 Val_Loss: 1669.9978  BEST VAL Loss: 1669.9978\n",
            "\n",
            "Epoch 199: Validation loss decreased (1669.997803 --> 1654.007080).\n",
            "\t Train_Loss: 776.8041 Val_Loss: 1654.0071  BEST VAL Loss: 1654.0071\n",
            "\n",
            "Epoch 200: Validation loss decreased (1654.007080 --> 1638.189941).\n",
            "\t Train_Loss: 766.6100 Val_Loss: 1638.1899  BEST VAL Loss: 1638.1899\n",
            "\n",
            "Epoch 201: Validation loss decreased (1638.189941 --> 1622.544434).\n",
            "\t Train_Loss: 756.5559 Val_Loss: 1622.5444  BEST VAL Loss: 1622.5444\n",
            "\n",
            "Epoch 202: Validation loss decreased (1622.544434 --> 1607.069336).\n",
            "\t Train_Loss: 746.6399 Val_Loss: 1607.0693  BEST VAL Loss: 1607.0693\n",
            "\n",
            "Epoch 203: Validation loss decreased (1607.069336 --> 1591.763916).\n",
            "\t Train_Loss: 736.8608 Val_Loss: 1591.7639  BEST VAL Loss: 1591.7639\n",
            "\n",
            "Epoch 204: Validation loss decreased (1591.763916 --> 1576.625122).\n",
            "\t Train_Loss: 727.2174 Val_Loss: 1576.6251  BEST VAL Loss: 1576.6251\n",
            "\n",
            "Epoch 205: Validation loss decreased (1576.625122 --> 1561.651367).\n",
            "\t Train_Loss: 717.7073 Val_Loss: 1561.6514  BEST VAL Loss: 1561.6514\n",
            "\n",
            "Epoch 206: Validation loss decreased (1561.651367 --> 1546.841797).\n",
            "\t Train_Loss: 708.3289 Val_Loss: 1546.8418  BEST VAL Loss: 1546.8418\n",
            "\n",
            "Epoch 207: Validation loss decreased (1546.841797 --> 1532.194702).\n",
            "\t Train_Loss: 699.0809 Val_Loss: 1532.1947  BEST VAL Loss: 1532.1947\n",
            "\n",
            "Epoch 208: Validation loss decreased (1532.194702 --> 1517.708374).\n",
            "\t Train_Loss: 689.9618 Val_Loss: 1517.7084  BEST VAL Loss: 1517.7084\n",
            "\n",
            "Epoch 209: Validation loss decreased (1517.708374 --> 1503.380615).\n",
            "\t Train_Loss: 680.9693 Val_Loss: 1503.3806  BEST VAL Loss: 1503.3806\n",
            "\n",
            "Epoch 210: Validation loss decreased (1503.380615 --> 1489.210693).\n",
            "\t Train_Loss: 672.1013 Val_Loss: 1489.2107  BEST VAL Loss: 1489.2107\n",
            "\n",
            "Epoch 211: Validation loss decreased (1489.210693 --> 1475.196045).\n",
            "\t Train_Loss: 663.3566 Val_Loss: 1475.1960  BEST VAL Loss: 1475.1960\n",
            "\n",
            "Epoch 212: Validation loss decreased (1475.196045 --> 1461.335205).\n",
            "\t Train_Loss: 654.7324 Val_Loss: 1461.3352  BEST VAL Loss: 1461.3352\n",
            "\n",
            "Epoch 213: Validation loss decreased (1461.335205 --> 1447.625977).\n",
            "\t Train_Loss: 646.2260 Val_Loss: 1447.6260  BEST VAL Loss: 1447.6260\n",
            "\n",
            "Epoch 214: Validation loss decreased (1447.625977 --> 1434.065796).\n",
            "\t Train_Loss: 637.8346 Val_Loss: 1434.0658  BEST VAL Loss: 1434.0658\n",
            "\n",
            "Epoch 215: Validation loss decreased (1434.065796 --> 1420.652710).\n",
            "\t Train_Loss: 629.5544 Val_Loss: 1420.6527  BEST VAL Loss: 1420.6527\n",
            "\n",
            "Epoch 216: Validation loss decreased (1420.652710 --> 1407.380859).\n",
            "\t Train_Loss: 621.3814 Val_Loss: 1407.3809  BEST VAL Loss: 1407.3809\n",
            "\n",
            "Epoch 217: Validation loss decreased (1407.380859 --> 1394.245728).\n",
            "\t Train_Loss: 613.3087 Val_Loss: 1394.2457  BEST VAL Loss: 1394.2457\n",
            "\n",
            "Epoch 218: Validation loss decreased (1394.245728 --> 1381.234985).\n",
            "\t Train_Loss: 605.3299 Val_Loss: 1381.2350  BEST VAL Loss: 1381.2350\n",
            "\n",
            "Epoch 219: Validation loss decreased (1381.234985 --> 1368.329346).\n",
            "\t Train_Loss: 597.4344 Val_Loss: 1368.3293  BEST VAL Loss: 1368.3293\n",
            "\n",
            "Epoch 220: Validation loss decreased (1368.329346 --> 1355.490234).\n",
            "\t Train_Loss: 589.6097 Val_Loss: 1355.4902  BEST VAL Loss: 1355.4902\n",
            "\n",
            "Epoch 221: Validation loss decreased (1355.490234 --> 1342.645264).\n",
            "\t Train_Loss: 581.8412 Val_Loss: 1342.6453  BEST VAL Loss: 1342.6453\n",
            "\n",
            "Epoch 222: Validation loss decreased (1342.645264 --> 1329.677368).\n",
            "\t Train_Loss: 574.1144 Val_Loss: 1329.6774  BEST VAL Loss: 1329.6774\n",
            "\n",
            "Epoch 223: Validation loss decreased (1329.677368 --> 1316.505127).\n",
            "\t Train_Loss: 566.4282 Val_Loss: 1316.5051  BEST VAL Loss: 1316.5051\n",
            "\n",
            "Epoch 224: Validation loss decreased (1316.505127 --> 1303.342041).\n",
            "\t Train_Loss: 558.8243 Val_Loss: 1303.3420  BEST VAL Loss: 1303.3420\n",
            "\n",
            "Epoch 225: Validation loss decreased (1303.342041 --> 1290.595337).\n",
            "\t Train_Loss: 551.3743 Val_Loss: 1290.5953  BEST VAL Loss: 1290.5953\n",
            "\n",
            "Epoch 226: Validation loss decreased (1290.595337 --> 1278.209229).\n",
            "\t Train_Loss: 544.0790 Val_Loss: 1278.2092  BEST VAL Loss: 1278.2092\n",
            "\n",
            "Epoch 227: Validation loss decreased (1278.209229 --> 1265.970947).\n",
            "\t Train_Loss: 536.8843 Val_Loss: 1265.9709  BEST VAL Loss: 1265.9709\n",
            "\n",
            "Epoch 228: Validation loss decreased (1265.970947 --> 1253.833740).\n",
            "\t Train_Loss: 529.7720 Val_Loss: 1253.8337  BEST VAL Loss: 1253.8337\n",
            "\n",
            "Epoch 229: Validation loss decreased (1253.833740 --> 1241.799561).\n",
            "\t Train_Loss: 522.7434 Val_Loss: 1241.7996  BEST VAL Loss: 1241.7996\n",
            "\n",
            "Epoch 230: Validation loss decreased (1241.799561 --> 1229.872925).\n",
            "\t Train_Loss: 515.8011 Val_Loss: 1229.8729  BEST VAL Loss: 1229.8729\n",
            "\n",
            "Epoch 231: Validation loss decreased (1229.872925 --> 1218.056885).\n",
            "\t Train_Loss: 508.9474 Val_Loss: 1218.0569  BEST VAL Loss: 1218.0569\n",
            "\n",
            "Epoch 232: Validation loss decreased (1218.056885 --> 1206.356079).\n",
            "\t Train_Loss: 502.1839 Val_Loss: 1206.3561  BEST VAL Loss: 1206.3561\n",
            "\n",
            "Epoch 233: Validation loss decreased (1206.356079 --> 1194.772095).\n",
            "\t Train_Loss: 495.5128 Val_Loss: 1194.7721  BEST VAL Loss: 1194.7721\n",
            "\n",
            "Epoch 234: Validation loss decreased (1194.772095 --> 1183.307495).\n",
            "\t Train_Loss: 488.9346 Val_Loss: 1183.3075  BEST VAL Loss: 1183.3075\n",
            "\n",
            "Epoch 235: Validation loss decreased (1183.307495 --> 1171.963501).\n",
            "\t Train_Loss: 482.4505 Val_Loss: 1171.9635  BEST VAL Loss: 1171.9635\n",
            "\n",
            "Epoch 236: Validation loss decreased (1171.963501 --> 1160.742310).\n",
            "\t Train_Loss: 476.0607 Val_Loss: 1160.7423  BEST VAL Loss: 1160.7423\n",
            "\n",
            "Epoch 237: Validation loss decreased (1160.742310 --> 1149.645386).\n",
            "\t Train_Loss: 469.7661 Val_Loss: 1149.6454  BEST VAL Loss: 1149.6454\n",
            "\n",
            "Epoch 238: Validation loss decreased (1149.645386 --> 1138.671265).\n",
            "\t Train_Loss: 463.5667 Val_Loss: 1138.6713  BEST VAL Loss: 1138.6713\n",
            "\n",
            "Epoch 239: Validation loss decreased (1138.671265 --> 1127.822021).\n",
            "\t Train_Loss: 457.4618 Val_Loss: 1127.8220  BEST VAL Loss: 1127.8220\n",
            "\n",
            "Epoch 240: Validation loss decreased (1127.822021 --> 1117.097900).\n",
            "\t Train_Loss: 451.4516 Val_Loss: 1117.0979  BEST VAL Loss: 1117.0979\n",
            "\n",
            "Epoch 241: Validation loss decreased (1117.097900 --> 1106.499023).\n",
            "\t Train_Loss: 445.5361 Val_Loss: 1106.4990  BEST VAL Loss: 1106.4990\n",
            "\n",
            "Epoch 242: Validation loss decreased (1106.499023 --> 1096.024902).\n",
            "\t Train_Loss: 439.7147 Val_Loss: 1096.0249  BEST VAL Loss: 1096.0249\n",
            "\n",
            "Epoch 243: Validation loss decreased (1096.024902 --> 1085.675049).\n",
            "\t Train_Loss: 433.9867 Val_Loss: 1085.6750  BEST VAL Loss: 1085.6750\n",
            "\n",
            "Epoch 244: Validation loss decreased (1085.675049 --> 1075.450073).\n",
            "\t Train_Loss: 428.3513 Val_Loss: 1075.4501  BEST VAL Loss: 1075.4501\n",
            "\n",
            "Epoch 245: Validation loss decreased (1075.450073 --> 1065.347900).\n",
            "\t Train_Loss: 422.8082 Val_Loss: 1065.3479  BEST VAL Loss: 1065.3479\n",
            "\n",
            "Epoch 246: Validation loss decreased (1065.347900 --> 1055.369751).\n",
            "\t Train_Loss: 417.3562 Val_Loss: 1055.3698  BEST VAL Loss: 1055.3698\n",
            "\n",
            "Epoch 247: Validation loss decreased (1055.369751 --> 1045.514404).\n",
            "\t Train_Loss: 411.9949 Val_Loss: 1045.5144  BEST VAL Loss: 1045.5144\n",
            "\n",
            "Epoch 248: Validation loss decreased (1045.514404 --> 1035.779541).\n",
            "\t Train_Loss: 406.7234 Val_Loss: 1035.7795  BEST VAL Loss: 1035.7795\n",
            "\n",
            "Epoch 249: Validation loss decreased (1035.779541 --> 1026.165283).\n",
            "\t Train_Loss: 401.5402 Val_Loss: 1026.1653  BEST VAL Loss: 1026.1653\n",
            "\n",
            "Epoch 250: Validation loss decreased (1026.165283 --> 1016.671692).\n",
            "\t Train_Loss: 396.4445 Val_Loss: 1016.6717  BEST VAL Loss: 1016.6717\n",
            "\n",
            "Epoch 251: Validation loss decreased (1016.671692 --> 1007.295776).\n",
            "\t Train_Loss: 391.4358 Val_Loss: 1007.2958  BEST VAL Loss: 1007.2958\n",
            "\n",
            "Epoch 252: Validation loss decreased (1007.295776 --> 998.038269).\n",
            "\t Train_Loss: 386.5122 Val_Loss: 998.0383  BEST VAL Loss: 998.0383\n",
            "\n",
            "Epoch 253: Validation loss decreased (998.038269 --> 988.897644).\n",
            "\t Train_Loss: 381.6735 Val_Loss: 988.8976  BEST VAL Loss: 988.8976\n",
            "\n",
            "Epoch 254: Validation loss decreased (988.897644 --> 979.872681).\n",
            "\t Train_Loss: 376.9183 Val_Loss: 979.8727  BEST VAL Loss: 979.8727\n",
            "\n",
            "Epoch 255: Validation loss decreased (979.872681 --> 970.962097).\n",
            "\t Train_Loss: 372.2456 Val_Loss: 970.9621  BEST VAL Loss: 970.9621\n",
            "\n",
            "Epoch 256: Validation loss decreased (970.962097 --> 962.164734).\n",
            "\t Train_Loss: 367.6542 Val_Loss: 962.1647  BEST VAL Loss: 962.1647\n",
            "\n",
            "Epoch 257: Validation loss decreased (962.164734 --> 953.480286).\n",
            "\t Train_Loss: 363.1429 Val_Loss: 953.4803  BEST VAL Loss: 953.4803\n",
            "\n",
            "Epoch 258: Validation loss decreased (953.480286 --> 944.905396).\n",
            "\t Train_Loss: 358.7110 Val_Loss: 944.9054  BEST VAL Loss: 944.9054\n",
            "\n",
            "Epoch 259: Validation loss decreased (944.905396 --> 936.441284).\n",
            "\t Train_Loss: 354.3566 Val_Loss: 936.4413  BEST VAL Loss: 936.4413\n",
            "\n",
            "Epoch 260: Validation loss decreased (936.441284 --> 928.085449).\n",
            "\t Train_Loss: 350.0794 Val_Loss: 928.0854  BEST VAL Loss: 928.0854\n",
            "\n",
            "Epoch 261: Validation loss decreased (928.085449 --> 919.837280).\n",
            "\t Train_Loss: 345.8780 Val_Loss: 919.8373  BEST VAL Loss: 919.8373\n",
            "\n",
            "Epoch 262: Validation loss decreased (919.837280 --> 911.695435).\n",
            "\t Train_Loss: 341.7512 Val_Loss: 911.6954  BEST VAL Loss: 911.6954\n",
            "\n",
            "Epoch 263: Validation loss decreased (911.695435 --> 903.657593).\n",
            "\t Train_Loss: 337.6982 Val_Loss: 903.6576  BEST VAL Loss: 903.6576\n",
            "\n",
            "Epoch 264: Validation loss decreased (903.657593 --> 895.724609).\n",
            "\t Train_Loss: 333.7172 Val_Loss: 895.7246  BEST VAL Loss: 895.7246\n",
            "\n",
            "Epoch 265: Validation loss decreased (895.724609 --> 887.893860).\n",
            "\t Train_Loss: 329.8081 Val_Loss: 887.8939  BEST VAL Loss: 887.8939\n",
            "\n",
            "Epoch 266: Validation loss decreased (887.893860 --> 880.164185).\n",
            "\t Train_Loss: 325.9691 Val_Loss: 880.1642  BEST VAL Loss: 880.1642\n",
            "\n",
            "Epoch 267: Validation loss decreased (880.164185 --> 872.534851).\n",
            "\t Train_Loss: 322.1994 Val_Loss: 872.5349  BEST VAL Loss: 872.5349\n",
            "\n",
            "Epoch 268: Validation loss decreased (872.534851 --> 865.004272).\n",
            "\t Train_Loss: 318.4978 Val_Loss: 865.0043  BEST VAL Loss: 865.0043\n",
            "\n",
            "Epoch 269: Validation loss decreased (865.004272 --> 857.571167).\n",
            "\t Train_Loss: 314.8633 Val_Loss: 857.5712  BEST VAL Loss: 857.5712\n",
            "\n",
            "Epoch 270: Validation loss decreased (857.571167 --> 850.235229).\n",
            "\t Train_Loss: 311.2945 Val_Loss: 850.2352  BEST VAL Loss: 850.2352\n",
            "\n",
            "Epoch 271: Validation loss decreased (850.235229 --> 842.994507).\n",
            "\t Train_Loss: 307.7908 Val_Loss: 842.9945  BEST VAL Loss: 842.9945\n",
            "\n",
            "Epoch 272: Validation loss decreased (842.994507 --> 835.848022).\n",
            "\t Train_Loss: 304.3524 Val_Loss: 835.8480  BEST VAL Loss: 835.8480\n",
            "\n",
            "Epoch 273: Validation loss decreased (835.848022 --> 828.795715).\n",
            "\t Train_Loss: 300.9746 Val_Loss: 828.7957  BEST VAL Loss: 828.7957\n",
            "\n",
            "Epoch 274: Validation loss decreased (828.795715 --> 821.832214).\n",
            "\t Train_Loss: 297.6683 Val_Loss: 821.8322  BEST VAL Loss: 821.8322\n",
            "\n",
            "Epoch 275: Validation loss decreased (821.832214 --> 814.961243).\n",
            "\t Train_Loss: 294.4064 Val_Loss: 814.9612  BEST VAL Loss: 814.9612\n",
            "\n",
            "Epoch 276: Validation loss decreased (814.961243 --> 808.179199).\n",
            "\t Train_Loss: 291.2166 Val_Loss: 808.1792  BEST VAL Loss: 808.1792\n",
            "\n",
            "Epoch 277: Validation loss decreased (808.179199 --> 801.486572).\n",
            "\t Train_Loss: 288.0834 Val_Loss: 801.4866  BEST VAL Loss: 801.4866\n",
            "\n",
            "Epoch 278: Validation loss decreased (801.486572 --> 794.880798).\n",
            "\t Train_Loss: 285.0078 Val_Loss: 794.8808  BEST VAL Loss: 794.8808\n",
            "\n",
            "Epoch 279: Validation loss decreased (794.880798 --> 788.361816).\n",
            "\t Train_Loss: 281.9893 Val_Loss: 788.3618  BEST VAL Loss: 788.3618\n",
            "\n",
            "Epoch 280: Validation loss decreased (788.361816 --> 781.927429).\n",
            "\t Train_Loss: 279.0271 Val_Loss: 781.9274  BEST VAL Loss: 781.9274\n",
            "\n",
            "Epoch 281: Validation loss decreased (781.927429 --> 775.578003).\n",
            "\t Train_Loss: 276.1202 Val_Loss: 775.5780  BEST VAL Loss: 775.5780\n",
            "\n",
            "Epoch 282: Validation loss decreased (775.578003 --> 769.311279).\n",
            "\t Train_Loss: 273.2679 Val_Loss: 769.3113  BEST VAL Loss: 769.3113\n",
            "\n",
            "Epoch 283: Validation loss decreased (769.311279 --> 763.126282).\n",
            "\t Train_Loss: 270.4690 Val_Loss: 763.1263  BEST VAL Loss: 763.1263\n",
            "\n",
            "Epoch 284: Validation loss decreased (763.126282 --> 757.022461).\n",
            "\t Train_Loss: 267.7227 Val_Loss: 757.0225  BEST VAL Loss: 757.0225\n",
            "\n",
            "Epoch 285: Validation loss decreased (757.022461 --> 750.998657).\n",
            "\t Train_Loss: 265.0283 Val_Loss: 750.9987  BEST VAL Loss: 750.9987\n",
            "\n",
            "Epoch 286: Validation loss decreased (750.998657 --> 745.053833).\n",
            "\t Train_Loss: 262.3849 Val_Loss: 745.0538  BEST VAL Loss: 745.0538\n",
            "\n",
            "Epoch 287: Validation loss decreased (745.053833 --> 739.186768).\n",
            "\t Train_Loss: 259.7915 Val_Loss: 739.1868  BEST VAL Loss: 739.1868\n",
            "\n",
            "Epoch 288: Validation loss decreased (739.186768 --> 733.396057).\n",
            "\t Train_Loss: 257.2474 Val_Loss: 733.3961  BEST VAL Loss: 733.3961\n",
            "\n",
            "Epoch 289: Validation loss decreased (733.396057 --> 727.682007).\n",
            "\t Train_Loss: 254.7514 Val_Loss: 727.6820  BEST VAL Loss: 727.6820\n",
            "\n",
            "Epoch 290: Validation loss decreased (727.682007 --> 722.042847).\n",
            "\t Train_Loss: 252.3034 Val_Loss: 722.0428  BEST VAL Loss: 722.0428\n",
            "\n",
            "Epoch 291: Validation loss decreased (722.042847 --> 716.478149).\n",
            "\t Train_Loss: 249.9021 Val_Loss: 716.4781  BEST VAL Loss: 716.4781\n",
            "\n",
            "Epoch 292: Validation loss decreased (716.478149 --> 710.985718).\n",
            "\t Train_Loss: 247.5470 Val_Loss: 710.9857  BEST VAL Loss: 710.9857\n",
            "\n",
            "Epoch 293: Validation loss decreased (710.985718 --> 705.565918).\n",
            "\t Train_Loss: 245.2368 Val_Loss: 705.5659  BEST VAL Loss: 705.5659\n",
            "\n",
            "Epoch 294: Validation loss decreased (705.565918 --> 700.217407).\n",
            "\t Train_Loss: 242.9713 Val_Loss: 700.2174  BEST VAL Loss: 700.2174\n",
            "\n",
            "Epoch 295: Validation loss decreased (700.217407 --> 694.938477).\n",
            "\t Train_Loss: 240.7495 Val_Loss: 694.9385  BEST VAL Loss: 694.9385\n",
            "\n",
            "Epoch 296: Validation loss decreased (694.938477 --> 689.728882).\n",
            "\t Train_Loss: 238.5705 Val_Loss: 689.7289  BEST VAL Loss: 689.7289\n",
            "\n",
            "Epoch 297: Validation loss decreased (689.728882 --> 684.588135).\n",
            "\t Train_Loss: 236.4335 Val_Loss: 684.5881  BEST VAL Loss: 684.5881\n",
            "\n",
            "Epoch 298: Validation loss decreased (684.588135 --> 679.515015).\n",
            "\t Train_Loss: 234.3383 Val_Loss: 679.5150  BEST VAL Loss: 679.5150\n",
            "\n",
            "Epoch 299: Validation loss decreased (679.515015 --> 674.508667).\n",
            "\t Train_Loss: 232.2839 Val_Loss: 674.5087  BEST VAL Loss: 674.5087\n",
            "\n",
            "Epoch 300: Validation loss decreased (674.508667 --> 669.567871).\n",
            "\t Train_Loss: 230.2696 Val_Loss: 669.5679  BEST VAL Loss: 669.5679\n",
            "\n",
            "Epoch 301: Validation loss decreased (669.567871 --> 664.692383).\n",
            "\t Train_Loss: 228.2945 Val_Loss: 664.6924  BEST VAL Loss: 664.6924\n",
            "\n",
            "Epoch 302: Validation loss decreased (664.692383 --> 659.880981).\n",
            "\t Train_Loss: 226.3582 Val_Loss: 659.8810  BEST VAL Loss: 659.8810\n",
            "\n",
            "Epoch 303: Validation loss decreased (659.880981 --> 655.133179).\n",
            "\t Train_Loss: 224.4599 Val_Loss: 655.1332  BEST VAL Loss: 655.1332\n",
            "\n",
            "Epoch 304: Validation loss decreased (655.133179 --> 650.447205).\n",
            "\t Train_Loss: 222.5992 Val_Loss: 650.4472  BEST VAL Loss: 650.4472\n",
            "\n",
            "Epoch 305: Validation loss decreased (650.447205 --> 645.823303).\n",
            "\t Train_Loss: 220.7748 Val_Loss: 645.8233  BEST VAL Loss: 645.8233\n",
            "\n",
            "Epoch 306: Validation loss decreased (645.823303 --> 641.260193).\n",
            "\t Train_Loss: 218.9866 Val_Loss: 641.2602  BEST VAL Loss: 641.2602\n",
            "\n",
            "Epoch 307: Validation loss decreased (641.260193 --> 636.757507).\n",
            "\t Train_Loss: 217.2339 Val_Loss: 636.7575  BEST VAL Loss: 636.7575\n",
            "\n",
            "Epoch 308: Validation loss decreased (636.757507 --> 632.313843).\n",
            "\t Train_Loss: 215.5160 Val_Loss: 632.3138  BEST VAL Loss: 632.3138\n",
            "\n",
            "Epoch 309: Validation loss decreased (632.313843 --> 627.928711).\n",
            "\t Train_Loss: 213.8323 Val_Loss: 627.9287  BEST VAL Loss: 627.9287\n",
            "\n",
            "Epoch 310: Validation loss decreased (627.928711 --> 623.601440).\n",
            "\t Train_Loss: 212.1820 Val_Loss: 623.6014  BEST VAL Loss: 623.6014\n",
            "\n",
            "Epoch 311: Validation loss decreased (623.601440 --> 619.331299).\n",
            "\t Train_Loss: 210.5648 Val_Loss: 619.3313  BEST VAL Loss: 619.3313\n",
            "\n",
            "Epoch 312: Validation loss decreased (619.331299 --> 615.117371).\n",
            "\t Train_Loss: 208.9800 Val_Loss: 615.1174  BEST VAL Loss: 615.1174\n",
            "\n",
            "Epoch 313: Validation loss decreased (615.117371 --> 610.959351).\n",
            "\t Train_Loss: 207.4270 Val_Loss: 610.9594  BEST VAL Loss: 610.9594\n",
            "\n",
            "Epoch 314: Validation loss decreased (610.959351 --> 606.856079).\n",
            "\t Train_Loss: 205.9054 Val_Loss: 606.8561  BEST VAL Loss: 606.8561\n",
            "\n",
            "Epoch 315: Validation loss decreased (606.856079 --> 602.806763).\n",
            "\t Train_Loss: 204.4143 Val_Loss: 602.8068  BEST VAL Loss: 602.8068\n",
            "\n",
            "Epoch 316: Validation loss decreased (602.806763 --> 598.810547).\n",
            "\t Train_Loss: 202.9534 Val_Loss: 598.8105  BEST VAL Loss: 598.8105\n",
            "\n",
            "Epoch 317: Validation loss decreased (598.810547 --> 594.867676).\n",
            "\t Train_Loss: 201.5219 Val_Loss: 594.8677  BEST VAL Loss: 594.8677\n",
            "\n",
            "Epoch 318: Validation loss decreased (594.867676 --> 590.976501).\n",
            "\t Train_Loss: 200.1197 Val_Loss: 590.9765  BEST VAL Loss: 590.9765\n",
            "\n",
            "Epoch 319: Validation loss decreased (590.976501 --> 587.136902).\n",
            "\t Train_Loss: 198.7459 Val_Loss: 587.1369  BEST VAL Loss: 587.1369\n",
            "\n",
            "Epoch 320: Validation loss decreased (587.136902 --> 583.347778).\n",
            "\t Train_Loss: 197.4001 Val_Loss: 583.3478  BEST VAL Loss: 583.3478\n",
            "\n",
            "Epoch 321: Validation loss decreased (583.347778 --> 579.609009).\n",
            "\t Train_Loss: 196.0818 Val_Loss: 579.6090  BEST VAL Loss: 579.6090\n",
            "\n",
            "Epoch 322: Validation loss decreased (579.609009 --> 575.919617).\n",
            "\t Train_Loss: 194.7906 Val_Loss: 575.9196  BEST VAL Loss: 575.9196\n",
            "\n",
            "Epoch 323: Validation loss decreased (575.919617 --> 572.278809).\n",
            "\t Train_Loss: 193.5258 Val_Loss: 572.2788  BEST VAL Loss: 572.2788\n",
            "\n",
            "Epoch 324: Validation loss decreased (572.278809 --> 568.686157).\n",
            "\t Train_Loss: 192.2870 Val_Loss: 568.6862  BEST VAL Loss: 568.6862\n",
            "\n",
            "Epoch 325: Validation loss decreased (568.686157 --> 565.141174).\n",
            "\t Train_Loss: 191.0738 Val_Loss: 565.1412  BEST VAL Loss: 565.1412\n",
            "\n",
            "Epoch 326: Validation loss decreased (565.141174 --> 561.642639).\n",
            "\t Train_Loss: 189.8857 Val_Loss: 561.6426  BEST VAL Loss: 561.6426\n",
            "\n",
            "Epoch 327: Validation loss decreased (561.642639 --> 558.191040).\n",
            "\t Train_Loss: 188.7220 Val_Loss: 558.1910  BEST VAL Loss: 558.1910\n",
            "\n",
            "Epoch 328: Validation loss decreased (558.191040 --> 554.784485).\n",
            "\t Train_Loss: 187.5827 Val_Loss: 554.7845  BEST VAL Loss: 554.7845\n",
            "\n",
            "Epoch 329: Validation loss decreased (554.784485 --> 551.423401).\n",
            "\t Train_Loss: 186.4669 Val_Loss: 551.4234  BEST VAL Loss: 551.4234\n",
            "\n",
            "Epoch 330: Validation loss decreased (551.423401 --> 548.106445).\n",
            "\t Train_Loss: 185.3744 Val_Loss: 548.1064  BEST VAL Loss: 548.1064\n",
            "\n",
            "Epoch 331: Validation loss decreased (548.106445 --> 544.833801).\n",
            "\t Train_Loss: 184.3047 Val_Loss: 544.8338  BEST VAL Loss: 544.8338\n",
            "\n",
            "Epoch 332: Validation loss decreased (544.833801 --> 541.603638).\n",
            "\t Train_Loss: 183.2575 Val_Loss: 541.6036  BEST VAL Loss: 541.6036\n",
            "\n",
            "Epoch 333: Validation loss decreased (541.603638 --> 538.416992).\n",
            "\t Train_Loss: 182.2319 Val_Loss: 538.4170  BEST VAL Loss: 538.4170\n",
            "\n",
            "Epoch 334: Validation loss decreased (538.416992 --> 535.272217).\n",
            "\t Train_Loss: 181.2282 Val_Loss: 535.2722  BEST VAL Loss: 535.2722\n",
            "\n",
            "Epoch 335: Validation loss decreased (535.272217 --> 532.169434).\n",
            "\t Train_Loss: 180.2455 Val_Loss: 532.1694  BEST VAL Loss: 532.1694\n",
            "\n",
            "Epoch 336: Validation loss decreased (532.169434 --> 529.107178).\n",
            "\t Train_Loss: 179.2837 Val_Loss: 529.1072  BEST VAL Loss: 529.1072\n",
            "\n",
            "Epoch 337: Validation loss decreased (529.107178 --> 526.086121).\n",
            "\t Train_Loss: 178.3420 Val_Loss: 526.0861  BEST VAL Loss: 526.0861\n",
            "\n",
            "Epoch 338: Validation loss decreased (526.086121 --> 523.104858).\n",
            "\t Train_Loss: 177.4205 Val_Loss: 523.1049  BEST VAL Loss: 523.1049\n",
            "\n",
            "Epoch 339: Validation loss decreased (523.104858 --> 520.162781).\n",
            "\t Train_Loss: 176.5185 Val_Loss: 520.1628  BEST VAL Loss: 520.1628\n",
            "\n",
            "Epoch 340: Validation loss decreased (520.162781 --> 517.260437).\n",
            "\t Train_Loss: 175.6356 Val_Loss: 517.2604  BEST VAL Loss: 517.2604\n",
            "\n",
            "Epoch 341: Validation loss decreased (517.260437 --> 514.395935).\n",
            "\t Train_Loss: 174.7718 Val_Loss: 514.3959  BEST VAL Loss: 514.3959\n",
            "\n",
            "Epoch 342: Validation loss decreased (514.395935 --> 511.569641).\n",
            "\t Train_Loss: 173.9262 Val_Loss: 511.5696  BEST VAL Loss: 511.5696\n",
            "\n",
            "Epoch 343: Validation loss decreased (511.569641 --> 508.780518).\n",
            "\t Train_Loss: 173.0988 Val_Loss: 508.7805  BEST VAL Loss: 508.7805\n",
            "\n",
            "Epoch 344: Validation loss decreased (508.780518 --> 506.028748).\n",
            "\t Train_Loss: 172.2891 Val_Loss: 506.0287  BEST VAL Loss: 506.0287\n",
            "\n",
            "Epoch 345: Validation loss decreased (506.028748 --> 503.313477).\n",
            "\t Train_Loss: 171.4969 Val_Loss: 503.3135  BEST VAL Loss: 503.3135\n",
            "\n",
            "Epoch 346: Validation loss decreased (503.313477 --> 500.633942).\n",
            "\t Train_Loss: 170.7219 Val_Loss: 500.6339  BEST VAL Loss: 500.6339\n",
            "\n",
            "Epoch 347: Validation loss decreased (500.633942 --> 497.990051).\n",
            "\t Train_Loss: 169.9634 Val_Loss: 497.9901  BEST VAL Loss: 497.9901\n",
            "\n",
            "Epoch 348: Validation loss decreased (497.990051 --> 495.381287).\n",
            "\t Train_Loss: 169.2215 Val_Loss: 495.3813  BEST VAL Loss: 495.3813\n",
            "\n",
            "Epoch 349: Validation loss decreased (495.381287 --> 492.807068).\n",
            "\t Train_Loss: 168.4956 Val_Loss: 492.8071  BEST VAL Loss: 492.8071\n",
            "\n",
            "Epoch 350: Validation loss decreased (492.807068 --> 490.267670).\n",
            "\t Train_Loss: 167.7855 Val_Loss: 490.2677  BEST VAL Loss: 490.2677\n",
            "\n",
            "Epoch 351: Validation loss decreased (490.267670 --> 487.761169).\n",
            "\t Train_Loss: 167.0911 Val_Loss: 487.7612  BEST VAL Loss: 487.7612\n",
            "\n",
            "Epoch 352: Validation loss decreased (487.761169 --> 485.288483).\n",
            "\t Train_Loss: 166.4116 Val_Loss: 485.2885  BEST VAL Loss: 485.2885\n",
            "\n",
            "Epoch 353: Validation loss decreased (485.288483 --> 482.848389).\n",
            "\t Train_Loss: 165.7471 Val_Loss: 482.8484  BEST VAL Loss: 482.8484\n",
            "\n",
            "Epoch 354: Validation loss decreased (482.848389 --> 480.440765).\n",
            "\t Train_Loss: 165.0972 Val_Loss: 480.4408  BEST VAL Loss: 480.4408\n",
            "\n",
            "Epoch 355: Validation loss decreased (480.440765 --> 478.065247).\n",
            "\t Train_Loss: 164.4615 Val_Loss: 478.0652  BEST VAL Loss: 478.0652\n",
            "\n",
            "Epoch 356: Validation loss decreased (478.065247 --> 475.720886).\n",
            "\t Train_Loss: 163.8398 Val_Loss: 475.7209  BEST VAL Loss: 475.7209\n",
            "\n",
            "Epoch 357: Validation loss decreased (475.720886 --> 473.408447).\n",
            "\t Train_Loss: 163.2318 Val_Loss: 473.4084  BEST VAL Loss: 473.4084\n",
            "\n",
            "Epoch 358: Validation loss decreased (473.408447 --> 471.126068).\n",
            "\t Train_Loss: 162.6374 Val_Loss: 471.1261  BEST VAL Loss: 471.1261\n",
            "\n",
            "Epoch 359: Validation loss decreased (471.126068 --> 468.874664).\n",
            "\t Train_Loss: 162.0560 Val_Loss: 468.8747  BEST VAL Loss: 468.8747\n",
            "\n",
            "Epoch 360: Validation loss decreased (468.874664 --> 466.652832).\n",
            "\t Train_Loss: 161.4877 Val_Loss: 466.6528  BEST VAL Loss: 466.6528\n",
            "\n",
            "Epoch 361: Validation loss decreased (466.652832 --> 464.460754).\n",
            "\t Train_Loss: 160.9320 Val_Loss: 464.4608  BEST VAL Loss: 464.4608\n",
            "\n",
            "Epoch 362: Validation loss decreased (464.460754 --> 462.297272).\n",
            "\t Train_Loss: 160.3886 Val_Loss: 462.2973  BEST VAL Loss: 462.2973\n",
            "\n",
            "Epoch 363: Validation loss decreased (462.297272 --> 460.163239).\n",
            "\t Train_Loss: 159.8573 Val_Loss: 460.1632  BEST VAL Loss: 460.1632\n",
            "\n",
            "Epoch 364: Validation loss decreased (460.163239 --> 458.057190).\n",
            "\t Train_Loss: 159.3380 Val_Loss: 458.0572  BEST VAL Loss: 458.0572\n",
            "\n",
            "Epoch 365: Validation loss decreased (458.057190 --> 455.979401).\n",
            "\t Train_Loss: 158.8303 Val_Loss: 455.9794  BEST VAL Loss: 455.9794\n",
            "\n",
            "Epoch 366: Validation loss decreased (455.979401 --> 453.929291).\n",
            "\t Train_Loss: 158.3341 Val_Loss: 453.9293  BEST VAL Loss: 453.9293\n",
            "\n",
            "Epoch 367: Validation loss decreased (453.929291 --> 451.906647).\n",
            "\t Train_Loss: 157.8490 Val_Loss: 451.9066  BEST VAL Loss: 451.9066\n",
            "\n",
            "Epoch 368: Validation loss decreased (451.906647 --> 449.910645).\n",
            "\t Train_Loss: 157.3749 Val_Loss: 449.9106  BEST VAL Loss: 449.9106\n",
            "\n",
            "Epoch 369: Validation loss decreased (449.910645 --> 447.941498).\n",
            "\t Train_Loss: 156.9115 Val_Loss: 447.9415  BEST VAL Loss: 447.9415\n",
            "\n",
            "Epoch 370: Validation loss decreased (447.941498 --> 445.998596).\n",
            "\t Train_Loss: 156.4587 Val_Loss: 445.9986  BEST VAL Loss: 445.9986\n",
            "\n",
            "Epoch 371: Validation loss decreased (445.998596 --> 444.081238).\n",
            "\t Train_Loss: 156.0161 Val_Loss: 444.0812  BEST VAL Loss: 444.0812\n",
            "\n",
            "Epoch 372: Validation loss decreased (444.081238 --> 442.189606).\n",
            "\t Train_Loss: 155.5835 Val_Loss: 442.1896  BEST VAL Loss: 442.1896\n",
            "\n",
            "Epoch 373: Validation loss decreased (442.189606 --> 440.323547).\n",
            "\t Train_Loss: 155.1609 Val_Loss: 440.3235  BEST VAL Loss: 440.3235\n",
            "\n",
            "Epoch 374: Validation loss decreased (440.323547 --> 438.482239).\n",
            "\t Train_Loss: 154.7480 Val_Loss: 438.4822  BEST VAL Loss: 438.4822\n",
            "\n",
            "Epoch 375: Validation loss decreased (438.482239 --> 436.665192).\n",
            "\t Train_Loss: 154.3445 Val_Loss: 436.6652  BEST VAL Loss: 436.6652\n",
            "\n",
            "Epoch 376: Validation loss decreased (436.665192 --> 434.872864).\n",
            "\t Train_Loss: 153.9502 Val_Loss: 434.8729  BEST VAL Loss: 434.8729\n",
            "\n",
            "Epoch 377: Validation loss decreased (434.872864 --> 433.104156).\n",
            "\t Train_Loss: 153.5650 Val_Loss: 433.1042  BEST VAL Loss: 433.1042\n",
            "\n",
            "Epoch 378: Validation loss decreased (433.104156 --> 431.359283).\n",
            "\t Train_Loss: 153.1887 Val_Loss: 431.3593  BEST VAL Loss: 431.3593\n",
            "\n",
            "Epoch 379: Validation loss decreased (431.359283 --> 429.637451).\n",
            "\t Train_Loss: 152.8211 Val_Loss: 429.6375  BEST VAL Loss: 429.6375\n",
            "\n",
            "Epoch 380: Validation loss decreased (429.637451 --> 427.939148).\n",
            "\t Train_Loss: 152.4620 Val_Loss: 427.9391  BEST VAL Loss: 427.9391\n",
            "\n",
            "Epoch 381: Validation loss decreased (427.939148 --> 426.262878).\n",
            "\t Train_Loss: 152.1113 Val_Loss: 426.2629  BEST VAL Loss: 426.2629\n",
            "\n",
            "Epoch 382: Validation loss decreased (426.262878 --> 424.609467).\n",
            "\t Train_Loss: 151.7686 Val_Loss: 424.6095  BEST VAL Loss: 424.6095\n",
            "\n",
            "Epoch 383: Validation loss decreased (424.609467 --> 422.978088).\n",
            "\t Train_Loss: 151.4340 Val_Loss: 422.9781  BEST VAL Loss: 422.9781\n",
            "\n",
            "Epoch 384: Validation loss decreased (422.978088 --> 421.368225).\n",
            "\t Train_Loss: 151.1071 Val_Loss: 421.3682  BEST VAL Loss: 421.3682\n",
            "\n",
            "Epoch 385: Validation loss decreased (421.368225 --> 419.780273).\n",
            "\t Train_Loss: 150.7878 Val_Loss: 419.7803  BEST VAL Loss: 419.7803\n",
            "\n",
            "Epoch 386: Validation loss decreased (419.780273 --> 418.213806).\n",
            "\t Train_Loss: 150.4762 Val_Loss: 418.2138  BEST VAL Loss: 418.2138\n",
            "\n",
            "Epoch 387: Validation loss decreased (418.213806 --> 416.667877).\n",
            "\t Train_Loss: 150.1719 Val_Loss: 416.6679  BEST VAL Loss: 416.6679\n",
            "\n",
            "Epoch 388: Validation loss decreased (416.667877 --> 415.142975).\n",
            "\t Train_Loss: 149.8746 Val_Loss: 415.1430  BEST VAL Loss: 415.1430\n",
            "\n",
            "Epoch 389: Validation loss decreased (415.142975 --> 413.638000).\n",
            "\t Train_Loss: 149.5844 Val_Loss: 413.6380  BEST VAL Loss: 413.6380\n",
            "\n",
            "Epoch 390: Validation loss decreased (413.638000 --> 412.153748).\n",
            "\t Train_Loss: 149.3009 Val_Loss: 412.1537  BEST VAL Loss: 412.1537\n",
            "\n",
            "Epoch 391: Validation loss decreased (412.153748 --> 410.689362).\n",
            "\t Train_Loss: 149.0243 Val_Loss: 410.6894  BEST VAL Loss: 410.6894\n",
            "\n",
            "Epoch 392: Validation loss decreased (410.689362 --> 409.244049).\n",
            "\t Train_Loss: 148.7542 Val_Loss: 409.2440  BEST VAL Loss: 409.2440\n",
            "\n",
            "Epoch 393: Validation loss decreased (409.244049 --> 407.818756).\n",
            "\t Train_Loss: 148.4903 Val_Loss: 407.8188  BEST VAL Loss: 407.8188\n",
            "\n",
            "Epoch 394: Validation loss decreased (407.818756 --> 406.412048).\n",
            "\t Train_Loss: 148.2329 Val_Loss: 406.4120  BEST VAL Loss: 406.4120\n",
            "\n",
            "Epoch 395: Validation loss decreased (406.412048 --> 405.024963).\n",
            "\t Train_Loss: 147.9812 Val_Loss: 405.0250  BEST VAL Loss: 405.0250\n",
            "\n",
            "Epoch 396: Validation loss decreased (405.024963 --> 403.665100).\n",
            "\t Train_Loss: 147.7343 Val_Loss: 403.6651  BEST VAL Loss: 403.6651\n",
            "\n",
            "Epoch 397: Validation loss decreased (403.665100 --> 403.119019).\n",
            "\t Train_Loss: 147.4474 Val_Loss: 403.1190  BEST VAL Loss: 403.1190\n",
            "\n",
            "Epoch 398: Validation loss did not decrease\n",
            "\t Train_Loss: 145.7647 Val_Loss: 435.3676  BEST VAL Loss: 403.1190\n",
            "\n",
            "Epoch 399: Validation loss decreased (403.119019 --> 401.417175).\n",
            "\t Train_Loss: 148.8799 Val_Loss: 401.4172  BEST VAL Loss: 401.4172\n",
            "\n",
            "Epoch 400: Validation loss decreased (401.417175 --> 398.387939).\n",
            "\t Train_Loss: 144.3240 Val_Loss: 398.3879  BEST VAL Loss: 398.3879\n",
            "\n",
            "Epoch 401: Validation loss decreased (398.387939 --> 396.889801).\n",
            "\t Train_Loss: 145.9834 Val_Loss: 396.8898  BEST VAL Loss: 396.8898\n",
            "\n",
            "Epoch 402: Validation loss decreased (396.889801 --> 395.542969).\n",
            "\t Train_Loss: 146.1938 Val_Loss: 395.5430  BEST VAL Loss: 395.5430\n",
            "\n",
            "Epoch 403: Validation loss decreased (395.542969 --> 394.238037).\n",
            "\t Train_Loss: 146.0839 Val_Loss: 394.2380  BEST VAL Loss: 394.2380\n",
            "\n",
            "Epoch 404: Validation loss decreased (394.238037 --> 392.959412).\n",
            "\t Train_Loss: 145.9042 Val_Loss: 392.9594  BEST VAL Loss: 392.9594\n",
            "\n",
            "Epoch 405: Validation loss decreased (392.959412 --> 391.703918).\n",
            "\t Train_Loss: 145.7101 Val_Loss: 391.7039  BEST VAL Loss: 391.7039\n",
            "\n",
            "Epoch 406: Validation loss decreased (391.703918 --> 390.469879).\n",
            "\t Train_Loss: 145.5154 Val_Loss: 390.4699  BEST VAL Loss: 390.4699\n",
            "\n",
            "Epoch 407: Validation loss decreased (390.469879 --> 389.256714).\n",
            "\t Train_Loss: 145.3242 Val_Loss: 389.2567  BEST VAL Loss: 389.2567\n",
            "\n",
            "Epoch 408: Validation loss decreased (389.256714 --> 388.063293).\n",
            "\t Train_Loss: 145.1376 Val_Loss: 388.0633  BEST VAL Loss: 388.0633\n",
            "\n",
            "Epoch 409: Validation loss decreased (388.063293 --> 386.889465).\n",
            "\t Train_Loss: 144.9558 Val_Loss: 386.8895  BEST VAL Loss: 386.8895\n",
            "\n",
            "Epoch 410: Validation loss decreased (386.889465 --> 385.734772).\n",
            "\t Train_Loss: 144.7790 Val_Loss: 385.7348  BEST VAL Loss: 385.7348\n",
            "\n",
            "Epoch 411: Validation loss decreased (385.734772 --> 384.598724).\n",
            "\t Train_Loss: 144.6070 Val_Loss: 384.5987  BEST VAL Loss: 384.5987\n",
            "\n",
            "Epoch 412: Validation loss decreased (384.598724 --> 383.479919).\n",
            "\t Train_Loss: 144.4398 Val_Loss: 383.4799  BEST VAL Loss: 383.4799\n",
            "\n",
            "Epoch 413: Validation loss decreased (383.479919 --> 382.379059).\n",
            "\t Train_Loss: 144.2769 Val_Loss: 382.3791  BEST VAL Loss: 382.3791\n",
            "\n",
            "Epoch 414: Validation loss decreased (382.379059 --> 381.294861).\n",
            "\t Train_Loss: 144.1185 Val_Loss: 381.2949  BEST VAL Loss: 381.2949\n",
            "\n",
            "Epoch 415: Validation loss decreased (381.294861 --> 380.227539).\n",
            "\t Train_Loss: 143.9643 Val_Loss: 380.2275  BEST VAL Loss: 380.2275\n",
            "\n",
            "Epoch 416: Validation loss decreased (380.227539 --> 379.176208).\n",
            "\t Train_Loss: 143.8143 Val_Loss: 379.1762  BEST VAL Loss: 379.1762\n",
            "\n",
            "Epoch 417: Validation loss decreased (379.176208 --> 378.140869).\n",
            "\t Train_Loss: 143.6683 Val_Loss: 378.1409  BEST VAL Loss: 378.1409\n",
            "\n",
            "Epoch 418: Validation loss decreased (378.140869 --> 377.121155).\n",
            "\t Train_Loss: 143.5262 Val_Loss: 377.1212  BEST VAL Loss: 377.1212\n",
            "\n",
            "Epoch 419: Validation loss decreased (377.121155 --> 376.116547).\n",
            "\t Train_Loss: 143.3878 Val_Loss: 376.1165  BEST VAL Loss: 376.1165\n",
            "\n",
            "Epoch 420: Validation loss decreased (376.116547 --> 375.126648).\n",
            "\t Train_Loss: 143.2532 Val_Loss: 375.1266  BEST VAL Loss: 375.1266\n",
            "\n",
            "Epoch 421: Validation loss decreased (375.126648 --> 374.151276).\n",
            "\t Train_Loss: 143.1220 Val_Loss: 374.1513  BEST VAL Loss: 374.1513\n",
            "\n",
            "Epoch 422: Validation loss decreased (374.151276 --> 373.190247).\n",
            "\t Train_Loss: 142.9943 Val_Loss: 373.1902  BEST VAL Loss: 373.1902\n",
            "\n",
            "Epoch 423: Validation loss decreased (373.190247 --> 372.243164).\n",
            "\t Train_Loss: 142.8700 Val_Loss: 372.2432  BEST VAL Loss: 372.2432\n",
            "\n",
            "Epoch 424: Validation loss decreased (372.243164 --> 371.309753).\n",
            "\t Train_Loss: 142.7488 Val_Loss: 371.3098  BEST VAL Loss: 371.3098\n",
            "\n",
            "Epoch 425: Validation loss decreased (371.309753 --> 370.389954).\n",
            "\t Train_Loss: 142.6307 Val_Loss: 370.3900  BEST VAL Loss: 370.3900\n",
            "\n",
            "Epoch 426: Validation loss decreased (370.389954 --> 369.484314).\n",
            "\t Train_Loss: 142.5145 Val_Loss: 369.4843  BEST VAL Loss: 369.4843\n",
            "\n",
            "Epoch 427: Validation loss decreased (369.484314 --> 368.723816).\n",
            "\t Train_Loss: 142.3765 Val_Loss: 368.7238  BEST VAL Loss: 368.7238\n",
            "\n",
            "Epoch 428: Validation loss did not decrease\n",
            "\t Train_Loss: 141.0196 Val_Loss: 378.3012  BEST VAL Loss: 368.7238\n",
            "\n",
            "Epoch 429: Validation loss did not decrease\n",
            "\t Train_Loss: 133.1549 Val_Loss: 368.9205  BEST VAL Loss: 368.7238\n",
            "\n",
            "Epoch 430: Validation loss did not decrease\n",
            "\t Train_Loss: 134.4668 Val_Loss: 387.9561  BEST VAL Loss: 368.7238\n",
            "\n",
            "Epoch 431: Validation loss decreased (368.723816 --> 366.940186).\n",
            "\t Train_Loss: 135.8765 Val_Loss: 366.9402  BEST VAL Loss: 366.9402\n",
            "\n",
            "Epoch 432: Validation loss decreased (366.940186 --> 365.117676).\n",
            "\t Train_Loss: 133.5393 Val_Loss: 365.1177  BEST VAL Loss: 365.1177\n",
            "\n",
            "Epoch 433: Validation loss did not decrease\n",
            "\t Train_Loss: 134.6273 Val_Loss: 366.9168  BEST VAL Loss: 365.1177\n",
            "\n",
            "Epoch 434: Validation loss did not decrease\n",
            "\t Train_Loss: 130.9739 Val_Loss: 382.1443  BEST VAL Loss: 365.1177\n",
            "\n",
            "Epoch 435: Validation loss did not decrease\n",
            "\t Train_Loss: 134.1044 Val_Loss: 369.0677  BEST VAL Loss: 365.1177\n",
            "\n",
            "Epoch 436: Validation loss decreased (365.117676 --> 361.763397).\n",
            "\t Train_Loss: 129.9739 Val_Loss: 361.7634  BEST VAL Loss: 361.7634\n",
            "\n",
            "Epoch 437: Validation loss decreased (361.763397 --> 360.408112).\n",
            "\t Train_Loss: 131.1591 Val_Loss: 360.4081  BEST VAL Loss: 360.4081\n",
            "\n",
            "Epoch 438: Validation loss did not decrease\n",
            "\t Train_Loss: 131.1638 Val_Loss: 361.9855  BEST VAL Loss: 360.4081\n",
            "\n",
            "Epoch 439: Validation loss did not decrease\n",
            "\t Train_Loss: 128.5969 Val_Loss: 369.1887  BEST VAL Loss: 360.4081\n",
            "\n",
            "Epoch 440: Validation loss did not decrease\n",
            "\t Train_Loss: 129.9054 Val_Loss: 364.8906  BEST VAL Loss: 360.4081\n",
            "\n",
            "Epoch 441: Validation loss decreased (360.408112 --> 357.603577).\n",
            "\t Train_Loss: 128.5390 Val_Loss: 357.6036  BEST VAL Loss: 357.6036\n",
            "\n",
            "Epoch 442: Validation loss decreased (357.603577 --> 355.270355).\n",
            "\t Train_Loss: 127.6767 Val_Loss: 355.2704  BEST VAL Loss: 355.2704\n",
            "\n",
            "Epoch 443: Validation loss decreased (355.270355 --> 354.988464).\n",
            "\t Train_Loss: 128.3839 Val_Loss: 354.9885  BEST VAL Loss: 354.9885\n",
            "\n",
            "Epoch 444: Validation loss did not decrease\n",
            "\t Train_Loss: 127.0929 Val_Loss: 357.3853  BEST VAL Loss: 354.9885\n",
            "\n",
            "Epoch 445: Validation loss did not decrease\n",
            "\t Train_Loss: 126.4714 Val_Loss: 358.8229  BEST VAL Loss: 354.9885\n",
            "\n",
            "Epoch 446: Validation loss decreased (354.988464 --> 354.200684).\n",
            "\t Train_Loss: 126.9733 Val_Loss: 354.2007  BEST VAL Loss: 354.2007\n",
            "\n",
            "Epoch 447: Validation loss decreased (354.200684 --> 350.520935).\n",
            "\t Train_Loss: 125.6723 Val_Loss: 350.5209  BEST VAL Loss: 350.5209\n",
            "\n",
            "Epoch 448: Validation loss decreased (350.520935 --> 349.004456).\n",
            "\t Train_Loss: 125.6406 Val_Loss: 349.0045  BEST VAL Loss: 349.0045\n",
            "\n",
            "Epoch 449: Validation loss decreased (349.004456 --> 348.808899).\n",
            "\t Train_Loss: 125.6693 Val_Loss: 348.8089  BEST VAL Loss: 348.8089\n",
            "\n",
            "Epoch 450: Validation loss did not decrease\n",
            "\t Train_Loss: 124.7565 Val_Loss: 349.9109  BEST VAL Loss: 348.8089\n",
            "\n",
            "Epoch 451: Validation loss did not decrease\n",
            "\t Train_Loss: 124.6103 Val_Loss: 349.5569  BEST VAL Loss: 348.8089\n",
            "\n",
            "Epoch 452: Validation loss decreased (348.808899 --> 346.505371).\n",
            "\t Train_Loss: 124.6073 Val_Loss: 346.5054  BEST VAL Loss: 346.5054\n",
            "\n",
            "Epoch 453: Validation loss decreased (346.505371 --> 344.047058).\n",
            "\t Train_Loss: 123.8475 Val_Loss: 344.0471  BEST VAL Loss: 344.0471\n",
            "\n",
            "Epoch 454: Validation loss decreased (344.047058 --> 342.761169).\n",
            "\t Train_Loss: 123.7846 Val_Loss: 342.7612  BEST VAL Loss: 342.7612\n",
            "\n",
            "Epoch 455: Validation loss decreased (342.761169 --> 342.322205).\n",
            "\t Train_Loss: 123.6784 Val_Loss: 342.3222  BEST VAL Loss: 342.3222\n",
            "\n",
            "Epoch 456: Validation loss did not decrease\n",
            "\t Train_Loss: 123.1128 Val_Loss: 342.5002  BEST VAL Loss: 342.3222\n",
            "\n",
            "Epoch 457: Validation loss decreased (342.322205 --> 341.858429).\n",
            "\t Train_Loss: 122.9617 Val_Loss: 341.8584  BEST VAL Loss: 341.8584\n",
            "\n",
            "Epoch 458: Validation loss decreased (341.858429 --> 339.815765).\n",
            "\t Train_Loss: 122.8782 Val_Loss: 339.8158  BEST VAL Loss: 339.8158\n",
            "\n",
            "Epoch 459: Validation loss decreased (339.815765 --> 337.932251).\n",
            "\t Train_Loss: 122.4082 Val_Loss: 337.9323  BEST VAL Loss: 337.9323\n",
            "\n",
            "Epoch 460: Validation loss decreased (337.932251 --> 336.728210).\n",
            "\t Train_Loss: 122.2671 Val_Loss: 336.7282  BEST VAL Loss: 336.7282\n",
            "\n",
            "Epoch 461: Validation loss decreased (336.728210 --> 336.075592).\n",
            "\t Train_Loss: 122.1603 Val_Loss: 336.0756  BEST VAL Loss: 336.0756\n",
            "\n",
            "Epoch 462: Validation loss decreased (336.075592 --> 335.781555).\n",
            "\t Train_Loss: 121.7970 Val_Loss: 335.7816  BEST VAL Loss: 335.7816\n",
            "\n",
            "Epoch 463: Validation loss decreased (335.781555 --> 335.131500).\n",
            "\t Train_Loss: 121.6103 Val_Loss: 335.1315  BEST VAL Loss: 335.1315\n",
            "\n",
            "Epoch 464: Validation loss decreased (335.131500 --> 333.688690).\n",
            "\t Train_Loss: 121.5204 Val_Loss: 333.6887  BEST VAL Loss: 333.6887\n",
            "\n",
            "Epoch 465: Validation loss decreased (333.688690 --> 332.166473).\n",
            "\t Train_Loss: 121.2159 Val_Loss: 332.1665  BEST VAL Loss: 332.1665\n",
            "\n",
            "Epoch 466: Validation loss decreased (332.166473 --> 331.023987).\n",
            "\t Train_Loss: 121.0361 Val_Loss: 331.0240  BEST VAL Loss: 331.0240\n",
            "\n",
            "Epoch 467: Validation loss decreased (331.023987 --> 330.252197).\n",
            "\t Train_Loss: 120.9350 Val_Loss: 330.2522  BEST VAL Loss: 330.2522\n",
            "\n",
            "Epoch 468: Validation loss decreased (330.252197 --> 329.727509).\n",
            "\t Train_Loss: 120.6936 Val_Loss: 329.7275  BEST VAL Loss: 329.7275\n",
            "\n",
            "Epoch 469: Validation loss decreased (329.727509 --> 329.084290).\n",
            "\t Train_Loss: 120.5010 Val_Loss: 329.0843  BEST VAL Loss: 329.0843\n",
            "\n",
            "Epoch 470: Validation loss decreased (329.084290 --> 327.996704).\n",
            "\t Train_Loss: 120.4026 Val_Loss: 327.9967  BEST VAL Loss: 327.9967\n",
            "\n",
            "Epoch 471: Validation loss decreased (327.996704 --> 326.744720).\n",
            "\t Train_Loss: 120.1990 Val_Loss: 326.7447  BEST VAL Loss: 326.7447\n",
            "\n",
            "Epoch 472: Validation loss decreased (326.744720 --> 325.679443).\n",
            "\t Train_Loss: 120.0180 Val_Loss: 325.6794  BEST VAL Loss: 325.6794\n",
            "\n",
            "Epoch 473: Validation loss decreased (325.679443 --> 324.865417).\n",
            "\t Train_Loss: 119.9123 Val_Loss: 324.8654  BEST VAL Loss: 324.8654\n",
            "\n",
            "Epoch 474: Validation loss decreased (324.865417 --> 324.233551).\n",
            "\t Train_Loss: 119.7427 Val_Loss: 324.2336  BEST VAL Loss: 324.2336\n",
            "\n",
            "Epoch 475: Validation loss decreased (324.233551 --> 323.585052).\n",
            "\t Train_Loss: 119.5683 Val_Loss: 323.5851  BEST VAL Loss: 323.5851\n",
            "\n",
            "Epoch 476: Validation loss decreased (323.585052 --> 322.698151).\n",
            "\t Train_Loss: 119.4601 Val_Loss: 322.6982  BEST VAL Loss: 322.6982\n",
            "\n",
            "Epoch 477: Validation loss decreased (322.698151 --> 321.653625).\n",
            "\t Train_Loss: 119.3124 Val_Loss: 321.6536  BEST VAL Loss: 321.6536\n",
            "\n",
            "Epoch 478: Validation loss decreased (321.653625 --> 320.683167).\n",
            "\t Train_Loss: 119.1512 Val_Loss: 320.6832  BEST VAL Loss: 320.6832\n",
            "\n",
            "Epoch 479: Validation loss decreased (320.683167 --> 319.876984).\n",
            "\t Train_Loss: 119.0405 Val_Loss: 319.8770  BEST VAL Loss: 319.8770\n",
            "\n",
            "Epoch 480: Validation loss decreased (319.876984 --> 319.205994).\n",
            "\t Train_Loss: 118.9083 Val_Loss: 319.2060  BEST VAL Loss: 319.2060\n",
            "\n",
            "Epoch 481: Validation loss decreased (319.205994 --> 318.554230).\n",
            "\t Train_Loss: 118.7588 Val_Loss: 318.5542  BEST VAL Loss: 318.5542\n",
            "\n",
            "Epoch 482: Validation loss decreased (318.554230 --> 317.778076).\n",
            "\t Train_Loss: 118.6464 Val_Loss: 317.7781  BEST VAL Loss: 317.7781\n",
            "\n",
            "Epoch 483: Validation loss decreased (317.778076 --> 316.885681).\n",
            "\t Train_Loss: 118.5241 Val_Loss: 316.8857  BEST VAL Loss: 316.8857\n",
            "\n",
            "Epoch 484: Validation loss decreased (316.885681 --> 316.012360).\n",
            "\t Train_Loss: 118.3832 Val_Loss: 316.0124  BEST VAL Loss: 316.0124\n",
            "\n",
            "Epoch 485: Validation loss decreased (316.012360 --> 315.240570).\n",
            "\t Train_Loss: 118.2671 Val_Loss: 315.2406  BEST VAL Loss: 315.2406\n",
            "\n",
            "Epoch 486: Validation loss decreased (315.240570 --> 314.563690).\n",
            "\t Train_Loss: 118.1451 Val_Loss: 314.5637  BEST VAL Loss: 314.5637\n",
            "\n",
            "Epoch 487: Validation loss decreased (314.563690 --> 313.912018).\n",
            "\t Train_Loss: 118.0034 Val_Loss: 313.9120  BEST VAL Loss: 313.9120\n",
            "\n",
            "Epoch 488: Validation loss decreased (313.912018 --> 313.196228).\n",
            "\t Train_Loss: 117.8705 Val_Loss: 313.1962  BEST VAL Loss: 313.1962\n",
            "\n",
            "Epoch 489: Validation loss decreased (313.196228 --> 312.401367).\n",
            "\t Train_Loss: 117.7210 Val_Loss: 312.4014  BEST VAL Loss: 312.4014\n",
            "\n",
            "Epoch 490: Validation loss decreased (312.401367 --> 311.593597).\n",
            "\t Train_Loss: 117.5210 Val_Loss: 311.5936  BEST VAL Loss: 311.5936\n",
            "\n",
            "Epoch 491: Validation loss decreased (311.593597 --> 310.819946).\n",
            "\t Train_Loss: 117.2550 Val_Loss: 310.8199  BEST VAL Loss: 310.8199\n",
            "\n",
            "Epoch 492: Validation loss decreased (310.819946 --> 310.069519).\n",
            "\t Train_Loss: 116.8554 Val_Loss: 310.0695  BEST VAL Loss: 310.0695\n",
            "\n",
            "Epoch 493: Validation loss decreased (310.069519 --> 309.274017).\n",
            "\t Train_Loss: 116.3971 Val_Loss: 309.2740  BEST VAL Loss: 309.2740\n",
            "\n",
            "Epoch 494: Validation loss decreased (309.274017 --> 308.403015).\n",
            "\t Train_Loss: 116.2470 Val_Loss: 308.4030  BEST VAL Loss: 308.4030\n",
            "\n",
            "Epoch 495: Validation loss decreased (308.403015 --> 307.633698).\n",
            "\t Train_Loss: 115.7429 Val_Loss: 307.6337  BEST VAL Loss: 307.6337\n",
            "\n",
            "Epoch 496: Validation loss decreased (307.633698 --> 307.008362).\n",
            "\t Train_Loss: 115.8304 Val_Loss: 307.0084  BEST VAL Loss: 307.0084\n",
            "\n",
            "Epoch 497: Validation loss decreased (307.008362 --> 306.451660).\n",
            "\t Train_Loss: 115.5685 Val_Loss: 306.4517  BEST VAL Loss: 306.4517\n",
            "\n",
            "Epoch 498: Validation loss decreased (306.451660 --> 305.824707).\n",
            "\t Train_Loss: 115.7278 Val_Loss: 305.8247  BEST VAL Loss: 305.8247\n",
            "\n",
            "Epoch 499: Validation loss decreased (305.824707 --> 305.146271).\n",
            "\t Train_Loss: 115.6236 Val_Loss: 305.1463  BEST VAL Loss: 305.1463\n",
            "\n",
            "Epoch 500: Validation loss decreased (305.146271 --> 304.523376).\n",
            "\t Train_Loss: 115.4260 Val_Loss: 304.5234  BEST VAL Loss: 304.5234\n",
            "\n",
            "Epoch 501: Validation loss decreased (304.523376 --> 303.982025).\n",
            "\t Train_Loss: 115.2369 Val_Loss: 303.9820  BEST VAL Loss: 303.9820\n",
            "\n",
            "Epoch 502: Validation loss decreased (303.982025 --> 303.416016).\n",
            "\t Train_Loss: 114.9364 Val_Loss: 303.4160  BEST VAL Loss: 303.4160\n",
            "\n",
            "Epoch 503: Validation loss decreased (303.416016 --> 302.810974).\n",
            "\t Train_Loss: 114.8068 Val_Loss: 302.8110  BEST VAL Loss: 302.8110\n",
            "\n",
            "Epoch 504: Validation loss decreased (302.810974 --> 302.209717).\n",
            "\t Train_Loss: 114.6154 Val_Loss: 302.2097  BEST VAL Loss: 302.2097\n",
            "\n",
            "Epoch 505: Validation loss decreased (302.209717 --> 301.653931).\n",
            "\t Train_Loss: 114.5319 Val_Loss: 301.6539  BEST VAL Loss: 301.6539\n",
            "\n",
            "Epoch 506: Validation loss decreased (301.653931 --> 301.133606).\n",
            "\t Train_Loss: 114.4604 Val_Loss: 301.1336  BEST VAL Loss: 301.1336\n",
            "\n",
            "Epoch 507: Validation loss decreased (301.133606 --> 300.604675).\n",
            "\t Train_Loss: 114.3391 Val_Loss: 300.6047  BEST VAL Loss: 300.6047\n",
            "\n",
            "Epoch 508: Validation loss decreased (300.604675 --> 300.048157).\n",
            "\t Train_Loss: 114.2411 Val_Loss: 300.0482  BEST VAL Loss: 300.0482\n",
            "\n",
            "Epoch 509: Validation loss decreased (300.048157 --> 299.468567).\n",
            "\t Train_Loss: 114.0977 Val_Loss: 299.4686  BEST VAL Loss: 299.4686\n",
            "\n",
            "Epoch 510: Validation loss decreased (299.468567 --> 298.882904).\n",
            "\t Train_Loss: 113.9170 Val_Loss: 298.8829  BEST VAL Loss: 298.8829\n",
            "\n",
            "Epoch 511: Validation loss decreased (298.882904 --> 298.306915).\n",
            "\t Train_Loss: 113.7301 Val_Loss: 298.3069  BEST VAL Loss: 298.3069\n",
            "\n",
            "Epoch 512: Validation loss decreased (298.306915 --> 297.756836).\n",
            "\t Train_Loss: 113.5616 Val_Loss: 297.7568  BEST VAL Loss: 297.7568\n",
            "\n",
            "Epoch 513: Validation loss decreased (297.756836 --> 297.243622).\n",
            "\t Train_Loss: 113.4118 Val_Loss: 297.2436  BEST VAL Loss: 297.2436\n",
            "\n",
            "Epoch 514: Validation loss decreased (297.243622 --> 296.743134).\n",
            "\t Train_Loss: 113.2633 Val_Loss: 296.7431  BEST VAL Loss: 296.7431\n",
            "\n",
            "Epoch 515: Validation loss decreased (296.743134 --> 296.225159).\n",
            "\t Train_Loss: 113.1461 Val_Loss: 296.2252  BEST VAL Loss: 296.2252\n",
            "\n",
            "Epoch 516: Validation loss decreased (296.225159 --> 295.691345).\n",
            "\t Train_Loss: 113.0187 Val_Loss: 295.6913  BEST VAL Loss: 295.6913\n",
            "\n",
            "Epoch 517: Validation loss decreased (295.691345 --> 295.185059).\n",
            "\t Train_Loss: 112.8833 Val_Loss: 295.1851  BEST VAL Loss: 295.1851\n",
            "\n",
            "Epoch 518: Validation loss decreased (295.185059 --> 294.914490).\n",
            "\t Train_Loss: 112.6697 Val_Loss: 294.9145  BEST VAL Loss: 294.9145\n",
            "\n",
            "Epoch 519: Validation loss did not decrease\n",
            "\t Train_Loss: 108.5912 Val_Loss: 316.2242  BEST VAL Loss: 294.9145\n",
            "\n",
            "Epoch 520: Validation loss did not decrease\n",
            "\t Train_Loss: 106.8994 Val_Loss: 295.0176  BEST VAL Loss: 294.9145\n",
            "\n",
            "Epoch 521: Validation loss decreased (294.914490 --> 293.597351).\n",
            "\t Train_Loss: 103.3078 Val_Loss: 293.5974  BEST VAL Loss: 293.5974\n",
            "\n",
            "Epoch 522: Validation loss did not decrease\n",
            "\t Train_Loss: 103.6073 Val_Loss: 294.3799  BEST VAL Loss: 293.5974\n",
            "\n",
            "Epoch 523: Validation loss did not decrease\n",
            "\t Train_Loss: 101.2106 Val_Loss: 298.8754  BEST VAL Loss: 293.5974\n",
            "\n",
            "Epoch 524: Validation loss did not decrease\n",
            "\t Train_Loss: 102.2401 Val_Loss: 295.9700  BEST VAL Loss: 293.5974\n",
            "\n",
            "Epoch 525: Validation loss decreased (293.597351 --> 292.301819).\n",
            "\t Train_Loss: 99.4694 Val_Loss: 292.3018  BEST VAL Loss: 292.3018\n",
            "\n",
            "Epoch 526: Validation loss decreased (292.301819 --> 291.282288).\n",
            "\t Train_Loss: 101.2680 Val_Loss: 291.2823  BEST VAL Loss: 291.2823\n",
            "\n",
            "Epoch 527: Validation loss did not decrease\n",
            "\t Train_Loss: 100.1649 Val_Loss: 291.4894  BEST VAL Loss: 291.2823\n",
            "\n",
            "Epoch 528: Validation loss decreased (291.282288 --> 290.995331).\n",
            "\t Train_Loss: 98.1747 Val_Loss: 290.9953  BEST VAL Loss: 290.9953\n",
            "\n",
            "Epoch 529: Validation loss decreased (290.995331 --> 288.813660).\n",
            "\t Train_Loss: 99.6145 Val_Loss: 288.8137  BEST VAL Loss: 288.8137\n",
            "\n",
            "Epoch 530: Validation loss decreased (288.813660 --> 287.272919).\n",
            "\t Train_Loss: 97.8583 Val_Loss: 287.2729  BEST VAL Loss: 287.2729\n",
            "\n",
            "Epoch 531: Validation loss decreased (287.272919 --> 286.421875).\n",
            "\t Train_Loss: 97.6422 Val_Loss: 286.4219  BEST VAL Loss: 286.4219\n",
            "\n",
            "Epoch 532: Validation loss decreased (286.421875 --> 286.055756).\n",
            "\t Train_Loss: 97.9274 Val_Loss: 286.0558  BEST VAL Loss: 286.0558\n",
            "\n",
            "Epoch 533: Validation loss did not decrease\n",
            "\t Train_Loss: 96.6206 Val_Loss: 286.2180  BEST VAL Loss: 286.0558\n",
            "\n",
            "Epoch 534: Validation loss decreased (286.055756 --> 285.858765).\n",
            "\t Train_Loss: 96.6987 Val_Loss: 285.8588  BEST VAL Loss: 285.8588\n",
            "\n",
            "Epoch 535: Validation loss decreased (285.858765 --> 284.371399).\n",
            "\t Train_Loss: 96.8381 Val_Loss: 284.3714  BEST VAL Loss: 284.3714\n",
            "\n",
            "Epoch 536: Validation loss decreased (284.371399 --> 282.930603).\n",
            "\t Train_Loss: 95.8484 Val_Loss: 282.9306  BEST VAL Loss: 282.9306\n",
            "\n",
            "Epoch 537: Validation loss decreased (282.930603 --> 281.913055).\n",
            "\t Train_Loss: 95.9666 Val_Loss: 281.9131  BEST VAL Loss: 281.9131\n",
            "\n",
            "Epoch 538: Validation loss decreased (281.913055 --> 281.144470).\n",
            "\t Train_Loss: 95.7760 Val_Loss: 281.1445  BEST VAL Loss: 281.1445\n",
            "\n",
            "Epoch 539: Validation loss decreased (281.144470 --> 280.424469).\n",
            "\t Train_Loss: 95.0491 Val_Loss: 280.4245  BEST VAL Loss: 280.4245\n",
            "\n",
            "Epoch 540: Validation loss decreased (280.424469 --> 279.548767).\n",
            "\t Train_Loss: 95.1691 Val_Loss: 279.5488  BEST VAL Loss: 279.5488\n",
            "\n",
            "Epoch 541: Validation loss decreased (279.548767 --> 278.580078).\n",
            "\t Train_Loss: 94.9757 Val_Loss: 278.5801  BEST VAL Loss: 278.5801\n",
            "\n",
            "Epoch 542: Validation loss decreased (278.580078 --> 277.715424).\n",
            "\t Train_Loss: 94.4311 Val_Loss: 277.7154  BEST VAL Loss: 277.7154\n",
            "\n",
            "Epoch 543: Validation loss decreased (277.715424 --> 276.934265).\n",
            "\t Train_Loss: 94.4525 Val_Loss: 276.9343  BEST VAL Loss: 276.9343\n",
            "\n",
            "Epoch 544: Validation loss decreased (276.934265 --> 276.296783).\n",
            "\t Train_Loss: 94.2085 Val_Loss: 276.2968  BEST VAL Loss: 276.2968\n",
            "\n",
            "Epoch 545: Validation loss decreased (276.296783 --> 275.689484).\n",
            "\t Train_Loss: 93.7715 Val_Loss: 275.6895  BEST VAL Loss: 275.6895\n",
            "\n",
            "Epoch 546: Validation loss decreased (275.689484 --> 274.947632).\n",
            "\t Train_Loss: 93.7663 Val_Loss: 274.9476  BEST VAL Loss: 274.9476\n",
            "\n",
            "Epoch 547: Validation loss decreased (274.947632 --> 274.087799).\n",
            "\t Train_Loss: 93.5050 Val_Loss: 274.0878  BEST VAL Loss: 274.0878\n",
            "\n",
            "Epoch 548: Validation loss decreased (274.087799 --> 273.261322).\n",
            "\t Train_Loss: 93.1898 Val_Loss: 273.2613  BEST VAL Loss: 273.2613\n",
            "\n",
            "Epoch 549: Validation loss decreased (273.261322 --> 272.521912).\n",
            "\t Train_Loss: 93.1341 Val_Loss: 272.5219  BEST VAL Loss: 272.5219\n",
            "\n",
            "Epoch 550: Validation loss decreased (272.521912 --> 271.848083).\n",
            "\t Train_Loss: 92.8675 Val_Loss: 271.8481  BEST VAL Loss: 271.8481\n",
            "\n",
            "Epoch 551: Validation loss decreased (271.848083 --> 271.147278).\n",
            "\t Train_Loss: 92.5698 Val_Loss: 271.1473  BEST VAL Loss: 271.1473\n",
            "\n",
            "Epoch 552: Validation loss decreased (271.147278 --> 270.346741).\n",
            "\t Train_Loss: 92.4855 Val_Loss: 270.3467  BEST VAL Loss: 270.3467\n",
            "\n",
            "Epoch 553: Validation loss decreased (270.346741 --> 269.517578).\n",
            "\t Train_Loss: 92.2038 Val_Loss: 269.5176  BEST VAL Loss: 269.5176\n",
            "\n",
            "Epoch 554: Validation loss decreased (269.517578 --> 268.754456).\n",
            "\t Train_Loss: 91.9840 Val_Loss: 268.7545  BEST VAL Loss: 268.7545\n",
            "\n",
            "Epoch 555: Validation loss decreased (268.754456 --> 268.077484).\n",
            "\t Train_Loss: 91.8657 Val_Loss: 268.0775  BEST VAL Loss: 268.0775\n",
            "\n",
            "Epoch 556: Validation loss decreased (268.077484 --> 267.454834).\n",
            "\t Train_Loss: 91.5900 Val_Loss: 267.4548  BEST VAL Loss: 267.4548\n",
            "\n",
            "Epoch 557: Validation loss decreased (267.454834 --> 266.834686).\n",
            "\t Train_Loss: 91.4085 Val_Loss: 266.8347  BEST VAL Loss: 266.8347\n",
            "\n",
            "Epoch 558: Validation loss decreased (266.834686 --> 266.099426).\n",
            "\t Train_Loss: 91.2470 Val_Loss: 266.0994  BEST VAL Loss: 266.0994\n",
            "\n",
            "Epoch 559: Validation loss decreased (266.099426 --> 265.400452).\n",
            "\t Train_Loss: 90.9812 Val_Loss: 265.4005  BEST VAL Loss: 265.4005\n",
            "\n",
            "Epoch 560: Validation loss decreased (265.400452 --> 264.776489).\n",
            "\t Train_Loss: 90.8238 Val_Loss: 264.7765  BEST VAL Loss: 264.7765\n",
            "\n",
            "Epoch 561: Validation loss decreased (264.776489 --> 264.199066).\n",
            "\t Train_Loss: 90.6287 Val_Loss: 264.1991  BEST VAL Loss: 264.1991\n",
            "\n",
            "Epoch 562: Validation loss decreased (264.199066 --> 263.644592).\n",
            "\t Train_Loss: 90.3889 Val_Loss: 263.6446  BEST VAL Loss: 263.6446\n",
            "\n",
            "Epoch 563: Validation loss decreased (263.644592 --> 263.196350).\n",
            "\t Train_Loss: 90.2128 Val_Loss: 263.1964  BEST VAL Loss: 263.1964\n",
            "\n",
            "Epoch 564: Validation loss did not decrease\n",
            "\t Train_Loss: 89.9002 Val_Loss: 267.0682  BEST VAL Loss: 263.1964\n",
            "\n",
            "Epoch 565: Validation loss decreased (263.196350 --> 262.190094).\n",
            "\t Train_Loss: 89.6880 Val_Loss: 262.1901  BEST VAL Loss: 262.1901\n",
            "\n",
            "Epoch 566: Validation loss decreased (262.190094 --> 261.145569).\n",
            "\t Train_Loss: 89.4246 Val_Loss: 261.1456  BEST VAL Loss: 261.1456\n",
            "\n",
            "Epoch 567: Validation loss decreased (261.145569 --> 260.450012).\n",
            "\t Train_Loss: 89.3302 Val_Loss: 260.4500  BEST VAL Loss: 260.4500\n",
            "\n",
            "Epoch 568: Validation loss decreased (260.450012 --> 259.846680).\n",
            "\t Train_Loss: 89.1779 Val_Loss: 259.8467  BEST VAL Loss: 259.8467\n",
            "\n",
            "Epoch 569: Validation loss decreased (259.846680 --> 259.410431).\n",
            "\t Train_Loss: 88.9690 Val_Loss: 259.4104  BEST VAL Loss: 259.4104\n",
            "\n",
            "Epoch 570: Validation loss did not decrease\n",
            "\t Train_Loss: 88.7077 Val_Loss: 260.2192  BEST VAL Loss: 259.4104\n",
            "\n",
            "Epoch 571: Validation loss did not decrease\n",
            "\t Train_Loss: 88.3420 Val_Loss: 268.7587  BEST VAL Loss: 259.4104\n",
            "\n",
            "Epoch 572: Validation loss decreased (259.410431 --> 258.109314).\n",
            "\t Train_Loss: 88.8545 Val_Loss: 258.1093  BEST VAL Loss: 258.1093\n",
            "\n",
            "Epoch 573: Validation loss decreased (258.109314 --> 256.798492).\n",
            "\t Train_Loss: 88.1352 Val_Loss: 256.7985  BEST VAL Loss: 256.7985\n",
            "\n",
            "Epoch 574: Validation loss decreased (256.798492 --> 256.032776).\n",
            "\t Train_Loss: 88.1534 Val_Loss: 256.0328  BEST VAL Loss: 256.0328\n",
            "\n",
            "Epoch 575: Validation loss decreased (256.032776 --> 255.390335).\n",
            "\t Train_Loss: 88.0096 Val_Loss: 255.3903  BEST VAL Loss: 255.3903\n",
            "\n",
            "Epoch 576: Validation loss decreased (255.390335 --> 254.865631).\n",
            "\t Train_Loss: 87.9231 Val_Loss: 254.8656  BEST VAL Loss: 254.8656\n",
            "\n",
            "Epoch 577: Validation loss decreased (254.865631 --> 254.408371).\n",
            "\t Train_Loss: 87.7136 Val_Loss: 254.4084  BEST VAL Loss: 254.4084\n",
            "\n",
            "Epoch 578: Validation loss decreased (254.408371 --> 253.905914).\n",
            "\t Train_Loss: 87.5351 Val_Loss: 253.9059  BEST VAL Loss: 253.9059\n",
            "\n",
            "Epoch 579: Validation loss decreased (253.905914 --> 253.314819).\n",
            "\t Train_Loss: 87.4070 Val_Loss: 253.3148  BEST VAL Loss: 253.3148\n",
            "\n",
            "Epoch 580: Validation loss decreased (253.314819 --> 252.652924).\n",
            "\t Train_Loss: 87.2006 Val_Loss: 252.6529  BEST VAL Loss: 252.6529\n",
            "\n",
            "Epoch 581: Validation loss decreased (252.652924 --> 252.052536).\n",
            "\t Train_Loss: 87.0359 Val_Loss: 252.0525  BEST VAL Loss: 252.0525\n",
            "\n",
            "Epoch 582: Validation loss decreased (252.052536 --> 251.546829).\n",
            "\t Train_Loss: 86.8934 Val_Loss: 251.5468  BEST VAL Loss: 251.5468\n",
            "\n",
            "Epoch 583: Validation loss decreased (251.546829 --> 251.081390).\n",
            "\t Train_Loss: 86.7009 Val_Loss: 251.0814  BEST VAL Loss: 251.0814\n",
            "\n",
            "Epoch 584: Validation loss decreased (251.081390 --> 250.579254).\n",
            "\t Train_Loss: 86.5466 Val_Loss: 250.5793  BEST VAL Loss: 250.5793\n",
            "\n",
            "Epoch 585: Validation loss decreased (250.579254 --> 250.017380).\n",
            "\t Train_Loss: 86.3998 Val_Loss: 250.0174  BEST VAL Loss: 250.0174\n",
            "\n",
            "Epoch 586: Validation loss decreased (250.017380 --> 249.448853).\n",
            "\t Train_Loss: 86.2196 Val_Loss: 249.4489  BEST VAL Loss: 249.4489\n",
            "\n",
            "Epoch 587: Validation loss decreased (249.448853 --> 248.936325).\n",
            "\t Train_Loss: 86.0671 Val_Loss: 248.9363  BEST VAL Loss: 248.9363\n",
            "\n",
            "Epoch 588: Validation loss decreased (248.936325 --> 248.492828).\n",
            "\t Train_Loss: 85.9195 Val_Loss: 248.4928  BEST VAL Loss: 248.4928\n",
            "\n",
            "Epoch 589: Validation loss decreased (248.492828 --> 248.075806).\n",
            "\t Train_Loss: 85.7490 Val_Loss: 248.0758  BEST VAL Loss: 248.0758\n",
            "\n",
            "Epoch 590: Validation loss decreased (248.075806 --> 247.627289).\n",
            "\t Train_Loss: 85.5987 Val_Loss: 247.6273  BEST VAL Loss: 247.6273\n",
            "\n",
            "Epoch 591: Validation loss decreased (247.627289 --> 247.120758).\n",
            "\t Train_Loss: 85.4541 Val_Loss: 247.1208  BEST VAL Loss: 247.1208\n",
            "\n",
            "Epoch 592: Validation loss decreased (247.120758 --> 246.559601).\n",
            "\t Train_Loss: 85.2938 Val_Loss: 246.5596  BEST VAL Loss: 246.5596\n",
            "\n",
            "Epoch 593: Validation loss decreased (246.559601 --> 246.044220).\n",
            "\t Train_Loss: 85.1433 Val_Loss: 246.0442  BEST VAL Loss: 246.0442\n",
            "\n",
            "Epoch 594: Validation loss decreased (246.044220 --> 245.582031).\n",
            "\t Train_Loss: 85.0008 Val_Loss: 245.5820  BEST VAL Loss: 245.5820\n",
            "\n",
            "Epoch 595: Validation loss decreased (245.582031 --> 245.148270).\n",
            "\t Train_Loss: 84.8481 Val_Loss: 245.1483  BEST VAL Loss: 245.1483\n",
            "\n",
            "Epoch 596: Validation loss decreased (245.148270 --> 244.701004).\n",
            "\t Train_Loss: 84.7015 Val_Loss: 244.7010  BEST VAL Loss: 244.7010\n",
            "\n",
            "Epoch 597: Validation loss decreased (244.701004 --> 244.218094).\n",
            "\t Train_Loss: 84.5618 Val_Loss: 244.2181  BEST VAL Loss: 244.2181\n",
            "\n",
            "Epoch 598: Validation loss decreased (244.218094 --> 243.717728).\n",
            "\t Train_Loss: 84.4151 Val_Loss: 243.7177  BEST VAL Loss: 243.7177\n",
            "\n",
            "Epoch 599: Validation loss decreased (243.717728 --> 243.237991).\n",
            "\t Train_Loss: 84.2708 Val_Loss: 243.2380  BEST VAL Loss: 243.2380\n",
            "\n",
            "Epoch 600: Validation loss decreased (243.237991 --> 242.801758).\n",
            "\t Train_Loss: 84.1334 Val_Loss: 242.8018  BEST VAL Loss: 242.8018\n",
            "\n",
            "Epoch 601: Validation loss decreased (242.801758 --> 242.401413).\n",
            "\t Train_Loss: 83.9925 Val_Loss: 242.4014  BEST VAL Loss: 242.4014\n",
            "\n",
            "Epoch 602: Validation loss decreased (242.401413 --> 242.002289).\n",
            "\t Train_Loss: 83.8520 Val_Loss: 242.0023  BEST VAL Loss: 242.0023\n",
            "\n",
            "Epoch 603: Validation loss decreased (242.002289 --> 241.565475).\n",
            "\t Train_Loss: 83.7178 Val_Loss: 241.5655  BEST VAL Loss: 241.5655\n",
            "\n",
            "Epoch 604: Validation loss decreased (241.565475 --> 241.096588).\n",
            "\t Train_Loss: 83.5822 Val_Loss: 241.0966  BEST VAL Loss: 241.0966\n",
            "\n",
            "Epoch 605: Validation loss decreased (241.096588 --> 240.627487).\n",
            "\t Train_Loss: 83.4452 Val_Loss: 240.6275  BEST VAL Loss: 240.6275\n",
            "\n",
            "Epoch 606: Validation loss decreased (240.627487 --> 240.184082).\n",
            "\t Train_Loss: 83.3127 Val_Loss: 240.1841  BEST VAL Loss: 240.1841\n",
            "\n",
            "Epoch 607: Validation loss decreased (240.184082 --> 239.773041).\n",
            "\t Train_Loss: 83.1805 Val_Loss: 239.7730  BEST VAL Loss: 239.7730\n",
            "\n",
            "Epoch 608: Validation loss decreased (239.773041 --> 239.405670).\n",
            "\t Train_Loss: 83.0442 Val_Loss: 239.4057  BEST VAL Loss: 239.4057\n",
            "\n",
            "Epoch 609: Validation loss did not decrease\n",
            "\t Train_Loss: 82.8989 Val_Loss: 245.2830  BEST VAL Loss: 239.4057\n",
            "\n",
            "Epoch 610: Validation loss decreased (239.405670 --> 238.490387).\n",
            "\t Train_Loss: 82.8409 Val_Loss: 238.4904  BEST VAL Loss: 238.4904\n",
            "\n",
            "Epoch 611: Validation loss decreased (238.490387 --> 238.090775).\n",
            "\t Train_Loss: 82.5571 Val_Loss: 238.0908  BEST VAL Loss: 238.0908\n",
            "\n",
            "Epoch 612: Validation loss did not decrease\n",
            "\t Train_Loss: 82.2233 Val_Loss: 238.9512  BEST VAL Loss: 238.0908\n",
            "\n",
            "Epoch 613: Validation loss did not decrease\n",
            "\t Train_Loss: 81.8680 Val_Loss: 241.5467  BEST VAL Loss: 238.0908\n",
            "\n",
            "Epoch 614: Validation loss did not decrease\n",
            "\t Train_Loss: 81.9819 Val_Loss: 239.7437  BEST VAL Loss: 238.0908\n",
            "\n",
            "Epoch 615: Validation loss decreased (238.090775 --> 236.890778).\n",
            "\t Train_Loss: 81.6617 Val_Loss: 236.8908  BEST VAL Loss: 236.8908\n",
            "\n",
            "Epoch 616: Validation loss decreased (236.890778 --> 235.875046).\n",
            "\t Train_Loss: 81.3446 Val_Loss: 235.8750  BEST VAL Loss: 235.8750\n",
            "\n",
            "Epoch 617: Validation loss did not decrease\n",
            "\t Train_Loss: 81.2102 Val_Loss: 237.2159  BEST VAL Loss: 235.8750\n",
            "\n",
            "Epoch 618: Validation loss did not decrease\n",
            "\t Train_Loss: 80.7392 Val_Loss: 236.7655  BEST VAL Loss: 235.8750\n",
            "\n",
            "Epoch 619: Validation loss decreased (235.875046 --> 235.583832).\n",
            "\t Train_Loss: 80.4379 Val_Loss: 235.5838  BEST VAL Loss: 235.5838\n",
            "\n",
            "Epoch 620: Validation loss did not decrease\n",
            "\t Train_Loss: 80.2127 Val_Loss: 236.4742  BEST VAL Loss: 235.5838\n",
            "\n",
            "Epoch 621: Validation loss did not decrease\n",
            "\t Train_Loss: 80.0396 Val_Loss: 238.0138  BEST VAL Loss: 235.5838\n",
            "\n",
            "Epoch 622: Validation loss decreased (235.583832 --> 234.777054).\n",
            "\t Train_Loss: 79.8766 Val_Loss: 234.7771  BEST VAL Loss: 234.7771\n",
            "\n",
            "Epoch 623: Validation loss decreased (234.777054 --> 233.307938).\n",
            "\t Train_Loss: 79.4237 Val_Loss: 233.3079  BEST VAL Loss: 233.3079\n",
            "\n",
            "Epoch 624: Validation loss did not decrease\n",
            "\t Train_Loss: 79.1853 Val_Loss: 234.9649  BEST VAL Loss: 233.3079\n",
            "\n",
            "Epoch 625: Validation loss decreased (233.307938 --> 232.286667).\n",
            "\t Train_Loss: 78.9179 Val_Loss: 232.2867  BEST VAL Loss: 232.2867\n",
            "\n",
            "Epoch 626: Validation loss did not decrease\n",
            "\t Train_Loss: 78.5353 Val_Loss: 233.3374  BEST VAL Loss: 232.2867\n",
            "\n",
            "Epoch 627: Validation loss did not decrease\n",
            "\t Train_Loss: 77.8689 Val_Loss: 235.2727  BEST VAL Loss: 232.2867\n",
            "\n",
            "Epoch 628: Validation loss decreased (232.286667 --> 231.316010).\n",
            "\t Train_Loss: 77.5946 Val_Loss: 231.3160  BEST VAL Loss: 231.3160\n",
            "\n",
            "Epoch 629: Validation loss decreased (231.316010 --> 230.616653).\n",
            "\t Train_Loss: 77.6723 Val_Loss: 230.6167  BEST VAL Loss: 230.6167\n",
            "\n",
            "Epoch 630: Validation loss did not decrease\n",
            "\t Train_Loss: 76.6227 Val_Loss: 241.8253  BEST VAL Loss: 230.6167\n",
            "\n",
            "Epoch 631: Validation loss decreased (230.616653 --> 229.522263).\n",
            "\t Train_Loss: 77.8561 Val_Loss: 229.5223  BEST VAL Loss: 229.5223\n",
            "\n",
            "Epoch 632: Validation loss decreased (229.522263 --> 229.104904).\n",
            "\t Train_Loss: 75.5785 Val_Loss: 229.1049  BEST VAL Loss: 229.1049\n",
            "\n",
            "Epoch 633: Validation loss did not decrease\n",
            "\t Train_Loss: 75.8768 Val_Loss: 231.1291  BEST VAL Loss: 229.1049\n",
            "\n",
            "Epoch 634: Validation loss did not decrease\n",
            "\t Train_Loss: 75.2993 Val_Loss: 229.7067  BEST VAL Loss: 229.1049\n",
            "\n",
            "Epoch 635: Validation loss did not decrease\n",
            "\t Train_Loss: 74.1451 Val_Loss: 231.7139  BEST VAL Loss: 229.1049\n",
            "\n",
            "Epoch 636: Validation loss decreased (229.104904 --> 227.097702).\n",
            "\t Train_Loss: 74.4238 Val_Loss: 227.0977  BEST VAL Loss: 227.0977\n",
            "\n",
            "Epoch 637: Validation loss did not decrease\n",
            "\t Train_Loss: 73.5613 Val_Loss: 227.2503  BEST VAL Loss: 227.0977\n",
            "\n",
            "Epoch 638: Validation loss did not decrease\n",
            "\t Train_Loss: 73.0302 Val_Loss: 230.9978  BEST VAL Loss: 227.0977\n",
            "\n",
            "Epoch 639: Validation loss decreased (227.097702 --> 225.993851).\n",
            "\t Train_Loss: 73.0770 Val_Loss: 225.9939  BEST VAL Loss: 225.9939\n",
            "\n",
            "Epoch 640: Validation loss decreased (225.993851 --> 225.368256).\n",
            "\t Train_Loss: 72.0507 Val_Loss: 225.3683  BEST VAL Loss: 225.3683\n",
            "\n",
            "Epoch 641: Validation loss decreased (225.368256 --> 224.884766).\n",
            "\t Train_Loss: 72.0377 Val_Loss: 224.8848  BEST VAL Loss: 224.8848\n",
            "\n",
            "Epoch 642: Validation loss did not decrease\n",
            "\t Train_Loss: 71.5724 Val_Loss: 241.2063  BEST VAL Loss: 224.8848\n",
            "\n",
            "Epoch 643: Validation loss did not decrease\n",
            "\t Train_Loss: 73.5974 Val_Loss: 226.3554  BEST VAL Loss: 224.8848\n",
            "\n",
            "Epoch 644: Validation loss decreased (224.884766 --> 223.471161).\n",
            "\t Train_Loss: 71.2873 Val_Loss: 223.4712  BEST VAL Loss: 223.4712\n",
            "\n",
            "Epoch 645: Validation loss did not decrease\n",
            "\t Train_Loss: 70.5718 Val_Loss: 223.9487  BEST VAL Loss: 223.4712\n",
            "\n",
            "Epoch 646: Validation loss did not decrease\n",
            "\t Train_Loss: 70.2828 Val_Loss: 234.9997  BEST VAL Loss: 223.4712\n",
            "\n",
            "Epoch 647: Validation loss decreased (223.471161 --> 220.869431).\n",
            "\t Train_Loss: 72.4546 Val_Loss: 220.8694  BEST VAL Loss: 220.8694\n",
            "\n",
            "Epoch 648: Validation loss decreased (220.869431 --> 220.304840).\n",
            "\t Train_Loss: 69.8568 Val_Loss: 220.3048  BEST VAL Loss: 220.3048\n",
            "\n",
            "Epoch 649: Validation loss did not decrease\n",
            "\t Train_Loss: 69.7708 Val_Loss: 221.8990  BEST VAL Loss: 220.3048\n",
            "\n",
            "Epoch 650: Validation loss did not decrease\n",
            "\t Train_Loss: 69.2119 Val_Loss: 242.2488  BEST VAL Loss: 220.3048\n",
            "\n",
            "Epoch 651: Validation loss decreased (220.304840 --> 218.391022).\n",
            "\t Train_Loss: 73.0607 Val_Loss: 218.3910  BEST VAL Loss: 218.3910\n",
            "\n",
            "Epoch 652: Validation loss did not decrease\n",
            "\t Train_Loss: 69.4923 Val_Loss: 223.3616  BEST VAL Loss: 218.3910\n",
            "\n",
            "Epoch 653: Validation loss decreased (218.391022 --> 217.735641).\n",
            "\t Train_Loss: 70.2384 Val_Loss: 217.7356  BEST VAL Loss: 217.7356\n",
            "\n",
            "Epoch 654: Validation loss did not decrease\n",
            "\t Train_Loss: 68.7378 Val_Loss: 217.7908  BEST VAL Loss: 217.7356\n",
            "\n",
            "Epoch 655: Validation loss did not decrease\n",
            "\t Train_Loss: 68.7790 Val_Loss: 218.6294  BEST VAL Loss: 217.7356\n",
            "\n",
            "Epoch 656: Validation loss did not decrease\n",
            "\t Train_Loss: 67.9803 Val_Loss: 227.2365  BEST VAL Loss: 217.7356\n",
            "\n",
            "Epoch 657: Validation loss did not decrease\n",
            "\t Train_Loss: 70.1421 Val_Loss: 224.8329  BEST VAL Loss: 217.7356\n",
            "\n",
            "Epoch 658: Validation loss decreased (217.735641 --> 215.732147).\n",
            "\t Train_Loss: 69.0501 Val_Loss: 215.7321  BEST VAL Loss: 215.7321\n",
            "\n",
            "Epoch 659: Validation loss decreased (215.732147 --> 214.970551).\n",
            "\t Train_Loss: 67.4070 Val_Loss: 214.9706  BEST VAL Loss: 214.9706\n",
            "\n",
            "Epoch 660: Validation loss decreased (214.970551 --> 214.543945).\n",
            "\t Train_Loss: 67.6071 Val_Loss: 214.5439  BEST VAL Loss: 214.5439\n",
            "\n",
            "Epoch 661: Validation loss decreased (214.543945 --> 213.277267).\n",
            "\t Train_Loss: 67.1538 Val_Loss: 213.2773  BEST VAL Loss: 213.2773\n",
            "\n",
            "Epoch 662: Validation loss did not decrease\n",
            "\t Train_Loss: 67.1263 Val_Loss: 213.4933  BEST VAL Loss: 213.2773\n",
            "\n",
            "Epoch 663: Validation loss did not decrease\n",
            "\t Train_Loss: 66.8177 Val_Loss: 214.1418  BEST VAL Loss: 213.2773\n",
            "\n",
            "Epoch 664: Validation loss decreased (213.277267 --> 213.194214).\n",
            "\t Train_Loss: 66.7638 Val_Loss: 213.1942  BEST VAL Loss: 213.1942\n",
            "\n",
            "Epoch 665: Validation loss did not decrease\n",
            "\t Train_Loss: 66.4951 Val_Loss: 225.9528  BEST VAL Loss: 213.1942\n",
            "\n",
            "Epoch 666: Validation loss decreased (213.194214 --> 211.087402).\n",
            "\t Train_Loss: 68.0954 Val_Loss: 211.0874  BEST VAL Loss: 211.0874\n",
            "\n",
            "Epoch 667: Validation loss decreased (211.087402 --> 210.950775).\n",
            "\t Train_Loss: 66.2352 Val_Loss: 210.9508  BEST VAL Loss: 210.9508\n",
            "\n",
            "Epoch 668: Validation loss decreased (210.950775 --> 210.767624).\n",
            "\t Train_Loss: 66.0840 Val_Loss: 210.7676  BEST VAL Loss: 210.7676\n",
            "\n",
            "Epoch 669: Validation loss decreased (210.767624 --> 210.221359).\n",
            "\t Train_Loss: 65.9726 Val_Loss: 210.2214  BEST VAL Loss: 210.2214\n",
            "\n",
            "Epoch 670: Validation loss decreased (210.221359 --> 209.708252).\n",
            "\t Train_Loss: 65.7152 Val_Loss: 209.7083  BEST VAL Loss: 209.7083\n",
            "\n",
            "Epoch 671: Validation loss decreased (209.708252 --> 209.657516).\n",
            "\t Train_Loss: 65.6963 Val_Loss: 209.6575  BEST VAL Loss: 209.6575\n",
            "\n",
            "Epoch 672: Validation loss decreased (209.657516 --> 209.171478).\n",
            "\t Train_Loss: 65.4873 Val_Loss: 209.1715  BEST VAL Loss: 209.1715\n",
            "\n",
            "Epoch 673: Validation loss decreased (209.171478 --> 208.274216).\n",
            "\t Train_Loss: 65.3517 Val_Loss: 208.2742  BEST VAL Loss: 208.2742\n",
            "\n",
            "Epoch 674: Validation loss decreased (208.274216 --> 207.678879).\n",
            "\t Train_Loss: 65.1862 Val_Loss: 207.6789  BEST VAL Loss: 207.6789\n",
            "\n",
            "Epoch 675: Validation loss did not decrease\n",
            "\t Train_Loss: 65.0387 Val_Loss: 214.5256  BEST VAL Loss: 207.6789\n",
            "\n",
            "Epoch 676: Validation loss decreased (207.678879 --> 206.755707).\n",
            "\t Train_Loss: 65.3582 Val_Loss: 206.7557  BEST VAL Loss: 206.7557\n",
            "\n",
            "Epoch 677: Validation loss decreased (206.755707 --> 206.574432).\n",
            "\t Train_Loss: 64.7977 Val_Loss: 206.5744  BEST VAL Loss: 206.5744\n",
            "\n",
            "Epoch 678: Validation loss did not decrease\n",
            "\t Train_Loss: 64.6453 Val_Loss: 206.6453  BEST VAL Loss: 206.5744\n",
            "\n",
            "Epoch 679: Validation loss decreased (206.574432 --> 205.287476).\n",
            "\t Train_Loss: 64.6553 Val_Loss: 205.2875  BEST VAL Loss: 205.2875\n",
            "\n",
            "Epoch 680: Validation loss decreased (205.287476 --> 204.448929).\n",
            "\t Train_Loss: 64.3946 Val_Loss: 204.4489  BEST VAL Loss: 204.4489\n",
            "\n",
            "Epoch 681: Validation loss did not decrease\n",
            "\t Train_Loss: 64.3588 Val_Loss: 205.0687  BEST VAL Loss: 204.4489\n",
            "\n",
            "Epoch 682: Validation loss decreased (204.448929 --> 203.785217).\n",
            "\t Train_Loss: 64.2439 Val_Loss: 203.7852  BEST VAL Loss: 203.7852\n",
            "\n",
            "Epoch 683: Validation loss decreased (203.785217 --> 203.407181).\n",
            "\t Train_Loss: 64.0744 Val_Loss: 203.4072  BEST VAL Loss: 203.4072\n",
            "\n",
            "Epoch 684: Validation loss decreased (203.407181 --> 202.927032).\n",
            "\t Train_Loss: 63.9299 Val_Loss: 202.9270  BEST VAL Loss: 202.9270\n",
            "\n",
            "Epoch 685: Validation loss decreased (202.927032 --> 202.701172).\n",
            "\t Train_Loss: 63.8056 Val_Loss: 202.7012  BEST VAL Loss: 202.7012\n",
            "\n",
            "Epoch 686: Validation loss decreased (202.701172 --> 202.331329).\n",
            "\t Train_Loss: 63.7381 Val_Loss: 202.3313  BEST VAL Loss: 202.3313\n",
            "\n",
            "Epoch 687: Validation loss decreased (202.331329 --> 201.691727).\n",
            "\t Train_Loss: 63.5864 Val_Loss: 201.6917  BEST VAL Loss: 201.6917\n",
            "\n",
            "Epoch 688: Validation loss decreased (201.691727 --> 201.079727).\n",
            "\t Train_Loss: 63.4751 Val_Loss: 201.0797  BEST VAL Loss: 201.0797\n",
            "\n",
            "Epoch 689: Validation loss decreased (201.079727 --> 200.557693).\n",
            "\t Train_Loss: 63.3638 Val_Loss: 200.5577  BEST VAL Loss: 200.5577\n",
            "\n",
            "Epoch 690: Validation loss decreased (200.557693 --> 200.195587).\n",
            "\t Train_Loss: 63.2710 Val_Loss: 200.1956  BEST VAL Loss: 200.1956\n",
            "\n",
            "Epoch 691: Validation loss decreased (200.195587 --> 200.005356).\n",
            "\t Train_Loss: 63.1485 Val_Loss: 200.0054  BEST VAL Loss: 200.0054\n",
            "\n",
            "Epoch 692: Validation loss decreased (200.005356 --> 199.762421).\n",
            "\t Train_Loss: 63.0339 Val_Loss: 199.7624  BEST VAL Loss: 199.7624\n",
            "\n",
            "Epoch 693: Validation loss decreased (199.762421 --> 199.197296).\n",
            "\t Train_Loss: 62.9395 Val_Loss: 199.1973  BEST VAL Loss: 199.1973\n",
            "\n",
            "Epoch 694: Validation loss decreased (199.197296 --> 198.672760).\n",
            "\t Train_Loss: 62.8295 Val_Loss: 198.6728  BEST VAL Loss: 198.6728\n",
            "\n",
            "Epoch 695: Validation loss decreased (198.672760 --> 198.324127).\n",
            "\t Train_Loss: 62.7261 Val_Loss: 198.3241  BEST VAL Loss: 198.3241\n",
            "\n",
            "Epoch 696: Validation loss decreased (198.324127 --> 197.957550).\n",
            "\t Train_Loss: 62.6143 Val_Loss: 197.9576  BEST VAL Loss: 197.9576\n",
            "\n",
            "Epoch 697: Validation loss decreased (197.957550 --> 197.474762).\n",
            "\t Train_Loss: 62.5277 Val_Loss: 197.4748  BEST VAL Loss: 197.4748\n",
            "\n",
            "Epoch 698: Validation loss decreased (197.474762 --> 197.013016).\n",
            "\t Train_Loss: 62.4185 Val_Loss: 197.0130  BEST VAL Loss: 197.0130\n",
            "\n",
            "Epoch 699: Validation loss decreased (197.013016 --> 196.711014).\n",
            "\t Train_Loss: 62.3230 Val_Loss: 196.7110  BEST VAL Loss: 196.7110\n",
            "\n",
            "Epoch 700: Validation loss decreased (196.711014 --> 196.467285).\n",
            "\t Train_Loss: 62.2186 Val_Loss: 196.4673  BEST VAL Loss: 196.4673\n",
            "\n",
            "Epoch 701: Validation loss decreased (196.467285 --> 195.998367).\n",
            "\t Train_Loss: 62.1282 Val_Loss: 195.9984  BEST VAL Loss: 195.9984\n",
            "\n",
            "Epoch 702: Validation loss decreased (195.998367 --> 195.441116).\n",
            "\t Train_Loss: 62.0265 Val_Loss: 195.4411  BEST VAL Loss: 195.4411\n",
            "\n",
            "Epoch 703: Validation loss decreased (195.441116 --> 195.013214).\n",
            "\t Train_Loss: 61.9293 Val_Loss: 195.0132  BEST VAL Loss: 195.0132\n",
            "\n",
            "Epoch 704: Validation loss decreased (195.013214 --> 194.679169).\n",
            "\t Train_Loss: 61.8360 Val_Loss: 194.6792  BEST VAL Loss: 194.6792\n",
            "\n",
            "Epoch 705: Validation loss decreased (194.679169 --> 194.313156).\n",
            "\t Train_Loss: 61.7433 Val_Loss: 194.3132  BEST VAL Loss: 194.3132\n",
            "\n",
            "Epoch 706: Validation loss decreased (194.313156 --> 193.883911).\n",
            "\t Train_Loss: 61.6516 Val_Loss: 193.8839  BEST VAL Loss: 193.8839\n",
            "\n",
            "Epoch 707: Validation loss decreased (193.883911 --> 193.491302).\n",
            "\t Train_Loss: 61.5547 Val_Loss: 193.4913  BEST VAL Loss: 193.4913\n",
            "\n",
            "Epoch 708: Validation loss decreased (193.491302 --> 193.182388).\n",
            "\t Train_Loss: 61.4658 Val_Loss: 193.1824  BEST VAL Loss: 193.1824\n",
            "\n",
            "Epoch 709: Validation loss decreased (193.182388 --> 192.850906).\n",
            "\t Train_Loss: 61.3729 Val_Loss: 192.8509  BEST VAL Loss: 192.8509\n",
            "\n",
            "Epoch 710: Validation loss decreased (192.850906 --> 192.423126).\n",
            "\t Train_Loss: 61.2845 Val_Loss: 192.4231  BEST VAL Loss: 192.4231\n",
            "\n",
            "Epoch 711: Validation loss decreased (192.423126 --> 191.999054).\n",
            "\t Train_Loss: 61.1922 Val_Loss: 191.9991  BEST VAL Loss: 191.9991\n",
            "\n",
            "Epoch 712: Validation loss decreased (191.999054 --> 191.654633).\n",
            "\t Train_Loss: 61.1055 Val_Loss: 191.6546  BEST VAL Loss: 191.6546\n",
            "\n",
            "Epoch 713: Validation loss decreased (191.654633 --> 191.355026).\n",
            "\t Train_Loss: 61.0168 Val_Loss: 191.3550  BEST VAL Loss: 191.3550\n",
            "\n",
            "Epoch 714: Validation loss decreased (191.355026 --> 191.025406).\n",
            "\t Train_Loss: 60.9288 Val_Loss: 191.0254  BEST VAL Loss: 191.0254\n",
            "\n",
            "Epoch 715: Validation loss decreased (191.025406 --> 190.659912).\n",
            "\t Train_Loss: 60.8409 Val_Loss: 190.6599  BEST VAL Loss: 190.6599\n",
            "\n",
            "Epoch 716: Validation loss decreased (190.659912 --> 190.317215).\n",
            "\t Train_Loss: 60.7545 Val_Loss: 190.3172  BEST VAL Loss: 190.3172\n",
            "\n",
            "Epoch 717: Validation loss decreased (190.317215 --> 190.001984).\n",
            "\t Train_Loss: 60.6696 Val_Loss: 190.0020  BEST VAL Loss: 190.0020\n",
            "\n",
            "Epoch 718: Validation loss decreased (190.001984 --> 189.656540).\n",
            "\t Train_Loss: 60.5832 Val_Loss: 189.6565  BEST VAL Loss: 189.6565\n",
            "\n",
            "Epoch 719: Validation loss decreased (189.656540 --> 189.272766).\n",
            "\t Train_Loss: 60.4987 Val_Loss: 189.2728  BEST VAL Loss: 189.2728\n",
            "\n",
            "Epoch 720: Validation loss decreased (189.272766 --> 188.907867).\n",
            "\t Train_Loss: 60.4140 Val_Loss: 188.9079  BEST VAL Loss: 188.9079\n",
            "\n",
            "Epoch 721: Validation loss decreased (188.907867 --> 188.592773).\n",
            "\t Train_Loss: 60.3311 Val_Loss: 188.5928  BEST VAL Loss: 188.5928\n",
            "\n",
            "Epoch 722: Validation loss decreased (188.592773 --> 188.294083).\n",
            "\t Train_Loss: 60.2467 Val_Loss: 188.2941  BEST VAL Loss: 188.2941\n",
            "\n",
            "Epoch 723: Validation loss decreased (188.294083 --> 187.962936).\n",
            "\t Train_Loss: 60.1639 Val_Loss: 187.9629  BEST VAL Loss: 187.9629\n",
            "\n",
            "Epoch 724: Validation loss decreased (187.962936 --> 187.611053).\n",
            "\t Train_Loss: 60.0811 Val_Loss: 187.6111  BEST VAL Loss: 187.6111\n",
            "\n",
            "Epoch 725: Validation loss decreased (187.611053 --> 187.280350).\n",
            "\t Train_Loss: 59.9992 Val_Loss: 187.2803  BEST VAL Loss: 187.2803\n",
            "\n",
            "Epoch 726: Validation loss decreased (187.280350 --> 186.965439).\n",
            "\t Train_Loss: 59.9165 Val_Loss: 186.9654  BEST VAL Loss: 186.9654\n",
            "\n",
            "Epoch 727: Validation loss decreased (186.965439 --> 186.644409).\n",
            "\t Train_Loss: 59.8327 Val_Loss: 186.6444  BEST VAL Loss: 186.6444\n",
            "\n",
            "Epoch 728: Validation loss did not decrease\n",
            "\t Train_Loss: 59.7319 Val_Loss: 187.1529  BEST VAL Loss: 186.6444\n",
            "\n",
            "Epoch 729: Validation loss did not decrease\n",
            "\t Train_Loss: 59.3804 Val_Loss: 247.4559  BEST VAL Loss: 186.6444\n",
            "\n",
            "Epoch 730: Validation loss decreased (186.644409 --> 185.588287).\n",
            "\t Train_Loss: 70.8551 Val_Loss: 185.5883  BEST VAL Loss: 185.5883\n",
            "\n",
            "Epoch 731: Validation loss decreased (185.588287 --> 184.288406).\n",
            "\t Train_Loss: 66.7151 Val_Loss: 184.2884  BEST VAL Loss: 184.2884\n",
            "\n",
            "Epoch 732: Validation loss did not decrease\n",
            "\t Train_Loss: 62.4446 Val_Loss: 185.8968  BEST VAL Loss: 184.2884\n",
            "\n",
            "Epoch 733: Validation loss did not decrease\n",
            "\t Train_Loss: 62.2175 Val_Loss: 186.9071  BEST VAL Loss: 184.2884\n",
            "\n",
            "Epoch 734: Validation loss did not decrease\n",
            "\t Train_Loss: 65.2235 Val_Loss: 184.5241  BEST VAL Loss: 184.2884\n",
            "\n",
            "Epoch 735: Validation loss did not decrease\n",
            "\t Train_Loss: 57.5973 Val_Loss: 214.0895  BEST VAL Loss: 184.2884\n",
            "\n",
            "Epoch 736: Validation loss did not decrease\n",
            "\t Train_Loss: 62.5520 Val_Loss: 184.7915  BEST VAL Loss: 184.2884\n",
            "\n",
            "Epoch 737: Validation loss decreased (184.288406 --> 182.135101).\n",
            "\t Train_Loss: 60.0711 Val_Loss: 182.1351  BEST VAL Loss: 182.1351\n",
            "\n",
            "Epoch 738: Validation loss did not decrease\n",
            "\t Train_Loss: 55.6549 Val_Loss: 182.8373  BEST VAL Loss: 182.1351\n",
            "\n",
            "Epoch 739: Validation loss did not decrease\n",
            "\t Train_Loss: 57.5205 Val_Loss: 183.4694  BEST VAL Loss: 182.1351\n",
            "\n",
            "Epoch 740: Validation loss did not decrease\n",
            "\t Train_Loss: 58.9586 Val_Loss: 182.3562  BEST VAL Loss: 182.1351\n",
            "\n",
            "Epoch 741: Validation loss decreased (182.135101 --> 182.082520).\n",
            "\t Train_Loss: 53.1839 Val_Loss: 182.0825  BEST VAL Loss: 182.0825\n",
            "\n",
            "Epoch 742: Validation loss did not decrease\n",
            "\t Train_Loss: 55.2458 Val_Loss: 190.7399  BEST VAL Loss: 182.0825\n",
            "\n",
            "Epoch 743: Validation loss did not decrease\n",
            "\t Train_Loss: 55.9302 Val_Loss: 187.4080  BEST VAL Loss: 182.0825\n",
            "\n",
            "Epoch 744: Validation loss did not decrease\n",
            "\t Train_Loss: 53.9523 Val_Loss: 183.7873  BEST VAL Loss: 182.0825\n",
            "\n",
            "Epoch 745: Validation loss decreased (182.082520 --> 179.847504).\n",
            "\t Train_Loss: 54.0838 Val_Loss: 179.8475  BEST VAL Loss: 179.8475\n",
            "\n",
            "Epoch 746: Validation loss decreased (179.847504 --> 178.286011).\n",
            "\t Train_Loss: 52.5864 Val_Loss: 178.2860  BEST VAL Loss: 178.2860\n",
            "\n",
            "Epoch 747: Validation loss decreased (178.286011 --> 177.690155).\n",
            "\t Train_Loss: 52.2787 Val_Loss: 177.6902  BEST VAL Loss: 177.6902\n",
            "\n",
            "Epoch 748: Validation loss decreased (177.690155 --> 177.528595).\n",
            "\t Train_Loss: 53.2429 Val_Loss: 177.5286  BEST VAL Loss: 177.5286\n",
            "\n",
            "Epoch 749: Validation loss did not decrease\n",
            "\t Train_Loss: 52.7806 Val_Loss: 177.6932  BEST VAL Loss: 177.5286\n",
            "\n",
            "Epoch 750: Validation loss did not decrease\n",
            "\t Train_Loss: 52.2336 Val_Loss: 177.5431  BEST VAL Loss: 177.5286\n",
            "\n",
            "Epoch 751: Validation loss decreased (177.528595 --> 177.185974).\n",
            "\t Train_Loss: 51.8116 Val_Loss: 177.1860  BEST VAL Loss: 177.1860\n",
            "\n",
            "Epoch 752: Validation loss decreased (177.185974 --> 176.951370).\n",
            "\t Train_Loss: 51.0815 Val_Loss: 176.9514  BEST VAL Loss: 176.9514\n",
            "\n",
            "Epoch 753: Validation loss did not decrease\n",
            "\t Train_Loss: 51.1077 Val_Loss: 177.2744  BEST VAL Loss: 176.9514\n",
            "\n",
            "Epoch 754: Validation loss did not decrease\n",
            "\t Train_Loss: 51.3391 Val_Loss: 178.2806  BEST VAL Loss: 176.9514\n",
            "\n",
            "Epoch 755: Validation loss did not decrease\n",
            "\t Train_Loss: 51.1237 Val_Loss: 179.0526  BEST VAL Loss: 176.9514\n",
            "\n",
            "Epoch 756: Validation loss did not decrease\n",
            "\t Train_Loss: 51.1524 Val_Loss: 178.0043  BEST VAL Loss: 176.9514\n",
            "\n",
            "Epoch 757: Validation loss decreased (176.951370 --> 175.990067).\n",
            "\t Train_Loss: 50.7715 Val_Loss: 175.9901  BEST VAL Loss: 175.9901\n",
            "\n",
            "Epoch 758: Validation loss decreased (175.990067 --> 174.890701).\n",
            "\t Train_Loss: 50.3178 Val_Loss: 174.8907  BEST VAL Loss: 174.8907\n",
            "\n",
            "Epoch 759: Validation loss did not decrease\n",
            "\t Train_Loss: 50.1868 Val_Loss: 176.5286  BEST VAL Loss: 174.8907\n",
            "\n",
            "Epoch 760: Validation loss decreased (174.890701 --> 174.681427).\n",
            "\t Train_Loss: 49.9689 Val_Loss: 174.6814  BEST VAL Loss: 174.6814\n",
            "\n",
            "Epoch 761: Validation loss decreased (174.681427 --> 173.898712).\n",
            "\t Train_Loss: 50.0507 Val_Loss: 173.8987  BEST VAL Loss: 173.8987\n",
            "\n",
            "Epoch 762: Validation loss decreased (173.898712 --> 173.141205).\n",
            "\t Train_Loss: 49.9413 Val_Loss: 173.1412  BEST VAL Loss: 173.1412\n",
            "\n",
            "Epoch 763: Validation loss decreased (173.141205 --> 172.584991).\n",
            "\t Train_Loss: 49.8129 Val_Loss: 172.5850  BEST VAL Loss: 172.5850\n",
            "\n",
            "Epoch 764: Validation loss decreased (172.584991 --> 172.288315).\n",
            "\t Train_Loss: 49.7354 Val_Loss: 172.2883  BEST VAL Loss: 172.2883\n",
            "\n",
            "Epoch 765: Validation loss decreased (172.288315 --> 172.164642).\n",
            "\t Train_Loss: 49.5108 Val_Loss: 172.1646  BEST VAL Loss: 172.1646\n",
            "\n",
            "Epoch 766: Validation loss decreased (172.164642 --> 171.990189).\n",
            "\t Train_Loss: 49.3164 Val_Loss: 171.9902  BEST VAL Loss: 171.9902\n",
            "\n",
            "Epoch 767: Validation loss decreased (171.990189 --> 171.661896).\n",
            "\t Train_Loss: 49.1883 Val_Loss: 171.6619  BEST VAL Loss: 171.6619\n",
            "\n",
            "Epoch 768: Validation loss decreased (171.661896 --> 171.328201).\n",
            "\t Train_Loss: 49.0390 Val_Loss: 171.3282  BEST VAL Loss: 171.3282\n",
            "\n",
            "Epoch 769: Validation loss decreased (171.328201 --> 170.936447).\n",
            "\t Train_Loss: 49.0212 Val_Loss: 170.9364  BEST VAL Loss: 170.9364\n",
            "\n",
            "Epoch 770: Validation loss decreased (170.936447 --> 170.497879).\n",
            "\t Train_Loss: 48.9695 Val_Loss: 170.4979  BEST VAL Loss: 170.4979\n",
            "\n",
            "Epoch 771: Validation loss decreased (170.497879 --> 170.080444).\n",
            "\t Train_Loss: 48.7649 Val_Loss: 170.0804  BEST VAL Loss: 170.0804\n",
            "\n",
            "Epoch 772: Validation loss decreased (170.080444 --> 169.516006).\n",
            "\t Train_Loss: 48.6349 Val_Loss: 169.5160  BEST VAL Loss: 169.5160\n",
            "\n",
            "Epoch 773: Validation loss decreased (169.516006 --> 168.841827).\n",
            "\t Train_Loss: 48.5223 Val_Loss: 168.8418  BEST VAL Loss: 168.8418\n",
            "\n",
            "Epoch 774: Validation loss decreased (168.841827 --> 168.263458).\n",
            "\t Train_Loss: 48.3922 Val_Loss: 168.2635  BEST VAL Loss: 168.2635\n",
            "\n",
            "Epoch 775: Validation loss decreased (168.263458 --> 167.894012).\n",
            "\t Train_Loss: 48.2998 Val_Loss: 167.8940  BEST VAL Loss: 167.8940\n",
            "\n",
            "Epoch 776: Validation loss decreased (167.894012 --> 167.678986).\n",
            "\t Train_Loss: 48.1823 Val_Loss: 167.6790  BEST VAL Loss: 167.6790\n",
            "\n",
            "Epoch 777: Validation loss decreased (167.678986 --> 167.444855).\n",
            "\t Train_Loss: 48.0757 Val_Loss: 167.4449  BEST VAL Loss: 167.4449\n",
            "\n",
            "Epoch 778: Validation loss decreased (167.444855 --> 167.176697).\n",
            "\t Train_Loss: 47.9739 Val_Loss: 167.1767  BEST VAL Loss: 167.1767\n",
            "\n",
            "Epoch 779: Validation loss did not decrease\n",
            "\t Train_Loss: 47.8305 Val_Loss: 167.8053  BEST VAL Loss: 167.1767\n",
            "\n",
            "Epoch 780: Validation loss decreased (167.176697 --> 166.403366).\n",
            "\t Train_Loss: 47.7512 Val_Loss: 166.4034  BEST VAL Loss: 166.4034\n",
            "\n",
            "Epoch 781: Validation loss decreased (166.403366 --> 166.280319).\n",
            "\t Train_Loss: 47.5811 Val_Loss: 166.2803  BEST VAL Loss: 166.2803\n",
            "\n",
            "Epoch 782: Validation loss decreased (166.280319 --> 166.053787).\n",
            "\t Train_Loss: 47.4866 Val_Loss: 166.0538  BEST VAL Loss: 166.0538\n",
            "\n",
            "Epoch 783: Validation loss decreased (166.053787 --> 165.705536).\n",
            "\t Train_Loss: 47.3207 Val_Loss: 165.7055  BEST VAL Loss: 165.7055\n",
            "\n",
            "Epoch 784: Validation loss decreased (165.705536 --> 165.539017).\n",
            "\t Train_Loss: 46.9709 Val_Loss: 165.5390  BEST VAL Loss: 165.5390\n",
            "\n",
            "Epoch 785: Validation loss did not decrease\n",
            "\t Train_Loss: 46.0046 Val_Loss: 168.9673  BEST VAL Loss: 165.5390\n",
            "\n",
            "Epoch 786: Validation loss decreased (165.539017 --> 165.245911).\n",
            "\t Train_Loss: 45.6748 Val_Loss: 165.2459  BEST VAL Loss: 165.2459\n",
            "\n",
            "Epoch 787: Validation loss decreased (165.245911 --> 164.522369).\n",
            "\t Train_Loss: 45.0834 Val_Loss: 164.5224  BEST VAL Loss: 164.5224\n",
            "\n",
            "Epoch 788: Validation loss did not decrease\n",
            "\t Train_Loss: 44.9688 Val_Loss: 166.3144  BEST VAL Loss: 164.5224\n",
            "\n",
            "Epoch 789: Validation loss decreased (164.522369 --> 164.257263).\n",
            "\t Train_Loss: 44.6743 Val_Loss: 164.2573  BEST VAL Loss: 164.2573\n",
            "\n",
            "Epoch 790: Validation loss decreased (164.257263 --> 163.014557).\n",
            "\t Train_Loss: 44.1486 Val_Loss: 163.0146  BEST VAL Loss: 163.0146\n",
            "\n",
            "Epoch 791: Validation loss decreased (163.014557 --> 162.835922).\n",
            "\t Train_Loss: 44.1675 Val_Loss: 162.8359  BEST VAL Loss: 162.8359\n",
            "\n",
            "Epoch 792: Validation loss did not decrease\n",
            "\t Train_Loss: 43.8241 Val_Loss: 163.2319  BEST VAL Loss: 162.8359\n",
            "\n",
            "Epoch 793: Validation loss did not decrease\n",
            "\t Train_Loss: 43.5350 Val_Loss: 163.0398  BEST VAL Loss: 162.8359\n",
            "\n",
            "Epoch 794: Validation loss decreased (162.835922 --> 162.078644).\n",
            "\t Train_Loss: 43.2845 Val_Loss: 162.0786  BEST VAL Loss: 162.0786\n",
            "\n",
            "Epoch 795: Validation loss decreased (162.078644 --> 161.814301).\n",
            "\t Train_Loss: 43.1214 Val_Loss: 161.8143  BEST VAL Loss: 161.8143\n",
            "\n",
            "Epoch 796: Validation loss did not decrease\n",
            "\t Train_Loss: 42.8823 Val_Loss: 164.3577  BEST VAL Loss: 161.8143\n",
            "\n",
            "Epoch 797: Validation loss decreased (161.814301 --> 161.199097).\n",
            "\t Train_Loss: 42.7203 Val_Loss: 161.1991  BEST VAL Loss: 161.1991\n",
            "\n",
            "Epoch 798: Validation loss decreased (161.199097 --> 160.436264).\n",
            "\t Train_Loss: 42.3639 Val_Loss: 160.4363  BEST VAL Loss: 160.4363\n",
            "\n",
            "Epoch 799: Validation loss decreased (160.436264 --> 160.126511).\n",
            "\t Train_Loss: 42.2005 Val_Loss: 160.1265  BEST VAL Loss: 160.1265\n",
            "\n",
            "Epoch 800: Validation loss decreased (160.126511 --> 159.943909).\n",
            "\t Train_Loss: 42.0351 Val_Loss: 159.9439  BEST VAL Loss: 159.9439\n",
            "\n",
            "Epoch 801: Validation loss decreased (159.943909 --> 159.435638).\n",
            "\t Train_Loss: 41.8621 Val_Loss: 159.4356  BEST VAL Loss: 159.4356\n",
            "\n",
            "Epoch 802: Validation loss decreased (159.435638 --> 158.753082).\n",
            "\t Train_Loss: 41.6224 Val_Loss: 158.7531  BEST VAL Loss: 158.7531\n",
            "\n",
            "Epoch 803: Validation loss decreased (158.753082 --> 158.325546).\n",
            "\t Train_Loss: 41.3951 Val_Loss: 158.3255  BEST VAL Loss: 158.3255\n",
            "\n",
            "Epoch 804: Validation loss decreased (158.325546 --> 158.123276).\n",
            "\t Train_Loss: 41.2243 Val_Loss: 158.1233  BEST VAL Loss: 158.1233\n",
            "\n",
            "Epoch 805: Validation loss decreased (158.123276 --> 157.707245).\n",
            "\t Train_Loss: 41.0634 Val_Loss: 157.7072  BEST VAL Loss: 157.7072\n",
            "\n",
            "Epoch 806: Validation loss decreased (157.707245 --> 157.206451).\n",
            "\t Train_Loss: 40.8631 Val_Loss: 157.2065  BEST VAL Loss: 157.2065\n",
            "\n",
            "Epoch 807: Validation loss decreased (157.206451 --> 156.773010).\n",
            "\t Train_Loss: 40.6842 Val_Loss: 156.7730  BEST VAL Loss: 156.7730\n",
            "\n",
            "Epoch 808: Validation loss decreased (156.773010 --> 156.354080).\n",
            "\t Train_Loss: 40.5076 Val_Loss: 156.3541  BEST VAL Loss: 156.3541\n",
            "\n",
            "Epoch 809: Validation loss decreased (156.354080 --> 155.835114).\n",
            "\t Train_Loss: 40.3217 Val_Loss: 155.8351  BEST VAL Loss: 155.8351\n",
            "\n",
            "Epoch 810: Validation loss decreased (155.835114 --> 155.267395).\n",
            "\t Train_Loss: 40.1369 Val_Loss: 155.2674  BEST VAL Loss: 155.2674\n",
            "\n",
            "Epoch 811: Validation loss decreased (155.267395 --> 154.790787).\n",
            "\t Train_Loss: 39.9654 Val_Loss: 154.7908  BEST VAL Loss: 154.7908\n",
            "\n",
            "Epoch 812: Validation loss decreased (154.790787 --> 154.419769).\n",
            "\t Train_Loss: 39.7937 Val_Loss: 154.4198  BEST VAL Loss: 154.4198\n",
            "\n",
            "Epoch 813: Validation loss decreased (154.419769 --> 154.047882).\n",
            "\t Train_Loss: 39.6023 Val_Loss: 154.0479  BEST VAL Loss: 154.0479\n",
            "\n",
            "Epoch 814: Validation loss decreased (154.047882 --> 153.623093).\n",
            "\t Train_Loss: 39.4147 Val_Loss: 153.6231  BEST VAL Loss: 153.6231\n",
            "\n",
            "Epoch 815: Validation loss decreased (153.623093 --> 153.197800).\n",
            "\t Train_Loss: 39.2430 Val_Loss: 153.1978  BEST VAL Loss: 153.1978\n",
            "\n",
            "Epoch 816: Validation loss decreased (153.197800 --> 152.786545).\n",
            "\t Train_Loss: 39.0751 Val_Loss: 152.7865  BEST VAL Loss: 152.7865\n",
            "\n",
            "Epoch 817: Validation loss decreased (152.786545 --> 152.330688).\n",
            "\t Train_Loss: 38.8958 Val_Loss: 152.3307  BEST VAL Loss: 152.3307\n",
            "\n",
            "Epoch 818: Validation loss decreased (152.330688 --> 151.831696).\n",
            "\t Train_Loss: 38.7131 Val_Loss: 151.8317  BEST VAL Loss: 151.8317\n",
            "\n",
            "Epoch 819: Validation loss decreased (151.831696 --> 151.383942).\n",
            "\t Train_Loss: 38.5342 Val_Loss: 151.3839  BEST VAL Loss: 151.3839\n",
            "\n",
            "Epoch 820: Validation loss decreased (151.383942 --> 151.002686).\n",
            "\t Train_Loss: 38.3615 Val_Loss: 151.0027  BEST VAL Loss: 151.0027\n",
            "\n",
            "Epoch 821: Validation loss decreased (151.002686 --> 150.592209).\n",
            "\t Train_Loss: 38.1869 Val_Loss: 150.5922  BEST VAL Loss: 150.5922\n",
            "\n",
            "Epoch 822: Validation loss decreased (150.592209 --> 150.185913).\n",
            "\t Train_Loss: 38.0093 Val_Loss: 150.1859  BEST VAL Loss: 150.1859\n",
            "\n",
            "Epoch 823: Validation loss decreased (150.185913 --> 149.808426).\n",
            "\t Train_Loss: 37.8377 Val_Loss: 149.8084  BEST VAL Loss: 149.8084\n",
            "\n",
            "Epoch 824: Validation loss decreased (149.808426 --> 149.399506).\n",
            "\t Train_Loss: 37.6681 Val_Loss: 149.3995  BEST VAL Loss: 149.3995\n",
            "\n",
            "Epoch 825: Validation loss decreased (149.399506 --> 148.943939).\n",
            "\t Train_Loss: 37.4967 Val_Loss: 148.9439  BEST VAL Loss: 148.9439\n",
            "\n",
            "Epoch 826: Validation loss decreased (148.943939 --> 148.506683).\n",
            "\t Train_Loss: 37.3260 Val_Loss: 148.5067  BEST VAL Loss: 148.5067\n",
            "\n",
            "Epoch 827: Validation loss decreased (148.506683 --> 148.079666).\n",
            "\t Train_Loss: 37.1592 Val_Loss: 148.0797  BEST VAL Loss: 148.0797\n",
            "\n",
            "Epoch 828: Validation loss decreased (148.079666 --> 147.641678).\n",
            "\t Train_Loss: 36.9965 Val_Loss: 147.6417  BEST VAL Loss: 147.6417\n",
            "\n",
            "Epoch 829: Validation loss decreased (147.641678 --> 147.249710).\n",
            "\t Train_Loss: 36.8360 Val_Loss: 147.2497  BEST VAL Loss: 147.2497\n",
            "\n",
            "Epoch 830: Validation loss decreased (147.249710 --> 146.871445).\n",
            "\t Train_Loss: 36.6762 Val_Loss: 146.8714  BEST VAL Loss: 146.8714\n",
            "\n",
            "Epoch 831: Validation loss decreased (146.871445 --> 146.468872).\n",
            "\t Train_Loss: 36.5192 Val_Loss: 146.4689  BEST VAL Loss: 146.4689\n",
            "\n",
            "Epoch 832: Validation loss decreased (146.468872 --> 146.094452).\n",
            "\t Train_Loss: 36.3660 Val_Loss: 146.0945  BEST VAL Loss: 146.0945\n",
            "\n",
            "Epoch 833: Validation loss decreased (146.094452 --> 145.699051).\n",
            "\t Train_Loss: 36.2160 Val_Loss: 145.6991  BEST VAL Loss: 145.6991\n",
            "\n",
            "Epoch 834: Validation loss decreased (145.699051 --> 145.288483).\n",
            "\t Train_Loss: 36.0704 Val_Loss: 145.2885  BEST VAL Loss: 145.2885\n",
            "\n",
            "Epoch 835: Validation loss decreased (145.288483 --> 144.910385).\n",
            "\t Train_Loss: 35.9286 Val_Loss: 144.9104  BEST VAL Loss: 144.9104\n",
            "\n",
            "Epoch 836: Validation loss decreased (144.910385 --> 144.518829).\n",
            "\t Train_Loss: 35.7894 Val_Loss: 144.5188  BEST VAL Loss: 144.5188\n",
            "\n",
            "Epoch 837: Validation loss decreased (144.518829 --> 144.151520).\n",
            "\t Train_Loss: 35.6529 Val_Loss: 144.1515  BEST VAL Loss: 144.1515\n",
            "\n",
            "Epoch 838: Validation loss decreased (144.151520 --> 143.813354).\n",
            "\t Train_Loss: 35.5194 Val_Loss: 143.8134  BEST VAL Loss: 143.8134\n",
            "\n",
            "Epoch 839: Validation loss decreased (143.813354 --> 143.466171).\n",
            "\t Train_Loss: 35.3890 Val_Loss: 143.4662  BEST VAL Loss: 143.4662\n",
            "\n",
            "Epoch 840: Validation loss decreased (143.466171 --> 143.155640).\n",
            "\t Train_Loss: 35.2607 Val_Loss: 143.1556  BEST VAL Loss: 143.1556\n",
            "\n",
            "Epoch 841: Validation loss decreased (143.155640 --> 142.829224).\n",
            "\t Train_Loss: 35.1333 Val_Loss: 142.8292  BEST VAL Loss: 142.8292\n",
            "\n",
            "Epoch 842: Validation loss decreased (142.829224 --> 142.498199).\n",
            "\t Train_Loss: 35.0077 Val_Loss: 142.4982  BEST VAL Loss: 142.4982\n",
            "\n",
            "Epoch 843: Validation loss decreased (142.498199 --> 142.169891).\n",
            "\t Train_Loss: 34.8837 Val_Loss: 142.1699  BEST VAL Loss: 142.1699\n",
            "\n",
            "Epoch 844: Validation loss decreased (142.169891 --> 141.815384).\n",
            "\t Train_Loss: 34.7610 Val_Loss: 141.8154  BEST VAL Loss: 141.8154\n",
            "\n",
            "Epoch 845: Validation loss decreased (141.815384 --> 141.480881).\n",
            "\t Train_Loss: 34.6391 Val_Loss: 141.4809  BEST VAL Loss: 141.4809\n",
            "\n",
            "Epoch 846: Validation loss decreased (141.480881 --> 141.134277).\n",
            "\t Train_Loss: 34.5176 Val_Loss: 141.1343  BEST VAL Loss: 141.1343\n",
            "\n",
            "Epoch 847: Validation loss decreased (141.134277 --> 140.803101).\n",
            "\t Train_Loss: 34.3973 Val_Loss: 140.8031  BEST VAL Loss: 140.8031\n",
            "\n",
            "Epoch 848: Validation loss decreased (140.803101 --> 140.483368).\n",
            "\t Train_Loss: 34.2781 Val_Loss: 140.4834  BEST VAL Loss: 140.4834\n",
            "\n",
            "Epoch 849: Validation loss decreased (140.483368 --> 140.161926).\n",
            "\t Train_Loss: 34.1593 Val_Loss: 140.1619  BEST VAL Loss: 140.1619\n",
            "\n",
            "Epoch 850: Validation loss decreased (140.161926 --> 139.859924).\n",
            "\t Train_Loss: 34.0407 Val_Loss: 139.8599  BEST VAL Loss: 139.8599\n",
            "\n",
            "Epoch 851: Validation loss decreased (139.859924 --> 139.539734).\n",
            "\t Train_Loss: 33.9228 Val_Loss: 139.5397  BEST VAL Loss: 139.5397\n",
            "\n",
            "Epoch 852: Validation loss decreased (139.539734 --> 139.228592).\n",
            "\t Train_Loss: 33.8058 Val_Loss: 139.2286  BEST VAL Loss: 139.2286\n",
            "\n",
            "Epoch 853: Validation loss decreased (139.228592 --> 138.893661).\n",
            "\t Train_Loss: 33.6897 Val_Loss: 138.8937  BEST VAL Loss: 138.8937\n",
            "\n",
            "Epoch 854: Validation loss decreased (138.893661 --> 138.560715).\n",
            "\t Train_Loss: 33.5739 Val_Loss: 138.5607  BEST VAL Loss: 138.5607\n",
            "\n",
            "Epoch 855: Validation loss decreased (138.560715 --> 138.213089).\n",
            "\t Train_Loss: 33.4587 Val_Loss: 138.2131  BEST VAL Loss: 138.2131\n",
            "\n",
            "Epoch 856: Validation loss decreased (138.213089 --> 137.870758).\n",
            "\t Train_Loss: 33.3444 Val_Loss: 137.8708  BEST VAL Loss: 137.8708\n",
            "\n",
            "Epoch 857: Validation loss decreased (137.870758 --> 137.527161).\n",
            "\t Train_Loss: 33.2309 Val_Loss: 137.5272  BEST VAL Loss: 137.5272\n",
            "\n",
            "Epoch 858: Validation loss decreased (137.527161 --> 137.194290).\n",
            "\t Train_Loss: 33.1180 Val_Loss: 137.1943  BEST VAL Loss: 137.1943\n",
            "\n",
            "Epoch 859: Validation loss decreased (137.194290 --> 136.865250).\n",
            "\t Train_Loss: 33.0057 Val_Loss: 136.8652  BEST VAL Loss: 136.8652\n",
            "\n",
            "Epoch 860: Validation loss decreased (136.865250 --> 136.545868).\n",
            "\t Train_Loss: 32.8939 Val_Loss: 136.5459  BEST VAL Loss: 136.5459\n",
            "\n",
            "Epoch 861: Validation loss decreased (136.545868 --> 136.223663).\n",
            "\t Train_Loss: 32.7828 Val_Loss: 136.2237  BEST VAL Loss: 136.2237\n",
            "\n",
            "Epoch 862: Validation loss decreased (136.223663 --> 135.910004).\n",
            "\t Train_Loss: 32.6721 Val_Loss: 135.9100  BEST VAL Loss: 135.9100\n",
            "\n",
            "Epoch 863: Validation loss decreased (135.910004 --> 135.581573).\n",
            "\t Train_Loss: 32.5618 Val_Loss: 135.5816  BEST VAL Loss: 135.5816\n",
            "\n",
            "Epoch 864: Validation loss decreased (135.581573 --> 135.281097).\n",
            "\t Train_Loss: 32.4519 Val_Loss: 135.2811  BEST VAL Loss: 135.2811\n",
            "\n",
            "Epoch 865: Validation loss decreased (135.281097 --> 134.932449).\n",
            "\t Train_Loss: 32.3425 Val_Loss: 134.9324  BEST VAL Loss: 134.9324\n",
            "\n",
            "Epoch 866: Validation loss decreased (134.932449 --> 134.694046).\n",
            "\t Train_Loss: 32.2348 Val_Loss: 134.6940  BEST VAL Loss: 134.6940\n",
            "\n",
            "Epoch 867: Validation loss decreased (134.694046 --> 134.244095).\n",
            "\t Train_Loss: 32.1337 Val_Loss: 134.2441  BEST VAL Loss: 134.2441\n",
            "\n",
            "Epoch 868: Validation loss did not decrease\n",
            "\t Train_Loss: 32.0657 Val_Loss: 134.2891  BEST VAL Loss: 134.2441\n",
            "\n",
            "Epoch 869: Validation loss decreased (134.244095 --> 133.311066).\n",
            "\t Train_Loss: 32.1619 Val_Loss: 133.3111  BEST VAL Loss: 133.3111\n",
            "\n",
            "Epoch 870: Validation loss did not decrease\n",
            "\t Train_Loss: 33.0390 Val_Loss: 134.9367  BEST VAL Loss: 133.3111\n",
            "\n",
            "Epoch 871: Validation loss decreased (133.311066 --> 132.027557).\n",
            "\t Train_Loss: 36.3311 Val_Loss: 132.0276  BEST VAL Loss: 132.0276\n",
            "\n",
            "Epoch 872: Validation loss did not decrease\n",
            "\t Train_Loss: 38.4099 Val_Loss: 133.9314  BEST VAL Loss: 132.0276\n",
            "\n",
            "Epoch 873: Validation loss did not decrease\n",
            "\t Train_Loss: 33.8535 Val_Loss: 132.8956  BEST VAL Loss: 132.0276\n",
            "\n",
            "Epoch 874: Validation loss decreased (132.027557 --> 131.854248).\n",
            "\t Train_Loss: 31.8573 Val_Loss: 131.8542  BEST VAL Loss: 131.8542\n",
            "\n",
            "Epoch 875: Validation loss did not decrease\n",
            "\t Train_Loss: 34.5067 Val_Loss: 133.2793  BEST VAL Loss: 131.8542\n",
            "\n",
            "Epoch 876: Validation loss did not decrease\n",
            "\t Train_Loss: 33.2977 Val_Loss: 132.5306  BEST VAL Loss: 131.8542\n",
            "\n",
            "Epoch 877: Validation loss decreased (131.854248 --> 131.848480).\n",
            "\t Train_Loss: 31.3807 Val_Loss: 131.8485  BEST VAL Loss: 131.8485\n",
            "\n",
            "Epoch 878: Validation loss did not decrease\n",
            "\t Train_Loss: 33.1492 Val_Loss: 132.9256  BEST VAL Loss: 131.8485\n",
            "\n",
            "Epoch 879: Validation loss did not decrease\n",
            "\t Train_Loss: 32.2537 Val_Loss: 132.3165  BEST VAL Loss: 131.8485\n",
            "\n",
            "Epoch 880: Validation loss decreased (131.848480 --> 131.572403).\n",
            "\t Train_Loss: 31.0219 Val_Loss: 131.5724  BEST VAL Loss: 131.5724\n",
            "\n",
            "Epoch 881: Validation loss did not decrease\n",
            "\t Train_Loss: 32.3188 Val_Loss: 133.0827  BEST VAL Loss: 131.5724\n",
            "\n",
            "Epoch 882: Validation loss did not decrease\n",
            "\t Train_Loss: 31.4310 Val_Loss: 131.8956  BEST VAL Loss: 131.5724\n",
            "\n",
            "Epoch 883: Validation loss decreased (131.572403 --> 130.413300).\n",
            "\t Train_Loss: 30.8542 Val_Loss: 130.4133  BEST VAL Loss: 130.4133\n",
            "\n",
            "Epoch 884: Validation loss did not decrease\n",
            "\t Train_Loss: 31.4894 Val_Loss: 130.5385  BEST VAL Loss: 130.4133\n",
            "\n",
            "Epoch 885: Validation loss decreased (130.413300 --> 130.227692).\n",
            "\t Train_Loss: 30.5959 Val_Loss: 130.2277  BEST VAL Loss: 130.2277\n",
            "\n",
            "Epoch 886: Validation loss decreased (130.227692 --> 129.298676).\n",
            "\t Train_Loss: 30.7132 Val_Loss: 129.2987  BEST VAL Loss: 129.2987\n",
            "\n",
            "Epoch 887: Validation loss did not decrease\n",
            "\t Train_Loss: 30.9020 Val_Loss: 129.3049  BEST VAL Loss: 129.2987\n",
            "\n",
            "Epoch 888: Validation loss decreased (129.298676 --> 129.289185).\n",
            "\t Train_Loss: 30.1454 Val_Loss: 129.2892  BEST VAL Loss: 129.2892\n",
            "\n",
            "Epoch 889: Validation loss decreased (129.289185 --> 128.459991).\n",
            "\t Train_Loss: 30.4427 Val_Loss: 128.4600  BEST VAL Loss: 128.4600\n",
            "\n",
            "Epoch 890: Validation loss decreased (128.459991 --> 128.437012).\n",
            "\t Train_Loss: 30.2461 Val_Loss: 128.4370  BEST VAL Loss: 128.4370\n",
            "\n",
            "Epoch 891: Validation loss did not decrease\n",
            "\t Train_Loss: 29.7534 Val_Loss: 128.6115  BEST VAL Loss: 128.4370\n",
            "\n",
            "Epoch 892: Validation loss decreased (128.437012 --> 127.847778).\n",
            "\t Train_Loss: 30.0254 Val_Loss: 127.8478  BEST VAL Loss: 127.8478\n",
            "\n",
            "Epoch 893: Validation loss decreased (127.847778 --> 127.679031).\n",
            "\t Train_Loss: 29.8058 Val_Loss: 127.6790  BEST VAL Loss: 127.6790\n",
            "\n",
            "Epoch 894: Validation loss decreased (127.679031 --> 127.625656).\n",
            "\t Train_Loss: 29.3963 Val_Loss: 127.6257  BEST VAL Loss: 127.6257\n",
            "\n",
            "Epoch 895: Validation loss decreased (127.625656 --> 126.671486).\n",
            "\t Train_Loss: 29.5410 Val_Loss: 126.6715  BEST VAL Loss: 126.6715\n",
            "\n",
            "Epoch 896: Validation loss decreased (126.671486 --> 126.569618).\n",
            "\t Train_Loss: 29.4438 Val_Loss: 126.5696  BEST VAL Loss: 126.5696\n",
            "\n",
            "Epoch 897: Validation loss decreased (126.569618 --> 126.336548).\n",
            "\t Train_Loss: 29.0659 Val_Loss: 126.3365  BEST VAL Loss: 126.3365\n",
            "\n",
            "Epoch 898: Validation loss decreased (126.336548 --> 125.694946).\n",
            "\t Train_Loss: 29.0837 Val_Loss: 125.6949  BEST VAL Loss: 125.6949\n",
            "\n",
            "Epoch 899: Validation loss did not decrease\n",
            "\t Train_Loss: 29.0569 Val_Loss: 125.7717  BEST VAL Loss: 125.6949\n",
            "\n",
            "Epoch 900: Validation loss decreased (125.694946 --> 125.610275).\n",
            "\t Train_Loss: 28.7251 Val_Loss: 125.6103  BEST VAL Loss: 125.6103\n",
            "\n",
            "Epoch 901: Validation loss decreased (125.610275 --> 125.239830).\n",
            "\t Train_Loss: 28.5697 Val_Loss: 125.2398  BEST VAL Loss: 125.2398\n",
            "\n",
            "Epoch 902: Validation loss did not decrease\n",
            "\t Train_Loss: 28.6065 Val_Loss: 125.4845  BEST VAL Loss: 125.2398\n",
            "\n",
            "Epoch 903: Validation loss decreased (125.239830 --> 124.796692).\n",
            "\t Train_Loss: 28.4754 Val_Loss: 124.7967  BEST VAL Loss: 124.7967\n",
            "\n",
            "Epoch 904: Validation loss decreased (124.796692 --> 124.421303).\n",
            "\t Train_Loss: 28.1740 Val_Loss: 124.4213  BEST VAL Loss: 124.4213\n",
            "\n",
            "Epoch 905: Validation loss decreased (124.421303 --> 124.275963).\n",
            "\t Train_Loss: 28.0157 Val_Loss: 124.2760  BEST VAL Loss: 124.2760\n",
            "\n",
            "Epoch 906: Validation loss decreased (124.275963 --> 123.667931).\n",
            "\t Train_Loss: 27.9963 Val_Loss: 123.6679  BEST VAL Loss: 123.6679\n",
            "\n",
            "Epoch 907: Validation loss decreased (123.667931 --> 123.611023).\n",
            "\t Train_Loss: 27.8728 Val_Loss: 123.6110  BEST VAL Loss: 123.6110\n",
            "\n",
            "Epoch 908: Validation loss decreased (123.611023 --> 123.315018).\n",
            "\t Train_Loss: 27.6381 Val_Loss: 123.3150  BEST VAL Loss: 123.3150\n",
            "\n",
            "Epoch 909: Validation loss decreased (123.315018 --> 123.040787).\n",
            "\t Train_Loss: 27.4360 Val_Loss: 123.0408  BEST VAL Loss: 123.0408\n",
            "\n",
            "Epoch 910: Validation loss did not decrease\n",
            "\t Train_Loss: 27.3447 Val_Loss: 123.0927  BEST VAL Loss: 123.0408\n",
            "\n",
            "Epoch 911: Validation loss decreased (123.040787 --> 122.431152).\n",
            "\t Train_Loss: 27.2868 Val_Loss: 122.4312  BEST VAL Loss: 122.4312\n",
            "\n",
            "Epoch 912: Validation loss decreased (122.431152 --> 122.391197).\n",
            "\t Train_Loss: 27.1678 Val_Loss: 122.3912  BEST VAL Loss: 122.3912\n",
            "\n",
            "Epoch 913: Validation loss decreased (122.391197 --> 121.793625).\n",
            "\t Train_Loss: 26.9966 Val_Loss: 121.7936  BEST VAL Loss: 121.7936\n",
            "\n",
            "Epoch 914: Validation loss decreased (121.793625 --> 121.633018).\n",
            "\t Train_Loss: 26.7884 Val_Loss: 121.6330  BEST VAL Loss: 121.6330\n",
            "\n",
            "Epoch 915: Validation loss decreased (121.633018 --> 121.246536).\n",
            "\t Train_Loss: 26.5790 Val_Loss: 121.2465  BEST VAL Loss: 121.2465\n",
            "\n",
            "Epoch 916: Validation loss decreased (121.246536 --> 120.987450).\n",
            "\t Train_Loss: 26.3859 Val_Loss: 120.9874  BEST VAL Loss: 120.9874\n",
            "\n",
            "Epoch 917: Validation loss decreased (120.987450 --> 120.817650).\n",
            "\t Train_Loss: 26.2264 Val_Loss: 120.8176  BEST VAL Loss: 120.8176\n",
            "\n",
            "Epoch 918: Validation loss decreased (120.817650 --> 120.385574).\n",
            "\t Train_Loss: 26.0970 Val_Loss: 120.3856  BEST VAL Loss: 120.3856\n",
            "\n",
            "Epoch 919: Validation loss decreased (120.385574 --> 120.334793).\n",
            "\t Train_Loss: 25.9848 Val_Loss: 120.3348  BEST VAL Loss: 120.3348\n",
            "\n",
            "Epoch 920: Validation loss decreased (120.334793 --> 119.727982).\n",
            "\t Train_Loss: 25.9095 Val_Loss: 119.7280  BEST VAL Loss: 119.7280\n",
            "\n",
            "Epoch 921: Validation loss did not decrease\n",
            "\t Train_Loss: 25.9005 Val_Loss: 119.8540  BEST VAL Loss: 119.7280\n",
            "\n",
            "Epoch 922: Validation loss decreased (119.727982 --> 119.042458).\n",
            "\t Train_Loss: 25.9535 Val_Loss: 119.0425  BEST VAL Loss: 119.0425\n",
            "\n",
            "Epoch 923: Validation loss did not decrease\n",
            "\t Train_Loss: 26.0617 Val_Loss: 119.3351  BEST VAL Loss: 119.0425\n",
            "\n",
            "Epoch 924: Validation loss decreased (119.042458 --> 118.381813).\n",
            "\t Train_Loss: 26.0918 Val_Loss: 118.3818  BEST VAL Loss: 118.3818\n",
            "\n",
            "Epoch 925: Validation loss did not decrease\n",
            "\t Train_Loss: 26.0076 Val_Loss: 118.6824  BEST VAL Loss: 118.3818\n",
            "\n",
            "Epoch 926: Validation loss decreased (118.381813 --> 117.912071).\n",
            "\t Train_Loss: 25.5784 Val_Loss: 117.9121  BEST VAL Loss: 117.9121\n",
            "\n",
            "Epoch 927: Validation loss did not decrease\n",
            "\t Train_Loss: 25.0254 Val_Loss: 117.9214  BEST VAL Loss: 117.9121\n",
            "\n",
            "Epoch 928: Validation loss decreased (117.912071 --> 117.737015).\n",
            "\t Train_Loss: 24.5747 Val_Loss: 117.7370  BEST VAL Loss: 117.7370\n",
            "\n",
            "Epoch 929: Validation loss decreased (117.737015 --> 117.343445).\n",
            "\t Train_Loss: 24.4224 Val_Loss: 117.3434  BEST VAL Loss: 117.3434\n",
            "\n",
            "Epoch 930: Validation loss did not decrease\n",
            "\t Train_Loss: 24.4878 Val_Loss: 117.5188  BEST VAL Loss: 117.3434\n",
            "\n",
            "Epoch 931: Validation loss decreased (117.343445 --> 116.839371).\n",
            "\t Train_Loss: 24.5055 Val_Loss: 116.8394  BEST VAL Loss: 116.8394\n",
            "\n",
            "Epoch 932: Validation loss decreased (116.839371 --> 116.796349).\n",
            "\t Train_Loss: 24.2817 Val_Loss: 116.7963  BEST VAL Loss: 116.7963\n",
            "\n",
            "Epoch 933: Validation loss decreased (116.796349 --> 116.383156).\n",
            "\t Train_Loss: 23.9052 Val_Loss: 116.3832  BEST VAL Loss: 116.3832\n",
            "\n",
            "Epoch 934: Validation loss decreased (116.383156 --> 115.961838).\n",
            "\t Train_Loss: 23.6672 Val_Loss: 115.9618  BEST VAL Loss: 115.9618\n",
            "\n",
            "Epoch 935: Validation loss decreased (115.961838 --> 115.936157).\n",
            "\t Train_Loss: 23.6471 Val_Loss: 115.9362  BEST VAL Loss: 115.9362\n",
            "\n",
            "Epoch 936: Validation loss decreased (115.936157 --> 115.428810).\n",
            "\t Train_Loss: 23.5895 Val_Loss: 115.4288  BEST VAL Loss: 115.4288\n",
            "\n",
            "Epoch 937: Validation loss decreased (115.428810 --> 115.296936).\n",
            "\t Train_Loss: 23.3505 Val_Loss: 115.2969  BEST VAL Loss: 115.2969\n",
            "\n",
            "Epoch 938: Validation loss decreased (115.296936 --> 115.118736).\n",
            "\t Train_Loss: 23.1143 Val_Loss: 115.1187  BEST VAL Loss: 115.1187\n",
            "\n",
            "Epoch 939: Validation loss decreased (115.118736 --> 114.667114).\n",
            "\t Train_Loss: 23.0333 Val_Loss: 114.6671  BEST VAL Loss: 114.6671\n",
            "\n",
            "Epoch 940: Validation loss decreased (114.667114 --> 114.597214).\n",
            "\t Train_Loss: 22.9747 Val_Loss: 114.5972  BEST VAL Loss: 114.5972\n",
            "\n",
            "Epoch 941: Validation loss decreased (114.597214 --> 114.192184).\n",
            "\t Train_Loss: 22.7882 Val_Loss: 114.1922  BEST VAL Loss: 114.1922\n",
            "\n",
            "Epoch 942: Validation loss decreased (114.192184 --> 113.876808).\n",
            "\t Train_Loss: 22.5691 Val_Loss: 113.8768  BEST VAL Loss: 113.8768\n",
            "\n",
            "Epoch 943: Validation loss decreased (113.876808 --> 113.757370).\n",
            "\t Train_Loss: 22.4283 Val_Loss: 113.7574  BEST VAL Loss: 113.7574\n",
            "\n",
            "Epoch 944: Validation loss decreased (113.757370 --> 113.420555).\n",
            "\t Train_Loss: 22.2499 Val_Loss: 113.4206  BEST VAL Loss: 113.4206\n",
            "\n",
            "Epoch 945: Validation loss did not decrease\n",
            "\t Train_Loss: 21.7994 Val_Loss: 113.8550  BEST VAL Loss: 113.4206\n",
            "\n",
            "Epoch 946: Validation loss did not decrease\n",
            "\t Train_Loss: 21.5845 Val_Loss: 113.7845  BEST VAL Loss: 113.4206\n",
            "\n",
            "Epoch 947: Validation loss decreased (113.420555 --> 112.816528).\n",
            "\t Train_Loss: 21.5467 Val_Loss: 112.8165  BEST VAL Loss: 112.8165\n",
            "\n",
            "Epoch 948: Validation loss decreased (112.816528 --> 112.493492).\n",
            "\t Train_Loss: 21.1646 Val_Loss: 112.4935  BEST VAL Loss: 112.4935\n",
            "\n",
            "Epoch 949: Validation loss decreased (112.493492 --> 112.154724).\n",
            "\t Train_Loss: 21.2160 Val_Loss: 112.1547  BEST VAL Loss: 112.1547\n",
            "\n",
            "Epoch 950: Validation loss did not decrease\n",
            "\t Train_Loss: 21.0621 Val_Loss: 112.2320  BEST VAL Loss: 112.1547\n",
            "\n",
            "Epoch 951: Validation loss did not decrease\n",
            "\t Train_Loss: 20.7650 Val_Loss: 112.2753  BEST VAL Loss: 112.1547\n",
            "\n",
            "Epoch 952: Validation loss decreased (112.154724 --> 111.863724).\n",
            "\t Train_Loss: 20.6870 Val_Loss: 111.8637  BEST VAL Loss: 111.8637\n",
            "\n",
            "Epoch 953: Validation loss decreased (111.863724 --> 111.445457).\n",
            "\t Train_Loss: 20.6535 Val_Loss: 111.4455  BEST VAL Loss: 111.4455\n",
            "\n",
            "Epoch 954: Validation loss decreased (111.445457 --> 110.908005).\n",
            "\t Train_Loss: 20.4394 Val_Loss: 110.9080  BEST VAL Loss: 110.9080\n",
            "\n",
            "Epoch 955: Validation loss decreased (110.908005 --> 110.446434).\n",
            "\t Train_Loss: 20.3253 Val_Loss: 110.4464  BEST VAL Loss: 110.4464\n",
            "\n",
            "Epoch 956: Validation loss decreased (110.446434 --> 110.334717).\n",
            "\t Train_Loss: 20.2856 Val_Loss: 110.3347  BEST VAL Loss: 110.3347\n",
            "\n",
            "Epoch 957: Validation loss decreased (110.334717 --> 110.236183).\n",
            "\t Train_Loss: 20.1383 Val_Loss: 110.2362  BEST VAL Loss: 110.2362\n",
            "\n",
            "Epoch 958: Validation loss decreased (110.236183 --> 110.006081).\n",
            "\t Train_Loss: 20.0035 Val_Loss: 110.0061  BEST VAL Loss: 110.0061\n",
            "\n",
            "Epoch 959: Validation loss decreased (110.006081 --> 109.815758).\n",
            "\t Train_Loss: 19.9374 Val_Loss: 109.8158  BEST VAL Loss: 109.8158\n",
            "\n",
            "Epoch 960: Validation loss decreased (109.815758 --> 109.347885).\n",
            "\t Train_Loss: 19.8240 Val_Loss: 109.3479  BEST VAL Loss: 109.3479\n",
            "\n",
            "Epoch 961: Validation loss decreased (109.347885 --> 108.782692).\n",
            "\t Train_Loss: 19.7111 Val_Loss: 108.7827  BEST VAL Loss: 108.7827\n",
            "\n",
            "Epoch 962: Validation loss decreased (108.782692 --> 108.431679).\n",
            "\t Train_Loss: 19.6310 Val_Loss: 108.4317  BEST VAL Loss: 108.4317\n",
            "\n",
            "Epoch 963: Validation loss decreased (108.431679 --> 108.109253).\n",
            "\t Train_Loss: 19.5327 Val_Loss: 108.1093  BEST VAL Loss: 108.1093\n",
            "\n",
            "Epoch 964: Validation loss decreased (108.109253 --> 107.841675).\n",
            "\t Train_Loss: 19.4424 Val_Loss: 107.8417  BEST VAL Loss: 107.8417\n",
            "\n",
            "Epoch 965: Validation loss decreased (107.841675 --> 107.708298).\n",
            "\t Train_Loss: 19.3682 Val_Loss: 107.7083  BEST VAL Loss: 107.7083\n",
            "\n",
            "Epoch 966: Validation loss decreased (107.708298 --> 107.473488).\n",
            "\t Train_Loss: 19.2780 Val_Loss: 107.4735  BEST VAL Loss: 107.4735\n",
            "\n",
            "Epoch 967: Validation loss decreased (107.473488 --> 107.154053).\n",
            "\t Train_Loss: 19.1906 Val_Loss: 107.1541  BEST VAL Loss: 107.1541\n",
            "\n",
            "Epoch 968: Validation loss decreased (107.154053 --> 106.868576).\n",
            "\t Train_Loss: 19.1163 Val_Loss: 106.8686  BEST VAL Loss: 106.8686\n",
            "\n",
            "Epoch 969: Validation loss decreased (106.868576 --> 106.494675).\n",
            "\t Train_Loss: 19.0251 Val_Loss: 106.4947  BEST VAL Loss: 106.4947\n",
            "\n",
            "Epoch 970: Validation loss decreased (106.494675 --> 106.135780).\n",
            "\t Train_Loss: 18.9393 Val_Loss: 106.1358  BEST VAL Loss: 106.1358\n",
            "\n",
            "Epoch 971: Validation loss decreased (106.135780 --> 105.895950).\n",
            "\t Train_Loss: 18.8687 Val_Loss: 105.8960  BEST VAL Loss: 105.8960\n",
            "\n",
            "Epoch 972: Validation loss decreased (105.895950 --> 105.653183).\n",
            "\t Train_Loss: 18.7825 Val_Loss: 105.6532  BEST VAL Loss: 105.6532\n",
            "\n",
            "Epoch 973: Validation loss decreased (105.653183 --> 105.415611).\n",
            "\t Train_Loss: 18.6980 Val_Loss: 105.4156  BEST VAL Loss: 105.4156\n",
            "\n",
            "Epoch 974: Validation loss decreased (105.415611 --> 105.242393).\n",
            "\t Train_Loss: 18.6256 Val_Loss: 105.2424  BEST VAL Loss: 105.2424\n",
            "\n",
            "Epoch 975: Validation loss decreased (105.242393 --> 104.997025).\n",
            "\t Train_Loss: 18.5462 Val_Loss: 104.9970  BEST VAL Loss: 104.9970\n",
            "\n",
            "Epoch 976: Validation loss decreased (104.997025 --> 104.693436).\n",
            "\t Train_Loss: 18.4668 Val_Loss: 104.6934  BEST VAL Loss: 104.6934\n",
            "\n",
            "Epoch 977: Validation loss decreased (104.693436 --> 104.431923).\n",
            "\t Train_Loss: 18.3925 Val_Loss: 104.4319  BEST VAL Loss: 104.4319\n",
            "\n",
            "Epoch 978: Validation loss decreased (104.431923 --> 104.126320).\n",
            "\t Train_Loss: 18.3134 Val_Loss: 104.1263  BEST VAL Loss: 104.1263\n",
            "\n",
            "Epoch 979: Validation loss decreased (104.126320 --> 103.827110).\n",
            "\t Train_Loss: 18.2370 Val_Loss: 103.8271  BEST VAL Loss: 103.8271\n",
            "\n",
            "Epoch 980: Validation loss decreased (103.827110 --> 103.597763).\n",
            "\t Train_Loss: 18.1659 Val_Loss: 103.5978  BEST VAL Loss: 103.5978\n",
            "\n",
            "Epoch 981: Validation loss decreased (103.597763 --> 103.340111).\n",
            "\t Train_Loss: 18.0892 Val_Loss: 103.3401  BEST VAL Loss: 103.3401\n",
            "\n",
            "Epoch 982: Validation loss decreased (103.340111 --> 103.078369).\n",
            "\t Train_Loss: 18.0115 Val_Loss: 103.0784  BEST VAL Loss: 103.0784\n",
            "\n",
            "Epoch 983: Validation loss decreased (103.078369 --> 102.849876).\n",
            "\t Train_Loss: 17.9396 Val_Loss: 102.8499  BEST VAL Loss: 102.8499\n",
            "\n",
            "Epoch 984: Validation loss decreased (102.849876 --> 102.558411).\n",
            "\t Train_Loss: 17.8673 Val_Loss: 102.5584  BEST VAL Loss: 102.5584\n",
            "\n",
            "Epoch 985: Validation loss decreased (102.558411 --> 102.265213).\n",
            "\t Train_Loss: 17.7925 Val_Loss: 102.2652  BEST VAL Loss: 102.2652\n",
            "\n",
            "Epoch 986: Validation loss decreased (102.265213 --> 102.002548).\n",
            "\t Train_Loss: 17.7196 Val_Loss: 102.0025  BEST VAL Loss: 102.0025\n",
            "\n",
            "Epoch 987: Validation loss decreased (102.002548 --> 101.717773).\n",
            "\t Train_Loss: 17.6485 Val_Loss: 101.7178  BEST VAL Loss: 101.7178\n",
            "\n",
            "Epoch 988: Validation loss decreased (101.717773 --> 101.470749).\n",
            "\t Train_Loss: 17.5766 Val_Loss: 101.4707  BEST VAL Loss: 101.4707\n",
            "\n",
            "Epoch 989: Validation loss decreased (101.470749 --> 101.238869).\n",
            "\t Train_Loss: 17.5048 Val_Loss: 101.2389  BEST VAL Loss: 101.2389\n",
            "\n",
            "Epoch 990: Validation loss decreased (101.238869 --> 100.981491).\n",
            "\t Train_Loss: 17.4339 Val_Loss: 100.9815  BEST VAL Loss: 100.9815\n",
            "\n",
            "Epoch 991: Validation loss decreased (100.981491 --> 100.748764).\n",
            "\t Train_Loss: 17.3637 Val_Loss: 100.7488  BEST VAL Loss: 100.7488\n",
            "\n",
            "Epoch 992: Validation loss decreased (100.748764 --> 100.487511).\n",
            "\t Train_Loss: 17.2933 Val_Loss: 100.4875  BEST VAL Loss: 100.4875\n",
            "\n",
            "Epoch 993: Validation loss decreased (100.487511 --> 100.216080).\n",
            "\t Train_Loss: 17.2230 Val_Loss: 100.2161  BEST VAL Loss: 100.2161\n",
            "\n",
            "Epoch 994: Validation loss decreased (100.216080 --> 99.971107).\n",
            "\t Train_Loss: 17.1536 Val_Loss: 99.9711  BEST VAL Loss: 99.9711\n",
            "\n",
            "Epoch 995: Validation loss decreased (99.971107 --> 99.711685).\n",
            "\t Train_Loss: 17.0851 Val_Loss: 99.7117  BEST VAL Loss: 99.7117\n",
            "\n",
            "Epoch 996: Validation loss decreased (99.711685 --> 99.479965).\n",
            "\t Train_Loss: 17.0163 Val_Loss: 99.4800  BEST VAL Loss: 99.4800\n",
            "\n",
            "Epoch 997: Validation loss decreased (99.479965 --> 99.249474).\n",
            "\t Train_Loss: 16.9471 Val_Loss: 99.2495  BEST VAL Loss: 99.2495\n",
            "\n",
            "Epoch 998: Validation loss decreased (99.249474 --> 99.007126).\n",
            "\t Train_Loss: 16.8788 Val_Loss: 99.0071  BEST VAL Loss: 99.0071\n",
            "\n",
            "Epoch 999: Validation loss decreased (99.007126 --> 98.777603).\n",
            "\t Train_Loss: 16.8116 Val_Loss: 98.7776  BEST VAL Loss: 98.7776\n",
            "\n",
            "Epoch 1000: Validation loss decreased (98.777603 --> 98.520088).\n",
            "\t Train_Loss: 16.7441 Val_Loss: 98.5201  BEST VAL Loss: 98.5201\n",
            "\n",
            "Epoch 1001: Validation loss decreased (98.520088 --> 98.276123).\n",
            "\t Train_Loss: 16.6760 Val_Loss: 98.2761  BEST VAL Loss: 98.2761\n",
            "\n",
            "Epoch 1002: Validation loss decreased (98.276123 --> 98.035004).\n",
            "\t Train_Loss: 16.6081 Val_Loss: 98.0350  BEST VAL Loss: 98.0350\n",
            "\n",
            "Epoch 1003: Validation loss decreased (98.035004 --> 97.793663).\n",
            "\t Train_Loss: 16.5410 Val_Loss: 97.7937  BEST VAL Loss: 97.7937\n",
            "\n",
            "Epoch 1004: Validation loss decreased (97.793663 --> 97.570900).\n",
            "\t Train_Loss: 16.4742 Val_Loss: 97.5709  BEST VAL Loss: 97.5709\n",
            "\n",
            "Epoch 1005: Validation loss decreased (97.570900 --> 97.332893).\n",
            "\t Train_Loss: 16.4072 Val_Loss: 97.3329  BEST VAL Loss: 97.3329\n",
            "\n",
            "Epoch 1006: Validation loss decreased (97.332893 --> 97.105362).\n",
            "\t Train_Loss: 16.3400 Val_Loss: 97.1054  BEST VAL Loss: 97.1054\n",
            "\n",
            "Epoch 1007: Validation loss decreased (97.105362 --> 96.867477).\n",
            "\t Train_Loss: 16.2729 Val_Loss: 96.8675  BEST VAL Loss: 96.8675\n",
            "\n",
            "Epoch 1008: Validation loss decreased (96.867477 --> 96.629875).\n",
            "\t Train_Loss: 16.2060 Val_Loss: 96.6299  BEST VAL Loss: 96.6299\n",
            "\n",
            "Epoch 1009: Validation loss decreased (96.629875 --> 96.401291).\n",
            "\t Train_Loss: 16.1393 Val_Loss: 96.4013  BEST VAL Loss: 96.4013\n",
            "\n",
            "Epoch 1010: Validation loss decreased (96.401291 --> 96.165733).\n",
            "\t Train_Loss: 16.0727 Val_Loss: 96.1657  BEST VAL Loss: 96.1657\n",
            "\n",
            "Epoch 1011: Validation loss decreased (96.165733 --> 95.942223).\n",
            "\t Train_Loss: 16.0061 Val_Loss: 95.9422  BEST VAL Loss: 95.9422\n",
            "\n",
            "Epoch 1012: Validation loss decreased (95.942223 --> 95.708847).\n",
            "\t Train_Loss: 15.9392 Val_Loss: 95.7088  BEST VAL Loss: 95.7088\n",
            "\n",
            "Epoch 1013: Validation loss decreased (95.708847 --> 95.479935).\n",
            "\t Train_Loss: 15.8722 Val_Loss: 95.4799  BEST VAL Loss: 95.4799\n",
            "\n",
            "Epoch 1014: Validation loss decreased (95.479935 --> 95.251511).\n",
            "\t Train_Loss: 15.8051 Val_Loss: 95.2515  BEST VAL Loss: 95.2515\n",
            "\n",
            "Epoch 1015: Validation loss decreased (95.251511 --> 95.022415).\n",
            "\t Train_Loss: 15.7380 Val_Loss: 95.0224  BEST VAL Loss: 95.0224\n",
            "\n",
            "Epoch 1016: Validation loss decreased (95.022415 --> 94.801956).\n",
            "\t Train_Loss: 15.6707 Val_Loss: 94.8020  BEST VAL Loss: 94.8020\n",
            "\n",
            "Epoch 1017: Validation loss decreased (94.801956 --> 94.573463).\n",
            "\t Train_Loss: 15.6032 Val_Loss: 94.5735  BEST VAL Loss: 94.5735\n",
            "\n",
            "Epoch 1018: Validation loss decreased (94.573463 --> 94.347870).\n",
            "\t Train_Loss: 15.5356 Val_Loss: 94.3479  BEST VAL Loss: 94.3479\n",
            "\n",
            "Epoch 1019: Validation loss decreased (94.347870 --> 94.114731).\n",
            "\t Train_Loss: 15.4680 Val_Loss: 94.1147  BEST VAL Loss: 94.1147\n",
            "\n",
            "Epoch 1020: Validation loss decreased (94.114731 --> 93.882530).\n",
            "\t Train_Loss: 15.4004 Val_Loss: 93.8825  BEST VAL Loss: 93.8825\n",
            "\n",
            "Epoch 1021: Validation loss decreased (93.882530 --> 93.654358).\n",
            "\t Train_Loss: 15.3331 Val_Loss: 93.6544  BEST VAL Loss: 93.6544\n",
            "\n",
            "Epoch 1022: Validation loss decreased (93.654358 --> 93.425552).\n",
            "\t Train_Loss: 15.2659 Val_Loss: 93.4256  BEST VAL Loss: 93.4256\n",
            "\n",
            "Epoch 1023: Validation loss decreased (93.425552 --> 93.201820).\n",
            "\t Train_Loss: 15.1988 Val_Loss: 93.2018  BEST VAL Loss: 93.2018\n",
            "\n",
            "Epoch 1024: Validation loss decreased (93.201820 --> 92.970215).\n",
            "\t Train_Loss: 15.1317 Val_Loss: 92.9702  BEST VAL Loss: 92.9702\n",
            "\n",
            "Epoch 1025: Validation loss decreased (92.970215 --> 92.745644).\n",
            "\t Train_Loss: 15.0645 Val_Loss: 92.7456  BEST VAL Loss: 92.7456\n",
            "\n",
            "Epoch 1026: Validation loss decreased (92.745644 --> 92.509399).\n",
            "\t Train_Loss: 14.9977 Val_Loss: 92.5094  BEST VAL Loss: 92.5094\n",
            "\n",
            "Epoch 1027: Validation loss decreased (92.509399 --> 92.294006).\n",
            "\t Train_Loss: 14.9327 Val_Loss: 92.2940  BEST VAL Loss: 92.2940\n",
            "\n",
            "Epoch 1028: Validation loss decreased (92.294006 --> 92.042862).\n",
            "\t Train_Loss: 14.8771 Val_Loss: 92.0429  BEST VAL Loss: 92.0429\n",
            "\n",
            "Epoch 1029: Validation loss decreased (92.042862 --> 91.883842).\n",
            "\t Train_Loss: 14.8794 Val_Loss: 91.8838  BEST VAL Loss: 91.8838\n",
            "\n",
            "Epoch 1030: Validation loss decreased (91.883842 --> 91.723267).\n",
            "\t Train_Loss: 15.2038 Val_Loss: 91.7233  BEST VAL Loss: 91.7233\n",
            "\n",
            "Epoch 1031: Validation loss did not decrease\n",
            "\t Train_Loss: 17.6984 Val_Loss: 92.0867  BEST VAL Loss: 91.7233\n",
            "\n",
            "Epoch 1032: Validation loss did not decrease\n",
            "\t Train_Loss: 19.2981 Val_Loss: 91.8282  BEST VAL Loss: 91.7233\n",
            "\n",
            "Epoch 1033: Validation loss did not decrease\n",
            "\t Train_Loss: 22.4877 Val_Loss: 91.8401  BEST VAL Loss: 91.7233\n",
            "\n",
            "Epoch 1034: Validation loss did not decrease\n",
            "\t Train_Loss: 16.5137 Val_Loss: 93.9529  BEST VAL Loss: 91.7233\n",
            "\n",
            "Epoch 1035: Validation loss decreased (91.723267 --> 91.224487).\n",
            "\t Train_Loss: 22.4990 Val_Loss: 91.2245  BEST VAL Loss: 91.2245\n",
            "\n",
            "Epoch 1036: Validation loss did not decrease\n",
            "\t Train_Loss: 20.3916 Val_Loss: 91.8432  BEST VAL Loss: 91.2245\n",
            "\n",
            "Epoch 1037: Validation loss did not decrease\n",
            "\t Train_Loss: 20.6132 Val_Loss: 97.9185  BEST VAL Loss: 91.2245\n",
            "\n",
            "Epoch 1038: Validation loss did not decrease\n",
            "\t Train_Loss: 18.9539 Val_Loss: 96.1594  BEST VAL Loss: 91.2245\n",
            "\n",
            "Epoch 1039: Validation loss decreased (91.224487 --> 90.254089).\n",
            "\t Train_Loss: 19.6521 Val_Loss: 90.2541  BEST VAL Loss: 90.2541\n",
            "\n",
            "Epoch 1040: Validation loss decreased (90.254089 --> 89.836533).\n",
            "\t Train_Loss: 16.1719 Val_Loss: 89.8365  BEST VAL Loss: 89.8365\n",
            "\n",
            "Epoch 1041: Validation loss did not decrease\n",
            "\t Train_Loss: 20.2997 Val_Loss: 90.0359  BEST VAL Loss: 89.8365\n",
            "\n",
            "Epoch 1042: Validation loss did not decrease\n",
            "\t Train_Loss: 15.5147 Val_Loss: 91.2148  BEST VAL Loss: 89.8365\n",
            "\n",
            "Epoch 1043: Validation loss decreased (89.836533 --> 89.327911).\n",
            "\t Train_Loss: 18.9047 Val_Loss: 89.3279  BEST VAL Loss: 89.3279\n",
            "\n",
            "Epoch 1044: Validation loss did not decrease\n",
            "\t Train_Loss: 15.4667 Val_Loss: 89.4124  BEST VAL Loss: 89.3279\n",
            "\n",
            "Epoch 1045: Validation loss decreased (89.327911 --> 89.067215).\n",
            "\t Train_Loss: 16.9434 Val_Loss: 89.0672  BEST VAL Loss: 89.0672\n",
            "\n",
            "Epoch 1046: Validation loss decreased (89.067215 --> 88.870583).\n",
            "\t Train_Loss: 16.6525 Val_Loss: 88.8706  BEST VAL Loss: 88.8706\n",
            "\n",
            "Epoch 1047: Validation loss did not decrease\n",
            "\t Train_Loss: 15.0495 Val_Loss: 90.0540  BEST VAL Loss: 88.8706\n",
            "\n",
            "Epoch 1048: Validation loss did not decrease\n",
            "\t Train_Loss: 16.8234 Val_Loss: 89.0134  BEST VAL Loss: 88.8706\n",
            "\n",
            "Epoch 1049: Validation loss decreased (88.870583 --> 88.519104).\n",
            "\t Train_Loss: 15.1401 Val_Loss: 88.5191  BEST VAL Loss: 88.5191\n",
            "\n",
            "Epoch 1050: Validation loss decreased (88.519104 --> 88.376541).\n",
            "\t Train_Loss: 15.5211 Val_Loss: 88.3765  BEST VAL Loss: 88.3765\n",
            "\n",
            "Epoch 1051: Validation loss decreased (88.376541 --> 88.273392).\n",
            "\t Train_Loss: 15.7114 Val_Loss: 88.2734  BEST VAL Loss: 88.2734\n",
            "\n",
            "Epoch 1052: Validation loss did not decrease\n",
            "\t Train_Loss: 14.5438 Val_Loss: 88.6290  BEST VAL Loss: 88.2734\n",
            "\n",
            "Epoch 1053: Validation loss decreased (88.273392 --> 87.829369).\n",
            "\t Train_Loss: 15.8756 Val_Loss: 87.8294  BEST VAL Loss: 87.8294\n",
            "\n",
            "Epoch 1054: Validation loss decreased (87.829369 --> 87.671829).\n",
            "\t Train_Loss: 14.3544 Val_Loss: 87.6718  BEST VAL Loss: 87.6718\n",
            "\n",
            "Epoch 1055: Validation loss decreased (87.671829 --> 87.462204).\n",
            "\t Train_Loss: 14.8754 Val_Loss: 87.4622  BEST VAL Loss: 87.4622\n",
            "\n",
            "Epoch 1056: Validation loss decreased (87.462204 --> 87.193161).\n",
            "\t Train_Loss: 14.7239 Val_Loss: 87.1932  BEST VAL Loss: 87.1932\n",
            "\n",
            "Epoch 1057: Validation loss did not decrease\n",
            "\t Train_Loss: 14.1207 Val_Loss: 87.1951  BEST VAL Loss: 87.1932\n",
            "\n",
            "Epoch 1058: Validation loss decreased (87.193161 --> 86.711777).\n",
            "\t Train_Loss: 14.7841 Val_Loss: 86.7118  BEST VAL Loss: 86.7118\n",
            "\n",
            "Epoch 1059: Validation loss decreased (86.711777 --> 86.606773).\n",
            "\t Train_Loss: 13.8456 Val_Loss: 86.6068  BEST VAL Loss: 86.6068\n",
            "\n",
            "Epoch 1060: Validation loss decreased (86.606773 --> 86.361900).\n",
            "\t Train_Loss: 14.3646 Val_Loss: 86.3619  BEST VAL Loss: 86.3619\n",
            "\n",
            "Epoch 1061: Validation loss decreased (86.361900 --> 86.249290).\n",
            "\t Train_Loss: 13.9346 Val_Loss: 86.2493  BEST VAL Loss: 86.2493\n",
            "\n",
            "Epoch 1062: Validation loss decreased (86.249290 --> 86.093895).\n",
            "\t Train_Loss: 13.8906 Val_Loss: 86.0939  BEST VAL Loss: 86.0939\n",
            "\n",
            "Epoch 1063: Validation loss decreased (86.093895 --> 85.714600).\n",
            "\t Train_Loss: 13.9753 Val_Loss: 85.7146  BEST VAL Loss: 85.7146\n",
            "\n",
            "Epoch 1064: Validation loss decreased (85.714600 --> 85.555534).\n",
            "\t Train_Loss: 13.6317 Val_Loss: 85.5555  BEST VAL Loss: 85.5555\n",
            "\n",
            "Epoch 1065: Validation loss decreased (85.555534 --> 85.288628).\n",
            "\t Train_Loss: 13.8945 Val_Loss: 85.2886  BEST VAL Loss: 85.2886\n",
            "\n",
            "Epoch 1066: Validation loss decreased (85.288628 --> 85.174156).\n",
            "\t Train_Loss: 13.4480 Val_Loss: 85.1742  BEST VAL Loss: 85.1742\n",
            "\n",
            "Epoch 1067: Validation loss decreased (85.174156 --> 85.034683).\n",
            "\t Train_Loss: 13.7389 Val_Loss: 85.0347  BEST VAL Loss: 85.0347\n",
            "\n",
            "Epoch 1068: Validation loss decreased (85.034683 --> 84.932961).\n",
            "\t Train_Loss: 13.3074 Val_Loss: 84.9330  BEST VAL Loss: 84.9330\n",
            "\n",
            "Epoch 1069: Validation loss decreased (84.932961 --> 84.739700).\n",
            "\t Train_Loss: 13.4845 Val_Loss: 84.7397  BEST VAL Loss: 84.7397\n",
            "\n",
            "Epoch 1070: Validation loss decreased (84.739700 --> 84.558380).\n",
            "\t Train_Loss: 13.2868 Val_Loss: 84.5584  BEST VAL Loss: 84.5584\n",
            "\n",
            "Epoch 1071: Validation loss decreased (84.558380 --> 84.256073).\n",
            "\t Train_Loss: 13.3074 Val_Loss: 84.2561  BEST VAL Loss: 84.2561\n",
            "\n",
            "Epoch 1072: Validation loss decreased (84.256073 --> 84.044609).\n",
            "\t Train_Loss: 13.1710 Val_Loss: 84.0446  BEST VAL Loss: 84.0446\n",
            "\n",
            "Epoch 1073: Validation loss decreased (84.044609 --> 83.858780).\n",
            "\t Train_Loss: 13.1325 Val_Loss: 83.8588  BEST VAL Loss: 83.8588\n",
            "\n",
            "Epoch 1074: Validation loss decreased (83.858780 --> 83.691360).\n",
            "\t Train_Loss: 13.0812 Val_Loss: 83.6914  BEST VAL Loss: 83.6914\n",
            "\n",
            "Epoch 1075: Validation loss decreased (83.691360 --> 83.672440).\n",
            "\t Train_Loss: 13.0201 Val_Loss: 83.6724  BEST VAL Loss: 83.6724\n",
            "\n",
            "Epoch 1076: Validation loss decreased (83.672440 --> 83.619949).\n",
            "\t Train_Loss: 12.8758 Val_Loss: 83.6199  BEST VAL Loss: 83.6199\n",
            "\n",
            "Epoch 1077: Validation loss did not decrease\n",
            "\t Train_Loss: 12.9344 Val_Loss: 83.6286  BEST VAL Loss: 83.6199\n",
            "\n",
            "Epoch 1078: Validation loss decreased (83.619949 --> 83.536667).\n",
            "\t Train_Loss: 12.8144 Val_Loss: 83.5367  BEST VAL Loss: 83.5367\n",
            "\n",
            "Epoch 1079: Validation loss decreased (83.536667 --> 83.244400).\n",
            "\t Train_Loss: 12.8083 Val_Loss: 83.2444  BEST VAL Loss: 83.2444\n",
            "\n",
            "Epoch 1080: Validation loss decreased (83.244400 --> 83.015434).\n",
            "\t Train_Loss: 12.6639 Val_Loss: 83.0154  BEST VAL Loss: 83.0154\n",
            "\n",
            "Epoch 1081: Validation loss decreased (83.015434 --> 82.844337).\n",
            "\t Train_Loss: 12.6558 Val_Loss: 82.8443  BEST VAL Loss: 82.8443\n",
            "\n",
            "Epoch 1082: Validation loss decreased (82.844337 --> 82.664383).\n",
            "\t Train_Loss: 12.6086 Val_Loss: 82.6644  BEST VAL Loss: 82.6644\n",
            "\n",
            "Epoch 1083: Validation loss decreased (82.664383 --> 82.528503).\n",
            "\t Train_Loss: 12.5360 Val_Loss: 82.5285  BEST VAL Loss: 82.5285\n",
            "\n",
            "Epoch 1084: Validation loss decreased (82.528503 --> 82.411125).\n",
            "\t Train_Loss: 12.4970 Val_Loss: 82.4111  BEST VAL Loss: 82.4111\n",
            "\n",
            "Epoch 1085: Validation loss decreased (82.411125 --> 82.321808).\n",
            "\t Train_Loss: 12.4110 Val_Loss: 82.3218  BEST VAL Loss: 82.3218\n",
            "\n",
            "Epoch 1086: Validation loss decreased (82.321808 --> 82.140358).\n",
            "\t Train_Loss: 12.3924 Val_Loss: 82.1404  BEST VAL Loss: 82.1404\n",
            "\n",
            "Epoch 1087: Validation loss decreased (82.140358 --> 81.933144).\n",
            "\t Train_Loss: 12.3047 Val_Loss: 81.9331  BEST VAL Loss: 81.9331\n",
            "\n",
            "Epoch 1088: Validation loss decreased (81.933144 --> 81.708145).\n",
            "\t Train_Loss: 12.3072 Val_Loss: 81.7081  BEST VAL Loss: 81.7081\n",
            "\n",
            "Epoch 1089: Validation loss decreased (81.708145 --> 81.495651).\n",
            "\t Train_Loss: 12.2859 Val_Loss: 81.4957  BEST VAL Loss: 81.4957\n",
            "\n",
            "Epoch 1090: Validation loss decreased (81.495651 --> 81.309570).\n",
            "\t Train_Loss: 12.1565 Val_Loss: 81.3096  BEST VAL Loss: 81.3096\n",
            "\n",
            "Epoch 1091: Validation loss decreased (81.309570 --> 81.115829).\n",
            "\t Train_Loss: 12.2029 Val_Loss: 81.1158  BEST VAL Loss: 81.1158\n",
            "\n",
            "Epoch 1092: Validation loss decreased (81.115829 --> 80.999893).\n",
            "\t Train_Loss: 12.1097 Val_Loss: 80.9999  BEST VAL Loss: 80.9999\n",
            "\n",
            "Epoch 1093: Validation loss decreased (80.999893 --> 80.919861).\n",
            "\t Train_Loss: 12.0532 Val_Loss: 80.9199  BEST VAL Loss: 80.9199\n",
            "\n",
            "Epoch 1094: Validation loss decreased (80.919861 --> 80.775398).\n",
            "\t Train_Loss: 12.0153 Val_Loss: 80.7754  BEST VAL Loss: 80.7754\n",
            "\n",
            "Epoch 1095: Validation loss decreased (80.775398 --> 80.674179).\n",
            "\t Train_Loss: 11.9164 Val_Loss: 80.6742  BEST VAL Loss: 80.6742\n",
            "\n",
            "Epoch 1096: Validation loss decreased (80.674179 --> 80.541740).\n",
            "\t Train_Loss: 11.9101 Val_Loss: 80.5417  BEST VAL Loss: 80.5417\n",
            "\n",
            "Epoch 1097: Validation loss decreased (80.541740 --> 80.433929).\n",
            "\t Train_Loss: 11.8285 Val_Loss: 80.4339  BEST VAL Loss: 80.4339\n",
            "\n",
            "Epoch 1098: Validation loss decreased (80.433929 --> 80.320335).\n",
            "\t Train_Loss: 11.8160 Val_Loss: 80.3203  BEST VAL Loss: 80.3203\n",
            "\n",
            "Epoch 1099: Validation loss decreased (80.320335 --> 80.178459).\n",
            "\t Train_Loss: 11.7645 Val_Loss: 80.1785  BEST VAL Loss: 80.1785\n",
            "\n",
            "Epoch 1100: Validation loss decreased (80.178459 --> 79.980118).\n",
            "\t Train_Loss: 11.6965 Val_Loss: 79.9801  BEST VAL Loss: 79.9801\n",
            "\n",
            "Epoch 1101: Validation loss decreased (79.980118 --> 79.770317).\n",
            "\t Train_Loss: 11.6828 Val_Loss: 79.7703  BEST VAL Loss: 79.7703\n",
            "\n",
            "Epoch 1102: Validation loss decreased (79.770317 --> 79.551956).\n",
            "\t Train_Loss: 11.6401 Val_Loss: 79.5520  BEST VAL Loss: 79.5520\n",
            "\n",
            "Epoch 1103: Validation loss decreased (79.551956 --> 79.363098).\n",
            "\t Train_Loss: 11.5949 Val_Loss: 79.3631  BEST VAL Loss: 79.3631\n",
            "\n",
            "Epoch 1104: Validation loss decreased (79.363098 --> 79.175362).\n",
            "\t Train_Loss: 11.5738 Val_Loss: 79.1754  BEST VAL Loss: 79.1754\n",
            "\n",
            "Epoch 1105: Validation loss decreased (79.175362 --> 79.062843).\n",
            "\t Train_Loss: 11.5127 Val_Loss: 79.0628  BEST VAL Loss: 79.0628\n",
            "\n",
            "Epoch 1106: Validation loss decreased (79.062843 --> 78.989853).\n",
            "\t Train_Loss: 11.4634 Val_Loss: 78.9899  BEST VAL Loss: 78.9899\n",
            "\n",
            "Epoch 1107: Validation loss decreased (78.989853 --> 78.875587).\n",
            "\t Train_Loss: 11.4208 Val_Loss: 78.8756  BEST VAL Loss: 78.8756\n",
            "\n",
            "Epoch 1108: Validation loss decreased (78.875587 --> 78.741356).\n",
            "\t Train_Loss: 11.3681 Val_Loss: 78.7414  BEST VAL Loss: 78.7414\n",
            "\n",
            "Epoch 1109: Validation loss decreased (78.741356 --> 78.614395).\n",
            "\t Train_Loss: 11.3365 Val_Loss: 78.6144  BEST VAL Loss: 78.6144\n",
            "\n",
            "Epoch 1110: Validation loss decreased (78.614395 --> 78.453438).\n",
            "\t Train_Loss: 11.3155 Val_Loss: 78.4534  BEST VAL Loss: 78.4534\n",
            "\n",
            "Epoch 1111: Validation loss decreased (78.453438 --> 78.278030).\n",
            "\t Train_Loss: 11.2710 Val_Loss: 78.2780  BEST VAL Loss: 78.2780\n",
            "\n",
            "Epoch 1112: Validation loss decreased (78.278030 --> 78.081139).\n",
            "\t Train_Loss: 11.2134 Val_Loss: 78.0811  BEST VAL Loss: 78.0811\n",
            "\n",
            "Epoch 1113: Validation loss decreased (78.081139 --> 77.825523).\n",
            "\t Train_Loss: 11.1981 Val_Loss: 77.8255  BEST VAL Loss: 77.8255\n",
            "\n",
            "Epoch 1114: Validation loss decreased (77.825523 --> 77.725319).\n",
            "\t Train_Loss: 11.1866 Val_Loss: 77.7253  BEST VAL Loss: 77.7253\n",
            "\n",
            "Epoch 1115: Validation loss decreased (77.725319 --> 77.654663).\n",
            "\t Train_Loss: 11.1065 Val_Loss: 77.6547  BEST VAL Loss: 77.6547\n",
            "\n",
            "Epoch 1116: Validation loss decreased (77.654663 --> 77.484367).\n",
            "\t Train_Loss: 11.0951 Val_Loss: 77.4844  BEST VAL Loss: 77.4844\n",
            "\n",
            "Epoch 1117: Validation loss decreased (77.484367 --> 77.392059).\n",
            "\t Train_Loss: 11.0539 Val_Loss: 77.3921  BEST VAL Loss: 77.3921\n",
            "\n",
            "Epoch 1118: Validation loss decreased (77.392059 --> 77.185822).\n",
            "\t Train_Loss: 11.0234 Val_Loss: 77.1858  BEST VAL Loss: 77.1858\n",
            "\n",
            "Epoch 1119: Validation loss decreased (77.185822 --> 77.059608).\n",
            "\t Train_Loss: 10.9645 Val_Loss: 77.0596  BEST VAL Loss: 77.0596\n",
            "\n",
            "Epoch 1120: Validation loss decreased (77.059608 --> 76.847366).\n",
            "\t Train_Loss: 10.9404 Val_Loss: 76.8474  BEST VAL Loss: 76.8474\n",
            "\n",
            "Epoch 1121: Validation loss decreased (76.847366 --> 76.682877).\n",
            "\t Train_Loss: 10.8616 Val_Loss: 76.6829  BEST VAL Loss: 76.6829\n",
            "\n",
            "Epoch 1122: Validation loss decreased (76.682877 --> 76.582382).\n",
            "\t Train_Loss: 10.8515 Val_Loss: 76.5824  BEST VAL Loss: 76.5824\n",
            "\n",
            "Epoch 1123: Validation loss decreased (76.582382 --> 76.363029).\n",
            "\t Train_Loss: 10.8529 Val_Loss: 76.3630  BEST VAL Loss: 76.3630\n",
            "\n",
            "Epoch 1124: Validation loss did not decrease\n",
            "\t Train_Loss: 10.9367 Val_Loss: 76.4328  BEST VAL Loss: 76.3630\n",
            "\n",
            "Epoch 1125: Validation loss decreased (76.363029 --> 76.240402).\n",
            "\t Train_Loss: 10.8903 Val_Loss: 76.2404  BEST VAL Loss: 76.2404\n",
            "\n",
            "Epoch 1126: Validation loss decreased (76.240402 --> 76.137550).\n",
            "\t Train_Loss: 10.7244 Val_Loss: 76.1376  BEST VAL Loss: 76.1376\n",
            "\n",
            "Epoch 1127: Validation loss decreased (76.137550 --> 76.045197).\n",
            "\t Train_Loss: 10.7200 Val_Loss: 76.0452  BEST VAL Loss: 76.0452\n",
            "\n",
            "Epoch 1128: Validation loss decreased (76.045197 --> 75.783302).\n",
            "\t Train_Loss: 10.7707 Val_Loss: 75.7833  BEST VAL Loss: 75.7833\n",
            "\n",
            "Epoch 1129: Validation loss decreased (75.783302 --> 75.738632).\n",
            "\t Train_Loss: 10.8605 Val_Loss: 75.7386  BEST VAL Loss: 75.7386\n",
            "\n",
            "Epoch 1130: Validation loss decreased (75.738632 --> 75.616096).\n",
            "\t Train_Loss: 10.7853 Val_Loss: 75.6161  BEST VAL Loss: 75.6161\n",
            "\n",
            "Epoch 1131: Validation loss decreased (75.616096 --> 75.560753).\n",
            "\t Train_Loss: 10.5893 Val_Loss: 75.5608  BEST VAL Loss: 75.5608\n",
            "\n",
            "Epoch 1132: Validation loss decreased (75.560753 --> 75.472885).\n",
            "\t Train_Loss: 10.5476 Val_Loss: 75.4729  BEST VAL Loss: 75.4729\n",
            "\n",
            "Epoch 1133: Validation loss decreased (75.472885 --> 75.253632).\n",
            "\t Train_Loss: 10.5824 Val_Loss: 75.2536  BEST VAL Loss: 75.2536\n",
            "\n",
            "Epoch 1134: Validation loss decreased (75.253632 --> 75.197151).\n",
            "\t Train_Loss: 10.5469 Val_Loss: 75.1972  BEST VAL Loss: 75.1972\n",
            "\n",
            "Epoch 1135: Validation loss decreased (75.197151 --> 74.958084).\n",
            "\t Train_Loss: 10.6267 Val_Loss: 74.9581  BEST VAL Loss: 74.9581\n",
            "\n",
            "Epoch 1136: Validation loss did not decrease\n",
            "\t Train_Loss: 10.7118 Val_Loss: 75.7487  BEST VAL Loss: 74.9581\n",
            "\n",
            "Epoch 1137: Validation loss did not decrease\n",
            "\t Train_Loss: 15.3378 Val_Loss: 78.4589  BEST VAL Loss: 74.9581\n",
            "\n",
            "Epoch 1138: Validation loss did not decrease\n",
            "\t Train_Loss: 15.1286 Val_Loss: 76.7455  BEST VAL Loss: 74.9581\n",
            "\n",
            "Epoch 1139: Validation loss did not decrease\n",
            "\t Train_Loss: 11.7874 Val_Loss: 75.9482  BEST VAL Loss: 74.9581\n",
            "\n",
            "Epoch 1140: Validation loss did not decrease\n",
            "\t Train_Loss: 17.2801 Val_Loss: 76.6660  BEST VAL Loss: 74.9581\n",
            "\n",
            "Epoch 1141: Validation loss did not decrease\n",
            "\t Train_Loss: 13.0126 Val_Loss: 77.8627  BEST VAL Loss: 74.9581\n",
            "\n",
            "Epoch 1142: Validation loss did not decrease\n",
            "\t Train_Loss: 14.4758 Val_Loss: 75.3852  BEST VAL Loss: 74.9581\n",
            "\n",
            "Epoch 1143: Validation loss did not decrease\n",
            "\t Train_Loss: 12.0594 Val_Loss: 75.3635  BEST VAL Loss: 74.9581\n",
            "\n",
            "Epoch 1144: Validation loss decreased (74.958084 --> 74.492783).\n",
            "\t Train_Loss: 14.4513 Val_Loss: 74.4928  BEST VAL Loss: 74.4928\n",
            "\n",
            "Epoch 1145: Validation loss did not decrease\n",
            "\t Train_Loss: 12.7857 Val_Loss: 75.1473  BEST VAL Loss: 74.4928\n",
            "\n",
            "Epoch 1146: Validation loss decreased (74.492783 --> 74.276535).\n",
            "\t Train_Loss: 14.8613 Val_Loss: 74.2765  BEST VAL Loss: 74.2765\n",
            "\n",
            "Epoch 1147: Validation loss decreased (74.276535 --> 73.787498).\n",
            "\t Train_Loss: 13.4977 Val_Loss: 73.7875  BEST VAL Loss: 73.7875\n",
            "\n",
            "Epoch 1148: Validation loss did not decrease\n",
            "\t Train_Loss: 12.2800 Val_Loss: 75.3119  BEST VAL Loss: 73.7875\n",
            "\n",
            "Epoch 1149: Validation loss did not decrease\n",
            "\t Train_Loss: 13.3879 Val_Loss: 76.0906  BEST VAL Loss: 73.7875\n",
            "\n",
            "Epoch 1150: Validation loss did not decrease\n",
            "\t Train_Loss: 13.5572 Val_Loss: 75.4857  BEST VAL Loss: 73.7875\n",
            "\n",
            "Epoch 1151: Validation loss did not decrease\n",
            "\t Train_Loss: 12.4843 Val_Loss: 74.3998  BEST VAL Loss: 73.7875\n",
            "\n",
            "Epoch 1152: Validation loss decreased (73.787498 --> 73.446266).\n",
            "\t Train_Loss: 12.5928 Val_Loss: 73.4463  BEST VAL Loss: 73.4463\n",
            "\n",
            "Epoch 1153: Validation loss did not decrease\n",
            "\t Train_Loss: 12.5732 Val_Loss: 73.8117  BEST VAL Loss: 73.4463\n",
            "\n",
            "Epoch 1154: Validation loss decreased (73.446266 --> 73.142960).\n",
            "\t Train_Loss: 12.1749 Val_Loss: 73.1430  BEST VAL Loss: 73.1430\n",
            "\n",
            "Epoch 1155: Validation loss decreased (73.142960 --> 72.182999).\n",
            "\t Train_Loss: 12.0120 Val_Loss: 72.1830  BEST VAL Loss: 72.1830\n",
            "\n",
            "Epoch 1156: Validation loss did not decrease\n",
            "\t Train_Loss: 11.6676 Val_Loss: 72.6033  BEST VAL Loss: 72.1830\n",
            "\n",
            "Epoch 1157: Validation loss did not decrease\n",
            "\t Train_Loss: 11.5539 Val_Loss: 72.9060  BEST VAL Loss: 72.1830\n",
            "\n",
            "Epoch 1158: Validation loss did not decrease\n",
            "\t Train_Loss: 11.5314 Val_Loss: 72.9137  BEST VAL Loss: 72.1830\n",
            "\n",
            "Epoch 1159: Validation loss did not decrease\n",
            "\t Train_Loss: 11.3868 Val_Loss: 72.5944  BEST VAL Loss: 72.1830\n",
            "\n",
            "Epoch 1160: Validation loss decreased (72.182999 --> 71.418198).\n",
            "\t Train_Loss: 11.2843 Val_Loss: 71.4182  BEST VAL Loss: 71.4182\n",
            "\n",
            "Epoch 1161: Validation loss decreased (71.418198 --> 70.777588).\n",
            "\t Train_Loss: 10.8253 Val_Loss: 70.7776  BEST VAL Loss: 70.7776\n",
            "\n",
            "Epoch 1162: Validation loss did not decrease\n",
            "\t Train_Loss: 10.9023 Val_Loss: 71.0755  BEST VAL Loss: 70.7776\n",
            "\n",
            "Epoch 1163: Validation loss did not decrease\n",
            "\t Train_Loss: 10.9122 Val_Loss: 71.5448  BEST VAL Loss: 70.7776\n",
            "\n",
            "Epoch 1164: Validation loss did not decrease\n",
            "\t Train_Loss: 11.0537 Val_Loss: 71.2080  BEST VAL Loss: 70.7776\n",
            "\n",
            "Epoch 1165: Validation loss decreased (70.777588 --> 70.750900).\n",
            "\t Train_Loss: 10.6844 Val_Loss: 70.7509  BEST VAL Loss: 70.7509\n",
            "\n",
            "Epoch 1166: Validation loss did not decrease\n",
            "\t Train_Loss: 10.9379 Val_Loss: 71.9137  BEST VAL Loss: 70.7509\n",
            "\n",
            "Epoch 1167: Validation loss did not decrease\n",
            "\t Train_Loss: 10.6786 Val_Loss: 72.3053  BEST VAL Loss: 70.7509\n",
            "\n",
            "Epoch 1168: Validation loss did not decrease\n",
            "\t Train_Loss: 11.0527 Val_Loss: 71.4287  BEST VAL Loss: 70.7509\n",
            "\n",
            "Epoch 1169: Validation loss decreased (70.750900 --> 70.449730).\n",
            "\t Train_Loss: 10.6389 Val_Loss: 70.4497  BEST VAL Loss: 70.4497\n",
            "\n",
            "Epoch 1170: Validation loss did not decrease\n",
            "\t Train_Loss: 10.7349 Val_Loss: 71.0179  BEST VAL Loss: 70.4497\n",
            "\n",
            "Epoch 1171: Validation loss did not decrease\n",
            "\t Train_Loss: 10.3701 Val_Loss: 71.1197  BEST VAL Loss: 70.4497\n",
            "\n",
            "Epoch 1172: Validation loss did not decrease\n",
            "\t Train_Loss: 10.5580 Val_Loss: 70.4548  BEST VAL Loss: 70.4497\n",
            "\n",
            "Epoch 1173: Validation loss decreased (70.449730 --> 70.429916).\n",
            "\t Train_Loss: 10.4038 Val_Loss: 70.4299  BEST VAL Loss: 70.4299\n",
            "\n",
            "Epoch 1174: Validation loss did not decrease\n",
            "\t Train_Loss: 10.4047 Val_Loss: 70.5067  BEST VAL Loss: 70.4299\n",
            "\n",
            "Epoch 1175: Validation loss decreased (70.429916 --> 70.358704).\n",
            "\t Train_Loss: 10.3050 Val_Loss: 70.3587  BEST VAL Loss: 70.3587\n",
            "\n",
            "Epoch 1176: Validation loss decreased (70.358704 --> 70.272087).\n",
            "\t Train_Loss: 10.0861 Val_Loss: 70.2721  BEST VAL Loss: 70.2721\n",
            "\n",
            "Epoch 1177: Validation loss did not decrease\n",
            "\t Train_Loss: 10.1455 Val_Loss: 70.7667  BEST VAL Loss: 70.2721\n",
            "\n",
            "Epoch 1178: Validation loss did not decrease\n",
            "\t Train_Loss: 10.2668 Val_Loss: 70.6034  BEST VAL Loss: 70.2721\n",
            "\n",
            "Epoch 1179: Validation loss decreased (70.272087 --> 70.041824).\n",
            "\t Train_Loss: 10.0644 Val_Loss: 70.0418  BEST VAL Loss: 70.0418\n",
            "\n",
            "Epoch 1180: Validation loss did not decrease\n",
            "\t Train_Loss: 10.0544 Val_Loss: 70.1281  BEST VAL Loss: 70.0418\n",
            "\n",
            "Epoch 1181: Validation loss did not decrease\n",
            "\t Train_Loss: 10.3071 Val_Loss: 70.4662  BEST VAL Loss: 70.0418\n",
            "\n",
            "Epoch 1182: Validation loss did not decrease\n",
            "\t Train_Loss: 10.7982 Val_Loss: 70.1906  BEST VAL Loss: 70.0418\n",
            "\n",
            "Epoch 1183: Validation loss did not decrease\n",
            "\t Train_Loss: 10.9188 Val_Loss: 70.2364  BEST VAL Loss: 70.0418\n",
            "\n",
            "Epoch 1184: Validation loss did not decrease\n",
            "\t Train_Loss: 10.1716 Val_Loss: 70.6788  BEST VAL Loss: 70.0418\n",
            "\n",
            "Epoch 1185: Validation loss decreased (70.041824 --> 70.000244).\n",
            "\t Train_Loss: 10.6759 Val_Loss: 70.0002  BEST VAL Loss: 70.0002\n",
            "\n",
            "Epoch 1186: Validation loss did not decrease\n",
            "\t Train_Loss: 10.4137 Val_Loss: 70.1514  BEST VAL Loss: 70.0002\n",
            "\n",
            "Epoch 1187: Validation loss did not decrease\n",
            "\t Train_Loss: 13.2565 Val_Loss: 71.3834  BEST VAL Loss: 70.0002\n",
            "\n",
            "Epoch 1188: Validation loss did not decrease\n",
            "\t Train_Loss: 13.0180 Val_Loss: 71.5247  BEST VAL Loss: 70.0002\n",
            "\n",
            "Epoch 1189: Validation loss decreased (70.000244 --> 68.265923).\n",
            "\t Train_Loss: 13.0020 Val_Loss: 68.2659  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1190: Validation loss did not decrease\n",
            "\t Train_Loss: 10.2481 Val_Loss: 68.3202  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1191: Validation loss did not decrease\n",
            "\t Train_Loss: 12.2973 Val_Loss: 69.1191  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1192: Validation loss did not decrease\n",
            "\t Train_Loss: 12.6559 Val_Loss: 68.8010  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1193: Validation loss did not decrease\n",
            "\t Train_Loss: 12.9402 Val_Loss: 70.2080  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1194: Validation loss did not decrease\n",
            "\t Train_Loss: 11.6430 Val_Loss: 70.5116  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1195: Validation loss did not decrease\n",
            "\t Train_Loss: 12.7129 Val_Loss: 71.8161  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1196: Validation loss did not decrease\n",
            "\t Train_Loss: 13.1259 Val_Loss: 72.6318  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1197: Validation loss did not decrease\n",
            "\t Train_Loss: 13.8891 Val_Loss: 70.9542  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1198: Validation loss did not decrease\n",
            "\t Train_Loss: 12.9504 Val_Loss: 69.8712  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1199: Validation loss did not decrease\n",
            "\t Train_Loss: 11.4963 Val_Loss: 68.8880  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1200: Validation loss did not decrease\n",
            "\t Train_Loss: 10.8725 Val_Loss: 68.4445  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1201: Validation loss did not decrease\n",
            "\t Train_Loss: 12.6321 Val_Loss: 70.8513  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1202: Validation loss did not decrease\n",
            "\t Train_Loss: 11.6571 Val_Loss: 70.4119  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1203: Validation loss did not decrease\n",
            "\t Train_Loss: 10.6411 Val_Loss: 68.4615  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1204: Validation loss did not decrease\n",
            "\t Train_Loss: 10.8244 Val_Loss: 68.3472  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1205: Validation loss did not decrease\n",
            "\t Train_Loss: 11.6103 Val_Loss: 69.2883  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1206: Validation loss did not decrease\n",
            "\t Train_Loss: 12.0454 Val_Loss: 68.3704  BEST VAL Loss: 68.2659\n",
            "\n",
            "Epoch 1207: Validation loss decreased (68.265923 --> 67.908241).\n",
            "\t Train_Loss: 10.7770 Val_Loss: 67.9082  BEST VAL Loss: 67.9082\n",
            "\n",
            "Epoch 1208: Validation loss did not decrease\n",
            "\t Train_Loss: 10.7959 Val_Loss: 68.7233  BEST VAL Loss: 67.9082\n",
            "\n",
            "Epoch 1209: Validation loss did not decrease\n",
            "\t Train_Loss: 10.1141 Val_Loss: 69.0042  BEST VAL Loss: 67.9082\n",
            "\n",
            "Epoch 1210: Validation loss decreased (67.908241 --> 67.296982).\n",
            "\t Train_Loss: 10.3056 Val_Loss: 67.2970  BEST VAL Loss: 67.2970\n",
            "\n",
            "Epoch 1211: Validation loss decreased (67.296982 --> 66.182190).\n",
            "\t Train_Loss: 9.8326 Val_Loss: 66.1822  BEST VAL Loss: 66.1822\n",
            "\n",
            "Epoch 1212: Validation loss did not decrease\n",
            "\t Train_Loss: 10.3303 Val_Loss: 67.3317  BEST VAL Loss: 66.1822\n",
            "\n",
            "Epoch 1213: Validation loss did not decrease\n",
            "\t Train_Loss: 9.8323 Val_Loss: 67.7979  BEST VAL Loss: 66.1822\n",
            "\n",
            "Epoch 1214: Validation loss did not decrease\n",
            "\t Train_Loss: 10.2364 Val_Loss: 66.7409  BEST VAL Loss: 66.1822\n",
            "\n",
            "Epoch 1215: Validation loss did not decrease\n",
            "\t Train_Loss: 9.9107 Val_Loss: 66.3588  BEST VAL Loss: 66.1822\n",
            "\n",
            "Epoch 1216: Validation loss did not decrease\n",
            "\t Train_Loss: 10.0993 Val_Loss: 66.6729  BEST VAL Loss: 66.1822\n",
            "\n",
            "Epoch 1217: Validation loss did not decrease\n",
            "\t Train_Loss: 9.6935 Val_Loss: 66.9858  BEST VAL Loss: 66.1822\n",
            "\n",
            "Epoch 1218: Validation loss did not decrease\n",
            "\t Train_Loss: 10.1840 Val_Loss: 66.2012  BEST VAL Loss: 66.1822\n",
            "\n",
            "Epoch 1219: Validation loss did not decrease\n",
            "\t Train_Loss: 10.0401 Val_Loss: 66.5218  BEST VAL Loss: 66.1822\n",
            "\n",
            "Epoch 1220: Validation loss did not decrease\n",
            "\t Train_Loss: 9.6773 Val_Loss: 67.3030  BEST VAL Loss: 66.1822\n",
            "\n",
            "Epoch 1221: Validation loss did not decrease\n",
            "\t Train_Loss: 9.9163 Val_Loss: 66.7952  BEST VAL Loss: 66.1822\n",
            "\n",
            "Epoch 1222: Validation loss decreased (66.182190 --> 65.624359).\n",
            "\t Train_Loss: 9.5084 Val_Loss: 65.6244  BEST VAL Loss: 65.6244\n",
            "\n",
            "Epoch 1223: Validation loss decreased (65.624359 --> 65.551323).\n",
            "\t Train_Loss: 9.7054 Val_Loss: 65.5513  BEST VAL Loss: 65.5513\n",
            "\n",
            "Epoch 1224: Validation loss did not decrease\n",
            "\t Train_Loss: 9.6462 Val_Loss: 66.1571  BEST VAL Loss: 65.5513\n",
            "\n",
            "Epoch 1225: Validation loss did not decrease\n",
            "\t Train_Loss: 9.5537 Val_Loss: 66.3332  BEST VAL Loss: 65.5513\n",
            "\n",
            "Epoch 1226: Validation loss did not decrease\n",
            "\t Train_Loss: 9.3452 Val_Loss: 65.8064  BEST VAL Loss: 65.5513\n",
            "\n",
            "Epoch 1227: Validation loss did not decrease\n",
            "\t Train_Loss: 9.4826 Val_Loss: 65.7539  BEST VAL Loss: 65.5513\n",
            "\n",
            "Epoch 1228: Validation loss did not decrease\n",
            "\t Train_Loss: 9.3997 Val_Loss: 66.3918  BEST VAL Loss: 65.5513\n",
            "\n",
            "Epoch 1229: Validation loss did not decrease\n",
            "\t Train_Loss: 9.3151 Val_Loss: 65.9178  BEST VAL Loss: 65.5513\n",
            "\n",
            "Epoch 1230: Validation loss decreased (65.551323 --> 65.077919).\n",
            "\t Train_Loss: 9.0998 Val_Loss: 65.0779  BEST VAL Loss: 65.0779\n",
            "\n",
            "Epoch 1231: Validation loss did not decrease\n",
            "\t Train_Loss: 9.3624 Val_Loss: 65.2812  BEST VAL Loss: 65.0779\n",
            "\n",
            "Epoch 1232: Validation loss did not decrease\n",
            "\t Train_Loss: 9.1134 Val_Loss: 65.8150  BEST VAL Loss: 65.0779\n",
            "\n",
            "Epoch 1233: Validation loss did not decrease\n",
            "\t Train_Loss: 9.9936 Val_Loss: 65.2747  BEST VAL Loss: 65.0779\n",
            "\n",
            "Epoch 1234: Validation loss did not decrease\n",
            "\t Train_Loss: 9.3426 Val_Loss: 65.2890  BEST VAL Loss: 65.0779\n",
            "\n",
            "Epoch 1235: Validation loss did not decrease\n",
            "\t Train_Loss: 9.3938 Val_Loss: 65.4386  BEST VAL Loss: 65.0779\n",
            "\n",
            "Epoch 1236: Validation loss did not decrease\n",
            "\t Train_Loss: 9.2648 Val_Loss: 65.3150  BEST VAL Loss: 65.0779\n",
            "\n",
            "Epoch 1237: Validation loss decreased (65.077919 --> 64.353195).\n",
            "\t Train_Loss: 9.2832 Val_Loss: 64.3532  BEST VAL Loss: 64.3532\n",
            "\n",
            "Epoch 1238: Validation loss did not decrease\n",
            "\t Train_Loss: 9.3490 Val_Loss: 64.8734  BEST VAL Loss: 64.3532\n",
            "\n",
            "Epoch 1239: Validation loss did not decrease\n",
            "\t Train_Loss: 9.0157 Val_Loss: 65.1366  BEST VAL Loss: 64.3532\n",
            "\n",
            "Epoch 1240: Validation loss decreased (64.353195 --> 64.136314).\n",
            "\t Train_Loss: 9.4653 Val_Loss: 64.1363  BEST VAL Loss: 64.1363\n",
            "\n",
            "Epoch 1241: Validation loss decreased (64.136314 --> 64.046646).\n",
            "\t Train_Loss: 9.0308 Val_Loss: 64.0466  BEST VAL Loss: 64.0466\n",
            "\n",
            "Epoch 1242: Validation loss did not decrease\n",
            "\t Train_Loss: 9.0054 Val_Loss: 64.7079  BEST VAL Loss: 64.0466\n",
            "\n",
            "Epoch 1243: Validation loss did not decrease\n",
            "\t Train_Loss: 9.0110 Val_Loss: 64.5002  BEST VAL Loss: 64.0466\n",
            "\n",
            "Epoch 1244: Validation loss decreased (64.046646 --> 63.932720).\n",
            "\t Train_Loss: 8.8729 Val_Loss: 63.9327  BEST VAL Loss: 63.9327\n",
            "\n",
            "Epoch 1245: Validation loss did not decrease\n",
            "\t Train_Loss: 9.2646 Val_Loss: 64.1602  BEST VAL Loss: 63.9327\n",
            "\n",
            "Epoch 1246: Validation loss did not decrease\n",
            "\t Train_Loss: 8.8992 Val_Loss: 64.6453  BEST VAL Loss: 63.9327\n",
            "\n",
            "Epoch 1247: Validation loss decreased (63.932720 --> 63.841198).\n",
            "\t Train_Loss: 9.5990 Val_Loss: 63.8412  BEST VAL Loss: 63.8412\n",
            "\n",
            "Epoch 1248: Validation loss decreased (63.841198 --> 63.244701).\n",
            "\t Train_Loss: 8.6171 Val_Loss: 63.2447  BEST VAL Loss: 63.2447\n",
            "\n",
            "Epoch 1249: Validation loss did not decrease\n",
            "\t Train_Loss: 9.2092 Val_Loss: 63.3107  BEST VAL Loss: 63.2447\n",
            "\n",
            "Epoch 1250: Validation loss did not decrease\n",
            "\t Train_Loss: 8.8892 Val_Loss: 64.0579  BEST VAL Loss: 63.2447\n",
            "\n",
            "Epoch 1251: Validation loss did not decrease\n",
            "\t Train_Loss: 8.9455 Val_Loss: 63.7472  BEST VAL Loss: 63.2447\n",
            "\n",
            "Epoch 1252: Validation loss decreased (63.244701 --> 62.934875).\n",
            "\t Train_Loss: 8.7094 Val_Loss: 62.9349  BEST VAL Loss: 62.9349\n",
            "\n",
            "Epoch 1253: Validation loss did not decrease\n",
            "\t Train_Loss: 9.0446 Val_Loss: 64.1274  BEST VAL Loss: 62.9349\n",
            "\n",
            "Epoch 1254: Validation loss did not decrease\n",
            "\t Train_Loss: 9.0460 Val_Loss: 63.8787  BEST VAL Loss: 62.9349\n",
            "\n",
            "Epoch 1255: Validation loss did not decrease\n",
            "\t Train_Loss: 8.9640 Val_Loss: 63.4601  BEST VAL Loss: 62.9349\n",
            "\n",
            "Epoch 1256: Validation loss did not decrease\n",
            "\t Train_Loss: 9.2897 Val_Loss: 63.7301  BEST VAL Loss: 62.9349\n",
            "\n",
            "Epoch 1257: Validation loss did not decrease\n",
            "\t Train_Loss: 8.6275 Val_Loss: 63.6437  BEST VAL Loss: 62.9349\n",
            "\n",
            "Epoch 1258: Validation loss decreased (62.934875 --> 62.708946).\n",
            "\t Train_Loss: 8.6750 Val_Loss: 62.7089  BEST VAL Loss: 62.7089\n",
            "\n",
            "Epoch 1259: Validation loss decreased (62.708946 --> 62.608055).\n",
            "\t Train_Loss: 8.8216 Val_Loss: 62.6081  BEST VAL Loss: 62.6081\n",
            "\n",
            "Epoch 1260: Validation loss did not decrease\n",
            "\t Train_Loss: 8.7178 Val_Loss: 62.6820  BEST VAL Loss: 62.6081\n",
            "\n",
            "Epoch 1261: Validation loss decreased (62.608055 --> 62.289040).\n",
            "\t Train_Loss: 8.7430 Val_Loss: 62.2890  BEST VAL Loss: 62.2890\n",
            "\n",
            "Epoch 1262: Validation loss did not decrease\n",
            "\t Train_Loss: 8.7726 Val_Loss: 62.3543  BEST VAL Loss: 62.2890\n",
            "\n",
            "Epoch 1263: Validation loss did not decrease\n",
            "\t Train_Loss: 8.5854 Val_Loss: 62.8616  BEST VAL Loss: 62.2890\n",
            "\n",
            "Epoch 1264: Validation loss did not decrease\n",
            "\t Train_Loss: 8.5849 Val_Loss: 63.1771  BEST VAL Loss: 62.2890\n",
            "\n",
            "Epoch 1265: Validation loss did not decrease\n",
            "\t Train_Loss: 8.4955 Val_Loss: 63.1723  BEST VAL Loss: 62.2890\n",
            "\n",
            "Epoch 1266: Validation loss did not decrease\n",
            "\t Train_Loss: 8.4904 Val_Loss: 62.9598  BEST VAL Loss: 62.2890\n",
            "\n",
            "Epoch 1267: Validation loss did not decrease\n",
            "\t Train_Loss: 8.6230 Val_Loss: 63.1367  BEST VAL Loss: 62.2890\n",
            "\n",
            "Epoch 1268: Validation loss did not decrease\n",
            "\t Train_Loss: 8.4014 Val_Loss: 62.8293  BEST VAL Loss: 62.2890\n",
            "\n",
            "Epoch 1269: Validation loss decreased (62.289040 --> 61.993080).\n",
            "\t Train_Loss: 8.3729 Val_Loss: 61.9931  BEST VAL Loss: 61.9931\n",
            "\n",
            "Epoch 1270: Validation loss did not decrease\n",
            "\t Train_Loss: 8.4670 Val_Loss: 62.2903  BEST VAL Loss: 61.9931\n",
            "\n",
            "Epoch 1271: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2989 Val_Loss: 62.0284  BEST VAL Loss: 61.9931\n",
            "\n",
            "Epoch 1272: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2426 Val_Loss: 62.0737  BEST VAL Loss: 61.9931\n",
            "\n",
            "Epoch 1273: Validation loss decreased (61.993080 --> 61.851524).\n",
            "\t Train_Loss: 8.1588 Val_Loss: 61.8515  BEST VAL Loss: 61.8515\n",
            "\n",
            "Epoch 1274: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1359 Val_Loss: 61.9369  BEST VAL Loss: 61.8515\n",
            "\n",
            "Epoch 1275: Validation loss decreased (61.851524 --> 61.813953).\n",
            "\t Train_Loss: 8.1958 Val_Loss: 61.8140  BEST VAL Loss: 61.8140\n",
            "\n",
            "Epoch 1276: Validation loss decreased (61.813953 --> 61.667488).\n",
            "\t Train_Loss: 8.1225 Val_Loss: 61.6675  BEST VAL Loss: 61.6675\n",
            "\n",
            "Epoch 1277: Validation loss decreased (61.667488 --> 61.499428).\n",
            "\t Train_Loss: 8.0928 Val_Loss: 61.4994  BEST VAL Loss: 61.4994\n",
            "\n",
            "Epoch 1278: Validation loss did not decrease\n",
            "\t Train_Loss: 8.0734 Val_Loss: 61.8894  BEST VAL Loss: 61.4994\n",
            "\n",
            "Epoch 1279: Validation loss decreased (61.499428 --> 61.405945).\n",
            "\t Train_Loss: 8.1793 Val_Loss: 61.4059  BEST VAL Loss: 61.4059\n",
            "\n",
            "Epoch 1280: Validation loss decreased (61.405945 --> 61.360176).\n",
            "\t Train_Loss: 8.1232 Val_Loss: 61.3602  BEST VAL Loss: 61.3602\n",
            "\n",
            "Epoch 1281: Validation loss did not decrease\n",
            "\t Train_Loss: 7.9776 Val_Loss: 61.7695  BEST VAL Loss: 61.3602\n",
            "\n",
            "Epoch 1282: Validation loss decreased (61.360176 --> 60.924950).\n",
            "\t Train_Loss: 8.4064 Val_Loss: 60.9249  BEST VAL Loss: 60.9249\n",
            "\n",
            "Epoch 1283: Validation loss did not decrease\n",
            "\t Train_Loss: 9.3936 Val_Loss: 66.5603  BEST VAL Loss: 60.9249\n",
            "\n",
            "Epoch 1284: Validation loss did not decrease\n",
            "\t Train_Loss: 16.3773 Val_Loss: 65.3551  BEST VAL Loss: 60.9249\n",
            "\n",
            "Epoch 1285: Validation loss did not decrease\n",
            "\t Train_Loss: 15.9366 Val_Loss: 67.7322  BEST VAL Loss: 60.9249\n",
            "\n",
            "Epoch 1286: Validation loss did not decrease\n",
            "\t Train_Loss: 19.2535 Val_Loss: 64.3537  BEST VAL Loss: 60.9249\n",
            "\n",
            "Epoch 1287: Validation loss did not decrease\n",
            "\t Train_Loss: 13.0228 Val_Loss: 65.8897  BEST VAL Loss: 60.9249\n",
            "\n",
            "Epoch 1288: Validation loss did not decrease\n",
            "\t Train_Loss: 12.0898 Val_Loss: 63.4374  BEST VAL Loss: 60.9249\n",
            "\n",
            "Epoch 1289: Validation loss did not decrease\n",
            "\t Train_Loss: 10.9808 Val_Loss: 62.5169  BEST VAL Loss: 60.9249\n",
            "\n",
            "Epoch 1290: Validation loss did not decrease\n",
            "\t Train_Loss: 15.2569 Val_Loss: 65.1480  BEST VAL Loss: 60.9249\n",
            "\n",
            "Epoch 1291: Validation loss did not decrease\n",
            "\t Train_Loss: 12.3531 Val_Loss: 68.9514  BEST VAL Loss: 60.9249\n",
            "\n",
            "Epoch 1292: Validation loss did not decrease\n",
            "\t Train_Loss: 12.8414 Val_Loss: 69.0246  BEST VAL Loss: 60.9249\n",
            "\n",
            "Epoch 1293: Validation loss did not decrease\n",
            "\t Train_Loss: 13.2739 Val_Loss: 65.0548  BEST VAL Loss: 60.9249\n",
            "\n",
            "Epoch 1294: Validation loss did not decrease\n",
            "\t Train_Loss: 12.7607 Val_Loss: 62.9240  BEST VAL Loss: 60.9249\n",
            "\n",
            "Epoch 1295: Validation loss did not decrease\n",
            "\t Train_Loss: 12.1420 Val_Loss: 61.3146  BEST VAL Loss: 60.9249\n",
            "\n",
            "Epoch 1296: Validation loss decreased (60.924950 --> 60.084251).\n",
            "\t Train_Loss: 11.3944 Val_Loss: 60.0843  BEST VAL Loss: 60.0843\n",
            "\n",
            "Epoch 1297: Validation loss decreased (60.084251 --> 58.633411).\n",
            "\t Train_Loss: 10.8533 Val_Loss: 58.6334  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1298: Validation loss did not decrease\n",
            "\t Train_Loss: 10.6382 Val_Loss: 58.9595  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1299: Validation loss did not decrease\n",
            "\t Train_Loss: 10.9736 Val_Loss: 61.4873  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1300: Validation loss did not decrease\n",
            "\t Train_Loss: 11.7764 Val_Loss: 60.4908  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1301: Validation loss did not decrease\n",
            "\t Train_Loss: 10.1863 Val_Loss: 59.8442  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1302: Validation loss did not decrease\n",
            "\t Train_Loss: 11.0997 Val_Loss: 62.2260  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1303: Validation loss did not decrease\n",
            "\t Train_Loss: 11.1172 Val_Loss: 63.2989  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1304: Validation loss did not decrease\n",
            "\t Train_Loss: 11.3530 Val_Loss: 62.7950  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1305: Validation loss did not decrease\n",
            "\t Train_Loss: 10.9788 Val_Loss: 60.5597  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1306: Validation loss did not decrease\n",
            "\t Train_Loss: 11.5194 Val_Loss: 60.6336  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1307: Validation loss did not decrease\n",
            "\t Train_Loss: 10.9049 Val_Loss: 60.7518  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1308: Validation loss did not decrease\n",
            "\t Train_Loss: 11.2978 Val_Loss: 59.2864  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1309: Validation loss did not decrease\n",
            "\t Train_Loss: 10.5443 Val_Loss: 58.6383  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1310: Validation loss did not decrease\n",
            "\t Train_Loss: 10.4744 Val_Loss: 59.3917  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1311: Validation loss did not decrease\n",
            "\t Train_Loss: 9.7547 Val_Loss: 60.2276  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1312: Validation loss did not decrease\n",
            "\t Train_Loss: 9.7676 Val_Loss: 59.7613  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1313: Validation loss did not decrease\n",
            "\t Train_Loss: 10.0038 Val_Loss: 59.0505  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1314: Validation loss did not decrease\n",
            "\t Train_Loss: 9.8770 Val_Loss: 58.7096  BEST VAL Loss: 58.6334\n",
            "\n",
            "Epoch 1315: Validation loss decreased (58.633411 --> 57.846546).\n",
            "\t Train_Loss: 9.7941 Val_Loss: 57.8465  BEST VAL Loss: 57.8465\n",
            "\n",
            "Epoch 1316: Validation loss decreased (57.846546 --> 57.730579).\n",
            "\t Train_Loss: 9.5219 Val_Loss: 57.7306  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1317: Validation loss did not decrease\n",
            "\t Train_Loss: 9.4731 Val_Loss: 58.6454  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1318: Validation loss did not decrease\n",
            "\t Train_Loss: 8.9755 Val_Loss: 60.1424  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1319: Validation loss did not decrease\n",
            "\t Train_Loss: 9.1377 Val_Loss: 60.1514  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1320: Validation loss did not decrease\n",
            "\t Train_Loss: 9.0270 Val_Loss: 59.3425  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1321: Validation loss did not decrease\n",
            "\t Train_Loss: 9.0739 Val_Loss: 58.7067  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1322: Validation loss did not decrease\n",
            "\t Train_Loss: 8.9045 Val_Loss: 58.4948  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1323: Validation loss did not decrease\n",
            "\t Train_Loss: 8.5507 Val_Loss: 58.5235  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1324: Validation loss did not decrease\n",
            "\t Train_Loss: 8.7373 Val_Loss: 57.8066  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1325: Validation loss did not decrease\n",
            "\t Train_Loss: 8.4021 Val_Loss: 57.8153  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1326: Validation loss did not decrease\n",
            "\t Train_Loss: 8.7114 Val_Loss: 58.0861  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1327: Validation loss did not decrease\n",
            "\t Train_Loss: 8.4441 Val_Loss: 58.6327  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1328: Validation loss did not decrease\n",
            "\t Train_Loss: 8.4028 Val_Loss: 58.6955  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1329: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2203 Val_Loss: 58.5598  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1330: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2608 Val_Loss: 58.3449  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1331: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2733 Val_Loss: 58.5620  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1332: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1936 Val_Loss: 58.7925  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1333: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2117 Val_Loss: 58.2623  BEST VAL Loss: 57.7306\n",
            "\n",
            "Epoch 1334: Validation loss decreased (57.730579 --> 57.639374).\n",
            "\t Train_Loss: 8.0807 Val_Loss: 57.6394  BEST VAL Loss: 57.6394\n",
            "\n",
            "Epoch 1335: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1706 Val_Loss: 57.8054  BEST VAL Loss: 57.6394\n",
            "\n",
            "Epoch 1336: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1048 Val_Loss: 58.2019  BEST VAL Loss: 57.6394\n",
            "\n",
            "Epoch 1337: Validation loss did not decrease\n",
            "\t Train_Loss: 8.0347 Val_Loss: 58.4528  BEST VAL Loss: 57.6394\n",
            "\n",
            "Epoch 1338: Validation loss did not decrease\n",
            "\t Train_Loss: 8.0168 Val_Loss: 58.0976  BEST VAL Loss: 57.6394\n",
            "\n",
            "Epoch 1339: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8967 Val_Loss: 57.8527  BEST VAL Loss: 57.6394\n",
            "\n",
            "Epoch 1340: Validation loss did not decrease\n",
            "\t Train_Loss: 7.9463 Val_Loss: 58.3001  BEST VAL Loss: 57.6394\n",
            "\n",
            "Epoch 1341: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8508 Val_Loss: 58.6863  BEST VAL Loss: 57.6394\n",
            "\n",
            "Epoch 1342: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8568 Val_Loss: 58.4180  BEST VAL Loss: 57.6394\n",
            "\n",
            "Epoch 1343: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8022 Val_Loss: 57.6511  BEST VAL Loss: 57.6394\n",
            "\n",
            "Epoch 1344: Validation loss decreased (57.639374 --> 57.623512).\n",
            "\t Train_Loss: 7.7688 Val_Loss: 57.6235  BEST VAL Loss: 57.6235\n",
            "\n",
            "Epoch 1345: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7120 Val_Loss: 58.0503  BEST VAL Loss: 57.6235\n",
            "\n",
            "Epoch 1346: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7186 Val_Loss: 57.8103  BEST VAL Loss: 57.6235\n",
            "\n",
            "Epoch 1347: Validation loss decreased (57.623512 --> 57.365135).\n",
            "\t Train_Loss: 7.6399 Val_Loss: 57.3651  BEST VAL Loss: 57.3651\n",
            "\n",
            "Epoch 1348: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6524 Val_Loss: 57.8437  BEST VAL Loss: 57.3651\n",
            "\n",
            "Epoch 1349: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5889 Val_Loss: 57.8141  BEST VAL Loss: 57.3651\n",
            "\n",
            "Epoch 1350: Validation loss decreased (57.365135 --> 57.174263).\n",
            "\t Train_Loss: 7.5771 Val_Loss: 57.1743  BEST VAL Loss: 57.1743\n",
            "\n",
            "Epoch 1351: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6117 Val_Loss: 57.5133  BEST VAL Loss: 57.1743\n",
            "\n",
            "Epoch 1352: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5258 Val_Loss: 57.5699  BEST VAL Loss: 57.1743\n",
            "\n",
            "Epoch 1353: Validation loss decreased (57.174263 --> 56.893227).\n",
            "\t Train_Loss: 7.5253 Val_Loss: 56.8932  BEST VAL Loss: 56.8932\n",
            "\n",
            "Epoch 1354: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5625 Val_Loss: 57.3252  BEST VAL Loss: 56.8932\n",
            "\n",
            "Epoch 1355: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4711 Val_Loss: 57.6092  BEST VAL Loss: 56.8932\n",
            "\n",
            "Epoch 1356: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4942 Val_Loss: 57.1479  BEST VAL Loss: 56.8932\n",
            "\n",
            "Epoch 1357: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4313 Val_Loss: 57.1050  BEST VAL Loss: 56.8932\n",
            "\n",
            "Epoch 1358: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4044 Val_Loss: 57.0307  BEST VAL Loss: 56.8932\n",
            "\n",
            "Epoch 1359: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3709 Val_Loss: 57.1643  BEST VAL Loss: 56.8932\n",
            "\n",
            "Epoch 1360: Validation loss decreased (56.893227 --> 56.486275).\n",
            "\t Train_Loss: 7.3763 Val_Loss: 56.4863  BEST VAL Loss: 56.4863\n",
            "\n",
            "Epoch 1361: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6105 Val_Loss: 59.4814  BEST VAL Loss: 56.4863\n",
            "\n",
            "Epoch 1362: Validation loss did not decrease\n",
            "\t Train_Loss: 8.8239 Val_Loss: 56.8742  BEST VAL Loss: 56.4863\n",
            "\n",
            "Epoch 1363: Validation loss decreased (56.486275 --> 56.161610).\n",
            "\t Train_Loss: 7.6589 Val_Loss: 56.1616  BEST VAL Loss: 56.1616\n",
            "\n",
            "Epoch 1364: Validation loss did not decrease\n",
            "\t Train_Loss: 8.5506 Val_Loss: 61.0794  BEST VAL Loss: 56.1616\n",
            "\n",
            "Epoch 1365: Validation loss did not decrease\n",
            "\t Train_Loss: 9.8754 Val_Loss: 58.0056  BEST VAL Loss: 56.1616\n",
            "\n",
            "Epoch 1366: Validation loss decreased (56.161610 --> 54.996143).\n",
            "\t Train_Loss: 8.0059 Val_Loss: 54.9961  BEST VAL Loss: 54.9961\n",
            "\n",
            "Epoch 1367: Validation loss did not decrease\n",
            "\t Train_Loss: 8.8992 Val_Loss: 58.4383  BEST VAL Loss: 54.9961\n",
            "\n",
            "Epoch 1368: Validation loss did not decrease\n",
            "\t Train_Loss: 8.3882 Val_Loss: 58.8752  BEST VAL Loss: 54.9961\n",
            "\n",
            "Epoch 1369: Validation loss decreased (54.996143 --> 54.699554).\n",
            "\t Train_Loss: 9.7753 Val_Loss: 54.6996  BEST VAL Loss: 54.6996\n",
            "\n",
            "Epoch 1370: Validation loss decreased (54.699554 --> 54.015419).\n",
            "\t Train_Loss: 9.1416 Val_Loss: 54.0154  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1371: Validation loss did not decrease\n",
            "\t Train_Loss: 10.3502 Val_Loss: 56.5602  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1372: Validation loss did not decrease\n",
            "\t Train_Loss: 8.4778 Val_Loss: 58.2358  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1373: Validation loss did not decrease\n",
            "\t Train_Loss: 10.3623 Val_Loss: 56.5963  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1374: Validation loss did not decrease\n",
            "\t Train_Loss: 8.7316 Val_Loss: 56.1796  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1375: Validation loss did not decrease\n",
            "\t Train_Loss: 11.9690 Val_Loss: 57.2103  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1376: Validation loss did not decrease\n",
            "\t Train_Loss: 8.0943 Val_Loss: 59.0537  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1377: Validation loss did not decrease\n",
            "\t Train_Loss: 10.5906 Val_Loss: 56.0744  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1378: Validation loss did not decrease\n",
            "\t Train_Loss: 9.3195 Val_Loss: 54.1320  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1379: Validation loss did not decrease\n",
            "\t Train_Loss: 9.8335 Val_Loss: 54.2054  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1380: Validation loss did not decrease\n",
            "\t Train_Loss: 8.8679 Val_Loss: 55.7488  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1381: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1107 Val_Loss: 56.8733  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1382: Validation loss did not decrease\n",
            "\t Train_Loss: 9.7554 Val_Loss: 56.7456  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1383: Validation loss did not decrease\n",
            "\t Train_Loss: 9.2041 Val_Loss: 56.4540  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1384: Validation loss did not decrease\n",
            "\t Train_Loss: 8.4628 Val_Loss: 55.7400  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1385: Validation loss did not decrease\n",
            "\t Train_Loss: 8.6148 Val_Loss: 54.6331  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1386: Validation loss did not decrease\n",
            "\t Train_Loss: 9.6521 Val_Loss: 54.4921  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1387: Validation loss did not decrease\n",
            "\t Train_Loss: 9.1814 Val_Loss: 55.6461  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1388: Validation loss did not decrease\n",
            "\t Train_Loss: 8.3615 Val_Loss: 56.9768  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1389: Validation loss did not decrease\n",
            "\t Train_Loss: 8.3752 Val_Loss: 56.8802  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1390: Validation loss did not decrease\n",
            "\t Train_Loss: 8.6782 Val_Loss: 55.7683  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1391: Validation loss did not decrease\n",
            "\t Train_Loss: 9.2044 Val_Loss: 55.3953  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1392: Validation loss did not decrease\n",
            "\t Train_Loss: 7.9221 Val_Loss: 55.8103  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1393: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8693 Val_Loss: 55.9935  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1394: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1368 Val_Loss: 55.5615  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1395: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2571 Val_Loss: 55.3051  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1396: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1077 Val_Loss: 55.5369  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1397: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8859 Val_Loss: 55.2216  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1398: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7105 Val_Loss: 54.8788  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1399: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7746 Val_Loss: 55.1511  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1400: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8118 Val_Loss: 56.4761  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1401: Validation loss did not decrease\n",
            "\t Train_Loss: 8.0837 Val_Loss: 56.4013  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1402: Validation loss did not decrease\n",
            "\t Train_Loss: 8.0162 Val_Loss: 55.2824  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1403: Validation loss did not decrease\n",
            "\t Train_Loss: 8.0928 Val_Loss: 55.8227  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1404: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6543 Val_Loss: 56.9250  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1405: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8408 Val_Loss: 56.9311  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1406: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8567 Val_Loss: 55.7750  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1407: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7042 Val_Loss: 54.7919  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1408: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7216 Val_Loss: 54.8957  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1409: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6119 Val_Loss: 54.9735  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1410: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5637 Val_Loss: 55.2921  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1411: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5296 Val_Loss: 55.2193  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1412: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3904 Val_Loss: 55.0589  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1413: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4345 Val_Loss: 54.8720  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1414: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3563 Val_Loss: 54.9520  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1415: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2545 Val_Loss: 54.8158  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1416: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2913 Val_Loss: 54.9634  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1417: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4522 Val_Loss: 54.1335  BEST VAL Loss: 54.0154\n",
            "\n",
            "Epoch 1418: Validation loss decreased (54.015419 --> 53.559986).\n",
            "\t Train_Loss: 7.1965 Val_Loss: 53.5600  BEST VAL Loss: 53.5600\n",
            "\n",
            "Epoch 1419: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3497 Val_Loss: 54.7223  BEST VAL Loss: 53.5600\n",
            "\n",
            "Epoch 1420: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1676 Val_Loss: 55.3977  BEST VAL Loss: 53.5600\n",
            "\n",
            "Epoch 1421: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3559 Val_Loss: 54.2976  BEST VAL Loss: 53.5600\n",
            "\n",
            "Epoch 1422: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0858 Val_Loss: 54.0765  BEST VAL Loss: 53.5600\n",
            "\n",
            "Epoch 1423: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2362 Val_Loss: 54.7159  BEST VAL Loss: 53.5600\n",
            "\n",
            "Epoch 1424: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0353 Val_Loss: 54.6851  BEST VAL Loss: 53.5600\n",
            "\n",
            "Epoch 1425: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0335 Val_Loss: 53.8231  BEST VAL Loss: 53.5600\n",
            "\n",
            "Epoch 1426: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1064 Val_Loss: 53.5629  BEST VAL Loss: 53.5600\n",
            "\n",
            "Epoch 1427: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0884 Val_Loss: 53.9175  BEST VAL Loss: 53.5600\n",
            "\n",
            "Epoch 1428: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9454 Val_Loss: 54.8644  BEST VAL Loss: 53.5600\n",
            "\n",
            "Epoch 1429: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9846 Val_Loss: 53.9494  BEST VAL Loss: 53.5600\n",
            "\n",
            "Epoch 1430: Validation loss decreased (53.559986 --> 53.342262).\n",
            "\t Train_Loss: 6.9929 Val_Loss: 53.3423  BEST VAL Loss: 53.3423\n",
            "\n",
            "Epoch 1431: Validation loss did not decrease\n",
            "\t Train_Loss: 8.0242 Val_Loss: 55.5981  BEST VAL Loss: 53.3423\n",
            "\n",
            "Epoch 1432: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4503 Val_Loss: 54.1188  BEST VAL Loss: 53.3423\n",
            "\n",
            "Epoch 1433: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8948 Val_Loss: 53.5282  BEST VAL Loss: 53.3423\n",
            "\n",
            "Epoch 1434: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2231 Val_Loss: 55.4101  BEST VAL Loss: 53.3423\n",
            "\n",
            "Epoch 1435: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1830 Val_Loss: 53.9396  BEST VAL Loss: 53.3423\n",
            "\n",
            "Epoch 1436: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8860 Val_Loss: 57.1601  BEST VAL Loss: 53.3423\n",
            "\n",
            "Epoch 1437: Validation loss decreased (53.342262 --> 52.431988).\n",
            "\t Train_Loss: 9.1900 Val_Loss: 52.4320  BEST VAL Loss: 52.4320\n",
            "\n",
            "Epoch 1438: Validation loss decreased (52.431988 --> 51.116585).\n",
            "\t Train_Loss: 7.6147 Val_Loss: 51.1166  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1439: Validation loss did not decrease\n",
            "\t Train_Loss: 9.1370 Val_Loss: 55.5298  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1440: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2408 Val_Loss: 56.1111  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1441: Validation loss did not decrease\n",
            "\t Train_Loss: 9.0255 Val_Loss: 51.6936  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1442: Validation loss did not decrease\n",
            "\t Train_Loss: 8.0287 Val_Loss: 52.1828  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1443: Validation loss did not decrease\n",
            "\t Train_Loss: 11.3946 Val_Loss: 52.8189  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1444: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7395 Val_Loss: 57.3834  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1445: Validation loss did not decrease\n",
            "\t Train_Loss: 11.2085 Val_Loss: 55.3772  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1446: Validation loss did not decrease\n",
            "\t Train_Loss: 9.0645 Val_Loss: 52.5396  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1447: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2825 Val_Loss: 52.0704  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1448: Validation loss did not decrease\n",
            "\t Train_Loss: 10.4076 Val_Loss: 51.4006  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1449: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1945 Val_Loss: 52.6735  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1450: Validation loss did not decrease\n",
            "\t Train_Loss: 8.3681 Val_Loss: 53.8206  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1451: Validation loss did not decrease\n",
            "\t Train_Loss: 9.2756 Val_Loss: 53.3638  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1452: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5605 Val_Loss: 54.6684  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1453: Validation loss did not decrease\n",
            "\t Train_Loss: 8.3492 Val_Loss: 54.8943  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1454: Validation loss did not decrease\n",
            "\t Train_Loss: 8.4021 Val_Loss: 54.1130  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1455: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6188 Val_Loss: 54.2975  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1456: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2911 Val_Loss: 53.0504  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1457: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6604 Val_Loss: 51.6786  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1458: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6939 Val_Loss: 51.2670  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1459: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1030 Val_Loss: 51.9055  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1460: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6064 Val_Loss: 53.1071  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1461: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1390 Val_Loss: 54.6642  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1462: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1454 Val_Loss: 53.9305  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1463: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3161 Val_Loss: 53.1731  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1464: Validation loss did not decrease\n",
            "\t Train_Loss: 8.0030 Val_Loss: 52.6603  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1465: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0753 Val_Loss: 53.6488  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1466: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2616 Val_Loss: 53.5380  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1467: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4012 Val_Loss: 52.2058  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1468: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2176 Val_Loss: 51.7864  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1469: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2601 Val_Loss: 51.9948  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1470: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1469 Val_Loss: 52.3089  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1471: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9868 Val_Loss: 52.4057  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1472: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9407 Val_Loss: 52.1788  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1473: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9021 Val_Loss: 52.3529  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1474: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7988 Val_Loss: 52.2763  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1475: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7475 Val_Loss: 51.9579  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1476: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7351 Val_Loss: 52.0809  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1477: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7161 Val_Loss: 51.9701  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1478: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7056 Val_Loss: 51.8256  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1479: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6482 Val_Loss: 51.6791  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1480: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5673 Val_Loss: 52.1108  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1481: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5633 Val_Loss: 51.7395  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1482: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6262 Val_Loss: 52.1376  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1483: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4722 Val_Loss: 52.0791  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1484: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6466 Val_Loss: 52.1403  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1485: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4771 Val_Loss: 51.6186  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1486: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4279 Val_Loss: 51.1644  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1487: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5544 Val_Loss: 51.8479  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1488: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6693 Val_Loss: 51.4688  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1489: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4444 Val_Loss: 51.5848  BEST VAL Loss: 51.1166\n",
            "\n",
            "Epoch 1490: Validation loss decreased (51.116585 --> 51.065052).\n",
            "\t Train_Loss: 6.3438 Val_Loss: 51.0651  BEST VAL Loss: 51.0651\n",
            "\n",
            "Epoch 1491: Validation loss decreased (51.065052 --> 50.941139).\n",
            "\t Train_Loss: 6.4037 Val_Loss: 50.9411  BEST VAL Loss: 50.9411\n",
            "\n",
            "Epoch 1492: Validation loss did not decrease\n",
            "\t Train_Loss: 6.3451 Val_Loss: 51.7253  BEST VAL Loss: 50.9411\n",
            "\n",
            "Epoch 1493: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5174 Val_Loss: 51.6939  BEST VAL Loss: 50.9411\n",
            "\n",
            "Epoch 1494: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6471 Val_Loss: 53.8880  BEST VAL Loss: 50.9411\n",
            "\n",
            "Epoch 1495: Validation loss decreased (50.941139 --> 50.927776).\n",
            "\t Train_Loss: 8.6283 Val_Loss: 50.9278  BEST VAL Loss: 50.9278\n",
            "\n",
            "Epoch 1496: Validation loss decreased (50.927776 --> 50.302197).\n",
            "\t Train_Loss: 7.4592 Val_Loss: 50.3022  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1497: Validation loss did not decrease\n",
            "\t Train_Loss: 9.2996 Val_Loss: 54.2790  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1498: Validation loss did not decrease\n",
            "\t Train_Loss: 8.9354 Val_Loss: 55.7191  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1499: Validation loss did not decrease\n",
            "\t Train_Loss: 10.4865 Val_Loss: 52.6021  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1500: Validation loss did not decrease\n",
            "\t Train_Loss: 8.7509 Val_Loss: 52.2888  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1501: Validation loss did not decrease\n",
            "\t Train_Loss: 8.7364 Val_Loss: 52.0491  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1502: Validation loss did not decrease\n",
            "\t Train_Loss: 9.0038 Val_Loss: 53.3161  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1503: Validation loss did not decrease\n",
            "\t Train_Loss: 7.9486 Val_Loss: 54.1258  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1504: Validation loss did not decrease\n",
            "\t Train_Loss: 9.4914 Val_Loss: 54.1018  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1505: Validation loss did not decrease\n",
            "\t Train_Loss: 8.7264 Val_Loss: 55.0536  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1506: Validation loss did not decrease\n",
            "\t Train_Loss: 9.6223 Val_Loss: 55.1942  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1507: Validation loss did not decrease\n",
            "\t Train_Loss: 12.1520 Val_Loss: 54.9694  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1508: Validation loss did not decrease\n",
            "\t Train_Loss: 11.3632 Val_Loss: 57.4521  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1509: Validation loss did not decrease\n",
            "\t Train_Loss: 9.8484 Val_Loss: 59.6198  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1510: Validation loss did not decrease\n",
            "\t Train_Loss: 11.1606 Val_Loss: 55.5362  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1511: Validation loss did not decrease\n",
            "\t Train_Loss: 9.8871 Val_Loss: 53.7734  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1512: Validation loss did not decrease\n",
            "\t Train_Loss: 9.1300 Val_Loss: 52.0882  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1513: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1281 Val_Loss: 50.9543  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1514: Validation loss did not decrease\n",
            "\t Train_Loss: 8.4583 Val_Loss: 51.0654  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1515: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1974 Val_Loss: 51.1001  BEST VAL Loss: 50.3022\n",
            "\n",
            "Epoch 1516: Validation loss decreased (50.302197 --> 50.045975).\n",
            "\t Train_Loss: 7.6439 Val_Loss: 50.0460  BEST VAL Loss: 50.0460\n",
            "\n",
            "Epoch 1517: Validation loss decreased (50.045975 --> 49.367348).\n",
            "\t Train_Loss: 7.1599 Val_Loss: 49.3673  BEST VAL Loss: 49.3673\n",
            "\n",
            "Epoch 1518: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4101 Val_Loss: 49.5936  BEST VAL Loss: 49.3673\n",
            "\n",
            "Epoch 1519: Validation loss decreased (49.367348 --> 49.250660).\n",
            "\t Train_Loss: 7.9022 Val_Loss: 49.2507  BEST VAL Loss: 49.2507\n",
            "\n",
            "Epoch 1520: Validation loss decreased (49.250660 --> 49.045959).\n",
            "\t Train_Loss: 7.6802 Val_Loss: 49.0460  BEST VAL Loss: 49.0460\n",
            "\n",
            "Epoch 1521: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8921 Val_Loss: 50.1109  BEST VAL Loss: 49.0460\n",
            "\n",
            "Epoch 1522: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5027 Val_Loss: 50.3462  BEST VAL Loss: 49.0460\n",
            "\n",
            "Epoch 1523: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5664 Val_Loss: 49.6851  BEST VAL Loss: 49.0460\n",
            "\n",
            "Epoch 1524: Validation loss decreased (49.045959 --> 48.572662).\n",
            "\t Train_Loss: 7.4318 Val_Loss: 48.5727  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1525: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5936 Val_Loss: 48.7311  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1526: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2251 Val_Loss: 49.0123  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1527: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1492 Val_Loss: 48.7799  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1528: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7292 Val_Loss: 49.2801  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1529: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8384 Val_Loss: 49.9409  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1530: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8527 Val_Loss: 50.4643  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1531: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5723 Val_Loss: 51.1190  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1532: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8967 Val_Loss: 51.1029  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1533: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6849 Val_Loss: 50.3007  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1534: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5920 Val_Loss: 49.7395  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1535: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6417 Val_Loss: 49.7795  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1536: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5735 Val_Loss: 49.6476  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1537: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4144 Val_Loss: 48.9918  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1538: Validation loss did not decrease\n",
            "\t Train_Loss: 6.2225 Val_Loss: 48.8836  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1539: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5541 Val_Loss: 49.1452  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1540: Validation loss did not decrease\n",
            "\t Train_Loss: 6.2205 Val_Loss: 49.6458  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1541: Validation loss did not decrease\n",
            "\t Train_Loss: 6.2409 Val_Loss: 49.3770  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1542: Validation loss did not decrease\n",
            "\t Train_Loss: 6.2690 Val_Loss: 49.4596  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1543: Validation loss did not decrease\n",
            "\t Train_Loss: 6.1692 Val_Loss: 50.0408  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1544: Validation loss did not decrease\n",
            "\t Train_Loss: 6.2403 Val_Loss: 49.6358  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1545: Validation loss did not decrease\n",
            "\t Train_Loss: 5.9949 Val_Loss: 49.1449  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1546: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4521 Val_Loss: 52.1720  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1547: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5460 Val_Loss: 49.4893  BEST VAL Loss: 48.5727\n",
            "\n",
            "Epoch 1548: Validation loss decreased (48.572662 --> 47.451447).\n",
            "\t Train_Loss: 6.5060 Val_Loss: 47.4514  BEST VAL Loss: 47.4514\n",
            "\n",
            "Epoch 1549: Validation loss decreased (47.451447 --> 47.363754).\n",
            "\t Train_Loss: 6.8672 Val_Loss: 47.3638  BEST VAL Loss: 47.3638\n",
            "\n",
            "Epoch 1550: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8977 Val_Loss: 47.9668  BEST VAL Loss: 47.3638\n",
            "\n",
            "Epoch 1551: Validation loss did not decrease\n",
            "\t Train_Loss: 6.3334 Val_Loss: 49.5717  BEST VAL Loss: 47.3638\n",
            "\n",
            "Epoch 1552: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1327 Val_Loss: 49.6305  BEST VAL Loss: 47.3638\n",
            "\n",
            "Epoch 1553: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4036 Val_Loss: 49.9847  BEST VAL Loss: 47.3638\n",
            "\n",
            "Epoch 1554: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7433 Val_Loss: 50.4862  BEST VAL Loss: 47.3638\n",
            "\n",
            "Epoch 1555: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1801 Val_Loss: 49.7062  BEST VAL Loss: 47.3638\n",
            "\n",
            "Epoch 1556: Validation loss did not decrease\n",
            "\t Train_Loss: 6.3558 Val_Loss: 51.4470  BEST VAL Loss: 47.3638\n",
            "\n",
            "Epoch 1557: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2161 Val_Loss: 48.7858  BEST VAL Loss: 47.3638\n",
            "\n",
            "Epoch 1558: Validation loss decreased (47.363754 --> 47.307129).\n",
            "\t Train_Loss: 6.3514 Val_Loss: 47.3071  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1559: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7357 Val_Loss: 47.9943  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1560: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9709 Val_Loss: 51.2666  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1561: Validation loss did not decrease\n",
            "\t Train_Loss: 9.2204 Val_Loss: 48.0494  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1562: Validation loss did not decrease\n",
            "\t Train_Loss: 6.0856 Val_Loss: 50.5843  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1563: Validation loss did not decrease\n",
            "\t Train_Loss: 9.0107 Val_Loss: 52.6690  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1564: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2544 Val_Loss: 55.5227  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1565: Validation loss did not decrease\n",
            "\t Train_Loss: 10.1122 Val_Loss: 53.2539  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1566: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7702 Val_Loss: 54.4565  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1567: Validation loss did not decrease\n",
            "\t Train_Loss: 8.6471 Val_Loss: 52.8629  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1568: Validation loss did not decrease\n",
            "\t Train_Loss: 8.0319 Val_Loss: 51.6173  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1569: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3252 Val_Loss: 50.7487  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1570: Validation loss did not decrease\n",
            "\t Train_Loss: 8.3376 Val_Loss: 49.7855  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1571: Validation loss did not decrease\n",
            "\t Train_Loss: 7.9990 Val_Loss: 49.1574  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1572: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8691 Val_Loss: 48.4487  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1573: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6859 Val_Loss: 47.6453  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1574: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7683 Val_Loss: 47.6119  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1575: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3662 Val_Loss: 48.4251  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1576: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5338 Val_Loss: 50.7249  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1577: Validation loss did not decrease\n",
            "\t Train_Loss: 11.0897 Val_Loss: 58.3262  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1578: Validation loss did not decrease\n",
            "\t Train_Loss: 11.8561 Val_Loss: 70.8108  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1579: Validation loss did not decrease\n",
            "\t Train_Loss: 16.2181 Val_Loss: 75.5719  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1580: Validation loss did not decrease\n",
            "\t Train_Loss: 17.6230 Val_Loss: 74.7298  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1581: Validation loss did not decrease\n",
            "\t Train_Loss: 16.2696 Val_Loss: 72.3140  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1582: Validation loss did not decrease\n",
            "\t Train_Loss: 15.3088 Val_Loss: 67.7478  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1583: Validation loss did not decrease\n",
            "\t Train_Loss: 13.4289 Val_Loss: 65.9591  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1584: Validation loss did not decrease\n",
            "\t Train_Loss: 12.5196 Val_Loss: 63.9868  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1585: Validation loss did not decrease\n",
            "\t Train_Loss: 13.1977 Val_Loss: 60.0809  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1586: Validation loss did not decrease\n",
            "\t Train_Loss: 14.5001 Val_Loss: 57.9546  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1587: Validation loss did not decrease\n",
            "\t Train_Loss: 16.3015 Val_Loss: 53.9423  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1588: Validation loss did not decrease\n",
            "\t Train_Loss: 15.9078 Val_Loss: 51.5510  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1589: Validation loss did not decrease\n",
            "\t Train_Loss: 13.0782 Val_Loss: 53.0290  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1590: Validation loss did not decrease\n",
            "\t Train_Loss: 15.2801 Val_Loss: 55.4476  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1591: Validation loss did not decrease\n",
            "\t Train_Loss: 11.1627 Val_Loss: 60.4751  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1592: Validation loss did not decrease\n",
            "\t Train_Loss: 14.8293 Val_Loss: 60.5567  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1593: Validation loss did not decrease\n",
            "\t Train_Loss: 12.0826 Val_Loss: 56.1841  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1594: Validation loss did not decrease\n",
            "\t Train_Loss: 12.2511 Val_Loss: 54.3168  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1595: Validation loss did not decrease\n",
            "\t Train_Loss: 12.0745 Val_Loss: 53.8447  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1596: Validation loss did not decrease\n",
            "\t Train_Loss: 10.7885 Val_Loss: 54.3124  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1597: Validation loss did not decrease\n",
            "\t Train_Loss: 11.9871 Val_Loss: 51.3410  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1598: Validation loss did not decrease\n",
            "\t Train_Loss: 10.7218 Val_Loss: 50.4585  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1599: Validation loss did not decrease\n",
            "\t Train_Loss: 9.9539 Val_Loss: 51.8167  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1600: Validation loss did not decrease\n",
            "\t Train_Loss: 11.1546 Val_Loss: 52.8279  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1601: Validation loss did not decrease\n",
            "\t Train_Loss: 11.8401 Val_Loss: 53.5382  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1602: Validation loss did not decrease\n",
            "\t Train_Loss: 11.5834 Val_Loss: 53.1113  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1603: Validation loss did not decrease\n",
            "\t Train_Loss: 10.9108 Val_Loss: 52.1522  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1604: Validation loss did not decrease\n",
            "\t Train_Loss: 9.8193 Val_Loss: 50.5902  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1605: Validation loss did not decrease\n",
            "\t Train_Loss: 9.7003 Val_Loss: 49.5829  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1606: Validation loss did not decrease\n",
            "\t Train_Loss: 10.0159 Val_Loss: 50.0478  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1607: Validation loss did not decrease\n",
            "\t Train_Loss: 10.1452 Val_Loss: 51.4027  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1608: Validation loss did not decrease\n",
            "\t Train_Loss: 10.3055 Val_Loss: 51.6800  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1609: Validation loss did not decrease\n",
            "\t Train_Loss: 10.0035 Val_Loss: 51.5057  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1610: Validation loss did not decrease\n",
            "\t Train_Loss: 9.6229 Val_Loss: 52.1463  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1611: Validation loss did not decrease\n",
            "\t Train_Loss: 9.2031 Val_Loss: 52.8574  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1612: Validation loss did not decrease\n",
            "\t Train_Loss: 9.0097 Val_Loss: 52.4906  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1613: Validation loss did not decrease\n",
            "\t Train_Loss: 9.2037 Val_Loss: 51.0625  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1614: Validation loss did not decrease\n",
            "\t Train_Loss: 9.1667 Val_Loss: 50.0713  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1615: Validation loss did not decrease\n",
            "\t Train_Loss: 9.4864 Val_Loss: 50.6189  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1616: Validation loss did not decrease\n",
            "\t Train_Loss: 8.9433 Val_Loss: 52.4177  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1617: Validation loss did not decrease\n",
            "\t Train_Loss: 9.4401 Val_Loss: 52.1268  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1618: Validation loss did not decrease\n",
            "\t Train_Loss: 8.6878 Val_Loss: 51.9702  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1619: Validation loss did not decrease\n",
            "\t Train_Loss: 8.7412 Val_Loss: 52.2490  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1620: Validation loss did not decrease\n",
            "\t Train_Loss: 8.8073 Val_Loss: 53.0226  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1621: Validation loss did not decrease\n",
            "\t Train_Loss: 8.8323 Val_Loss: 54.0372  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1622: Validation loss did not decrease\n",
            "\t Train_Loss: 8.7618 Val_Loss: 54.2277  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1623: Validation loss did not decrease\n",
            "\t Train_Loss: 8.6450 Val_Loss: 53.0359  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1624: Validation loss did not decrease\n",
            "\t Train_Loss: 8.4826 Val_Loss: 51.7396  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1625: Validation loss did not decrease\n",
            "\t Train_Loss: 8.3808 Val_Loss: 51.3763  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1626: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2833 Val_Loss: 51.6248  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1627: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2099 Val_Loss: 52.0934  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1628: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1823 Val_Loss: 51.5433  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1629: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2073 Val_Loss: 51.3746  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1630: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1255 Val_Loss: 51.6135  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1631: Validation loss did not decrease\n",
            "\t Train_Loss: 8.0562 Val_Loss: 51.8810  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1632: Validation loss did not decrease\n",
            "\t Train_Loss: 8.0442 Val_Loss: 51.5583  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1633: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8963 Val_Loss: 51.1885  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1634: Validation loss did not decrease\n",
            "\t Train_Loss: 7.9492 Val_Loss: 51.6339  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1635: Validation loss did not decrease\n",
            "\t Train_Loss: 7.9092 Val_Loss: 51.8235  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1636: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8118 Val_Loss: 51.5734  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1637: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8339 Val_Loss: 51.2112  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1638: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8093 Val_Loss: 50.7794  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1639: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7857 Val_Loss: 50.5113  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1640: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7790 Val_Loss: 50.6124  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1641: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7384 Val_Loss: 50.8806  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1642: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6944 Val_Loss: 50.9438  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1643: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6200 Val_Loss: 50.9069  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1644: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5622 Val_Loss: 51.2592  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1645: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5219 Val_Loss: 51.3543  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1646: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4716 Val_Loss: 51.4492  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1647: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4072 Val_Loss: 51.5156  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1648: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3590 Val_Loss: 51.2932  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1649: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3322 Val_Loss: 51.0947  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1650: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3363 Val_Loss: 51.0651  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1651: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3359 Val_Loss: 51.1622  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1652: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3252 Val_Loss: 51.2350  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1653: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3010 Val_Loss: 51.2714  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1654: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2725 Val_Loss: 51.3853  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1655: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2467 Val_Loss: 51.4738  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1656: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2286 Val_Loss: 51.2348  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1657: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2034 Val_Loss: 51.0880  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1658: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1793 Val_Loss: 50.9710  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1659: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1655 Val_Loss: 50.7132  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1660: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1491 Val_Loss: 50.5328  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1661: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1358 Val_Loss: 50.5698  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1662: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1194 Val_Loss: 50.5353  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1663: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0997 Val_Loss: 50.4976  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1664: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0836 Val_Loss: 50.5964  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1665: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0671 Val_Loss: 50.5308  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1666: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0503 Val_Loss: 50.3450  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1667: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0338 Val_Loss: 50.2320  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1668: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0164 Val_Loss: 50.1234  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1669: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0005 Val_Loss: 49.9764  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1670: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9862 Val_Loss: 49.9108  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1671: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9730 Val_Loss: 49.8680  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1672: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9592 Val_Loss: 49.8146  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1673: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9439 Val_Loss: 49.8186  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1674: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9270 Val_Loss: 49.8575  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1675: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9101 Val_Loss: 49.8420  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1676: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8939 Val_Loss: 49.8095  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1677: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8775 Val_Loss: 49.7796  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1678: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8613 Val_Loss: 49.7029  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1679: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8454 Val_Loss: 49.6343  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1680: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8299 Val_Loss: 49.6115  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1681: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8148 Val_Loss: 49.5698  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1682: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7994 Val_Loss: 49.5281  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1683: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7836 Val_Loss: 49.5367  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1684: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7678 Val_Loss: 49.5423  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1685: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7520 Val_Loss: 49.5245  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1686: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7362 Val_Loss: 49.5148  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1687: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7205 Val_Loss: 49.4628  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1688: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7047 Val_Loss: 49.3745  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1689: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6892 Val_Loss: 49.3221  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1690: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6739 Val_Loss: 49.2692  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1691: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6584 Val_Loss: 49.2176  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1692: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6432 Val_Loss: 49.1882  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1693: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6279 Val_Loss: 49.1206  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1694: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6128 Val_Loss: 49.0670  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1695: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5981 Val_Loss: 49.0236  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1696: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5837 Val_Loss: 48.9611  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1697: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5696 Val_Loss: 48.9177  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1698: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5558 Val_Loss: 48.8559  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1699: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5424 Val_Loss: 48.8090  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1700: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5293 Val_Loss: 48.7865  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1701: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5164 Val_Loss: 48.7490  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1702: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5035 Val_Loss: 48.7163  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1703: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4909 Val_Loss: 48.6822  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1704: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4784 Val_Loss: 48.6373  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1705: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4662 Val_Loss: 48.6097  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1706: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4541 Val_Loss: 48.5879  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1707: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4423 Val_Loss: 48.5524  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1708: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4307 Val_Loss: 48.5230  BEST VAL Loss: 47.3071\n",
            "\n",
            "Epoch 1709: Validation loss did not decrease\n",
            "Early stopped at epoch : 1709\n"
          ]
        }
      ],
      "source": [
        "GRU_best_model, train_losses, val_losses = trainer(GRU_model, X_train, y_train, X_val, y_val, optimizer, criterion, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "jaUYwd9vFHuC",
        "outputId": "7ec90594-2408-4786-91a4-e446af189ed4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_losses, label = 'Train_loss')\n",
        "plt.plot(val_losses, label = 'validation_loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jcdsct5Y9a8"
      },
      "source": [
        "---\n",
        "### 5.4 Evaluate model on validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PHWWy8uCY7Vg"
      },
      "outputs": [],
      "source": [
        "val_predict_GRU = GRU_best_model(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "wThiG7D-ZBA_",
        "outputId": "d8401eeb-0837-4b73-ac6d-508d711819c2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(df[-len(y_val):].index, y_val.cpu(), label=\"actual\", marker=\"o\")\n",
        "plt.plot(df[-len(y_val):].index, val_predict_GRU.detach().cpu(), label=\"predicted\", marker=\"o\")\n",
        "plt.title(\"Electric production IP prediction by GRU RNN model\", fontsize=25)\n",
        "plt.ylabel(\"ylabel\")\n",
        "plt.legend(title_fontsize=14, fontsize=13, fancybox=True, shadow=True, frameon=True)\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDMYeUTH5Ki7"
      },
      "source": [
        "---\n",
        "---\n",
        "## 6 LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1qXDXQ9VfIW"
      },
      "source": [
        "---\n",
        "### 6.1 Define single LSTM cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bVP9ju7m39TL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self, input_length=10, hidden_size=20, bias=True):\n",
        "        super(LSTMCell, self).__init__()\n",
        "\n",
        "        self.input_length = input_length\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Define the layers\n",
        "        self.forget_gate = nn.Linear(input_length + hidden_size, hidden_size, bias=bias)\n",
        "        self.input_gate = nn.Linear(input_length + hidden_size, hidden_size, bias=bias)\n",
        "        self.cell_gate = nn.Linear(input_length + hidden_size, hidden_size, bias=bias)\n",
        "        self.output_gate = nn.Linear(input_length + hidden_size, hidden_size, bias=bias)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        std = 1.0 / np.sqrt(self.hidden_size)\n",
        "        for w in self.parameters():\n",
        "            w.data.uniform_(-std, std)\n",
        "\n",
        "    def forward(self, x, hx=None):\n",
        "        if hx is None:\n",
        "            hx = x.new_zeros(x.size(0), self.hidden_size, requires_grad=False)\n",
        "            cx = x.new_zeros(x.size(0), self.hidden_size, requires_grad=False)\n",
        "        else:\n",
        "            hx, cx = hx\n",
        "\n",
        "        combined = torch.cat((x, hx), 1)\n",
        "\n",
        "        # Compute the forget gate\n",
        "        fg = torch.sigmoid(self.forget_gate(combined))\n",
        "\n",
        "        # Compute the input gate\n",
        "        ig = torch.sigmoid(self.input_gate(combined))\n",
        "\n",
        "        # Compute the cell gate\n",
        "        cg = torch.tanh(self.cell_gate(combined))\n",
        "\n",
        "        # Compute the new cell state\n",
        "        cx = fg * cx + ig * cg\n",
        "\n",
        "        # Compute the output gate\n",
        "        og = torch.sigmoid(self.output_gate(combined))\n",
        "\n",
        "        # Compute the new hidden state\n",
        "        hx = og * torch.tanh(cx)\n",
        "\n",
        "        return hx, cx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQpH0TuoVpVf"
      },
      "source": [
        "---\n",
        "### 6.2 LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PshO9vv35REY"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, bias, output_size):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, bias=bias, batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hx=None):\n",
        "        out, _ = self.lstm(input, hx)\n",
        "\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7G5_9S7VxJ0"
      },
      "source": [
        "---\n",
        "### 6.3 Train LSTM model and plot losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQTMa2Xj6maS",
        "outputId": "984f608c-87c0-47c5-9479-59ff87482ea8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (lstm): LSTM(1, 50, batch_first=True)\n",
              "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LSTM_model = LSTM(input_size=1, hidden_size=50, num_layers=1, bias=True, output_size=1)\n",
        "LSTM_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "XuzlCGTrV_xH"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.008\n",
        "n_epochs = 2000\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(LSTM_model.parameters(), lr = learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwpdUK6Z6skV",
        "outputId": "aa3e8ec3-5e78-4b3d-d3fe-da1291ff6b91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 52: Validation loss decreased (7490.795898 --> 7436.373535).\n",
            "\t Train_Loss: 5270.1562 Val_Loss: 7436.3735  BEST VAL Loss: 7436.3735\n",
            "\n",
            "Epoch 53: Validation loss decreased (7436.373535 --> 7382.295898).\n",
            "\t Train_Loss: 5224.8135 Val_Loss: 7382.2959  BEST VAL Loss: 7382.2959\n",
            "\n",
            "Epoch 54: Validation loss decreased (7382.295898 --> 7328.570312).\n",
            "\t Train_Loss: 5179.7910 Val_Loss: 7328.5703  BEST VAL Loss: 7328.5703\n",
            "\n",
            "Epoch 55: Validation loss decreased (7328.570312 --> 7275.200195).\n",
            "\t Train_Loss: 5135.0947 Val_Loss: 7275.2002  BEST VAL Loss: 7275.2002\n",
            "\n",
            "Epoch 56: Validation loss decreased (7275.200195 --> 7222.190430).\n",
            "\t Train_Loss: 5090.7285 Val_Loss: 7222.1904  BEST VAL Loss: 7222.1904\n",
            "\n",
            "Epoch 57: Validation loss decreased (7222.190430 --> 7169.543945).\n",
            "\t Train_Loss: 5046.6943 Val_Loss: 7169.5439  BEST VAL Loss: 7169.5439\n",
            "\n",
            "Epoch 58: Validation loss decreased (7169.543945 --> 7117.262695).\n",
            "\t Train_Loss: 5002.9941 Val_Loss: 7117.2627  BEST VAL Loss: 7117.2627\n",
            "\n",
            "Epoch 59: Validation loss decreased (7117.262695 --> 7065.345215).\n",
            "\t Train_Loss: 4959.6304 Val_Loss: 7065.3452  BEST VAL Loss: 7065.3452\n",
            "\n",
            "Epoch 60: Validation loss decreased (7065.345215 --> 7013.795410).\n",
            "\t Train_Loss: 4916.6025 Val_Loss: 7013.7954  BEST VAL Loss: 7013.7954\n",
            "\n",
            "Epoch 61: Validation loss decreased (7013.795410 --> 6962.610840).\n",
            "\t Train_Loss: 4873.9102 Val_Loss: 6962.6108  BEST VAL Loss: 6962.6108\n",
            "\n",
            "Epoch 62: Validation loss decreased (6962.610840 --> 6911.791504).\n",
            "\t Train_Loss: 4831.5532 Val_Loss: 6911.7915  BEST VAL Loss: 6911.7915\n",
            "\n",
            "Epoch 63: Validation loss decreased (6911.791504 --> 6861.334473).\n",
            "\t Train_Loss: 4789.5303 Val_Loss: 6861.3345  BEST VAL Loss: 6861.3345\n",
            "\n",
            "Epoch 64: Validation loss decreased (6861.334473 --> 6811.239746).\n",
            "\t Train_Loss: 4747.8384 Val_Loss: 6811.2397  BEST VAL Loss: 6811.2397\n",
            "\n",
            "Epoch 65: Validation loss decreased (6811.239746 --> 6761.505371).\n",
            "\t Train_Loss: 4706.4780 Val_Loss: 6761.5054  BEST VAL Loss: 6761.5054\n",
            "\n",
            "Epoch 66: Validation loss decreased (6761.505371 --> 6712.128906).\n",
            "\t Train_Loss: 4665.4453 Val_Loss: 6712.1289  BEST VAL Loss: 6712.1289\n",
            "\n",
            "Epoch 67: Validation loss decreased (6712.128906 --> 6663.106445).\n",
            "\t Train_Loss: 4624.7368 Val_Loss: 6663.1064  BEST VAL Loss: 6663.1064\n",
            "\n",
            "Epoch 68: Validation loss decreased (6663.106445 --> 6614.434570).\n",
            "\t Train_Loss: 4584.3491 Val_Loss: 6614.4346  BEST VAL Loss: 6614.4346\n",
            "\n",
            "Epoch 69: Validation loss decreased (6614.434570 --> 6566.108398).\n",
            "\t Train_Loss: 4544.2788 Val_Loss: 6566.1084  BEST VAL Loss: 6566.1084\n",
            "\n",
            "Epoch 70: Validation loss decreased (6566.108398 --> 6518.123047).\n",
            "\t Train_Loss: 4504.5171 Val_Loss: 6518.1230  BEST VAL Loss: 6518.1230\n",
            "\n",
            "Epoch 71: Validation loss decreased (6518.123047 --> 6470.465820).\n",
            "\t Train_Loss: 4465.0552 Val_Loss: 6470.4658  BEST VAL Loss: 6470.4658\n",
            "\n",
            "Epoch 72: Validation loss decreased (6470.465820 --> 6423.117188).\n",
            "\t Train_Loss: 4425.8770 Val_Loss: 6423.1172  BEST VAL Loss: 6423.1172\n",
            "\n",
            "Epoch 73: Validation loss decreased (6423.117188 --> 6376.033691).\n",
            "\t Train_Loss: 4386.9565 Val_Loss: 6376.0337  BEST VAL Loss: 6376.0337\n",
            "\n",
            "Epoch 74: Validation loss decreased (6376.033691 --> 6329.113281).\n",
            "\t Train_Loss: 4348.2427 Val_Loss: 6329.1133  BEST VAL Loss: 6329.1133\n",
            "\n",
            "Epoch 75: Validation loss decreased (6329.113281 --> 6282.125488).\n",
            "\t Train_Loss: 4309.6406 Val_Loss: 6282.1255  BEST VAL Loss: 6282.1255\n",
            "\n",
            "Epoch 76: Validation loss decreased (6282.125488 --> 6234.713379).\n",
            "\t Train_Loss: 4270.9980 Val_Loss: 6234.7134  BEST VAL Loss: 6234.7134\n",
            "\n",
            "Epoch 77: Validation loss decreased (6234.713379 --> 6186.956543).\n",
            "\t Train_Loss: 4232.2026 Val_Loss: 6186.9565  BEST VAL Loss: 6186.9565\n",
            "\n",
            "Epoch 78: Validation loss decreased (6186.956543 --> 6139.776367).\n",
            "\t Train_Loss: 4193.4893 Val_Loss: 6139.7764  BEST VAL Loss: 6139.7764\n",
            "\n",
            "Epoch 79: Validation loss decreased (6139.776367 --> 6093.444336).\n",
            "\t Train_Loss: 4155.3086 Val_Loss: 6093.4443  BEST VAL Loss: 6093.4443\n",
            "\n",
            "Epoch 80: Validation loss decreased (6093.444336 --> 6047.596191).\n",
            "\t Train_Loss: 4117.6587 Val_Loss: 6047.5962  BEST VAL Loss: 6047.5962\n",
            "\n",
            "Epoch 81: Validation loss decreased (6047.596191 --> 6002.046875).\n",
            "\t Train_Loss: 4080.3394 Val_Loss: 6002.0469  BEST VAL Loss: 6002.0469\n",
            "\n",
            "Epoch 82: Validation loss decreased (6002.046875 --> 5956.758789).\n",
            "\t Train_Loss: 4043.2725 Val_Loss: 5956.7588  BEST VAL Loss: 5956.7588\n",
            "\n",
            "Epoch 83: Validation loss decreased (5956.758789 --> 5911.730957).\n",
            "\t Train_Loss: 4006.4431 Val_Loss: 5911.7310  BEST VAL Loss: 5911.7310\n",
            "\n",
            "Epoch 84: Validation loss decreased (5911.730957 --> 5866.971680).\n",
            "\t Train_Loss: 3969.8560 Val_Loss: 5866.9717  BEST VAL Loss: 5866.9717\n",
            "\n",
            "Epoch 85: Validation loss decreased (5866.971680 --> 5822.490723).\n",
            "\t Train_Loss: 3933.5200 Val_Loss: 5822.4907  BEST VAL Loss: 5822.4907\n",
            "\n",
            "Epoch 86: Validation loss decreased (5822.490723 --> 5778.293945).\n",
            "\t Train_Loss: 3897.4412 Val_Loss: 5778.2939  BEST VAL Loss: 5778.2939\n",
            "\n",
            "Epoch 87: Validation loss decreased (5778.293945 --> 5734.387695).\n",
            "\t Train_Loss: 3861.6262 Val_Loss: 5734.3877  BEST VAL Loss: 5734.3877\n",
            "\n",
            "Epoch 88: Validation loss decreased (5734.387695 --> 5690.778320).\n",
            "\t Train_Loss: 3826.0791 Val_Loss: 5690.7783  BEST VAL Loss: 5690.7783\n",
            "\n",
            "Epoch 89: Validation loss decreased (5690.778320 --> 5647.467285).\n",
            "\t Train_Loss: 3790.8037 Val_Loss: 5647.4673  BEST VAL Loss: 5647.4673\n",
            "\n",
            "Epoch 90: Validation loss decreased (5647.467285 --> 5604.458008).\n",
            "\t Train_Loss: 3755.8027 Val_Loss: 5604.4580  BEST VAL Loss: 5604.4580\n",
            "\n",
            "Epoch 91: Validation loss decreased (5604.458008 --> 5561.750000).\n",
            "\t Train_Loss: 3721.0769 Val_Loss: 5561.7500  BEST VAL Loss: 5561.7500\n",
            "\n",
            "Epoch 92: Validation loss decreased (5561.750000 --> 5519.348145).\n",
            "\t Train_Loss: 3686.6272 Val_Loss: 5519.3481  BEST VAL Loss: 5519.3481\n",
            "\n",
            "Epoch 93: Validation loss decreased (5519.348145 --> 5477.248535).\n",
            "\t Train_Loss: 3652.4551 Val_Loss: 5477.2485  BEST VAL Loss: 5477.2485\n",
            "\n",
            "Epoch 94: Validation loss decreased (5477.248535 --> 5435.451660).\n",
            "\t Train_Loss: 3618.5579 Val_Loss: 5435.4517  BEST VAL Loss: 5435.4517\n",
            "\n",
            "Epoch 95: Validation loss decreased (5435.451660 --> 5393.953125).\n",
            "\t Train_Loss: 3584.9314 Val_Loss: 5393.9531  BEST VAL Loss: 5393.9531\n",
            "\n",
            "Epoch 96: Validation loss decreased (5393.953125 --> 5352.730469).\n",
            "\t Train_Loss: 3551.5566 Val_Loss: 5352.7305  BEST VAL Loss: 5352.7305\n",
            "\n",
            "Epoch 97: Validation loss decreased (5352.730469 --> 5311.704102).\n",
            "\t Train_Loss: 3518.3762 Val_Loss: 5311.7041  BEST VAL Loss: 5311.7041\n",
            "\n",
            "Epoch 98: Validation loss decreased (5311.704102 --> 5270.557617).\n",
            "\t Train_Loss: 3485.2117 Val_Loss: 5270.5576  BEST VAL Loss: 5270.5576\n",
            "\n",
            "Epoch 99: Validation loss decreased (5270.557617 --> 5228.157227).\n",
            "\t Train_Loss: 3451.5498 Val_Loss: 5228.1572  BEST VAL Loss: 5228.1572\n",
            "\n",
            "Epoch 100: Validation loss decreased (5228.157227 --> 5182.319336).\n",
            "\t Train_Loss: 3416.4617 Val_Loss: 5182.3193  BEST VAL Loss: 5182.3193\n",
            "\n",
            "Epoch 101: Validation loss decreased (5182.319336 --> 5138.890137).\n",
            "\t Train_Loss: 3380.4189 Val_Loss: 5138.8901  BEST VAL Loss: 5138.8901\n",
            "\n",
            "Epoch 102: Validation loss decreased (5138.890137 --> 5099.003906).\n",
            "\t Train_Loss: 3347.3423 Val_Loss: 5099.0039  BEST VAL Loss: 5099.0039\n",
            "\n",
            "Epoch 103: Validation loss decreased (5099.003906 --> 5059.400391).\n",
            "\t Train_Loss: 3315.5200 Val_Loss: 5059.4004  BEST VAL Loss: 5059.4004\n",
            "\n",
            "Epoch 104: Validation loss decreased (5059.400391 --> 5020.078613).\n",
            "\t Train_Loss: 3283.9526 Val_Loss: 5020.0786  BEST VAL Loss: 5020.0786\n",
            "\n",
            "Epoch 105: Validation loss decreased (5020.078613 --> 4981.038086).\n",
            "\t Train_Loss: 3252.6416 Val_Loss: 4981.0381  BEST VAL Loss: 4981.0381\n",
            "\n",
            "Epoch 106: Validation loss decreased (4981.038086 --> 4942.282227).\n",
            "\t Train_Loss: 3221.5867 Val_Loss: 4942.2822  BEST VAL Loss: 4942.2822\n",
            "\n",
            "Epoch 107: Validation loss decreased (4942.282227 --> 4903.812012).\n",
            "\t Train_Loss: 3190.7896 Val_Loss: 4903.8120  BEST VAL Loss: 4903.8120\n",
            "\n",
            "Epoch 108: Validation loss decreased (4903.812012 --> 4865.624512).\n",
            "\t Train_Loss: 3160.2493 Val_Loss: 4865.6245  BEST VAL Loss: 4865.6245\n",
            "\n",
            "Epoch 109: Validation loss decreased (4865.624512 --> 4827.720703).\n",
            "\t Train_Loss: 3129.9663 Val_Loss: 4827.7207  BEST VAL Loss: 4827.7207\n",
            "\n",
            "Epoch 110: Validation loss decreased (4827.720703 --> 4790.100098).\n",
            "\t Train_Loss: 3099.9377 Val_Loss: 4790.1001  BEST VAL Loss: 4790.1001\n",
            "\n",
            "Epoch 111: Validation loss decreased (4790.100098 --> 4752.761230).\n",
            "\t Train_Loss: 3070.1631 Val_Loss: 4752.7612  BEST VAL Loss: 4752.7612\n",
            "\n",
            "Epoch 112: Validation loss decreased (4752.761230 --> 4715.699707).\n",
            "\t Train_Loss: 3040.6372 Val_Loss: 4715.6997  BEST VAL Loss: 4715.6997\n",
            "\n",
            "Epoch 113: Validation loss decreased (4715.699707 --> 4678.899414).\n",
            "\t Train_Loss: 3011.3450 Val_Loss: 4678.8994  BEST VAL Loss: 4678.8994\n",
            "\n",
            "Epoch 114: Validation loss decreased (4678.899414 --> 4642.271484).\n",
            "\t Train_Loss: 2982.2173 Val_Loss: 4642.2715  BEST VAL Loss: 4642.2715\n",
            "\n",
            "Epoch 115: Validation loss decreased (4642.271484 --> 4605.453125).\n",
            "\t Train_Loss: 2953.0032 Val_Loss: 4605.4531  BEST VAL Loss: 4605.4531\n",
            "\n",
            "Epoch 116: Validation loss decreased (4605.453125 --> 4567.141113).\n",
            "\t Train_Loss: 2923.2009 Val_Loss: 4567.1411  BEST VAL Loss: 4567.1411\n",
            "\n",
            "Epoch 117: Validation loss decreased (4567.141113 --> 4526.036621).\n",
            "\t Train_Loss: 2892.1941 Val_Loss: 4526.0366  BEST VAL Loss: 4526.0366\n",
            "\n",
            "Epoch 118: Validation loss decreased (4526.036621 --> 4486.096191).\n",
            "\t Train_Loss: 2860.5571 Val_Loss: 4486.0962  BEST VAL Loss: 4486.0962\n",
            "\n",
            "Epoch 119: Validation loss decreased (4486.096191 --> 4448.735840).\n",
            "\t Train_Loss: 2830.3689 Val_Loss: 4448.7358  BEST VAL Loss: 4448.7358\n",
            "\n",
            "Epoch 120: Validation loss decreased (4448.735840 --> 4411.127930).\n",
            "\t Train_Loss: 2801.1218 Val_Loss: 4411.1279  BEST VAL Loss: 4411.1279\n",
            "\n",
            "Epoch 121: Validation loss decreased (4411.127930 --> 4371.422852).\n",
            "\t Train_Loss: 2771.2859 Val_Loss: 4371.4229  BEST VAL Loss: 4371.4229\n",
            "\n",
            "Epoch 122: Validation loss decreased (4371.422852 --> 4330.298828).\n",
            "\t Train_Loss: 2740.1853 Val_Loss: 4330.2988  BEST VAL Loss: 4330.2988\n",
            "\n",
            "Epoch 123: Validation loss decreased (4330.298828 --> 4289.170410).\n",
            "\t Train_Loss: 2708.3218 Val_Loss: 4289.1704  BEST VAL Loss: 4289.1704\n",
            "\n",
            "Epoch 124: Validation loss decreased (4289.170410 --> 4251.451172).\n",
            "\t Train_Loss: 2676.8645 Val_Loss: 4251.4512  BEST VAL Loss: 4251.4512\n",
            "\n",
            "Epoch 125: Validation loss decreased (4251.451172 --> 4214.110352).\n",
            "\t Train_Loss: 2647.5796 Val_Loss: 4214.1104  BEST VAL Loss: 4214.1104\n",
            "\n",
            "Epoch 126: Validation loss decreased (4214.110352 --> 4176.964355).\n",
            "\t Train_Loss: 2618.5527 Val_Loss: 4176.9644  BEST VAL Loss: 4176.9644\n",
            "\n",
            "Epoch 127: Validation loss decreased (4176.964355 --> 4139.976074).\n",
            "\t Train_Loss: 2589.6953 Val_Loss: 4139.9761  BEST VAL Loss: 4139.9761\n",
            "\n",
            "Epoch 128: Validation loss decreased (4139.976074 --> 4102.899414).\n",
            "\t Train_Loss: 2560.9331 Val_Loss: 4102.8994  BEST VAL Loss: 4102.8994\n",
            "\n",
            "Epoch 129: Validation loss decreased (4102.899414 --> 4064.697754).\n",
            "\t Train_Loss: 2531.9534 Val_Loss: 4064.6978  BEST VAL Loss: 4064.6978\n",
            "\n",
            "Epoch 130: Validation loss decreased (4064.697754 --> 4024.775391).\n",
            "\t Train_Loss: 2501.9805 Val_Loss: 4024.7754  BEST VAL Loss: 4024.7754\n",
            "\n",
            "Epoch 131: Validation loss decreased (4024.775391 --> 3988.076904).\n",
            "\t Train_Loss: 2471.8352 Val_Loss: 3988.0769  BEST VAL Loss: 3988.0769\n",
            "\n",
            "Epoch 132: Validation loss decreased (3988.076904 --> 3951.987061).\n",
            "\t Train_Loss: 2443.7029 Val_Loss: 3951.9871  BEST VAL Loss: 3951.9871\n",
            "\n",
            "Epoch 133: Validation loss decreased (3951.987061 --> 3916.196777).\n",
            "\t Train_Loss: 2415.9207 Val_Loss: 3916.1968  BEST VAL Loss: 3916.1968\n",
            "\n",
            "Epoch 134: Validation loss decreased (3916.196777 --> 3880.715332).\n",
            "\t Train_Loss: 2388.4077 Val_Loss: 3880.7153  BEST VAL Loss: 3880.7153\n",
            "\n",
            "Epoch 135: Validation loss decreased (3880.715332 --> 3845.548340).\n",
            "\t Train_Loss: 2361.1702 Val_Loss: 3845.5483  BEST VAL Loss: 3845.5483\n",
            "\n",
            "Epoch 136: Validation loss decreased (3845.548340 --> 3810.699707).\n",
            "\t Train_Loss: 2334.2124 Val_Loss: 3810.6997  BEST VAL Loss: 3810.6997\n",
            "\n",
            "Epoch 137: Validation loss decreased (3810.699707 --> 3776.173340).\n",
            "\t Train_Loss: 2307.5369 Val_Loss: 3776.1733  BEST VAL Loss: 3776.1733\n",
            "\n",
            "Epoch 138: Validation loss decreased (3776.173340 --> 3741.971436).\n",
            "\t Train_Loss: 2281.1467 Val_Loss: 3741.9714  BEST VAL Loss: 3741.9714\n",
            "\n",
            "Epoch 139: Validation loss decreased (3741.971436 --> 3708.096191).\n",
            "\t Train_Loss: 2255.0417 Val_Loss: 3708.0962  BEST VAL Loss: 3708.0962\n",
            "\n",
            "Epoch 140: Validation loss decreased (3708.096191 --> 3674.545654).\n",
            "\t Train_Loss: 2229.2231 Val_Loss: 3674.5457  BEST VAL Loss: 3674.5457\n",
            "\n",
            "Epoch 141: Validation loss decreased (3674.545654 --> 3641.319092).\n",
            "\t Train_Loss: 2203.6902 Val_Loss: 3641.3191  BEST VAL Loss: 3641.3191\n",
            "\n",
            "Epoch 142: Validation loss decreased (3641.319092 --> 3608.418701).\n",
            "\t Train_Loss: 2178.4414 Val_Loss: 3608.4187  BEST VAL Loss: 3608.4187\n",
            "\n",
            "Epoch 143: Validation loss decreased (3608.418701 --> 3575.839355).\n",
            "\t Train_Loss: 2153.4763 Val_Loss: 3575.8394  BEST VAL Loss: 3575.8394\n",
            "\n",
            "Epoch 144: Validation loss decreased (3575.839355 --> 3543.581543).\n",
            "\t Train_Loss: 2128.7925 Val_Loss: 3543.5815  BEST VAL Loss: 3543.5815\n",
            "\n",
            "Epoch 145: Validation loss decreased (3543.581543 --> 3511.641357).\n",
            "\t Train_Loss: 2104.3882 Val_Loss: 3511.6414  BEST VAL Loss: 3511.6414\n",
            "\n",
            "Epoch 146: Validation loss decreased (3511.641357 --> 3480.018066).\n",
            "\t Train_Loss: 2080.2610 Val_Loss: 3480.0181  BEST VAL Loss: 3480.0181\n",
            "\n",
            "Epoch 147: Validation loss decreased (3480.018066 --> 3448.708252).\n",
            "\t Train_Loss: 2056.4092 Val_Loss: 3448.7083  BEST VAL Loss: 3448.7083\n",
            "\n",
            "Epoch 148: Validation loss decreased (3448.708252 --> 3417.708252).\n",
            "\t Train_Loss: 2032.8298 Val_Loss: 3417.7083  BEST VAL Loss: 3417.7083\n",
            "\n",
            "Epoch 149: Validation loss decreased (3417.708252 --> 3387.015625).\n",
            "\t Train_Loss: 2009.5193 Val_Loss: 3387.0156  BEST VAL Loss: 3387.0156\n",
            "\n",
            "Epoch 150: Validation loss decreased (3387.015625 --> 3356.628174).\n",
            "\t Train_Loss: 1986.4761 Val_Loss: 3356.6282  BEST VAL Loss: 3356.6282\n",
            "\n",
            "Epoch 151: Validation loss decreased (3356.628174 --> 3326.541016).\n",
            "\t Train_Loss: 1963.6968 Val_Loss: 3326.5410  BEST VAL Loss: 3326.5410\n",
            "\n",
            "Epoch 152: Validation loss decreased (3326.541016 --> 3296.752686).\n",
            "\t Train_Loss: 1941.1779 Val_Loss: 3296.7527  BEST VAL Loss: 3296.7527\n",
            "\n",
            "Epoch 153: Validation loss decreased (3296.752686 --> 3267.259277).\n",
            "\t Train_Loss: 1918.9175 Val_Loss: 3267.2593  BEST VAL Loss: 3267.2593\n",
            "\n",
            "Epoch 154: Validation loss decreased (3267.259277 --> 3238.057373).\n",
            "\t Train_Loss: 1896.9117 Val_Loss: 3238.0574  BEST VAL Loss: 3238.0574\n",
            "\n",
            "Epoch 155: Validation loss decreased (3238.057373 --> 3209.143311).\n",
            "\t Train_Loss: 1875.1580 Val_Loss: 3209.1433  BEST VAL Loss: 3209.1433\n",
            "\n",
            "Epoch 156: Validation loss decreased (3209.143311 --> 3180.514893).\n",
            "\t Train_Loss: 1853.6533 Val_Loss: 3180.5149  BEST VAL Loss: 3180.5149\n",
            "\n",
            "Epoch 157: Validation loss decreased (3180.514893 --> 3152.168457).\n",
            "\t Train_Loss: 1832.3953 Val_Loss: 3152.1685  BEST VAL Loss: 3152.1685\n",
            "\n",
            "Epoch 158: Validation loss decreased (3152.168457 --> 3124.099609).\n",
            "\t Train_Loss: 1811.3799 Val_Loss: 3124.0996  BEST VAL Loss: 3124.0996\n",
            "\n",
            "Epoch 159: Validation loss decreased (3124.099609 --> 3096.307129).\n",
            "\t Train_Loss: 1790.6044 Val_Loss: 3096.3071  BEST VAL Loss: 3096.3071\n",
            "\n",
            "Epoch 160: Validation loss decreased (3096.307129 --> 3068.786377).\n",
            "\t Train_Loss: 1770.0665 Val_Loss: 3068.7864  BEST VAL Loss: 3068.7864\n",
            "\n",
            "Epoch 161: Validation loss decreased (3068.786377 --> 3041.534668).\n",
            "\t Train_Loss: 1749.7632 Val_Loss: 3041.5347  BEST VAL Loss: 3041.5347\n",
            "\n",
            "Epoch 162: Validation loss decreased (3041.534668 --> 3014.548828).\n",
            "\t Train_Loss: 1729.6912 Val_Loss: 3014.5488  BEST VAL Loss: 3014.5488\n",
            "\n",
            "Epoch 163: Validation loss decreased (3014.548828 --> 2987.826172).\n",
            "\t Train_Loss: 1709.8481 Val_Loss: 2987.8262  BEST VAL Loss: 2987.8262\n",
            "\n",
            "Epoch 164: Validation loss decreased (2987.826172 --> 2961.363770).\n",
            "\t Train_Loss: 1690.2307 Val_Loss: 2961.3638  BEST VAL Loss: 2961.3638\n",
            "\n",
            "Epoch 165: Validation loss decreased (2961.363770 --> 2935.157471).\n",
            "\t Train_Loss: 1670.8373 Val_Loss: 2935.1575  BEST VAL Loss: 2935.1575\n",
            "\n",
            "Epoch 166: Validation loss decreased (2935.157471 --> 2909.205811).\n",
            "\t Train_Loss: 1651.6638 Val_Loss: 2909.2058  BEST VAL Loss: 2909.2058\n",
            "\n",
            "Epoch 167: Validation loss decreased (2909.205811 --> 2883.504639).\n",
            "\t Train_Loss: 1632.7089 Val_Loss: 2883.5046  BEST VAL Loss: 2883.5046\n",
            "\n",
            "Epoch 168: Validation loss decreased (2883.504639 --> 2858.052246).\n",
            "\t Train_Loss: 1613.9690 Val_Loss: 2858.0522  BEST VAL Loss: 2858.0522\n",
            "\n",
            "Epoch 169: Validation loss decreased (2858.052246 --> 2832.845215).\n",
            "\t Train_Loss: 1595.4420 Val_Loss: 2832.8452  BEST VAL Loss: 2832.8452\n",
            "\n",
            "Epoch 170: Validation loss decreased (2832.845215 --> 2807.880615).\n",
            "\t Train_Loss: 1577.1252 Val_Loss: 2807.8806  BEST VAL Loss: 2807.8806\n",
            "\n",
            "Epoch 171: Validation loss decreased (2807.880615 --> 2783.156738).\n",
            "\t Train_Loss: 1559.0164 Val_Loss: 2783.1567  BEST VAL Loss: 2783.1567\n",
            "\n",
            "Epoch 172: Validation loss decreased (2783.156738 --> 2758.669922).\n",
            "\t Train_Loss: 1541.1130 Val_Loss: 2758.6699  BEST VAL Loss: 2758.6699\n",
            "\n",
            "Epoch 173: Validation loss decreased (2758.669922 --> 2734.418213).\n",
            "\t Train_Loss: 1523.4122 Val_Loss: 2734.4182  BEST VAL Loss: 2734.4182\n",
            "\n",
            "Epoch 174: Validation loss decreased (2734.418213 --> 2710.398193).\n",
            "\t Train_Loss: 1505.9126 Val_Loss: 2710.3982  BEST VAL Loss: 2710.3982\n",
            "\n",
            "Epoch 175: Validation loss decreased (2710.398193 --> 2686.608154).\n",
            "\t Train_Loss: 1488.6112 Val_Loss: 2686.6082  BEST VAL Loss: 2686.6082\n",
            "\n",
            "Epoch 176: Validation loss decreased (2686.608154 --> 2663.045898).\n",
            "\t Train_Loss: 1471.5055 Val_Loss: 2663.0459  BEST VAL Loss: 2663.0459\n",
            "\n",
            "Epoch 177: Validation loss decreased (2663.045898 --> 2639.708496).\n",
            "\t Train_Loss: 1454.5944 Val_Loss: 2639.7085  BEST VAL Loss: 2639.7085\n",
            "\n",
            "Epoch 178: Validation loss decreased (2639.708496 --> 2616.593506).\n",
            "\t Train_Loss: 1437.8748 Val_Loss: 2616.5935  BEST VAL Loss: 2616.5935\n",
            "\n",
            "Epoch 179: Validation loss decreased (2616.593506 --> 2593.698730).\n",
            "\t Train_Loss: 1421.3444 Val_Loss: 2593.6987  BEST VAL Loss: 2593.6987\n",
            "\n",
            "Epoch 180: Validation loss decreased (2593.698730 --> 2571.021484).\n",
            "\t Train_Loss: 1405.0016 Val_Loss: 2571.0215  BEST VAL Loss: 2571.0215\n",
            "\n",
            "Epoch 181: Validation loss decreased (2571.021484 --> 2548.560303).\n",
            "\t Train_Loss: 1388.8439 Val_Loss: 2548.5603  BEST VAL Loss: 2548.5603\n",
            "\n",
            "Epoch 182: Validation loss decreased (2548.560303 --> 2526.312500).\n",
            "\t Train_Loss: 1372.8698 Val_Loss: 2526.3125  BEST VAL Loss: 2526.3125\n",
            "\n",
            "Epoch 183: Validation loss decreased (2526.312500 --> 2504.275879).\n",
            "\t Train_Loss: 1357.0767 Val_Loss: 2504.2759  BEST VAL Loss: 2504.2759\n",
            "\n",
            "Epoch 184: Validation loss decreased (2504.275879 --> 2482.448730).\n",
            "\t Train_Loss: 1341.4625 Val_Loss: 2482.4487  BEST VAL Loss: 2482.4487\n",
            "\n",
            "Epoch 185: Validation loss decreased (2482.448730 --> 2460.827881).\n",
            "\t Train_Loss: 1326.0262 Val_Loss: 2460.8279  BEST VAL Loss: 2460.8279\n",
            "\n",
            "Epoch 186: Validation loss decreased (2460.827881 --> 2439.412354).\n",
            "\t Train_Loss: 1310.7649 Val_Loss: 2439.4124  BEST VAL Loss: 2439.4124\n",
            "\n",
            "Epoch 187: Validation loss decreased (2439.412354 --> 2418.199707).\n",
            "\t Train_Loss: 1295.6771 Val_Loss: 2418.1997  BEST VAL Loss: 2418.1997\n",
            "\n",
            "Epoch 188: Validation loss decreased (2418.199707 --> 2397.187744).\n",
            "\t Train_Loss: 1280.7610 Val_Loss: 2397.1877  BEST VAL Loss: 2397.1877\n",
            "\n",
            "Epoch 189: Validation loss decreased (2397.187744 --> 2376.374512).\n",
            "\t Train_Loss: 1266.0143 Val_Loss: 2376.3745  BEST VAL Loss: 2376.3745\n",
            "\n",
            "Epoch 190: Validation loss decreased (2376.374512 --> 2355.758057).\n",
            "\t Train_Loss: 1251.4359 Val_Loss: 2355.7581  BEST VAL Loss: 2355.7581\n",
            "\n",
            "Epoch 191: Validation loss decreased (2355.758057 --> 2335.337402).\n",
            "\t Train_Loss: 1237.0233 Val_Loss: 2335.3374  BEST VAL Loss: 2335.3374\n",
            "\n",
            "Epoch 192: Validation loss decreased (2335.337402 --> 2315.108887).\n",
            "\t Train_Loss: 1222.7753 Val_Loss: 2315.1089  BEST VAL Loss: 2315.1089\n",
            "\n",
            "Epoch 193: Validation loss decreased (2315.108887 --> 2295.072510).\n",
            "\t Train_Loss: 1208.6901 Val_Loss: 2295.0725  BEST VAL Loss: 2295.0725\n",
            "\n",
            "Epoch 194: Validation loss decreased (2295.072510 --> 2275.224609).\n",
            "\t Train_Loss: 1194.7654 Val_Loss: 2275.2246  BEST VAL Loss: 2275.2246\n",
            "\n",
            "Epoch 195: Validation loss decreased (2275.224609 --> 2255.564941).\n",
            "\t Train_Loss: 1181.0001 Val_Loss: 2255.5649  BEST VAL Loss: 2255.5649\n",
            "\n",
            "Epoch 196: Validation loss decreased (2255.564941 --> 2236.090820).\n",
            "\t Train_Loss: 1167.3923 Val_Loss: 2236.0908  BEST VAL Loss: 2236.0908\n",
            "\n",
            "Epoch 197: Validation loss decreased (2236.090820 --> 2216.800781).\n",
            "\t Train_Loss: 1153.9407 Val_Loss: 2216.8008  BEST VAL Loss: 2216.8008\n",
            "\n",
            "Epoch 198: Validation loss decreased (2216.800781 --> 2197.692871).\n",
            "\t Train_Loss: 1140.6429 Val_Loss: 2197.6929  BEST VAL Loss: 2197.6929\n",
            "\n",
            "Epoch 199: Validation loss decreased (2197.692871 --> 2178.765625).\n",
            "\t Train_Loss: 1127.4980 Val_Loss: 2178.7656  BEST VAL Loss: 2178.7656\n",
            "\n",
            "Epoch 200: Validation loss decreased (2178.765625 --> 2160.017090).\n",
            "\t Train_Loss: 1114.5044 Val_Loss: 2160.0171  BEST VAL Loss: 2160.0171\n",
            "\n",
            "Epoch 201: Validation loss decreased (2160.017090 --> 2141.446289).\n",
            "\t Train_Loss: 1101.6600 Val_Loss: 2141.4463  BEST VAL Loss: 2141.4463\n",
            "\n",
            "Epoch 202: Validation loss decreased (2141.446289 --> 2123.050293).\n",
            "\t Train_Loss: 1088.9639 Val_Loss: 2123.0503  BEST VAL Loss: 2123.0503\n",
            "\n",
            "Epoch 203: Validation loss decreased (2123.050293 --> 2104.828613).\n",
            "\t Train_Loss: 1076.4139 Val_Loss: 2104.8286  BEST VAL Loss: 2104.8286\n",
            "\n",
            "Epoch 204: Validation loss decreased (2104.828613 --> 2086.779297).\n",
            "\t Train_Loss: 1064.0088 Val_Loss: 2086.7793  BEST VAL Loss: 2086.7793\n",
            "\n",
            "Epoch 205: Validation loss decreased (2086.779297 --> 2068.900879).\n",
            "\t Train_Loss: 1051.7474 Val_Loss: 2068.9009  BEST VAL Loss: 2068.9009\n",
            "\n",
            "Epoch 206: Validation loss decreased (2068.900879 --> 2051.190918).\n",
            "\t Train_Loss: 1039.6283 Val_Loss: 2051.1909  BEST VAL Loss: 2051.1909\n",
            "\n",
            "Epoch 207: Validation loss decreased (2051.190918 --> 2033.648804).\n",
            "\t Train_Loss: 1027.6493 Val_Loss: 2033.6488  BEST VAL Loss: 2033.6488\n",
            "\n",
            "Epoch 208: Validation loss decreased (2033.648804 --> 2016.273071).\n",
            "\t Train_Loss: 1015.8094 Val_Loss: 2016.2731  BEST VAL Loss: 2016.2731\n",
            "\n",
            "Epoch 209: Validation loss decreased (2016.273071 --> 1999.061279).\n",
            "\t Train_Loss: 1004.1074 Val_Loss: 1999.0613  BEST VAL Loss: 1999.0613\n",
            "\n",
            "Epoch 210: Validation loss decreased (1999.061279 --> 1982.013306).\n",
            "\t Train_Loss: 992.5413 Val_Loss: 1982.0133  BEST VAL Loss: 1982.0133\n",
            "\n",
            "Epoch 211: Validation loss decreased (1982.013306 --> 1965.126221).\n",
            "\t Train_Loss: 981.1104 Val_Loss: 1965.1262  BEST VAL Loss: 1965.1262\n",
            "\n",
            "Epoch 212: Validation loss decreased (1965.126221 --> 1948.399658).\n",
            "\t Train_Loss: 969.8129 Val_Loss: 1948.3997  BEST VAL Loss: 1948.3997\n",
            "\n",
            "Epoch 213: Validation loss decreased (1948.399658 --> 1931.831421).\n",
            "\t Train_Loss: 958.6478 Val_Loss: 1931.8314  BEST VAL Loss: 1931.8314\n",
            "\n",
            "Epoch 214: Validation loss decreased (1931.831421 --> 1915.420288).\n",
            "\t Train_Loss: 947.6132 Val_Loss: 1915.4203  BEST VAL Loss: 1915.4203\n",
            "\n",
            "Epoch 215: Validation loss decreased (1915.420288 --> 1899.165405).\n",
            "\t Train_Loss: 936.7082 Val_Loss: 1899.1654  BEST VAL Loss: 1899.1654\n",
            "\n",
            "Epoch 216: Validation loss decreased (1899.165405 --> 1883.064819).\n",
            "\t Train_Loss: 925.9313 Val_Loss: 1883.0648  BEST VAL Loss: 1883.0648\n",
            "\n",
            "Epoch 217: Validation loss decreased (1883.064819 --> 1867.117432).\n",
            "\t Train_Loss: 915.2813 Val_Loss: 1867.1174  BEST VAL Loss: 1867.1174\n",
            "\n",
            "Epoch 218: Validation loss decreased (1867.117432 --> 1851.321045).\n",
            "\t Train_Loss: 904.7571 Val_Loss: 1851.3210  BEST VAL Loss: 1851.3210\n",
            "\n",
            "Epoch 219: Validation loss decreased (1851.321045 --> 1835.675537).\n",
            "\t Train_Loss: 894.3569 Val_Loss: 1835.6755  BEST VAL Loss: 1835.6755\n",
            "\n",
            "Epoch 220: Validation loss decreased (1835.675537 --> 1820.178955).\n",
            "\t Train_Loss: 884.0798 Val_Loss: 1820.1790  BEST VAL Loss: 1820.1790\n",
            "\n",
            "Epoch 221: Validation loss decreased (1820.178955 --> 1804.829712).\n",
            "\t Train_Loss: 873.9246 Val_Loss: 1804.8297  BEST VAL Loss: 1804.8297\n",
            "\n",
            "Epoch 222: Validation loss decreased (1804.829712 --> 1789.626953).\n",
            "\t Train_Loss: 863.8896 Val_Loss: 1789.6270  BEST VAL Loss: 1789.6270\n",
            "\n",
            "Epoch 223: Validation loss decreased (1789.626953 --> 1774.569336).\n",
            "\t Train_Loss: 853.9744 Val_Loss: 1774.5693  BEST VAL Loss: 1774.5693\n",
            "\n",
            "Epoch 224: Validation loss decreased (1774.569336 --> 1759.654907).\n",
            "\t Train_Loss: 844.1773 Val_Loss: 1759.6549  BEST VAL Loss: 1759.6549\n",
            "\n",
            "Epoch 225: Validation loss decreased (1759.654907 --> 1744.883423).\n",
            "\t Train_Loss: 834.4967 Val_Loss: 1744.8834  BEST VAL Loss: 1744.8834\n",
            "\n",
            "Epoch 226: Validation loss decreased (1744.883423 --> 1730.252563).\n",
            "\t Train_Loss: 824.9322 Val_Loss: 1730.2526  BEST VAL Loss: 1730.2526\n",
            "\n",
            "Epoch 227: Validation loss decreased (1730.252563 --> 1715.762451).\n",
            "\t Train_Loss: 815.4819 Val_Loss: 1715.7625  BEST VAL Loss: 1715.7625\n",
            "\n",
            "Epoch 228: Validation loss decreased (1715.762451 --> 1701.410156).\n",
            "\t Train_Loss: 806.1454 Val_Loss: 1701.4102  BEST VAL Loss: 1701.4102\n",
            "\n",
            "Epoch 229: Validation loss decreased (1701.410156 --> 1687.195679).\n",
            "\t Train_Loss: 796.9208 Val_Loss: 1687.1957  BEST VAL Loss: 1687.1957\n",
            "\n",
            "Epoch 230: Validation loss decreased (1687.195679 --> 1673.117188).\n",
            "\t Train_Loss: 787.8074 Val_Loss: 1673.1172  BEST VAL Loss: 1673.1172\n",
            "\n",
            "Epoch 231: Validation loss decreased (1673.117188 --> 1659.174194).\n",
            "\t Train_Loss: 778.8038 Val_Loss: 1659.1742  BEST VAL Loss: 1659.1742\n",
            "\n",
            "Epoch 232: Validation loss decreased (1659.174194 --> 1645.364258).\n",
            "\t Train_Loss: 769.9093 Val_Loss: 1645.3643  BEST VAL Loss: 1645.3643\n",
            "\n",
            "Epoch 233: Validation loss decreased (1645.364258 --> 1631.687256).\n",
            "\t Train_Loss: 761.1223 Val_Loss: 1631.6873  BEST VAL Loss: 1631.6873\n",
            "\n",
            "Epoch 234: Validation loss decreased (1631.687256 --> 1618.141968).\n",
            "\t Train_Loss: 752.4418 Val_Loss: 1618.1420  BEST VAL Loss: 1618.1420\n",
            "\n",
            "Epoch 235: Validation loss decreased (1618.141968 --> 1604.726318).\n",
            "\t Train_Loss: 743.8671 Val_Loss: 1604.7263  BEST VAL Loss: 1604.7263\n",
            "\n",
            "Epoch 236: Validation loss decreased (1604.726318 --> 1591.440796).\n",
            "\t Train_Loss: 735.3964 Val_Loss: 1591.4408  BEST VAL Loss: 1591.4408\n",
            "\n",
            "Epoch 237: Validation loss decreased (1591.440796 --> 1578.282227).\n",
            "\t Train_Loss: 727.0295 Val_Loss: 1578.2822  BEST VAL Loss: 1578.2822\n",
            "\n",
            "Epoch 238: Validation loss decreased (1578.282227 --> 1565.251343).\n",
            "\t Train_Loss: 718.7646 Val_Loss: 1565.2513  BEST VAL Loss: 1565.2513\n",
            "\n",
            "Epoch 239: Validation loss decreased (1565.251343 --> 1552.345825).\n",
            "\t Train_Loss: 710.6011 Val_Loss: 1552.3458  BEST VAL Loss: 1552.3458\n",
            "\n",
            "Epoch 240: Validation loss decreased (1552.345825 --> 1539.564697).\n",
            "\t Train_Loss: 702.5378 Val_Loss: 1539.5647  BEST VAL Loss: 1539.5647\n",
            "\n",
            "Epoch 241: Validation loss decreased (1539.564697 --> 1526.907715).\n",
            "\t Train_Loss: 694.5735 Val_Loss: 1526.9077  BEST VAL Loss: 1526.9077\n",
            "\n",
            "Epoch 242: Validation loss decreased (1526.907715 --> 1514.372314).\n",
            "\t Train_Loss: 686.7077 Val_Loss: 1514.3723  BEST VAL Loss: 1514.3723\n",
            "\n",
            "Epoch 243: Validation loss decreased (1514.372314 --> 1501.958740).\n",
            "\t Train_Loss: 678.9385 Val_Loss: 1501.9587  BEST VAL Loss: 1501.9587\n",
            "\n",
            "Epoch 244: Validation loss decreased (1501.958740 --> 1489.665283).\n",
            "\t Train_Loss: 671.2656 Val_Loss: 1489.6653  BEST VAL Loss: 1489.6653\n",
            "\n",
            "Epoch 245: Validation loss decreased (1489.665283 --> 1477.490845).\n",
            "\t Train_Loss: 663.6877 Val_Loss: 1477.4908  BEST VAL Loss: 1477.4908\n",
            "\n",
            "Epoch 246: Validation loss decreased (1477.490845 --> 1465.435059).\n",
            "\t Train_Loss: 656.2042 Val_Loss: 1465.4351  BEST VAL Loss: 1465.4351\n",
            "\n",
            "Epoch 247: Validation loss decreased (1465.435059 --> 1453.495728).\n",
            "\t Train_Loss: 648.8138 Val_Loss: 1453.4957  BEST VAL Loss: 1453.4957\n",
            "\n",
            "Epoch 248: Validation loss decreased (1453.495728 --> 1441.672607).\n",
            "\t Train_Loss: 641.5154 Val_Loss: 1441.6726  BEST VAL Loss: 1441.6726\n",
            "\n",
            "Epoch 249: Validation loss decreased (1441.672607 --> 1429.964844).\n",
            "\t Train_Loss: 634.3082 Val_Loss: 1429.9648  BEST VAL Loss: 1429.9648\n",
            "\n",
            "Epoch 250: Validation loss decreased (1429.964844 --> 1418.370483).\n",
            "\t Train_Loss: 627.1913 Val_Loss: 1418.3705  BEST VAL Loss: 1418.3705\n",
            "\n",
            "Epoch 251: Validation loss decreased (1418.370483 --> 1406.889282).\n",
            "\t Train_Loss: 620.1635 Val_Loss: 1406.8893  BEST VAL Loss: 1406.8893\n",
            "\n",
            "Epoch 252: Validation loss decreased (1406.889282 --> 1395.520264).\n",
            "\t Train_Loss: 613.2242 Val_Loss: 1395.5203  BEST VAL Loss: 1395.5203\n",
            "\n",
            "Epoch 253: Validation loss decreased (1395.520264 --> 1384.261475).\n",
            "\t Train_Loss: 606.3725 Val_Loss: 1384.2615  BEST VAL Loss: 1384.2615\n",
            "\n",
            "Epoch 254: Validation loss decreased (1384.261475 --> 1373.113037).\n",
            "\t Train_Loss: 599.6068 Val_Loss: 1373.1130  BEST VAL Loss: 1373.1130\n",
            "\n",
            "Epoch 255: Validation loss decreased (1373.113037 --> 1362.074585).\n",
            "\t Train_Loss: 592.9268 Val_Loss: 1362.0746  BEST VAL Loss: 1362.0746\n",
            "\n",
            "Epoch 256: Validation loss decreased (1362.074585 --> 1351.142578).\n",
            "\t Train_Loss: 586.3321 Val_Loss: 1351.1426  BEST VAL Loss: 1351.1426\n",
            "\n",
            "Epoch 257: Validation loss decreased (1351.142578 --> 1340.318970).\n",
            "\t Train_Loss: 579.8204 Val_Loss: 1340.3190  BEST VAL Loss: 1340.3190\n",
            "\n",
            "Epoch 258: Validation loss decreased (1340.318970 --> 1329.600464).\n",
            "\t Train_Loss: 573.3923 Val_Loss: 1329.6005  BEST VAL Loss: 1329.6005\n",
            "\n",
            "Epoch 259: Validation loss decreased (1329.600464 --> 1318.987427).\n",
            "\t Train_Loss: 567.0456 Val_Loss: 1318.9874  BEST VAL Loss: 1318.9874\n",
            "\n",
            "Epoch 260: Validation loss decreased (1318.987427 --> 1308.478638).\n",
            "\t Train_Loss: 560.7802 Val_Loss: 1308.4786  BEST VAL Loss: 1308.4786\n",
            "\n",
            "Epoch 261: Validation loss decreased (1308.478638 --> 1298.072998).\n",
            "\t Train_Loss: 554.5951 Val_Loss: 1298.0730  BEST VAL Loss: 1298.0730\n",
            "\n",
            "Epoch 262: Validation loss decreased (1298.072998 --> 1287.769897).\n",
            "\t Train_Loss: 548.4893 Val_Loss: 1287.7699  BEST VAL Loss: 1287.7699\n",
            "\n",
            "Epoch 263: Validation loss decreased (1287.769897 --> 1277.568115).\n",
            "\t Train_Loss: 542.4622 Val_Loss: 1277.5681  BEST VAL Loss: 1277.5681\n",
            "\n",
            "Epoch 264: Validation loss decreased (1277.568115 --> 1267.465820).\n",
            "\t Train_Loss: 536.5126 Val_Loss: 1267.4658  BEST VAL Loss: 1267.4658\n",
            "\n",
            "Epoch 265: Validation loss decreased (1267.465820 --> 1257.464600).\n",
            "\t Train_Loss: 530.6396 Val_Loss: 1257.4646  BEST VAL Loss: 1257.4646\n",
            "\n",
            "Epoch 266: Validation loss decreased (1257.464600 --> 1247.561279).\n",
            "\t Train_Loss: 524.8431 Val_Loss: 1247.5613  BEST VAL Loss: 1247.5613\n",
            "\n",
            "Epoch 267: Validation loss decreased (1247.561279 --> 1237.756104).\n",
            "\t Train_Loss: 519.1214 Val_Loss: 1237.7561  BEST VAL Loss: 1237.7561\n",
            "\n",
            "Epoch 268: Validation loss decreased (1237.756104 --> 1228.047852).\n",
            "\t Train_Loss: 513.4744 Val_Loss: 1228.0479  BEST VAL Loss: 1228.0479\n",
            "\n",
            "Epoch 269: Validation loss decreased (1228.047852 --> 1218.435425).\n",
            "\t Train_Loss: 507.9010 Val_Loss: 1218.4354  BEST VAL Loss: 1218.4354\n",
            "\n",
            "Epoch 270: Validation loss decreased (1218.435425 --> 1208.918091).\n",
            "\t Train_Loss: 502.4001 Val_Loss: 1208.9181  BEST VAL Loss: 1208.9181\n",
            "\n",
            "Epoch 271: Validation loss decreased (1208.918091 --> 1199.495483).\n",
            "\t Train_Loss: 496.9711 Val_Loss: 1199.4955  BEST VAL Loss: 1199.4955\n",
            "\n",
            "Epoch 272: Validation loss decreased (1199.495483 --> 1190.166016).\n",
            "\t Train_Loss: 491.6136 Val_Loss: 1190.1660  BEST VAL Loss: 1190.1660\n",
            "\n",
            "Epoch 273: Validation loss decreased (1190.166016 --> 1180.928955).\n",
            "\t Train_Loss: 486.3263 Val_Loss: 1180.9290  BEST VAL Loss: 1180.9290\n",
            "\n",
            "Epoch 274: Validation loss decreased (1180.928955 --> 1171.783203).\n",
            "\t Train_Loss: 481.1085 Val_Loss: 1171.7832  BEST VAL Loss: 1171.7832\n",
            "\n",
            "Epoch 275: Validation loss decreased (1171.783203 --> 1162.729248).\n",
            "\t Train_Loss: 475.9594 Val_Loss: 1162.7292  BEST VAL Loss: 1162.7292\n",
            "\n",
            "Epoch 276: Validation loss decreased (1162.729248 --> 1153.765137).\n",
            "\t Train_Loss: 470.8786 Val_Loss: 1153.7651  BEST VAL Loss: 1153.7651\n",
            "\n",
            "Epoch 277: Validation loss decreased (1153.765137 --> 1144.890259).\n",
            "\t Train_Loss: 465.8651 Val_Loss: 1144.8903  BEST VAL Loss: 1144.8903\n",
            "\n",
            "Epoch 278: Validation loss decreased (1144.890259 --> 1136.103638).\n",
            "\t Train_Loss: 460.9182 Val_Loss: 1136.1036  BEST VAL Loss: 1136.1036\n",
            "\n",
            "Epoch 279: Validation loss decreased (1136.103638 --> 1127.404541).\n",
            "\t Train_Loss: 456.0370 Val_Loss: 1127.4045  BEST VAL Loss: 1127.4045\n",
            "\n",
            "Epoch 280: Validation loss decreased (1127.404541 --> 1118.792358).\n",
            "\t Train_Loss: 451.2208 Val_Loss: 1118.7924  BEST VAL Loss: 1118.7924\n",
            "\n",
            "Epoch 281: Validation loss decreased (1118.792358 --> 1110.266846).\n",
            "\t Train_Loss: 446.4690 Val_Loss: 1110.2668  BEST VAL Loss: 1110.2668\n",
            "\n",
            "Epoch 282: Validation loss decreased (1110.266846 --> 1101.825439).\n",
            "\t Train_Loss: 441.7811 Val_Loss: 1101.8254  BEST VAL Loss: 1101.8254\n",
            "\n",
            "Epoch 283: Validation loss decreased (1101.825439 --> 1093.469360).\n",
            "\t Train_Loss: 437.1556 Val_Loss: 1093.4694  BEST VAL Loss: 1093.4694\n",
            "\n",
            "Epoch 284: Validation loss decreased (1093.469360 --> 1085.197510).\n",
            "\t Train_Loss: 432.5928 Val_Loss: 1085.1975  BEST VAL Loss: 1085.1975\n",
            "\n",
            "Epoch 285: Validation loss decreased (1085.197510 --> 1077.007202).\n",
            "\t Train_Loss: 428.0916 Val_Loss: 1077.0072  BEST VAL Loss: 1077.0072\n",
            "\n",
            "Epoch 286: Validation loss decreased (1077.007202 --> 1068.899658).\n",
            "\t Train_Loss: 423.6508 Val_Loss: 1068.8997  BEST VAL Loss: 1068.8997\n",
            "\n",
            "Epoch 287: Validation loss decreased (1068.899658 --> 1060.873291).\n",
            "\t Train_Loss: 419.2701 Val_Loss: 1060.8733  BEST VAL Loss: 1060.8733\n",
            "\n",
            "Epoch 288: Validation loss decreased (1060.873291 --> 1052.927734).\n",
            "\t Train_Loss: 414.9489 Val_Loss: 1052.9277  BEST VAL Loss: 1052.9277\n",
            "\n",
            "Epoch 289: Validation loss decreased (1052.927734 --> 1045.061768).\n",
            "\t Train_Loss: 410.6864 Val_Loss: 1045.0618  BEST VAL Loss: 1045.0618\n",
            "\n",
            "Epoch 290: Validation loss decreased (1045.061768 --> 1037.275391).\n",
            "\t Train_Loss: 406.4818 Val_Loss: 1037.2754  BEST VAL Loss: 1037.2754\n",
            "\n",
            "Epoch 291: Validation loss decreased (1037.275391 --> 1029.567017).\n",
            "\t Train_Loss: 402.3347 Val_Loss: 1029.5670  BEST VAL Loss: 1029.5670\n",
            "\n",
            "Epoch 292: Validation loss decreased (1029.567017 --> 1021.935852).\n",
            "\t Train_Loss: 398.2442 Val_Loss: 1021.9359  BEST VAL Loss: 1021.9359\n",
            "\n",
            "Epoch 293: Validation loss decreased (1021.935852 --> 1014.381958).\n",
            "\t Train_Loss: 394.2094 Val_Loss: 1014.3820  BEST VAL Loss: 1014.3820\n",
            "\n",
            "Epoch 294: Validation loss decreased (1014.381958 --> 1006.904175).\n",
            "\t Train_Loss: 390.2301 Val_Loss: 1006.9042  BEST VAL Loss: 1006.9042\n",
            "\n",
            "Epoch 295: Validation loss decreased (1006.904175 --> 999.500793).\n",
            "\t Train_Loss: 386.3052 Val_Loss: 999.5008  BEST VAL Loss: 999.5008\n",
            "\n",
            "Epoch 296: Validation loss decreased (999.500793 --> 992.171570).\n",
            "\t Train_Loss: 382.4335 Val_Loss: 992.1716  BEST VAL Loss: 992.1716\n",
            "\n",
            "Epoch 297: Validation loss decreased (992.171570 --> 984.914368).\n",
            "\t Train_Loss: 378.6142 Val_Loss: 984.9144  BEST VAL Loss: 984.9144\n",
            "\n",
            "Epoch 298: Validation loss decreased (984.914368 --> 977.725403).\n",
            "\t Train_Loss: 374.8451 Val_Loss: 977.7254  BEST VAL Loss: 977.7254\n",
            "\n",
            "Epoch 299: Validation loss decreased (977.725403 --> 970.597839).\n",
            "\t Train_Loss: 371.1226 Val_Loss: 970.5978  BEST VAL Loss: 970.5978\n",
            "\n",
            "Epoch 300: Validation loss decreased (970.597839 --> 963.510559).\n",
            "\t Train_Loss: 367.4395 Val_Loss: 963.5106  BEST VAL Loss: 963.5106\n",
            "\n",
            "Epoch 301: Validation loss decreased (963.510559 --> 956.389526).\n",
            "\t Train_Loss: 363.7769 Val_Loss: 956.3895  BEST VAL Loss: 956.3895\n",
            "\n",
            "Epoch 302: Validation loss decreased (956.389526 --> 948.976074).\n",
            "\t Train_Loss: 360.0811 Val_Loss: 948.9761  BEST VAL Loss: 948.9761\n",
            "\n",
            "Epoch 303: Validation loss decreased (948.976074 --> 940.716675).\n",
            "\t Train_Loss: 356.2126 Val_Loss: 940.7167  BEST VAL Loss: 940.7167\n",
            "\n",
            "Epoch 304: Validation loss decreased (940.716675 --> 932.013794).\n",
            "\t Train_Loss: 352.0122 Val_Loss: 932.0138  BEST VAL Loss: 932.0138\n",
            "\n",
            "Epoch 305: Validation loss decreased (932.013794 --> 923.388000).\n",
            "\t Train_Loss: 347.7653 Val_Loss: 923.3880  BEST VAL Loss: 923.3880\n",
            "\n",
            "Epoch 306: Validation loss decreased (923.388000 --> 915.059265).\n",
            "\t Train_Loss: 343.4807 Val_Loss: 915.0593  BEST VAL Loss: 915.0593\n",
            "\n",
            "Epoch 307: Validation loss decreased (915.059265 --> 907.129395).\n",
            "\t Train_Loss: 339.3703 Val_Loss: 907.1294  BEST VAL Loss: 907.1294\n",
            "\n",
            "Epoch 308: Validation loss decreased (907.129395 --> 899.228149).\n",
            "\t Train_Loss: 335.4344 Val_Loss: 899.2281  BEST VAL Loss: 899.2281\n",
            "\n",
            "Epoch 309: Validation loss decreased (899.228149 --> 891.369446).\n",
            "\t Train_Loss: 331.5322 Val_Loss: 891.3694  BEST VAL Loss: 891.3694\n",
            "\n",
            "Epoch 310: Validation loss decreased (891.369446 --> 883.566711).\n",
            "\t Train_Loss: 327.6709 Val_Loss: 883.5667  BEST VAL Loss: 883.5667\n",
            "\n",
            "Epoch 311: Validation loss decreased (883.566711 --> 875.829102).\n",
            "\t Train_Loss: 323.8567 Val_Loss: 875.8291  BEST VAL Loss: 875.8291\n",
            "\n",
            "Epoch 312: Validation loss decreased (875.829102 --> 868.164246).\n",
            "\t Train_Loss: 320.0942 Val_Loss: 868.1642  BEST VAL Loss: 868.1642\n",
            "\n",
            "Epoch 313: Validation loss decreased (868.164246 --> 860.578247).\n",
            "\t Train_Loss: 316.3868 Val_Loss: 860.5782  BEST VAL Loss: 860.5782\n",
            "\n",
            "Epoch 314: Validation loss decreased (860.578247 --> 853.076843).\n",
            "\t Train_Loss: 312.7370 Val_Loss: 853.0768  BEST VAL Loss: 853.0768\n",
            "\n",
            "Epoch 315: Validation loss decreased (853.076843 --> 845.662781).\n",
            "\t Train_Loss: 309.1473 Val_Loss: 845.6628  BEST VAL Loss: 845.6628\n",
            "\n",
            "Epoch 316: Validation loss decreased (845.662781 --> 838.338867).\n",
            "\t Train_Loss: 305.6189 Val_Loss: 838.3389  BEST VAL Loss: 838.3389\n",
            "\n",
            "Epoch 317: Validation loss decreased (838.338867 --> 831.108093).\n",
            "\t Train_Loss: 302.1523 Val_Loss: 831.1081  BEST VAL Loss: 831.1081\n",
            "\n",
            "Epoch 318: Validation loss decreased (831.108093 --> 823.970520).\n",
            "\t Train_Loss: 298.7487 Val_Loss: 823.9705  BEST VAL Loss: 823.9705\n",
            "\n",
            "Epoch 319: Validation loss decreased (823.970520 --> 816.927917).\n",
            "\t Train_Loss: 295.4078 Val_Loss: 816.9279  BEST VAL Loss: 816.9279\n",
            "\n",
            "Epoch 320: Validation loss decreased (816.927917 --> 809.981018).\n",
            "\t Train_Loss: 292.1298 Val_Loss: 809.9810  BEST VAL Loss: 809.9810\n",
            "\n",
            "Epoch 321: Validation loss decreased (809.981018 --> 803.129578).\n",
            "\t Train_Loss: 288.9144 Val_Loss: 803.1296  BEST VAL Loss: 803.1296\n",
            "\n",
            "Epoch 322: Validation loss decreased (803.129578 --> 796.374146).\n",
            "\t Train_Loss: 285.7614 Val_Loss: 796.3741  BEST VAL Loss: 796.3741\n",
            "\n",
            "Epoch 323: Validation loss decreased (796.374146 --> 789.713501).\n",
            "\t Train_Loss: 282.6702 Val_Loss: 789.7135  BEST VAL Loss: 789.7135\n",
            "\n",
            "Epoch 324: Validation loss decreased (789.713501 --> 783.147034).\n",
            "\t Train_Loss: 279.6400 Val_Loss: 783.1470  BEST VAL Loss: 783.1470\n",
            "\n",
            "Epoch 325: Validation loss decreased (783.147034 --> 776.675171).\n",
            "\t Train_Loss: 276.6699 Val_Loss: 776.6752  BEST VAL Loss: 776.6752\n",
            "\n",
            "Epoch 326: Validation loss decreased (776.675171 --> 770.296753).\n",
            "\t Train_Loss: 273.7597 Val_Loss: 770.2968  BEST VAL Loss: 770.2968\n",
            "\n",
            "Epoch 327: Validation loss decreased (770.296753 --> 764.010376).\n",
            "\t Train_Loss: 270.9081 Val_Loss: 764.0104  BEST VAL Loss: 764.0104\n",
            "\n",
            "Epoch 328: Validation loss decreased (764.010376 --> 757.815002).\n",
            "\t Train_Loss: 268.1144 Val_Loss: 757.8150  BEST VAL Loss: 757.8150\n",
            "\n",
            "Epoch 329: Validation loss decreased (757.815002 --> 751.709961).\n",
            "\t Train_Loss: 265.3773 Val_Loss: 751.7100  BEST VAL Loss: 751.7100\n",
            "\n",
            "Epoch 330: Validation loss decreased (751.709961 --> 745.693970).\n",
            "\t Train_Loss: 262.6962 Val_Loss: 745.6940  BEST VAL Loss: 745.6940\n",
            "\n",
            "Epoch 331: Validation loss decreased (745.693970 --> 739.765930).\n",
            "\t Train_Loss: 260.0702 Val_Loss: 739.7659  BEST VAL Loss: 739.7659\n",
            "\n",
            "Epoch 332: Validation loss decreased (739.765930 --> 733.923889).\n",
            "\t Train_Loss: 257.4979 Val_Loss: 733.9239  BEST VAL Loss: 733.9239\n",
            "\n",
            "Epoch 333: Validation loss decreased (733.923889 --> 728.167480).\n",
            "\t Train_Loss: 254.9783 Val_Loss: 728.1675  BEST VAL Loss: 728.1675\n",
            "\n",
            "Epoch 334: Validation loss decreased (728.167480 --> 722.495728).\n",
            "\t Train_Loss: 252.5108 Val_Loss: 722.4957  BEST VAL Loss: 722.4957\n",
            "\n",
            "Epoch 335: Validation loss decreased (722.495728 --> 716.905151).\n",
            "\t Train_Loss: 250.0944 Val_Loss: 716.9052  BEST VAL Loss: 716.9052\n",
            "\n",
            "Epoch 336: Validation loss decreased (716.905151 --> 711.397278).\n",
            "\t Train_Loss: 247.7272 Val_Loss: 711.3973  BEST VAL Loss: 711.3973\n",
            "\n",
            "Epoch 337: Validation loss decreased (711.397278 --> 705.969238).\n",
            "\t Train_Loss: 245.4095 Val_Loss: 705.9692  BEST VAL Loss: 705.9692\n",
            "\n",
            "Epoch 338: Validation loss decreased (705.969238 --> 700.619812).\n",
            "\t Train_Loss: 243.1394 Val_Loss: 700.6198  BEST VAL Loss: 700.6198\n",
            "\n",
            "Epoch 339: Validation loss decreased (700.619812 --> 695.347656).\n",
            "\t Train_Loss: 240.9163 Val_Loss: 695.3477  BEST VAL Loss: 695.3477\n",
            "\n",
            "Epoch 340: Validation loss decreased (695.347656 --> 690.152710).\n",
            "\t Train_Loss: 238.7389 Val_Loss: 690.1527  BEST VAL Loss: 690.1527\n",
            "\n",
            "Epoch 341: Validation loss decreased (690.152710 --> 685.032532).\n",
            "\t Train_Loss: 236.6070 Val_Loss: 685.0325  BEST VAL Loss: 685.0325\n",
            "\n",
            "Epoch 342: Validation loss decreased (685.032532 --> 679.985413).\n",
            "\t Train_Loss: 234.5190 Val_Loss: 679.9854  BEST VAL Loss: 679.9854\n",
            "\n",
            "Epoch 343: Validation loss decreased (679.985413 --> 675.011292).\n",
            "\t Train_Loss: 232.4739 Val_Loss: 675.0113  BEST VAL Loss: 675.0113\n",
            "\n",
            "Epoch 344: Validation loss decreased (675.011292 --> 670.108521).\n",
            "\t Train_Loss: 230.4713 Val_Loss: 670.1085  BEST VAL Loss: 670.1085\n",
            "\n",
            "Epoch 345: Validation loss decreased (670.108521 --> 665.276001).\n",
            "\t Train_Loss: 228.5101 Val_Loss: 665.2760  BEST VAL Loss: 665.2760\n",
            "\n",
            "Epoch 346: Validation loss decreased (665.276001 --> 660.512207).\n",
            "\t Train_Loss: 226.5894 Val_Loss: 660.5122  BEST VAL Loss: 660.5122\n",
            "\n",
            "Epoch 347: Validation loss decreased (660.512207 --> 655.816528).\n",
            "\t Train_Loss: 224.7084 Val_Loss: 655.8165  BEST VAL Loss: 655.8165\n",
            "\n",
            "Epoch 348: Validation loss decreased (655.816528 --> 651.187622).\n",
            "\t Train_Loss: 222.8663 Val_Loss: 651.1876  BEST VAL Loss: 651.1876\n",
            "\n",
            "Epoch 349: Validation loss decreased (651.187622 --> 646.623413).\n",
            "\t Train_Loss: 221.0624 Val_Loss: 646.6234  BEST VAL Loss: 646.6234\n",
            "\n",
            "Epoch 350: Validation loss decreased (646.623413 --> 642.124634).\n",
            "\t Train_Loss: 219.2953 Val_Loss: 642.1246  BEST VAL Loss: 642.1246\n",
            "\n",
            "Epoch 351: Validation loss decreased (642.124634 --> 637.689026).\n",
            "\t Train_Loss: 217.5651 Val_Loss: 637.6890  BEST VAL Loss: 637.6890\n",
            "\n",
            "Epoch 352: Validation loss decreased (637.689026 --> 633.315552).\n",
            "\t Train_Loss: 215.8705 Val_Loss: 633.3156  BEST VAL Loss: 633.3156\n",
            "\n",
            "Epoch 353: Validation loss decreased (633.315552 --> 629.003540).\n",
            "\t Train_Loss: 214.2109 Val_Loss: 629.0035  BEST VAL Loss: 629.0035\n",
            "\n",
            "Epoch 354: Validation loss decreased (629.003540 --> 624.752014).\n",
            "\t Train_Loss: 212.5855 Val_Loss: 624.7520  BEST VAL Loss: 624.7520\n",
            "\n",
            "Epoch 355: Validation loss decreased (624.752014 --> 620.559692).\n",
            "\t Train_Loss: 210.9938 Val_Loss: 620.5597  BEST VAL Loss: 620.5597\n",
            "\n",
            "Epoch 356: Validation loss decreased (620.559692 --> 616.425537).\n",
            "\t Train_Loss: 209.4348 Val_Loss: 616.4255  BEST VAL Loss: 616.4255\n",
            "\n",
            "Epoch 357: Validation loss decreased (616.425537 --> 612.348999).\n",
            "\t Train_Loss: 207.9080 Val_Loss: 612.3490  BEST VAL Loss: 612.3490\n",
            "\n",
            "Epoch 358: Validation loss decreased (612.348999 --> 608.328979).\n",
            "\t Train_Loss: 206.4128 Val_Loss: 608.3290  BEST VAL Loss: 608.3290\n",
            "\n",
            "Epoch 359: Validation loss decreased (608.328979 --> 604.364258).\n",
            "\t Train_Loss: 204.9484 Val_Loss: 604.3643  BEST VAL Loss: 604.3643\n",
            "\n",
            "Epoch 360: Validation loss decreased (604.364258 --> 600.454346).\n",
            "\t Train_Loss: 203.5142 Val_Loss: 600.4543  BEST VAL Loss: 600.4543\n",
            "\n",
            "Epoch 361: Validation loss decreased (600.454346 --> 596.598511).\n",
            "\t Train_Loss: 202.1096 Val_Loss: 596.5985  BEST VAL Loss: 596.5985\n",
            "\n",
            "Epoch 362: Validation loss decreased (596.598511 --> 592.795288).\n",
            "\t Train_Loss: 200.7341 Val_Loss: 592.7953  BEST VAL Loss: 592.7953\n",
            "\n",
            "Epoch 363: Validation loss decreased (592.795288 --> 589.044312).\n",
            "\t Train_Loss: 199.3868 Val_Loss: 589.0443  BEST VAL Loss: 589.0443\n",
            "\n",
            "Epoch 364: Validation loss decreased (589.044312 --> 585.344360).\n",
            "\t Train_Loss: 198.0676 Val_Loss: 585.3444  BEST VAL Loss: 585.3444\n",
            "\n",
            "Epoch 365: Validation loss decreased (585.344360 --> 581.695007).\n",
            "\t Train_Loss: 196.7754 Val_Loss: 581.6950  BEST VAL Loss: 581.6950\n",
            "\n",
            "Epoch 366: Validation loss decreased (581.695007 --> 578.095337).\n",
            "\t Train_Loss: 195.5099 Val_Loss: 578.0953  BEST VAL Loss: 578.0953\n",
            "\n",
            "Epoch 367: Validation loss decreased (578.095337 --> 574.544556).\n",
            "\t Train_Loss: 194.2707 Val_Loss: 574.5446  BEST VAL Loss: 574.5446\n",
            "\n",
            "Epoch 368: Validation loss decreased (574.544556 --> 571.042114).\n",
            "\t Train_Loss: 193.0570 Val_Loss: 571.0421  BEST VAL Loss: 571.0421\n",
            "\n",
            "Epoch 369: Validation loss decreased (571.042114 --> 567.586487).\n",
            "\t Train_Loss: 191.8685 Val_Loss: 567.5865  BEST VAL Loss: 567.5865\n",
            "\n",
            "Epoch 370: Validation loss decreased (567.586487 --> 564.177917).\n",
            "\t Train_Loss: 190.7044 Val_Loss: 564.1779  BEST VAL Loss: 564.1779\n",
            "\n",
            "Epoch 371: Validation loss decreased (564.177917 --> 560.815308).\n",
            "\t Train_Loss: 189.5645 Val_Loss: 560.8153  BEST VAL Loss: 560.8153\n",
            "\n",
            "Epoch 372: Validation loss decreased (560.815308 --> 557.498108).\n",
            "\t Train_Loss: 188.4482 Val_Loss: 557.4981  BEST VAL Loss: 557.4981\n",
            "\n",
            "Epoch 373: Validation loss decreased (557.498108 --> 554.225098).\n",
            "\t Train_Loss: 187.3551 Val_Loss: 554.2251  BEST VAL Loss: 554.2251\n",
            "\n",
            "Epoch 374: Validation loss decreased (554.225098 --> 550.995850).\n",
            "\t Train_Loss: 186.2846 Val_Loss: 550.9958  BEST VAL Loss: 550.9958\n",
            "\n",
            "Epoch 375: Validation loss decreased (550.995850 --> 547.810730).\n",
            "\t Train_Loss: 185.2362 Val_Loss: 547.8107  BEST VAL Loss: 547.8107\n",
            "\n",
            "Epoch 376: Validation loss decreased (547.810730 --> 544.667480).\n",
            "\t Train_Loss: 184.2099 Val_Loss: 544.6675  BEST VAL Loss: 544.6675\n",
            "\n",
            "Epoch 377: Validation loss decreased (544.667480 --> 541.566040).\n",
            "\t Train_Loss: 183.2046 Val_Loss: 541.5660  BEST VAL Loss: 541.5660\n",
            "\n",
            "Epoch 378: Validation loss decreased (541.566040 --> 538.506348).\n",
            "\t Train_Loss: 182.2202 Val_Loss: 538.5063  BEST VAL Loss: 538.5063\n",
            "\n",
            "Epoch 379: Validation loss decreased (538.506348 --> 535.487183).\n",
            "\t Train_Loss: 181.2564 Val_Loss: 535.4872  BEST VAL Loss: 535.4872\n",
            "\n",
            "Epoch 380: Validation loss decreased (535.487183 --> 532.508179).\n",
            "\t Train_Loss: 180.3125 Val_Loss: 532.5082  BEST VAL Loss: 532.5082\n",
            "\n",
            "Epoch 381: Validation loss decreased (532.508179 --> 529.568909).\n",
            "\t Train_Loss: 179.3884 Val_Loss: 529.5689  BEST VAL Loss: 529.5689\n",
            "\n",
            "Epoch 382: Validation loss decreased (529.568909 --> 526.668518).\n",
            "\t Train_Loss: 178.4836 Val_Loss: 526.6685  BEST VAL Loss: 526.6685\n",
            "\n",
            "Epoch 383: Validation loss decreased (526.668518 --> 523.805969).\n",
            "\t Train_Loss: 177.5977 Val_Loss: 523.8060  BEST VAL Loss: 523.8060\n",
            "\n",
            "Epoch 384: Validation loss decreased (523.805969 --> 520.982117).\n",
            "\t Train_Loss: 176.7301 Val_Loss: 520.9821  BEST VAL Loss: 520.9821\n",
            "\n",
            "Epoch 385: Validation loss decreased (520.982117 --> 518.194519).\n",
            "\t Train_Loss: 175.8809 Val_Loss: 518.1945  BEST VAL Loss: 518.1945\n",
            "\n",
            "Epoch 386: Validation loss decreased (518.194519 --> 515.444336).\n",
            "\t Train_Loss: 175.0491 Val_Loss: 515.4443  BEST VAL Loss: 515.4443\n",
            "\n",
            "Epoch 387: Validation loss decreased (515.444336 --> 512.730591).\n",
            "\t Train_Loss: 174.2350 Val_Loss: 512.7306  BEST VAL Loss: 512.7306\n",
            "\n",
            "Epoch 388: Validation loss decreased (512.730591 --> 510.051910).\n",
            "\t Train_Loss: 173.4380 Val_Loss: 510.0519  BEST VAL Loss: 510.0519\n",
            "\n",
            "Epoch 389: Validation loss decreased (510.051910 --> 507.408630).\n",
            "\t Train_Loss: 172.6575 Val_Loss: 507.4086  BEST VAL Loss: 507.4086\n",
            "\n",
            "Epoch 390: Validation loss decreased (507.408630 --> 504.800354).\n",
            "\t Train_Loss: 171.8935 Val_Loss: 504.8004  BEST VAL Loss: 504.8004\n",
            "\n",
            "Epoch 391: Validation loss decreased (504.800354 --> 502.225830).\n",
            "\t Train_Loss: 171.1456 Val_Loss: 502.2258  BEST VAL Loss: 502.2258\n",
            "\n",
            "Epoch 392: Validation loss decreased (502.225830 --> 499.685638).\n",
            "\t Train_Loss: 170.4134 Val_Loss: 499.6856  BEST VAL Loss: 499.6856\n",
            "\n",
            "Epoch 393: Validation loss decreased (499.685638 --> 497.178131).\n",
            "\t Train_Loss: 169.6968 Val_Loss: 497.1781  BEST VAL Loss: 497.1781\n",
            "\n",
            "Epoch 394: Validation loss decreased (497.178131 --> 494.703033).\n",
            "\t Train_Loss: 168.9951 Val_Loss: 494.7030  BEST VAL Loss: 494.7030\n",
            "\n",
            "Epoch 395: Validation loss decreased (494.703033 --> 492.260681).\n",
            "\t Train_Loss: 168.3081 Val_Loss: 492.2607  BEST VAL Loss: 492.2607\n",
            "\n",
            "Epoch 396: Validation loss decreased (492.260681 --> 489.850342).\n",
            "\t Train_Loss: 167.6358 Val_Loss: 489.8503  BEST VAL Loss: 489.8503\n",
            "\n",
            "Epoch 397: Validation loss decreased (489.850342 --> 487.471344).\n",
            "\t Train_Loss: 166.9777 Val_Loss: 487.4713  BEST VAL Loss: 487.4713\n",
            "\n",
            "Epoch 398: Validation loss decreased (487.471344 --> 485.123230).\n",
            "\t Train_Loss: 166.3336 Val_Loss: 485.1232  BEST VAL Loss: 485.1232\n",
            "\n",
            "Epoch 399: Validation loss decreased (485.123230 --> 482.805573).\n",
            "\t Train_Loss: 165.7031 Val_Loss: 482.8056  BEST VAL Loss: 482.8056\n",
            "\n",
            "Epoch 400: Validation loss decreased (482.805573 --> 480.518066).\n",
            "\t Train_Loss: 165.0860 Val_Loss: 480.5181  BEST VAL Loss: 480.5181\n",
            "\n",
            "Epoch 401: Validation loss decreased (480.518066 --> 478.260498).\n",
            "\t Train_Loss: 164.4819 Val_Loss: 478.2605  BEST VAL Loss: 478.2605\n",
            "\n",
            "Epoch 402: Validation loss decreased (478.260498 --> 476.032471).\n",
            "\t Train_Loss: 163.8909 Val_Loss: 476.0325  BEST VAL Loss: 476.0325\n",
            "\n",
            "Epoch 403: Validation loss decreased (476.032471 --> 473.832672).\n",
            "\t Train_Loss: 163.3125 Val_Loss: 473.8327  BEST VAL Loss: 473.8327\n",
            "\n",
            "Epoch 404: Validation loss decreased (473.832672 --> 471.661713).\n",
            "\t Train_Loss: 162.7462 Val_Loss: 471.6617  BEST VAL Loss: 471.6617\n",
            "\n",
            "Epoch 405: Validation loss decreased (471.661713 --> 469.519043).\n",
            "\t Train_Loss: 162.1922 Val_Loss: 469.5190  BEST VAL Loss: 469.5190\n",
            "\n",
            "Epoch 406: Validation loss decreased (469.519043 --> 467.403656).\n",
            "\t Train_Loss: 161.6500 Val_Loss: 467.4037  BEST VAL Loss: 467.4037\n",
            "\n",
            "Epoch 407: Validation loss decreased (467.403656 --> 465.316315).\n",
            "\t Train_Loss: 161.1193 Val_Loss: 465.3163  BEST VAL Loss: 465.3163\n",
            "\n",
            "Epoch 408: Validation loss decreased (465.316315 --> 463.255066).\n",
            "\t Train_Loss: 160.6003 Val_Loss: 463.2551  BEST VAL Loss: 463.2551\n",
            "\n",
            "Epoch 409: Validation loss decreased (463.255066 --> 461.220886).\n",
            "\t Train_Loss: 160.0921 Val_Loss: 461.2209  BEST VAL Loss: 461.2209\n",
            "\n",
            "Epoch 410: Validation loss decreased (461.220886 --> 459.213074).\n",
            "\t Train_Loss: 159.5949 Val_Loss: 459.2131  BEST VAL Loss: 459.2131\n",
            "\n",
            "Epoch 411: Validation loss decreased (459.213074 --> 457.230957).\n",
            "\t Train_Loss: 159.1086 Val_Loss: 457.2310  BEST VAL Loss: 457.2310\n",
            "\n",
            "Epoch 412: Validation loss decreased (457.230957 --> 455.274719).\n",
            "\t Train_Loss: 158.6326 Val_Loss: 455.2747  BEST VAL Loss: 455.2747\n",
            "\n",
            "Epoch 413: Validation loss decreased (455.274719 --> 453.343323).\n",
            "\t Train_Loss: 158.1670 Val_Loss: 453.3433  BEST VAL Loss: 453.3433\n",
            "\n",
            "Epoch 414: Validation loss decreased (453.343323 --> 451.437103).\n",
            "\t Train_Loss: 157.7114 Val_Loss: 451.4371  BEST VAL Loss: 451.4371\n",
            "\n",
            "Epoch 415: Validation loss decreased (451.437103 --> 449.555115).\n",
            "\t Train_Loss: 157.2657 Val_Loss: 449.5551  BEST VAL Loss: 449.5551\n",
            "\n",
            "Epoch 416: Validation loss decreased (449.555115 --> 447.697601).\n",
            "\t Train_Loss: 156.8296 Val_Loss: 447.6976  BEST VAL Loss: 447.6976\n",
            "\n",
            "Epoch 417: Validation loss decreased (447.697601 --> 445.864166).\n",
            "\t Train_Loss: 156.4031 Val_Loss: 445.8642  BEST VAL Loss: 445.8642\n",
            "\n",
            "Epoch 418: Validation loss decreased (445.864166 --> 444.053619).\n",
            "\t Train_Loss: 155.9859 Val_Loss: 444.0536  BEST VAL Loss: 444.0536\n",
            "\n",
            "Epoch 419: Validation loss decreased (444.053619 --> 442.267029).\n",
            "\t Train_Loss: 155.5775 Val_Loss: 442.2670  BEST VAL Loss: 442.2670\n",
            "\n",
            "Epoch 420: Validation loss decreased (442.267029 --> 440.503326).\n",
            "\t Train_Loss: 155.1783 Val_Loss: 440.5033  BEST VAL Loss: 440.5033\n",
            "\n",
            "Epoch 421: Validation loss decreased (440.503326 --> 438.761902).\n",
            "\t Train_Loss: 154.7878 Val_Loss: 438.7619  BEST VAL Loss: 438.7619\n",
            "\n",
            "Epoch 422: Validation loss decreased (438.761902 --> 437.043365).\n",
            "\t Train_Loss: 154.4057 Val_Loss: 437.0434  BEST VAL Loss: 437.0434\n",
            "\n",
            "Epoch 423: Validation loss decreased (437.043365 --> 435.346252).\n",
            "\t Train_Loss: 154.0321 Val_Loss: 435.3463  BEST VAL Loss: 435.3463\n",
            "\n",
            "Epoch 424: Validation loss decreased (435.346252 --> 433.671570).\n",
            "\t Train_Loss: 153.6666 Val_Loss: 433.6716  BEST VAL Loss: 433.6716\n",
            "\n",
            "Epoch 425: Validation loss decreased (433.671570 --> 432.017578).\n",
            "\t Train_Loss: 153.3093 Val_Loss: 432.0176  BEST VAL Loss: 432.0176\n",
            "\n",
            "Epoch 426: Validation loss decreased (432.017578 --> 430.385101).\n",
            "\t Train_Loss: 152.9595 Val_Loss: 430.3851  BEST VAL Loss: 430.3851\n",
            "\n",
            "Epoch 427: Validation loss decreased (430.385101 --> 428.773529).\n",
            "\t Train_Loss: 152.6177 Val_Loss: 428.7735  BEST VAL Loss: 428.7735\n",
            "\n",
            "Epoch 428: Validation loss decreased (428.773529 --> 427.182922).\n",
            "\t Train_Loss: 152.2833 Val_Loss: 427.1829  BEST VAL Loss: 427.1829\n",
            "\n",
            "Epoch 429: Validation loss decreased (427.182922 --> 425.612640).\n",
            "\t Train_Loss: 151.9565 Val_Loss: 425.6126  BEST VAL Loss: 425.6126\n",
            "\n",
            "Epoch 430: Validation loss decreased (425.612640 --> 424.062317).\n",
            "\t Train_Loss: 151.6369 Val_Loss: 424.0623  BEST VAL Loss: 424.0623\n",
            "\n",
            "Epoch 431: Validation loss decreased (424.062317 --> 422.531738).\n",
            "\t Train_Loss: 151.3242 Val_Loss: 422.5317  BEST VAL Loss: 422.5317\n",
            "\n",
            "Epoch 432: Validation loss decreased (422.531738 --> 421.021149).\n",
            "\t Train_Loss: 151.0185 Val_Loss: 421.0211  BEST VAL Loss: 421.0211\n",
            "\n",
            "Epoch 433: Validation loss decreased (421.021149 --> 419.529633).\n",
            "\t Train_Loss: 150.7197 Val_Loss: 419.5296  BEST VAL Loss: 419.5296\n",
            "\n",
            "Epoch 434: Validation loss decreased (419.529633 --> 418.057068).\n",
            "\t Train_Loss: 150.4275 Val_Loss: 418.0571  BEST VAL Loss: 418.0571\n",
            "\n",
            "Epoch 435: Validation loss decreased (418.057068 --> 416.603424).\n",
            "\t Train_Loss: 150.1418 Val_Loss: 416.6034  BEST VAL Loss: 416.6034\n",
            "\n",
            "Epoch 436: Validation loss decreased (416.603424 --> 415.168365).\n",
            "\t Train_Loss: 149.8625 Val_Loss: 415.1684  BEST VAL Loss: 415.1684\n",
            "\n",
            "Epoch 437: Validation loss decreased (415.168365 --> 413.752197).\n",
            "\t Train_Loss: 149.5894 Val_Loss: 413.7522  BEST VAL Loss: 413.7522\n",
            "\n",
            "Epoch 438: Validation loss decreased (413.752197 --> 412.353455).\n",
            "\t Train_Loss: 149.3226 Val_Loss: 412.3535  BEST VAL Loss: 412.3535\n",
            "\n",
            "Epoch 439: Validation loss decreased (412.353455 --> 410.972717).\n",
            "\t Train_Loss: 149.0616 Val_Loss: 410.9727  BEST VAL Loss: 410.9727\n",
            "\n",
            "Epoch 440: Validation loss decreased (410.972717 --> 409.609711).\n",
            "\t Train_Loss: 148.8064 Val_Loss: 409.6097  BEST VAL Loss: 409.6097\n",
            "\n",
            "Epoch 441: Validation loss decreased (409.609711 --> 408.264313).\n",
            "\t Train_Loss: 148.5571 Val_Loss: 408.2643  BEST VAL Loss: 408.2643\n",
            "\n",
            "Epoch 442: Validation loss decreased (408.264313 --> 406.936005).\n",
            "\t Train_Loss: 148.3134 Val_Loss: 406.9360  BEST VAL Loss: 406.9360\n",
            "\n",
            "Epoch 443: Validation loss decreased (406.936005 --> 405.624420).\n",
            "\t Train_Loss: 148.0752 Val_Loss: 405.6244  BEST VAL Loss: 405.6244\n",
            "\n",
            "Epoch 444: Validation loss decreased (405.624420 --> 404.329926).\n",
            "\t Train_Loss: 147.8423 Val_Loss: 404.3299  BEST VAL Loss: 404.3299\n",
            "\n",
            "Epoch 445: Validation loss decreased (404.329926 --> 403.051941).\n",
            "\t Train_Loss: 147.6148 Val_Loss: 403.0519  BEST VAL Loss: 403.0519\n",
            "\n",
            "Epoch 446: Validation loss decreased (403.051941 --> 401.790192).\n",
            "\t Train_Loss: 147.3924 Val_Loss: 401.7902  BEST VAL Loss: 401.7902\n",
            "\n",
            "Epoch 447: Validation loss decreased (401.790192 --> 400.544434).\n",
            "\t Train_Loss: 147.1751 Val_Loss: 400.5444  BEST VAL Loss: 400.5444\n",
            "\n",
            "Epoch 448: Validation loss decreased (400.544434 --> 399.314758).\n",
            "\t Train_Loss: 146.9626 Val_Loss: 399.3148  BEST VAL Loss: 399.3148\n",
            "\n",
            "Epoch 449: Validation loss decreased (399.314758 --> 398.100891).\n",
            "\t Train_Loss: 146.7551 Val_Loss: 398.1009  BEST VAL Loss: 398.1009\n",
            "\n",
            "Epoch 450: Validation loss decreased (398.100891 --> 396.902466).\n",
            "\t Train_Loss: 146.5523 Val_Loss: 396.9025  BEST VAL Loss: 396.9025\n",
            "\n",
            "Epoch 451: Validation loss decreased (396.902466 --> 395.719452).\n",
            "\t Train_Loss: 146.3541 Val_Loss: 395.7195  BEST VAL Loss: 395.7195\n",
            "\n",
            "Epoch 452: Validation loss decreased (395.719452 --> 394.551453).\n",
            "\t Train_Loss: 146.1605 Val_Loss: 394.5515  BEST VAL Loss: 394.5515\n",
            "\n",
            "Epoch 453: Validation loss decreased (394.551453 --> 393.398438).\n",
            "\t Train_Loss: 145.9713 Val_Loss: 393.3984  BEST VAL Loss: 393.3984\n",
            "\n",
            "Epoch 454: Validation loss decreased (393.398438 --> 392.260101).\n",
            "\t Train_Loss: 145.7864 Val_Loss: 392.2601  BEST VAL Loss: 392.2601\n",
            "\n",
            "Epoch 455: Validation loss decreased (392.260101 --> 391.136505).\n",
            "\t Train_Loss: 145.6059 Val_Loss: 391.1365  BEST VAL Loss: 391.1365\n",
            "\n",
            "Epoch 456: Validation loss decreased (391.136505 --> 390.027100).\n",
            "\t Train_Loss: 145.4294 Val_Loss: 390.0271  BEST VAL Loss: 390.0271\n",
            "\n",
            "Epoch 457: Validation loss decreased (390.027100 --> 388.932281).\n",
            "\t Train_Loss: 145.2571 Val_Loss: 388.9323  BEST VAL Loss: 388.9323\n",
            "\n",
            "Epoch 458: Validation loss decreased (388.932281 --> 387.850891).\n",
            "\t Train_Loss: 145.0888 Val_Loss: 387.8509  BEST VAL Loss: 387.8509\n",
            "\n",
            "Epoch 459: Validation loss decreased (387.850891 --> 386.783630).\n",
            "\t Train_Loss: 144.9243 Val_Loss: 386.7836  BEST VAL Loss: 386.7836\n",
            "\n",
            "Epoch 460: Validation loss decreased (386.783630 --> 385.730103).\n",
            "\t Train_Loss: 144.7636 Val_Loss: 385.7301  BEST VAL Loss: 385.7301\n",
            "\n",
            "Epoch 461: Validation loss decreased (385.730103 --> 384.689575).\n",
            "\t Train_Loss: 144.6067 Val_Loss: 384.6896  BEST VAL Loss: 384.6896\n",
            "\n",
            "Epoch 462: Validation loss decreased (384.689575 --> 383.662811).\n",
            "\t Train_Loss: 144.4534 Val_Loss: 383.6628  BEST VAL Loss: 383.6628\n",
            "\n",
            "Epoch 463: Validation loss decreased (383.662811 --> 382.649078).\n",
            "\t Train_Loss: 144.3037 Val_Loss: 382.6491  BEST VAL Loss: 382.6491\n",
            "\n",
            "Epoch 464: Validation loss decreased (382.649078 --> 381.648102).\n",
            "\t Train_Loss: 144.1575 Val_Loss: 381.6481  BEST VAL Loss: 381.6481\n",
            "\n",
            "Epoch 465: Validation loss decreased (381.648102 --> 380.660461).\n",
            "\t Train_Loss: 144.0146 Val_Loss: 380.6605  BEST VAL Loss: 380.6605\n",
            "\n",
            "Epoch 466: Validation loss decreased (380.660461 --> 379.685272).\n",
            "\t Train_Loss: 143.8753 Val_Loss: 379.6853  BEST VAL Loss: 379.6853\n",
            "\n",
            "Epoch 467: Validation loss decreased (379.685272 --> 378.722260).\n",
            "\t Train_Loss: 143.7391 Val_Loss: 378.7223  BEST VAL Loss: 378.7223\n",
            "\n",
            "Epoch 468: Validation loss decreased (378.722260 --> 377.771851).\n",
            "\t Train_Loss: 143.6060 Val_Loss: 377.7719  BEST VAL Loss: 377.7719\n",
            "\n",
            "Epoch 469: Validation loss decreased (377.771851 --> 376.833679).\n",
            "\t Train_Loss: 143.4762 Val_Loss: 376.8337  BEST VAL Loss: 376.8337\n",
            "\n",
            "Epoch 470: Validation loss decreased (376.833679 --> 375.907684).\n",
            "\t Train_Loss: 143.3494 Val_Loss: 375.9077  BEST VAL Loss: 375.9077\n",
            "\n",
            "Epoch 471: Validation loss decreased (375.907684 --> 374.993103).\n",
            "\t Train_Loss: 143.2257 Val_Loss: 374.9931  BEST VAL Loss: 374.9931\n",
            "\n",
            "Epoch 472: Validation loss decreased (374.993103 --> 374.090515).\n",
            "\t Train_Loss: 143.1047 Val_Loss: 374.0905  BEST VAL Loss: 374.0905\n",
            "\n",
            "Epoch 473: Validation loss decreased (374.090515 --> 373.199280).\n",
            "\t Train_Loss: 142.9868 Val_Loss: 373.1993  BEST VAL Loss: 373.1993\n",
            "\n",
            "Epoch 474: Validation loss decreased (373.199280 --> 372.319763).\n",
            "\t Train_Loss: 142.8715 Val_Loss: 372.3198  BEST VAL Loss: 372.3198\n",
            "\n",
            "Epoch 475: Validation loss decreased (372.319763 --> 371.451599).\n",
            "\t Train_Loss: 142.7590 Val_Loss: 371.4516  BEST VAL Loss: 371.4516\n",
            "\n",
            "Epoch 476: Validation loss decreased (371.451599 --> 370.594421).\n",
            "\t Train_Loss: 142.6492 Val_Loss: 370.5944  BEST VAL Loss: 370.5944\n",
            "\n",
            "Epoch 477: Validation loss decreased (370.594421 --> 369.748108).\n",
            "\t Train_Loss: 142.5421 Val_Loss: 369.7481  BEST VAL Loss: 369.7481\n",
            "\n",
            "Epoch 478: Validation loss decreased (369.748108 --> 368.912933).\n",
            "\t Train_Loss: 142.4374 Val_Loss: 368.9129  BEST VAL Loss: 368.9129\n",
            "\n",
            "Epoch 479: Validation loss decreased (368.912933 --> 368.088623).\n",
            "\t Train_Loss: 142.3353 Val_Loss: 368.0886  BEST VAL Loss: 368.0886\n",
            "\n",
            "Epoch 480: Validation loss decreased (368.088623 --> 367.274689).\n",
            "\t Train_Loss: 142.2356 Val_Loss: 367.2747  BEST VAL Loss: 367.2747\n",
            "\n",
            "Epoch 481: Validation loss decreased (367.274689 --> 366.471222).\n",
            "\t Train_Loss: 142.1384 Val_Loss: 366.4712  BEST VAL Loss: 366.4712\n",
            "\n",
            "Epoch 482: Validation loss decreased (366.471222 --> 365.678070).\n",
            "\t Train_Loss: 142.0434 Val_Loss: 365.6781  BEST VAL Loss: 365.6781\n",
            "\n",
            "Epoch 483: Validation loss decreased (365.678070 --> 364.895172).\n",
            "\t Train_Loss: 141.9507 Val_Loss: 364.8952  BEST VAL Loss: 364.8952\n",
            "\n",
            "Epoch 484: Validation loss decreased (364.895172 --> 364.122284).\n",
            "\t Train_Loss: 141.8603 Val_Loss: 364.1223  BEST VAL Loss: 364.1223\n",
            "\n",
            "Epoch 485: Validation loss decreased (364.122284 --> 363.359344).\n",
            "\t Train_Loss: 141.7720 Val_Loss: 363.3593  BEST VAL Loss: 363.3593\n",
            "\n",
            "Epoch 486: Validation loss decreased (363.359344 --> 362.606262).\n",
            "\t Train_Loss: 141.6858 Val_Loss: 362.6063  BEST VAL Loss: 362.6063\n",
            "\n",
            "Epoch 487: Validation loss decreased (362.606262 --> 361.863068).\n",
            "\t Train_Loss: 141.6017 Val_Loss: 361.8631  BEST VAL Loss: 361.8631\n",
            "\n",
            "Epoch 488: Validation loss decreased (361.863068 --> 361.129333).\n",
            "\t Train_Loss: 141.5198 Val_Loss: 361.1293  BEST VAL Loss: 361.1293\n",
            "\n",
            "Epoch 489: Validation loss decreased (361.129333 --> 360.405090).\n",
            "\t Train_Loss: 141.4397 Val_Loss: 360.4051  BEST VAL Loss: 360.4051\n",
            "\n",
            "Epoch 490: Validation loss decreased (360.405090 --> 359.690125).\n",
            "\t Train_Loss: 141.3617 Val_Loss: 359.6901  BEST VAL Loss: 359.6901\n",
            "\n",
            "Epoch 491: Validation loss decreased (359.690125 --> 358.984589).\n",
            "\t Train_Loss: 141.2854 Val_Loss: 358.9846  BEST VAL Loss: 358.9846\n",
            "\n",
            "Epoch 492: Validation loss decreased (358.984589 --> 358.288147).\n",
            "\t Train_Loss: 141.2112 Val_Loss: 358.2881  BEST VAL Loss: 358.2881\n",
            "\n",
            "Epoch 493: Validation loss decreased (358.288147 --> 357.600647).\n",
            "\t Train_Loss: 141.1386 Val_Loss: 357.6006  BEST VAL Loss: 357.6006\n",
            "\n",
            "Epoch 494: Validation loss decreased (357.600647 --> 356.921722).\n",
            "\t Train_Loss: 141.0679 Val_Loss: 356.9217  BEST VAL Loss: 356.9217\n",
            "\n",
            "Epoch 495: Validation loss decreased (356.921722 --> 356.251953).\n",
            "\t Train_Loss: 140.9989 Val_Loss: 356.2520  BEST VAL Loss: 356.2520\n",
            "\n",
            "Epoch 496: Validation loss decreased (356.251953 --> 355.590881).\n",
            "\t Train_Loss: 140.9315 Val_Loss: 355.5909  BEST VAL Loss: 355.5909\n",
            "\n",
            "Epoch 497: Validation loss decreased (355.590881 --> 354.938171).\n",
            "\t Train_Loss: 140.8659 Val_Loss: 354.9382  BEST VAL Loss: 354.9382\n",
            "\n",
            "Epoch 498: Validation loss decreased (354.938171 --> 354.294128).\n",
            "\t Train_Loss: 140.8018 Val_Loss: 354.2941  BEST VAL Loss: 354.2941\n",
            "\n",
            "Epoch 499: Validation loss decreased (354.294128 --> 353.658386).\n",
            "\t Train_Loss: 140.7393 Val_Loss: 353.6584  BEST VAL Loss: 353.6584\n",
            "\n",
            "Epoch 500: Validation loss decreased (353.658386 --> 353.030853).\n",
            "\t Train_Loss: 140.6784 Val_Loss: 353.0309  BEST VAL Loss: 353.0309\n",
            "\n",
            "Epoch 501: Validation loss decreased (353.030853 --> 352.411469).\n",
            "\t Train_Loss: 140.6189 Val_Loss: 352.4115  BEST VAL Loss: 352.4115\n",
            "\n",
            "Epoch 502: Validation loss decreased (352.411469 --> 351.800201).\n",
            "\t Train_Loss: 140.5609 Val_Loss: 351.8002  BEST VAL Loss: 351.8002\n",
            "\n",
            "Epoch 503: Validation loss decreased (351.800201 --> 351.196838).\n",
            "\t Train_Loss: 140.5043 Val_Loss: 351.1968  BEST VAL Loss: 351.1968\n",
            "\n",
            "Epoch 504: Validation loss decreased (351.196838 --> 350.601227).\n",
            "\t Train_Loss: 140.4491 Val_Loss: 350.6012  BEST VAL Loss: 350.6012\n",
            "\n",
            "Epoch 505: Validation loss decreased (350.601227 --> 350.013489).\n",
            "\t Train_Loss: 140.3952 Val_Loss: 350.0135  BEST VAL Loss: 350.0135\n",
            "\n",
            "Epoch 506: Validation loss decreased (350.013489 --> 349.433594).\n",
            "\t Train_Loss: 140.3427 Val_Loss: 349.4336  BEST VAL Loss: 349.4336\n",
            "\n",
            "Epoch 507: Validation loss decreased (349.433594 --> 348.861145).\n",
            "\t Train_Loss: 140.2914 Val_Loss: 348.8611  BEST VAL Loss: 348.8611\n",
            "\n",
            "Epoch 508: Validation loss decreased (348.861145 --> 348.296082).\n",
            "\t Train_Loss: 140.2414 Val_Loss: 348.2961  BEST VAL Loss: 348.2961\n",
            "\n",
            "Epoch 509: Validation loss decreased (348.296082 --> 347.738373).\n",
            "\t Train_Loss: 140.1926 Val_Loss: 347.7384  BEST VAL Loss: 347.7384\n",
            "\n",
            "Epoch 510: Validation loss decreased (347.738373 --> 347.188171).\n",
            "\t Train_Loss: 140.1449 Val_Loss: 347.1882  BEST VAL Loss: 347.1882\n",
            "\n",
            "Epoch 511: Validation loss decreased (347.188171 --> 346.645172).\n",
            "\t Train_Loss: 140.0983 Val_Loss: 346.6452  BEST VAL Loss: 346.6452\n",
            "\n",
            "Epoch 512: Validation loss decreased (346.645172 --> 346.109039).\n",
            "\t Train_Loss: 140.0527 Val_Loss: 346.1090  BEST VAL Loss: 346.1090\n",
            "\n",
            "Epoch 513: Validation loss decreased (346.109039 --> 345.580261).\n",
            "\t Train_Loss: 140.0082 Val_Loss: 345.5803  BEST VAL Loss: 345.5803\n",
            "\n",
            "Epoch 514: Validation loss decreased (345.580261 --> 345.058411).\n",
            "\t Train_Loss: 139.9646 Val_Loss: 345.0584  BEST VAL Loss: 345.0584\n",
            "\n",
            "Epoch 515: Validation loss decreased (345.058411 --> 344.543579).\n",
            "\t Train_Loss: 139.9218 Val_Loss: 344.5436  BEST VAL Loss: 344.5436\n",
            "\n",
            "Epoch 516: Validation loss decreased (344.543579 --> 344.035583).\n",
            "\t Train_Loss: 139.8798 Val_Loss: 344.0356  BEST VAL Loss: 344.0356\n",
            "\n",
            "Epoch 517: Validation loss decreased (344.035583 --> 343.534515).\n",
            "\t Train_Loss: 139.8385 Val_Loss: 343.5345  BEST VAL Loss: 343.5345\n",
            "\n",
            "Epoch 518: Validation loss decreased (343.534515 --> 343.040131).\n",
            "\t Train_Loss: 139.7976 Val_Loss: 343.0401  BEST VAL Loss: 343.0401\n",
            "\n",
            "Epoch 519: Validation loss decreased (343.040131 --> 342.552643).\n",
            "\t Train_Loss: 139.7570 Val_Loss: 342.5526  BEST VAL Loss: 342.5526\n",
            "\n",
            "Epoch 520: Validation loss decreased (342.552643 --> 342.072388).\n",
            "\t Train_Loss: 139.7164 Val_Loss: 342.0724  BEST VAL Loss: 342.0724\n",
            "\n",
            "Epoch 521: Validation loss decreased (342.072388 --> 341.598999).\n",
            "\t Train_Loss: 139.6752 Val_Loss: 341.5990  BEST VAL Loss: 341.5990\n",
            "\n",
            "Epoch 522: Validation loss decreased (341.598999 --> 341.133392).\n",
            "\t Train_Loss: 139.6329 Val_Loss: 341.1334  BEST VAL Loss: 341.1334\n",
            "\n",
            "Epoch 523: Validation loss decreased (341.133392 --> 340.676300).\n",
            "\t Train_Loss: 139.5882 Val_Loss: 340.6763  BEST VAL Loss: 340.6763\n",
            "\n",
            "Epoch 524: Validation loss decreased (340.676300 --> 340.229065).\n",
            "\t Train_Loss: 139.5392 Val_Loss: 340.2291  BEST VAL Loss: 340.2291\n",
            "\n",
            "Epoch 525: Validation loss decreased (340.229065 --> 339.795563).\n",
            "\t Train_Loss: 139.4826 Val_Loss: 339.7956  BEST VAL Loss: 339.7956\n",
            "\n",
            "Epoch 526: Validation loss decreased (339.795563 --> 339.384460).\n",
            "\t Train_Loss: 139.4115 Val_Loss: 339.3845  BEST VAL Loss: 339.3845\n",
            "\n",
            "Epoch 527: Validation loss decreased (339.384460 --> 339.022278).\n",
            "\t Train_Loss: 139.3104 Val_Loss: 339.0223  BEST VAL Loss: 339.0223\n",
            "\n",
            "Epoch 528: Validation loss decreased (339.022278 --> 338.812103).\n",
            "\t Train_Loss: 139.1394 Val_Loss: 338.8121  BEST VAL Loss: 338.8121\n",
            "\n",
            "Epoch 529: Validation loss did not decrease\n",
            "\t Train_Loss: 138.7729 Val_Loss: 339.3528  BEST VAL Loss: 338.8121\n",
            "\n",
            "Epoch 530: Validation loss did not decrease\n",
            "\t Train_Loss: 137.7514 Val_Loss: 346.0881  BEST VAL Loss: 338.8121\n",
            "\n",
            "Epoch 531: Validation loss did not decrease\n",
            "\t Train_Loss: 135.6663 Val_Loss: 370.5124  BEST VAL Loss: 338.8121\n",
            "\n",
            "Epoch 532: Validation loss did not decrease\n",
            "\t Train_Loss: 139.3255 Val_Loss: 352.6995  BEST VAL Loss: 338.8121\n",
            "\n",
            "Epoch 533: Validation loss did not decrease\n",
            "\t Train_Loss: 135.6859 Val_Loss: 339.7060  BEST VAL Loss: 338.8121\n",
            "\n",
            "Epoch 534: Validation loss decreased (338.812103 --> 337.107117).\n",
            "\t Train_Loss: 135.7523 Val_Loss: 337.1071  BEST VAL Loss: 337.1071\n",
            "\n",
            "Epoch 535: Validation loss decreased (337.107117 --> 336.334015).\n",
            "\t Train_Loss: 136.7922 Val_Loss: 336.3340  BEST VAL Loss: 336.3340\n",
            "\n",
            "Epoch 536: Validation loss did not decrease\n",
            "\t Train_Loss: 136.8538 Val_Loss: 336.4035  BEST VAL Loss: 336.3340\n",
            "\n",
            "Epoch 537: Validation loss did not decrease\n",
            "\t Train_Loss: 136.0446 Val_Loss: 338.5326  BEST VAL Loss: 336.3340\n",
            "\n",
            "Epoch 538: Validation loss did not decrease\n",
            "\t Train_Loss: 134.2685 Val_Loss: 347.2022  BEST VAL Loss: 336.3340\n",
            "\n",
            "Epoch 539: Validation loss did not decrease\n",
            "\t Train_Loss: 133.8020 Val_Loss: 353.8422  BEST VAL Loss: 336.3340\n",
            "\n",
            "Epoch 540: Validation loss did not decrease\n",
            "\t Train_Loss: 134.9521 Val_Loss: 346.6437  BEST VAL Loss: 336.3340\n",
            "\n",
            "Epoch 541: Validation loss did not decrease\n",
            "\t Train_Loss: 133.3485 Val_Loss: 343.2966  BEST VAL Loss: 336.3340\n",
            "\n",
            "Epoch 542: Validation loss decreased (336.334015 --> 334.579681).\n",
            "\t Train_Loss: 132.9048 Val_Loss: 334.5797  BEST VAL Loss: 334.5797\n",
            "\n",
            "Epoch 543: Validation loss decreased (334.579681 --> 333.707184).\n",
            "\t Train_Loss: 133.2326 Val_Loss: 333.7072  BEST VAL Loss: 333.7072\n",
            "\n",
            "Epoch 544: Validation loss did not decrease\n",
            "\t Train_Loss: 133.1320 Val_Loss: 334.5270  BEST VAL Loss: 333.7072\n",
            "\n",
            "Epoch 545: Validation loss did not decrease\n",
            "\t Train_Loss: 132.1039 Val_Loss: 337.8759  BEST VAL Loss: 333.7072\n",
            "\n",
            "Epoch 546: Validation loss did not decrease\n",
            "\t Train_Loss: 131.3366 Val_Loss: 342.1787  BEST VAL Loss: 333.7072\n",
            "\n",
            "Epoch 547: Validation loss did not decrease\n",
            "\t Train_Loss: 131.7418 Val_Loss: 341.5864  BEST VAL Loss: 333.7072\n",
            "\n",
            "Epoch 548: Validation loss did not decrease\n",
            "\t Train_Loss: 131.5194 Val_Loss: 336.7390  BEST VAL Loss: 333.7072\n",
            "\n",
            "Epoch 549: Validation loss decreased (333.707184 --> 332.595245).\n",
            "\t Train_Loss: 130.5966 Val_Loss: 332.5952  BEST VAL Loss: 332.5952\n",
            "\n",
            "Epoch 550: Validation loss decreased (332.595245 --> 330.637482).\n",
            "\t Train_Loss: 130.3843 Val_Loss: 330.6375  BEST VAL Loss: 330.6375\n",
            "\n",
            "Epoch 551: Validation loss decreased (330.637482 --> 330.195374).\n",
            "\t Train_Loss: 130.5022 Val_Loss: 330.1954  BEST VAL Loss: 330.1954\n",
            "\n",
            "Epoch 552: Validation loss did not decrease\n",
            "\t Train_Loss: 130.1627 Val_Loss: 331.0317  BEST VAL Loss: 330.1954\n",
            "\n",
            "Epoch 553: Validation loss did not decrease\n",
            "\t Train_Loss: 129.5173 Val_Loss: 332.9439  BEST VAL Loss: 330.1954\n",
            "\n",
            "Epoch 554: Validation loss did not decrease\n",
            "\t Train_Loss: 129.1902 Val_Loss: 334.4066  BEST VAL Loss: 330.1954\n",
            "\n",
            "Epoch 555: Validation loss did not decrease\n",
            "\t Train_Loss: 129.1184 Val_Loss: 333.7502  BEST VAL Loss: 330.1954\n",
            "\n",
            "Epoch 556: Validation loss did not decrease\n",
            "\t Train_Loss: 128.6476 Val_Loss: 331.8181  BEST VAL Loss: 330.1954\n",
            "\n",
            "Epoch 557: Validation loss did not decrease\n",
            "\t Train_Loss: 127.8313 Val_Loss: 331.0895  BEST VAL Loss: 330.1954\n",
            "\n",
            "Epoch 558: Validation loss did not decrease\n",
            "\t Train_Loss: 127.0711 Val_Loss: 334.1647  BEST VAL Loss: 330.1954\n",
            "\n",
            "Epoch 559: Validation loss did not decrease\n",
            "\t Train_Loss: 126.5711 Val_Loss: 341.1842  BEST VAL Loss: 330.1954\n",
            "\n",
            "Epoch 560: Validation loss did not decrease\n",
            "\t Train_Loss: 126.8614 Val_Loss: 341.1949  BEST VAL Loss: 330.1954\n",
            "\n",
            "Epoch 561: Validation loss did not decrease\n",
            "\t Train_Loss: 125.5945 Val_Loss: 341.3481  BEST VAL Loss: 330.1954\n",
            "\n",
            "Epoch 562: Validation loss did not decrease\n",
            "\t Train_Loss: 122.2963 Val_Loss: 356.5378  BEST VAL Loss: 330.1954\n",
            "\n",
            "Epoch 563: Validation loss did not decrease\n",
            "\t Train_Loss: 125.6474 Val_Loss: 332.4436  BEST VAL Loss: 330.1954\n",
            "\n",
            "Epoch 564: Validation loss decreased (330.195374 --> 325.086334).\n",
            "\t Train_Loss: 121.4262 Val_Loss: 325.0863  BEST VAL Loss: 325.0863\n",
            "\n",
            "Epoch 565: Validation loss decreased (325.086334 --> 322.931244).\n",
            "\t Train_Loss: 123.1203 Val_Loss: 322.9312  BEST VAL Loss: 322.9312\n",
            "\n",
            "Epoch 566: Validation loss decreased (322.931244 --> 322.554504).\n",
            "\t Train_Loss: 123.7422 Val_Loss: 322.5545  BEST VAL Loss: 322.5545\n",
            "\n",
            "Epoch 567: Validation loss did not decrease\n",
            "\t Train_Loss: 122.4836 Val_Loss: 327.5207  BEST VAL Loss: 322.5545\n",
            "\n",
            "Epoch 568: Validation loss did not decrease\n",
            "\t Train_Loss: 118.2997 Val_Loss: 365.3603  BEST VAL Loss: 322.5545\n",
            "\n",
            "Epoch 569: Validation loss did not decrease\n",
            "\t Train_Loss: 124.7831 Val_Loss: 350.0307  BEST VAL Loss: 322.5545\n",
            "\n",
            "Epoch 570: Validation loss did not decrease\n",
            "\t Train_Loss: 118.8328 Val_Loss: 335.5754  BEST VAL Loss: 322.5545\n",
            "\n",
            "Epoch 571: Validation loss did not decrease\n",
            "\t Train_Loss: 116.2707 Val_Loss: 330.5052  BEST VAL Loss: 322.5545\n",
            "\n",
            "Epoch 572: Validation loss did not decrease\n",
            "\t Train_Loss: 116.9222 Val_Loss: 326.6562  BEST VAL Loss: 322.5545\n",
            "\n",
            "Epoch 573: Validation loss did not decrease\n",
            "\t Train_Loss: 116.9971 Val_Loss: 324.1756  BEST VAL Loss: 322.5545\n",
            "\n",
            "Epoch 574: Validation loss did not decrease\n",
            "\t Train_Loss: 116.5919 Val_Loss: 323.4722  BEST VAL Loss: 322.5545\n",
            "\n",
            "Epoch 575: Validation loss did not decrease\n",
            "\t Train_Loss: 115.9337 Val_Loss: 324.5075  BEST VAL Loss: 322.5545\n",
            "\n",
            "Epoch 576: Validation loss did not decrease\n",
            "\t Train_Loss: 115.5079 Val_Loss: 325.3976  BEST VAL Loss: 322.5545\n",
            "\n",
            "Epoch 577: Validation loss did not decrease\n",
            "\t Train_Loss: 115.2534 Val_Loss: 324.0455  BEST VAL Loss: 322.5545\n",
            "\n",
            "Epoch 578: Validation loss decreased (322.554504 --> 321.492981).\n",
            "\t Train_Loss: 114.6220 Val_Loss: 321.4930  BEST VAL Loss: 321.4930\n",
            "\n",
            "Epoch 579: Validation loss decreased (321.492981 --> 319.587067).\n",
            "\t Train_Loss: 113.9470 Val_Loss: 319.5871  BEST VAL Loss: 319.5871\n",
            "\n",
            "Epoch 580: Validation loss decreased (319.587067 --> 318.441864).\n",
            "\t Train_Loss: 113.6064 Val_Loss: 318.4419  BEST VAL Loss: 318.4419\n",
            "\n",
            "Epoch 581: Validation loss decreased (318.441864 --> 317.773773).\n",
            "\t Train_Loss: 113.2403 Val_Loss: 317.7738  BEST VAL Loss: 317.7738\n",
            "\n",
            "Epoch 582: Validation loss decreased (317.773773 --> 317.515076).\n",
            "\t Train_Loss: 112.6785 Val_Loss: 317.5151  BEST VAL Loss: 317.5151\n",
            "\n",
            "Epoch 583: Validation loss decreased (317.515076 --> 316.927795).\n",
            "\t Train_Loss: 112.2033 Val_Loss: 316.9278  BEST VAL Loss: 316.9278\n",
            "\n",
            "Epoch 584: Validation loss decreased (316.927795 --> 315.455505).\n",
            "\t Train_Loss: 111.8323 Val_Loss: 315.4555  BEST VAL Loss: 315.4555\n",
            "\n",
            "Epoch 585: Validation loss decreased (315.455505 --> 313.693176).\n",
            "\t Train_Loss: 111.3753 Val_Loss: 313.6932  BEST VAL Loss: 313.6932\n",
            "\n",
            "Epoch 586: Validation loss decreased (313.693176 --> 312.342133).\n",
            "\t Train_Loss: 110.9354 Val_Loss: 312.3421  BEST VAL Loss: 312.3421\n",
            "\n",
            "Epoch 587: Validation loss decreased (312.342133 --> 311.493164).\n",
            "\t Train_Loss: 110.5810 Val_Loss: 311.4932  BEST VAL Loss: 311.4932\n",
            "\n",
            "Epoch 588: Validation loss decreased (311.493164 --> 310.967377).\n",
            "\t Train_Loss: 110.1950 Val_Loss: 310.9674  BEST VAL Loss: 310.9674\n",
            "\n",
            "Epoch 589: Validation loss decreased (310.967377 --> 310.532776).\n",
            "\t Train_Loss: 109.7494 Val_Loss: 310.5328  BEST VAL Loss: 310.5328\n",
            "\n",
            "Epoch 590: Validation loss decreased (310.532776 --> 309.804047).\n",
            "\t Train_Loss: 109.3417 Val_Loss: 309.8040  BEST VAL Loss: 309.8040\n",
            "\n",
            "Epoch 591: Validation loss decreased (309.804047 --> 308.501953).\n",
            "\t Train_Loss: 108.9746 Val_Loss: 308.5020  BEST VAL Loss: 308.5020\n",
            "\n",
            "Epoch 592: Validation loss decreased (308.501953 --> 306.937927).\n",
            "\t Train_Loss: 108.5150 Val_Loss: 306.9379  BEST VAL Loss: 306.9379\n",
            "\n",
            "Epoch 593: Validation loss decreased (306.937927 --> 306.071594).\n",
            "\t Train_Loss: 107.8444 Val_Loss: 306.0716  BEST VAL Loss: 306.0716\n",
            "\n",
            "Epoch 594: Validation loss did not decrease\n",
            "\t Train_Loss: 106.6347 Val_Loss: 310.2635  BEST VAL Loss: 306.0716\n",
            "\n",
            "Epoch 595: Validation loss did not decrease\n",
            "\t Train_Loss: 105.3211 Val_Loss: 316.6578  BEST VAL Loss: 306.0716\n",
            "\n",
            "Epoch 596: Validation loss decreased (306.071594 --> 306.060028).\n",
            "\t Train_Loss: 106.4937 Val_Loss: 306.0600  BEST VAL Loss: 306.0600\n",
            "\n",
            "Epoch 597: Validation loss decreased (306.060028 --> 301.920166).\n",
            "\t Train_Loss: 104.3897 Val_Loss: 301.9202  BEST VAL Loss: 301.9202\n",
            "\n",
            "Epoch 598: Validation loss decreased (301.920166 --> 301.141724).\n",
            "\t Train_Loss: 104.6268 Val_Loss: 301.1417  BEST VAL Loss: 301.1417\n",
            "\n",
            "Epoch 599: Validation loss did not decrease\n",
            "\t Train_Loss: 104.4915 Val_Loss: 301.6363  BEST VAL Loss: 301.1417\n",
            "\n",
            "Epoch 600: Validation loss did not decrease\n",
            "\t Train_Loss: 103.7400 Val_Loss: 303.2092  BEST VAL Loss: 301.1417\n",
            "\n",
            "Epoch 601: Validation loss did not decrease\n",
            "\t Train_Loss: 102.5953 Val_Loss: 306.6682  BEST VAL Loss: 301.1417\n",
            "\n",
            "Epoch 602: Validation loss did not decrease\n",
            "\t Train_Loss: 102.0548 Val_Loss: 308.1669  BEST VAL Loss: 301.1417\n",
            "\n",
            "Epoch 603: Validation loss did not decrease\n",
            "\t Train_Loss: 101.7755 Val_Loss: 305.2253  BEST VAL Loss: 301.1417\n",
            "\n",
            "Epoch 604: Validation loss did not decrease\n",
            "\t Train_Loss: 100.6991 Val_Loss: 303.3731  BEST VAL Loss: 301.1417\n",
            "\n",
            "Epoch 605: Validation loss did not decrease\n",
            "\t Train_Loss: 100.4059 Val_Loss: 302.3786  BEST VAL Loss: 301.1417\n",
            "\n",
            "Epoch 606: Validation loss did not decrease\n",
            "\t Train_Loss: 100.1436 Val_Loss: 301.4897  BEST VAL Loss: 301.1417\n",
            "\n",
            "Epoch 607: Validation loss did not decrease\n",
            "\t Train_Loss: 99.3751 Val_Loss: 301.6103  BEST VAL Loss: 301.1417\n",
            "\n",
            "Epoch 608: Validation loss did not decrease\n",
            "\t Train_Loss: 98.6122 Val_Loss: 302.0183  BEST VAL Loss: 301.1417\n",
            "\n",
            "Epoch 609: Validation loss decreased (301.141724 --> 300.864929).\n",
            "\t Train_Loss: 98.1666 Val_Loss: 300.8649  BEST VAL Loss: 300.8649\n",
            "\n",
            "Epoch 610: Validation loss decreased (300.864929 --> 297.603638).\n",
            "\t Train_Loss: 97.7610 Val_Loss: 297.6036  BEST VAL Loss: 297.6036\n",
            "\n",
            "Epoch 611: Validation loss decreased (297.603638 --> 294.129425).\n",
            "\t Train_Loss: 97.0254 Val_Loss: 294.1294  BEST VAL Loss: 294.1294\n",
            "\n",
            "Epoch 612: Validation loss decreased (294.129425 --> 292.292328).\n",
            "\t Train_Loss: 96.2973 Val_Loss: 292.2923  BEST VAL Loss: 292.2923\n",
            "\n",
            "Epoch 613: Validation loss did not decrease\n",
            "\t Train_Loss: 95.7373 Val_Loss: 292.4236  BEST VAL Loss: 292.2923\n",
            "\n",
            "Epoch 614: Validation loss did not decrease\n",
            "\t Train_Loss: 95.0548 Val_Loss: 293.9975  BEST VAL Loss: 292.2923\n",
            "\n",
            "Epoch 615: Validation loss did not decrease\n",
            "\t Train_Loss: 94.2289 Val_Loss: 296.1234  BEST VAL Loss: 292.2923\n",
            "\n",
            "Epoch 616: Validation loss did not decrease\n",
            "\t Train_Loss: 93.4480 Val_Loss: 298.0925  BEST VAL Loss: 292.2923\n",
            "\n",
            "Epoch 617: Validation loss did not decrease\n",
            "\t Train_Loss: 93.2565 Val_Loss: 293.2610  BEST VAL Loss: 292.2923\n",
            "\n",
            "Epoch 618: Validation loss decreased (292.292328 --> 287.747314).\n",
            "\t Train_Loss: 92.2878 Val_Loss: 287.7473  BEST VAL Loss: 287.7473\n",
            "\n",
            "Epoch 619: Validation loss decreased (287.747314 --> 284.975616).\n",
            "\t Train_Loss: 91.7494 Val_Loss: 284.9756  BEST VAL Loss: 284.9756\n",
            "\n",
            "Epoch 620: Validation loss decreased (284.975616 --> 284.215393).\n",
            "\t Train_Loss: 91.5202 Val_Loss: 284.2154  BEST VAL Loss: 284.2154\n",
            "\n",
            "Epoch 621: Validation loss did not decrease\n",
            "\t Train_Loss: 90.9389 Val_Loss: 284.9617  BEST VAL Loss: 284.2154\n",
            "\n",
            "Epoch 622: Validation loss did not decrease\n",
            "\t Train_Loss: 90.1407 Val_Loss: 286.5569  BEST VAL Loss: 284.2154\n",
            "\n",
            "Epoch 623: Validation loss did not decrease\n",
            "\t Train_Loss: 89.5592 Val_Loss: 287.2112  BEST VAL Loss: 284.2154\n",
            "\n",
            "Epoch 624: Validation loss did not decrease\n",
            "\t Train_Loss: 89.2372 Val_Loss: 284.8040  BEST VAL Loss: 284.2154\n",
            "\n",
            "Epoch 625: Validation loss decreased (284.215393 --> 281.093201).\n",
            "\t Train_Loss: 88.6182 Val_Loss: 281.0932  BEST VAL Loss: 281.0932\n",
            "\n",
            "Epoch 626: Validation loss decreased (281.093201 --> 278.428284).\n",
            "\t Train_Loss: 88.0427 Val_Loss: 278.4283  BEST VAL Loss: 278.4283\n",
            "\n",
            "Epoch 627: Validation loss decreased (278.428284 --> 277.253326).\n",
            "\t Train_Loss: 87.6894 Val_Loss: 277.2533  BEST VAL Loss: 277.2533\n",
            "\n",
            "Epoch 628: Validation loss did not decrease\n",
            "\t Train_Loss: 87.2072 Val_Loss: 277.3375  BEST VAL Loss: 277.2533\n",
            "\n",
            "Epoch 629: Validation loss did not decrease\n",
            "\t Train_Loss: 86.6075 Val_Loss: 278.0209  BEST VAL Loss: 277.2533\n",
            "\n",
            "Epoch 630: Validation loss did not decrease\n",
            "\t Train_Loss: 86.1720 Val_Loss: 277.9083  BEST VAL Loss: 277.2533\n",
            "\n",
            "Epoch 631: Validation loss decreased (277.253326 --> 276.120544).\n",
            "\t Train_Loss: 85.8288 Val_Loss: 276.1205  BEST VAL Loss: 276.1205\n",
            "\n",
            "Epoch 632: Validation loss decreased (276.120544 --> 273.561554).\n",
            "\t Train_Loss: 85.3272 Val_Loss: 273.5616  BEST VAL Loss: 273.5616\n",
            "\n",
            "Epoch 633: Validation loss decreased (273.561554 --> 271.419983).\n",
            "\t Train_Loss: 84.8476 Val_Loss: 271.4200  BEST VAL Loss: 271.4200\n",
            "\n",
            "Epoch 634: Validation loss decreased (271.419983 --> 270.163940).\n",
            "\t Train_Loss: 84.4908 Val_Loss: 270.1639  BEST VAL Loss: 270.1639\n",
            "\n",
            "Epoch 635: Validation loss decreased (270.163940 --> 269.760223).\n",
            "\t Train_Loss: 84.1024 Val_Loss: 269.7602  BEST VAL Loss: 269.7602\n",
            "\n",
            "Epoch 636: Validation loss did not decrease\n",
            "\t Train_Loss: 83.6484 Val_Loss: 269.8080  BEST VAL Loss: 269.7602\n",
            "\n",
            "Epoch 637: Validation loss decreased (269.760223 --> 269.555481).\n",
            "\t Train_Loss: 83.2538 Val_Loss: 269.5555  BEST VAL Loss: 269.5555\n",
            "\n",
            "Epoch 638: Validation loss decreased (269.555481 --> 268.466095).\n",
            "\t Train_Loss: 82.9168 Val_Loss: 268.4661  BEST VAL Loss: 268.4661\n",
            "\n",
            "Epoch 639: Validation loss decreased (268.466095 --> 266.784729).\n",
            "\t Train_Loss: 82.5277 Val_Loss: 266.7847  BEST VAL Loss: 266.7847\n",
            "\n",
            "Epoch 640: Validation loss decreased (266.784729 --> 265.104462).\n",
            "\t Train_Loss: 82.1257 Val_Loss: 265.1045  BEST VAL Loss: 265.1045\n",
            "\n",
            "Epoch 641: Validation loss decreased (265.104462 --> 263.812592).\n",
            "\t Train_Loss: 81.7785 Val_Loss: 263.8126  BEST VAL Loss: 263.8126\n",
            "\n",
            "Epoch 642: Validation loss decreased (263.812592 --> 263.013245).\n",
            "\t Train_Loss: 81.4438 Val_Loss: 263.0132  BEST VAL Loss: 263.0132\n",
            "\n",
            "Epoch 643: Validation loss decreased (263.013245 --> 262.583496).\n",
            "\t Train_Loss: 81.0797 Val_Loss: 262.5835  BEST VAL Loss: 262.5835\n",
            "\n",
            "Epoch 644: Validation loss decreased (262.583496 --> 262.199554).\n",
            "\t Train_Loss: 80.7205 Val_Loss: 262.1996  BEST VAL Loss: 262.1996\n",
            "\n",
            "Epoch 645: Validation loss decreased (262.199554 --> 261.490448).\n",
            "\t Train_Loss: 80.3979 Val_Loss: 261.4904  BEST VAL Loss: 261.4904\n",
            "\n",
            "Epoch 646: Validation loss decreased (261.490448 --> 260.358459).\n",
            "\t Train_Loss: 80.0753 Val_Loss: 260.3585  BEST VAL Loss: 260.3585\n",
            "\n",
            "Epoch 647: Validation loss decreased (260.358459 --> 259.042297).\n",
            "\t Train_Loss: 79.7307 Val_Loss: 259.0423  BEST VAL Loss: 259.0423\n",
            "\n",
            "Epoch 648: Validation loss decreased (259.042297 --> 257.840485).\n",
            "\t Train_Loss: 79.3989 Val_Loss: 257.8405  BEST VAL Loss: 257.8405\n",
            "\n",
            "Epoch 649: Validation loss decreased (257.840485 --> 256.908722).\n",
            "\t Train_Loss: 79.0930 Val_Loss: 256.9087  BEST VAL Loss: 256.9087\n",
            "\n",
            "Epoch 650: Validation loss decreased (256.908722 --> 256.243744).\n",
            "\t Train_Loss: 78.7867 Val_Loss: 256.2437  BEST VAL Loss: 256.2437\n",
            "\n",
            "Epoch 651: Validation loss decreased (256.243744 --> 255.722504).\n",
            "\t Train_Loss: 78.4689 Val_Loss: 255.7225  BEST VAL Loss: 255.7225\n",
            "\n",
            "Epoch 652: Validation loss decreased (255.722504 --> 255.152634).\n",
            "\t Train_Loss: 78.1570 Val_Loss: 255.1526  BEST VAL Loss: 255.1526\n",
            "\n",
            "Epoch 653: Validation loss decreased (255.152634 --> 254.374191).\n",
            "\t Train_Loss: 77.8603 Val_Loss: 254.3742  BEST VAL Loss: 254.3742\n",
            "\n",
            "Epoch 654: Validation loss decreased (254.374191 --> 253.374710).\n",
            "\t Train_Loss: 77.5659 Val_Loss: 253.3747  BEST VAL Loss: 253.3747\n",
            "\n",
            "Epoch 655: Validation loss decreased (253.374710 --> 252.292648).\n",
            "\t Train_Loss: 77.2675 Val_Loss: 252.2926  BEST VAL Loss: 252.2926\n",
            "\n",
            "Epoch 656: Validation loss decreased (252.292648 --> 251.298370).\n",
            "\t Train_Loss: 76.9754 Val_Loss: 251.2984  BEST VAL Loss: 251.2984\n",
            "\n",
            "Epoch 657: Validation loss decreased (251.298370 --> 250.488800).\n",
            "\t Train_Loss: 76.6930 Val_Loss: 250.4888  BEST VAL Loss: 250.4888\n",
            "\n",
            "Epoch 658: Validation loss decreased (250.488800 --> 249.857712).\n",
            "\t Train_Loss: 76.4108 Val_Loss: 249.8577  BEST VAL Loss: 249.8577\n",
            "\n",
            "Epoch 659: Validation loss decreased (249.857712 --> 249.315720).\n",
            "\t Train_Loss: 76.1258 Val_Loss: 249.3157  BEST VAL Loss: 249.3157\n",
            "\n",
            "Epoch 660: Validation loss decreased (249.315720 --> 248.734665).\n",
            "\t Train_Loss: 75.8452 Val_Loss: 248.7347  BEST VAL Loss: 248.7347\n",
            "\n",
            "Epoch 661: Validation loss decreased (248.734665 --> 248.014984).\n",
            "\t Train_Loss: 75.5717 Val_Loss: 248.0150  BEST VAL Loss: 248.0150\n",
            "\n",
            "Epoch 662: Validation loss decreased (248.014984 --> 247.148880).\n",
            "\t Train_Loss: 75.2979 Val_Loss: 247.1489  BEST VAL Loss: 247.1489\n",
            "\n",
            "Epoch 663: Validation loss decreased (247.148880 --> 246.226242).\n",
            "\t Train_Loss: 75.0167 Val_Loss: 246.2262  BEST VAL Loss: 246.2262\n",
            "\n",
            "Epoch 664: Validation loss decreased (246.226242 --> 245.397583).\n",
            "\t Train_Loss: 74.7233 Val_Loss: 245.3976  BEST VAL Loss: 245.3976\n",
            "\n",
            "Epoch 665: Validation loss decreased (245.397583 --> 244.970993).\n",
            "\t Train_Loss: 74.3941 Val_Loss: 244.9710  BEST VAL Loss: 244.9710\n",
            "\n",
            "Epoch 666: Validation loss did not decrease\n",
            "\t Train_Loss: 73.9380 Val_Loss: 247.1792  BEST VAL Loss: 244.9710\n",
            "\n",
            "Epoch 667: Validation loss did not decrease\n",
            "\t Train_Loss: 73.4557 Val_Loss: 246.8238  BEST VAL Loss: 244.9710\n",
            "\n",
            "Epoch 668: Validation loss decreased (244.970993 --> 242.361984).\n",
            "\t Train_Loss: 73.1454 Val_Loss: 242.3620  BEST VAL Loss: 242.3620\n",
            "\n",
            "Epoch 669: Validation loss decreased (242.361984 --> 241.185745).\n",
            "\t Train_Loss: 72.8407 Val_Loss: 241.1857  BEST VAL Loss: 241.1857\n",
            "\n",
            "Epoch 670: Validation loss did not decrease\n",
            "\t Train_Loss: 72.5896 Val_Loss: 241.4689  BEST VAL Loss: 241.1857\n",
            "\n",
            "Epoch 671: Validation loss did not decrease\n",
            "\t Train_Loss: 71.9924 Val_Loss: 244.3565  BEST VAL Loss: 241.1857\n",
            "\n",
            "Epoch 672: Validation loss did not decrease\n",
            "\t Train_Loss: 71.8113 Val_Loss: 241.3703  BEST VAL Loss: 241.1857\n",
            "\n",
            "Epoch 673: Validation loss decreased (241.185745 --> 239.044769).\n",
            "\t Train_Loss: 71.1879 Val_Loss: 239.0448  BEST VAL Loss: 239.0448\n",
            "\n",
            "Epoch 674: Validation loss decreased (239.044769 --> 238.194046).\n",
            "\t Train_Loss: 70.9269 Val_Loss: 238.1940  BEST VAL Loss: 238.1940\n",
            "\n",
            "Epoch 675: Validation loss did not decrease\n",
            "\t Train_Loss: 70.5483 Val_Loss: 238.4734  BEST VAL Loss: 238.1940\n",
            "\n",
            "Epoch 676: Validation loss did not decrease\n",
            "\t Train_Loss: 70.0294 Val_Loss: 239.1473  BEST VAL Loss: 238.1940\n",
            "\n",
            "Epoch 677: Validation loss decreased (238.194046 --> 237.614868).\n",
            "\t Train_Loss: 69.7267 Val_Loss: 237.6149  BEST VAL Loss: 237.6149\n",
            "\n",
            "Epoch 678: Validation loss decreased (237.614868 --> 236.744308).\n",
            "\t Train_Loss: 69.1276 Val_Loss: 236.7443  BEST VAL Loss: 236.7443\n",
            "\n",
            "Epoch 679: Validation loss did not decrease\n",
            "\t Train_Loss: 68.6449 Val_Loss: 238.2037  BEST VAL Loss: 236.7443\n",
            "\n",
            "Epoch 680: Validation loss did not decrease\n",
            "\t Train_Loss: 68.1531 Val_Loss: 242.7094  BEST VAL Loss: 236.7443\n",
            "\n",
            "Epoch 681: Validation loss did not decrease\n",
            "\t Train_Loss: 73.8336 Val_Loss: 237.1747  BEST VAL Loss: 236.7443\n",
            "\n",
            "Epoch 682: Validation loss decreased (236.744308 --> 235.994019).\n",
            "\t Train_Loss: 68.5437 Val_Loss: 235.9940  BEST VAL Loss: 235.9940\n",
            "\n",
            "Epoch 683: Validation loss decreased (235.994019 --> 232.188644).\n",
            "\t Train_Loss: 69.8103 Val_Loss: 232.1886  BEST VAL Loss: 232.1886\n",
            "\n",
            "Epoch 684: Validation loss decreased (232.188644 --> 229.481644).\n",
            "\t Train_Loss: 69.4753 Val_Loss: 229.4816  BEST VAL Loss: 229.4816\n",
            "\n",
            "Epoch 685: Validation loss decreased (229.481644 --> 229.390045).\n",
            "\t Train_Loss: 68.6361 Val_Loss: 229.3900  BEST VAL Loss: 229.3900\n",
            "\n",
            "Epoch 686: Validation loss did not decrease\n",
            "\t Train_Loss: 67.4939 Val_Loss: 231.3882  BEST VAL Loss: 229.3900\n",
            "\n",
            "Epoch 687: Validation loss did not decrease\n",
            "\t Train_Loss: 66.8741 Val_Loss: 231.6052  BEST VAL Loss: 229.3900\n",
            "\n",
            "Epoch 688: Validation loss did not decrease\n",
            "\t Train_Loss: 66.4520 Val_Loss: 230.6586  BEST VAL Loss: 229.3900\n",
            "\n",
            "Epoch 689: Validation loss did not decrease\n",
            "\t Train_Loss: 66.2126 Val_Loss: 229.5471  BEST VAL Loss: 229.3900\n",
            "\n",
            "Epoch 690: Validation loss decreased (229.390045 --> 228.336838).\n",
            "\t Train_Loss: 66.0559 Val_Loss: 228.3368  BEST VAL Loss: 228.3368\n",
            "\n",
            "Epoch 691: Validation loss decreased (228.336838 --> 227.347733).\n",
            "\t Train_Loss: 65.7107 Val_Loss: 227.3477  BEST VAL Loss: 227.3477\n",
            "\n",
            "Epoch 692: Validation loss decreased (227.347733 --> 226.975342).\n",
            "\t Train_Loss: 65.2055 Val_Loss: 226.9753  BEST VAL Loss: 226.9753\n",
            "\n",
            "Epoch 693: Validation loss did not decrease\n",
            "\t Train_Loss: 64.7286 Val_Loss: 227.1472  BEST VAL Loss: 226.9753\n",
            "\n",
            "Epoch 694: Validation loss did not decrease\n",
            "\t Train_Loss: 64.3151 Val_Loss: 227.3230  BEST VAL Loss: 226.9753\n",
            "\n",
            "Epoch 695: Validation loss decreased (226.975342 --> 226.812469).\n",
            "\t Train_Loss: 63.9239 Val_Loss: 226.8125  BEST VAL Loss: 226.8125\n",
            "\n",
            "Epoch 696: Validation loss decreased (226.812469 --> 224.868729).\n",
            "\t Train_Loss: 63.5758 Val_Loss: 224.8687  BEST VAL Loss: 224.8687\n",
            "\n",
            "Epoch 697: Validation loss decreased (224.868729 --> 222.280518).\n",
            "\t Train_Loss: 63.1881 Val_Loss: 222.2805  BEST VAL Loss: 222.2805\n",
            "\n",
            "Epoch 698: Validation loss decreased (222.280518 --> 220.430862).\n",
            "\t Train_Loss: 62.9244 Val_Loss: 220.4309  BEST VAL Loss: 220.4309\n",
            "\n",
            "Epoch 699: Validation loss decreased (220.430862 --> 219.771896).\n",
            "\t Train_Loss: 62.7515 Val_Loss: 219.7719  BEST VAL Loss: 219.7719\n",
            "\n",
            "Epoch 700: Validation loss did not decrease\n",
            "\t Train_Loss: 62.4130 Val_Loss: 220.0808  BEST VAL Loss: 219.7719\n",
            "\n",
            "Epoch 701: Validation loss did not decrease\n",
            "\t Train_Loss: 61.9689 Val_Loss: 220.6476  BEST VAL Loss: 219.7719\n",
            "\n",
            "Epoch 702: Validation loss did not decrease\n",
            "\t Train_Loss: 61.5988 Val_Loss: 220.6762  BEST VAL Loss: 219.7719\n",
            "\n",
            "Epoch 703: Validation loss did not decrease\n",
            "\t Train_Loss: 61.2954 Val_Loss: 219.9706  BEST VAL Loss: 219.7719\n",
            "\n",
            "Epoch 704: Validation loss decreased (219.771896 --> 218.815460).\n",
            "\t Train_Loss: 61.0271 Val_Loss: 218.8155  BEST VAL Loss: 218.8155\n",
            "\n",
            "Epoch 705: Validation loss decreased (218.815460 --> 217.551025).\n",
            "\t Train_Loss: 60.8075 Val_Loss: 217.5510  BEST VAL Loss: 217.5510\n",
            "\n",
            "Epoch 706: Validation loss decreased (217.551025 --> 216.457977).\n",
            "\t Train_Loss: 60.5724 Val_Loss: 216.4580  BEST VAL Loss: 216.4580\n",
            "\n",
            "Epoch 707: Validation loss decreased (216.457977 --> 215.755219).\n",
            "\t Train_Loss: 60.2446 Val_Loss: 215.7552  BEST VAL Loss: 215.7552\n",
            "\n",
            "Epoch 708: Validation loss decreased (215.755219 --> 215.459518).\n",
            "\t Train_Loss: 59.8690 Val_Loss: 215.4595  BEST VAL Loss: 215.4595\n",
            "\n",
            "Epoch 709: Validation loss decreased (215.459518 --> 215.211792).\n",
            "\t Train_Loss: 59.5664 Val_Loss: 215.2118  BEST VAL Loss: 215.2118\n",
            "\n",
            "Epoch 710: Validation loss decreased (215.211792 --> 214.539154).\n",
            "\t Train_Loss: 59.3490 Val_Loss: 214.5392  BEST VAL Loss: 214.5392\n",
            "\n",
            "Epoch 711: Validation loss decreased (214.539154 --> 213.416107).\n",
            "\t Train_Loss: 59.1146 Val_Loss: 213.4161  BEST VAL Loss: 213.4161\n",
            "\n",
            "Epoch 712: Validation loss decreased (213.416107 --> 212.193527).\n",
            "\t Train_Loss: 58.8443 Val_Loss: 212.1935  BEST VAL Loss: 212.1935\n",
            "\n",
            "Epoch 713: Validation loss decreased (212.193527 --> 211.187988).\n",
            "\t Train_Loss: 58.5856 Val_Loss: 211.1880  BEST VAL Loss: 211.1880\n",
            "\n",
            "Epoch 714: Validation loss decreased (211.187988 --> 210.545807).\n",
            "\t Train_Loss: 58.3302 Val_Loss: 210.5458  BEST VAL Loss: 210.5458\n",
            "\n",
            "Epoch 715: Validation loss decreased (210.545807 --> 210.244781).\n",
            "\t Train_Loss: 58.0550 Val_Loss: 210.2448  BEST VAL Loss: 210.2448\n",
            "\n",
            "Epoch 716: Validation loss decreased (210.244781 --> 210.085846).\n",
            "\t Train_Loss: 57.7839 Val_Loss: 210.0858  BEST VAL Loss: 210.0858\n",
            "\n",
            "Epoch 717: Validation loss decreased (210.085846 --> 209.748901).\n",
            "\t Train_Loss: 57.5505 Val_Loss: 209.7489  BEST VAL Loss: 209.7489\n",
            "\n",
            "Epoch 718: Validation loss decreased (209.748901 --> 209.026489).\n",
            "\t Train_Loss: 57.3332 Val_Loss: 209.0265  BEST VAL Loss: 209.0265\n",
            "\n",
            "Epoch 719: Validation loss decreased (209.026489 --> 208.026459).\n",
            "\t Train_Loss: 57.0906 Val_Loss: 208.0265  BEST VAL Loss: 208.0265\n",
            "\n",
            "Epoch 720: Validation loss decreased (208.026459 --> 207.032837).\n",
            "\t Train_Loss: 56.8374 Val_Loss: 207.0328  BEST VAL Loss: 207.0328\n",
            "\n",
            "Epoch 721: Validation loss decreased (207.032837 --> 206.249634).\n",
            "\t Train_Loss: 56.6054 Val_Loss: 206.2496  BEST VAL Loss: 206.2496\n",
            "\n",
            "Epoch 722: Validation loss decreased (206.249634 --> 205.720825).\n",
            "\t Train_Loss: 56.3859 Val_Loss: 205.7208  BEST VAL Loss: 205.7208\n",
            "\n",
            "Epoch 723: Validation loss decreased (205.720825 --> 205.363525).\n",
            "\t Train_Loss: 56.1588 Val_Loss: 205.3635  BEST VAL Loss: 205.3635\n",
            "\n",
            "Epoch 724: Validation loss decreased (205.363525 --> 205.017090).\n",
            "\t Train_Loss: 55.9281 Val_Loss: 205.0171  BEST VAL Loss: 205.0171\n",
            "\n",
            "Epoch 725: Validation loss decreased (205.017090 --> 204.514908).\n",
            "\t Train_Loss: 55.7066 Val_Loss: 204.5149  BEST VAL Loss: 204.5149\n",
            "\n",
            "Epoch 726: Validation loss decreased (204.514908 --> 203.792023).\n",
            "\t Train_Loss: 55.4924 Val_Loss: 203.7920  BEST VAL Loss: 203.7920\n",
            "\n",
            "Epoch 727: Validation loss decreased (203.792023 --> 202.937286).\n",
            "\t Train_Loss: 55.2781 Val_Loss: 202.9373  BEST VAL Loss: 202.9373\n",
            "\n",
            "Epoch 728: Validation loss decreased (202.937286 --> 202.115280).\n",
            "\t Train_Loss: 55.0664 Val_Loss: 202.1153  BEST VAL Loss: 202.1153\n",
            "\n",
            "Epoch 729: Validation loss decreased (202.115280 --> 201.443848).\n",
            "\t Train_Loss: 54.8605 Val_Loss: 201.4438  BEST VAL Loss: 201.4438\n",
            "\n",
            "Epoch 730: Validation loss decreased (201.443848 --> 200.936890).\n",
            "\t Train_Loss: 54.6544 Val_Loss: 200.9369  BEST VAL Loss: 200.9369\n",
            "\n",
            "Epoch 731: Validation loss decreased (200.936890 --> 200.518112).\n",
            "\t Train_Loss: 54.4453 Val_Loss: 200.5181  BEST VAL Loss: 200.5181\n",
            "\n",
            "Epoch 732: Validation loss decreased (200.518112 --> 200.073105).\n",
            "\t Train_Loss: 54.2383 Val_Loss: 200.0731  BEST VAL Loss: 200.0731\n",
            "\n",
            "Epoch 733: Validation loss decreased (200.073105 --> 199.515213).\n",
            "\t Train_Loss: 54.0373 Val_Loss: 199.5152  BEST VAL Loss: 199.5152\n",
            "\n",
            "Epoch 734: Validation loss decreased (199.515213 --> 198.835815).\n",
            "\t Train_Loss: 53.8400 Val_Loss: 198.8358  BEST VAL Loss: 198.8358\n",
            "\n",
            "Epoch 735: Validation loss decreased (198.835815 --> 198.103226).\n",
            "\t Train_Loss: 53.6441 Val_Loss: 198.1032  BEST VAL Loss: 198.1032\n",
            "\n",
            "Epoch 736: Validation loss decreased (198.103226 --> 197.414398).\n",
            "\t Train_Loss: 53.4495 Val_Loss: 197.4144  BEST VAL Loss: 197.4144\n",
            "\n",
            "Epoch 737: Validation loss decreased (197.414398 --> 196.837265).\n",
            "\t Train_Loss: 53.2551 Val_Loss: 196.8373  BEST VAL Loss: 196.8373\n",
            "\n",
            "Epoch 738: Validation loss decreased (196.837265 --> 196.377762).\n",
            "\t Train_Loss: 53.0590 Val_Loss: 196.3778  BEST VAL Loss: 196.3778\n",
            "\n",
            "Epoch 739: Validation loss decreased (196.377762 --> 195.981750).\n",
            "\t Train_Loss: 52.8622 Val_Loss: 195.9818  BEST VAL Loss: 195.9818\n",
            "\n",
            "Epoch 740: Validation loss decreased (195.981750 --> 195.565125).\n",
            "\t Train_Loss: 52.6681 Val_Loss: 195.5651  BEST VAL Loss: 195.5651\n",
            "\n",
            "Epoch 741: Validation loss decreased (195.565125 --> 195.059601).\n",
            "\t Train_Loss: 52.4773 Val_Loss: 195.0596  BEST VAL Loss: 195.0596\n",
            "\n",
            "Epoch 742: Validation loss decreased (195.059601 --> 194.453690).\n",
            "\t Train_Loss: 52.2872 Val_Loss: 194.4537  BEST VAL Loss: 194.4537\n",
            "\n",
            "Epoch 743: Validation loss decreased (194.453690 --> 193.794312).\n",
            "\t Train_Loss: 52.0968 Val_Loss: 193.7943  BEST VAL Loss: 193.7943\n",
            "\n",
            "Epoch 744: Validation loss decreased (193.794312 --> 193.154037).\n",
            "\t Train_Loss: 51.9083 Val_Loss: 193.1540  BEST VAL Loss: 193.1540\n",
            "\n",
            "Epoch 745: Validation loss decreased (193.154037 --> 192.585373).\n",
            "\t Train_Loss: 51.7234 Val_Loss: 192.5854  BEST VAL Loss: 192.5854\n",
            "\n",
            "Epoch 746: Validation loss decreased (192.585373 --> 192.093140).\n",
            "\t Train_Loss: 51.5421 Val_Loss: 192.0931  BEST VAL Loss: 192.0931\n",
            "\n",
            "Epoch 747: Validation loss decreased (192.093140 --> 191.635376).\n",
            "\t Train_Loss: 51.3635 Val_Loss: 191.6354  BEST VAL Loss: 191.6354\n",
            "\n",
            "Epoch 748: Validation loss decreased (191.635376 --> 191.160721).\n",
            "\t Train_Loss: 51.1857 Val_Loss: 191.1607  BEST VAL Loss: 191.1607\n",
            "\n",
            "Epoch 749: Validation loss decreased (191.160721 --> 190.652222).\n",
            "\t Train_Loss: 51.0056 Val_Loss: 190.6522  BEST VAL Loss: 190.6522\n",
            "\n",
            "Epoch 750: Validation loss decreased (190.652222 --> 190.131424).\n",
            "\t Train_Loss: 50.8226 Val_Loss: 190.1314  BEST VAL Loss: 190.1314\n",
            "\n",
            "Epoch 751: Validation loss decreased (190.131424 --> 189.624908).\n",
            "\t Train_Loss: 50.6394 Val_Loss: 189.6249  BEST VAL Loss: 189.6249\n",
            "\n",
            "Epoch 752: Validation loss decreased (189.624908 --> 189.135574).\n",
            "\t Train_Loss: 50.4600 Val_Loss: 189.1356  BEST VAL Loss: 189.1356\n",
            "\n",
            "Epoch 753: Validation loss decreased (189.135574 --> 188.616074).\n",
            "\t Train_Loss: 50.2865 Val_Loss: 188.6161  BEST VAL Loss: 188.6161\n",
            "\n",
            "Epoch 754: Validation loss decreased (188.616074 --> 188.011078).\n",
            "\t Train_Loss: 50.1161 Val_Loss: 188.0111  BEST VAL Loss: 188.0111\n",
            "\n",
            "Epoch 755: Validation loss decreased (188.011078 --> 187.362869).\n",
            "\t Train_Loss: 49.9432 Val_Loss: 187.3629  BEST VAL Loss: 187.3629\n",
            "\n",
            "Epoch 756: Validation loss decreased (187.362869 --> 186.769241).\n",
            "\t Train_Loss: 49.7679 Val_Loss: 186.7692  BEST VAL Loss: 186.7692\n",
            "\n",
            "Epoch 757: Validation loss decreased (186.769241 --> 186.269745).\n",
            "\t Train_Loss: 49.5942 Val_Loss: 186.2697  BEST VAL Loss: 186.2697\n",
            "\n",
            "Epoch 758: Validation loss decreased (186.269745 --> 185.829437).\n",
            "\t Train_Loss: 49.4227 Val_Loss: 185.8294  BEST VAL Loss: 185.8294\n",
            "\n",
            "Epoch 759: Validation loss decreased (185.829437 --> 185.382935).\n",
            "\t Train_Loss: 49.2530 Val_Loss: 185.3829  BEST VAL Loss: 185.3829\n",
            "\n",
            "Epoch 760: Validation loss decreased (185.382935 --> 184.881302).\n",
            "\t Train_Loss: 49.0840 Val_Loss: 184.8813  BEST VAL Loss: 184.8813\n",
            "\n",
            "Epoch 761: Validation loss decreased (184.881302 --> 184.317612).\n",
            "\t Train_Loss: 48.9144 Val_Loss: 184.3176  BEST VAL Loss: 184.3176\n",
            "\n",
            "Epoch 762: Validation loss decreased (184.317612 --> 183.723633).\n",
            "\t Train_Loss: 48.7448 Val_Loss: 183.7236  BEST VAL Loss: 183.7236\n",
            "\n",
            "Epoch 763: Validation loss decreased (183.723633 --> 183.148605).\n",
            "\t Train_Loss: 48.5767 Val_Loss: 183.1486  BEST VAL Loss: 183.1486\n",
            "\n",
            "Epoch 764: Validation loss decreased (183.148605 --> 182.639816).\n",
            "\t Train_Loss: 48.4106 Val_Loss: 182.6398  BEST VAL Loss: 182.6398\n",
            "\n",
            "Epoch 765: Validation loss decreased (182.639816 --> 182.237946).\n",
            "\t Train_Loss: 48.2444 Val_Loss: 182.2379  BEST VAL Loss: 182.2379\n",
            "\n",
            "Epoch 766: Validation loss decreased (182.237946 --> 181.922989).\n",
            "\t Train_Loss: 48.0762 Val_Loss: 181.9230  BEST VAL Loss: 181.9230\n",
            "\n",
            "Epoch 767: Validation loss decreased (181.922989 --> 181.340912).\n",
            "\t Train_Loss: 47.9063 Val_Loss: 181.3409  BEST VAL Loss: 181.3409\n",
            "\n",
            "Epoch 768: Validation loss decreased (181.340912 --> 180.692307).\n",
            "\t Train_Loss: 47.7262 Val_Loss: 180.6923  BEST VAL Loss: 180.6923\n",
            "\n",
            "Epoch 769: Validation loss decreased (180.692307 --> 180.337860).\n",
            "\t Train_Loss: 47.5425 Val_Loss: 180.3379  BEST VAL Loss: 180.3379\n",
            "\n",
            "Epoch 770: Validation loss decreased (180.337860 --> 180.049774).\n",
            "\t Train_Loss: 47.3523 Val_Loss: 180.0498  BEST VAL Loss: 180.0498\n",
            "\n",
            "Epoch 771: Validation loss decreased (180.049774 --> 178.939011).\n",
            "\t Train_Loss: 47.1648 Val_Loss: 178.9390  BEST VAL Loss: 178.9390\n",
            "\n",
            "Epoch 772: Validation loss decreased (178.939011 --> 178.741730).\n",
            "\t Train_Loss: 46.9808 Val_Loss: 178.7417  BEST VAL Loss: 178.7417\n",
            "\n",
            "Epoch 773: Validation loss decreased (178.741730 --> 178.061295).\n",
            "\t Train_Loss: 46.7905 Val_Loss: 178.0613  BEST VAL Loss: 178.0613\n",
            "\n",
            "Epoch 774: Validation loss decreased (178.061295 --> 177.171631).\n",
            "\t Train_Loss: 46.6131 Val_Loss: 177.1716  BEST VAL Loss: 177.1716\n",
            "\n",
            "Epoch 775: Validation loss decreased (177.171631 --> 177.019531).\n",
            "\t Train_Loss: 46.4477 Val_Loss: 177.0195  BEST VAL Loss: 177.0195\n",
            "\n",
            "Epoch 776: Validation loss decreased (177.019531 --> 176.160553).\n",
            "\t Train_Loss: 46.2825 Val_Loss: 176.1606  BEST VAL Loss: 176.1606\n",
            "\n",
            "Epoch 777: Validation loss decreased (176.160553 --> 175.800018).\n",
            "\t Train_Loss: 46.1165 Val_Loss: 175.8000  BEST VAL Loss: 175.8000\n",
            "\n",
            "Epoch 778: Validation loss decreased (175.800018 --> 175.522156).\n",
            "\t Train_Loss: 45.9527 Val_Loss: 175.5222  BEST VAL Loss: 175.5222\n",
            "\n",
            "Epoch 779: Validation loss decreased (175.522156 --> 174.790527).\n",
            "\t Train_Loss: 45.7978 Val_Loss: 174.7905  BEST VAL Loss: 174.7905\n",
            "\n",
            "Epoch 780: Validation loss decreased (174.790527 --> 174.428131).\n",
            "\t Train_Loss: 45.6402 Val_Loss: 174.4281  BEST VAL Loss: 174.4281\n",
            "\n",
            "Epoch 781: Validation loss decreased (174.428131 --> 174.142334).\n",
            "\t Train_Loss: 45.4825 Val_Loss: 174.1423  BEST VAL Loss: 174.1423\n",
            "\n",
            "Epoch 782: Validation loss decreased (174.142334 --> 173.429459).\n",
            "\t Train_Loss: 45.3352 Val_Loss: 173.4295  BEST VAL Loss: 173.4295\n",
            "\n",
            "Epoch 783: Validation loss decreased (173.429459 --> 172.959396).\n",
            "\t Train_Loss: 45.1847 Val_Loss: 172.9594  BEST VAL Loss: 172.9594\n",
            "\n",
            "Epoch 784: Validation loss decreased (172.959396 --> 172.703278).\n",
            "\t Train_Loss: 45.0406 Val_Loss: 172.7033  BEST VAL Loss: 172.7033\n",
            "\n",
            "Epoch 785: Validation loss decreased (172.703278 --> 172.140213).\n",
            "\t Train_Loss: 44.9010 Val_Loss: 172.1402  BEST VAL Loss: 172.1402\n",
            "\n",
            "Epoch 786: Validation loss decreased (172.140213 --> 171.565536).\n",
            "\t Train_Loss: 44.7609 Val_Loss: 171.5655  BEST VAL Loss: 171.5655\n",
            "\n",
            "Epoch 787: Validation loss decreased (171.565536 --> 171.228363).\n",
            "\t Train_Loss: 44.6277 Val_Loss: 171.2284  BEST VAL Loss: 171.2284\n",
            "\n",
            "Epoch 788: Validation loss decreased (171.228363 --> 170.854538).\n",
            "\t Train_Loss: 44.4925 Val_Loss: 170.8545  BEST VAL Loss: 170.8545\n",
            "\n",
            "Epoch 789: Validation loss decreased (170.854538 --> 170.248810).\n",
            "\t Train_Loss: 44.3622 Val_Loss: 170.2488  BEST VAL Loss: 170.2488\n",
            "\n",
            "Epoch 790: Validation loss decreased (170.248810 --> 169.741547).\n",
            "\t Train_Loss: 44.2304 Val_Loss: 169.7415  BEST VAL Loss: 169.7415\n",
            "\n",
            "Epoch 791: Validation loss decreased (169.741547 --> 169.396759).\n",
            "\t Train_Loss: 44.1019 Val_Loss: 169.3968  BEST VAL Loss: 169.3968\n",
            "\n",
            "Epoch 792: Validation loss decreased (169.396759 --> 168.961182).\n",
            "\t Train_Loss: 43.9734 Val_Loss: 168.9612  BEST VAL Loss: 168.9612\n",
            "\n",
            "Epoch 793: Validation loss decreased (168.961182 --> 168.399445).\n",
            "\t Train_Loss: 43.8475 Val_Loss: 168.3994  BEST VAL Loss: 168.3994\n",
            "\n",
            "Epoch 794: Validation loss decreased (168.399445 --> 167.940323).\n",
            "\t Train_Loss: 43.7224 Val_Loss: 167.9403  BEST VAL Loss: 167.9403\n",
            "\n",
            "Epoch 795: Validation loss decreased (167.940323 --> 167.581818).\n",
            "\t Train_Loss: 43.5995 Val_Loss: 167.5818  BEST VAL Loss: 167.5818\n",
            "\n",
            "Epoch 796: Validation loss decreased (167.581818 --> 167.138992).\n",
            "\t Train_Loss: 43.4776 Val_Loss: 167.1390  BEST VAL Loss: 167.1390\n",
            "\n",
            "Epoch 797: Validation loss decreased (167.138992 --> 166.604889).\n",
            "\t Train_Loss: 43.3575 Val_Loss: 166.6049  BEST VAL Loss: 166.6049\n",
            "\n",
            "Epoch 798: Validation loss decreased (166.604889 --> 166.145523).\n",
            "\t Train_Loss: 43.2384 Val_Loss: 166.1455  BEST VAL Loss: 166.1455\n",
            "\n",
            "Epoch 799: Validation loss decreased (166.145523 --> 165.776093).\n",
            "\t Train_Loss: 43.1207 Val_Loss: 165.7761  BEST VAL Loss: 165.7761\n",
            "\n",
            "Epoch 800: Validation loss decreased (165.776093 --> 165.364502).\n",
            "\t Train_Loss: 43.0036 Val_Loss: 165.3645  BEST VAL Loss: 165.3645\n",
            "\n",
            "Epoch 801: Validation loss decreased (165.364502 --> 164.886688).\n",
            "\t Train_Loss: 42.8878 Val_Loss: 164.8867  BEST VAL Loss: 164.8867\n",
            "\n",
            "Epoch 802: Validation loss decreased (164.886688 --> 164.465271).\n",
            "\t Train_Loss: 42.7725 Val_Loss: 164.4653  BEST VAL Loss: 164.4653\n",
            "\n",
            "Epoch 803: Validation loss decreased (164.465271 --> 164.122223).\n",
            "\t Train_Loss: 42.6583 Val_Loss: 164.1222  BEST VAL Loss: 164.1222\n",
            "\n",
            "Epoch 804: Validation loss decreased (164.122223 --> 163.751038).\n",
            "\t Train_Loss: 42.5446 Val_Loss: 163.7510  BEST VAL Loss: 163.7510\n",
            "\n",
            "Epoch 805: Validation loss decreased (163.751038 --> 163.304993).\n",
            "\t Train_Loss: 42.4320 Val_Loss: 163.3050  BEST VAL Loss: 163.3050\n",
            "\n",
            "Epoch 806: Validation loss decreased (163.304993 --> 162.880905).\n",
            "\t Train_Loss: 42.3199 Val_Loss: 162.8809  BEST VAL Loss: 162.8809\n",
            "\n",
            "Epoch 807: Validation loss decreased (162.880905 --> 162.524872).\n",
            "\t Train_Loss: 42.2089 Val_Loss: 162.5249  BEST VAL Loss: 162.5249\n",
            "\n",
            "Epoch 808: Validation loss decreased (162.524872 --> 162.159622).\n",
            "\t Train_Loss: 42.0983 Val_Loss: 162.1596  BEST VAL Loss: 162.1596\n",
            "\n",
            "Epoch 809: Validation loss decreased (162.159622 --> 161.732269).\n",
            "\t Train_Loss: 41.9887 Val_Loss: 161.7323  BEST VAL Loss: 161.7323\n",
            "\n",
            "Epoch 810: Validation loss decreased (161.732269 --> 161.321304).\n",
            "\t Train_Loss: 41.8796 Val_Loss: 161.3213  BEST VAL Loss: 161.3213\n",
            "\n",
            "Epoch 811: Validation loss decreased (161.321304 --> 160.974976).\n",
            "\t Train_Loss: 41.7714 Val_Loss: 160.9750  BEST VAL Loss: 160.9750\n",
            "\n",
            "Epoch 812: Validation loss decreased (160.974976 --> 160.623749).\n",
            "\t Train_Loss: 41.6637 Val_Loss: 160.6237  BEST VAL Loss: 160.6237\n",
            "\n",
            "Epoch 813: Validation loss decreased (160.623749 --> 160.213196).\n",
            "\t Train_Loss: 41.5569 Val_Loss: 160.2132  BEST VAL Loss: 160.2132\n",
            "\n",
            "Epoch 814: Validation loss decreased (160.213196 --> 159.812988).\n",
            "\t Train_Loss: 41.4505 Val_Loss: 159.8130  BEST VAL Loss: 159.8130\n",
            "\n",
            "Epoch 815: Validation loss decreased (159.812988 --> 159.471130).\n",
            "\t Train_Loss: 41.3451 Val_Loss: 159.4711  BEST VAL Loss: 159.4711\n",
            "\n",
            "Epoch 816: Validation loss decreased (159.471130 --> 159.126801).\n",
            "\t Train_Loss: 41.2402 Val_Loss: 159.1268  BEST VAL Loss: 159.1268\n",
            "\n",
            "Epoch 817: Validation loss decreased (159.126801 --> 158.736450).\n",
            "\t Train_Loss: 41.1362 Val_Loss: 158.7365  BEST VAL Loss: 158.7365\n",
            "\n",
            "Epoch 818: Validation loss decreased (158.736450 --> 158.362976).\n",
            "\t Train_Loss: 41.0328 Val_Loss: 158.3630  BEST VAL Loss: 158.3630\n",
            "\n",
            "Epoch 819: Validation loss decreased (158.362976 --> 158.040268).\n",
            "\t Train_Loss: 40.9302 Val_Loss: 158.0403  BEST VAL Loss: 158.0403\n",
            "\n",
            "Epoch 820: Validation loss decreased (158.040268 --> 157.706711).\n",
            "\t Train_Loss: 40.8281 Val_Loss: 157.7067  BEST VAL Loss: 157.7067\n",
            "\n",
            "Epoch 821: Validation loss decreased (157.706711 --> 157.331131).\n",
            "\t Train_Loss: 40.7267 Val_Loss: 157.3311  BEST VAL Loss: 157.3311\n",
            "\n",
            "Epoch 822: Validation loss decreased (157.331131 --> 156.974930).\n",
            "\t Train_Loss: 40.6256 Val_Loss: 156.9749  BEST VAL Loss: 156.9749\n",
            "\n",
            "Epoch 823: Validation loss decreased (156.974930 --> 156.662781).\n",
            "\t Train_Loss: 40.5252 Val_Loss: 156.6628  BEST VAL Loss: 156.6628\n",
            "\n",
            "Epoch 824: Validation loss decreased (156.662781 --> 156.338669).\n",
            "\t Train_Loss: 40.4251 Val_Loss: 156.3387  BEST VAL Loss: 156.3387\n",
            "\n",
            "Epoch 825: Validation loss decreased (156.338669 --> 155.985718).\n",
            "\t Train_Loss: 40.3254 Val_Loss: 155.9857  BEST VAL Loss: 155.9857\n",
            "\n",
            "Epoch 826: Validation loss decreased (155.985718 --> 155.658524).\n",
            "\t Train_Loss: 40.2262 Val_Loss: 155.6585  BEST VAL Loss: 155.6585\n",
            "\n",
            "Epoch 827: Validation loss decreased (155.658524 --> 155.366241).\n",
            "\t Train_Loss: 40.1273 Val_Loss: 155.3662  BEST VAL Loss: 155.3662\n",
            "\n",
            "Epoch 828: Validation loss decreased (155.366241 --> 155.054565).\n",
            "\t Train_Loss: 40.0288 Val_Loss: 155.0546  BEST VAL Loss: 155.0546\n",
            "\n",
            "Epoch 829: Validation loss decreased (155.054565 --> 154.718796).\n",
            "\t Train_Loss: 39.9306 Val_Loss: 154.7188  BEST VAL Loss: 154.7188\n",
            "\n",
            "Epoch 830: Validation loss decreased (154.718796 --> 154.409912).\n",
            "\t Train_Loss: 39.8327 Val_Loss: 154.4099  BEST VAL Loss: 154.4099\n",
            "\n",
            "Epoch 831: Validation loss decreased (154.409912 --> 154.125565).\n",
            "\t Train_Loss: 39.7351 Val_Loss: 154.1256  BEST VAL Loss: 154.1256\n",
            "\n",
            "Epoch 832: Validation loss decreased (154.125565 --> 153.817993).\n",
            "\t Train_Loss: 39.6377 Val_Loss: 153.8180  BEST VAL Loss: 153.8180\n",
            "\n",
            "Epoch 833: Validation loss decreased (153.817993 --> 153.498047).\n",
            "\t Train_Loss: 39.5405 Val_Loss: 153.4980  BEST VAL Loss: 153.4980\n",
            "\n",
            "Epoch 834: Validation loss decreased (153.498047 --> 153.209320).\n",
            "\t Train_Loss: 39.4434 Val_Loss: 153.2093  BEST VAL Loss: 153.2093\n",
            "\n",
            "Epoch 835: Validation loss decreased (153.209320 --> 152.927536).\n",
            "\t Train_Loss: 39.3466 Val_Loss: 152.9275  BEST VAL Loss: 152.9275\n",
            "\n",
            "Epoch 836: Validation loss decreased (152.927536 --> 152.616165).\n",
            "\t Train_Loss: 39.2499 Val_Loss: 152.6162  BEST VAL Loss: 152.6162\n",
            "\n",
            "Epoch 837: Validation loss decreased (152.616165 --> 152.312683).\n",
            "\t Train_Loss: 39.1534 Val_Loss: 152.3127  BEST VAL Loss: 152.3127\n",
            "\n",
            "Epoch 838: Validation loss decreased (152.312683 --> 152.035812).\n",
            "\t Train_Loss: 39.0570 Val_Loss: 152.0358  BEST VAL Loss: 152.0358\n",
            "\n",
            "Epoch 839: Validation loss decreased (152.035812 --> 151.739120).\n",
            "\t Train_Loss: 38.9608 Val_Loss: 151.7391  BEST VAL Loss: 151.7391\n",
            "\n",
            "Epoch 840: Validation loss decreased (151.739120 --> 151.444458).\n",
            "\t Train_Loss: 38.8646 Val_Loss: 151.4445  BEST VAL Loss: 151.4445\n",
            "\n",
            "Epoch 841: Validation loss decreased (151.444458 --> 151.312469).\n",
            "\t Train_Loss: 38.7680 Val_Loss: 151.3125  BEST VAL Loss: 151.3125\n",
            "\n",
            "Epoch 842: Validation loss decreased (151.312469 --> 150.809296).\n",
            "\t Train_Loss: 38.6749 Val_Loss: 150.8093  BEST VAL Loss: 150.8093\n",
            "\n",
            "Epoch 843: Validation loss decreased (150.809296 --> 150.376740).\n",
            "\t Train_Loss: 38.5771 Val_Loss: 150.3767  BEST VAL Loss: 150.3767\n",
            "\n",
            "Epoch 844: Validation loss decreased (150.376740 --> 150.182693).\n",
            "\t Train_Loss: 38.4841 Val_Loss: 150.1827  BEST VAL Loss: 150.1827\n",
            "\n",
            "Epoch 845: Validation loss decreased (150.182693 --> 149.974533).\n",
            "\t Train_Loss: 38.3887 Val_Loss: 149.9745  BEST VAL Loss: 149.9745\n",
            "\n",
            "Epoch 846: Validation loss decreased (149.974533 --> 149.672363).\n",
            "\t Train_Loss: 38.2942 Val_Loss: 149.6724  BEST VAL Loss: 149.6724\n",
            "\n",
            "Epoch 847: Validation loss decreased (149.672363 --> 149.469589).\n",
            "\t Train_Loss: 38.2010 Val_Loss: 149.4696  BEST VAL Loss: 149.4696\n",
            "\n",
            "Epoch 848: Validation loss decreased (149.469589 --> 149.058533).\n",
            "\t Train_Loss: 38.1070 Val_Loss: 149.0585  BEST VAL Loss: 149.0585\n",
            "\n",
            "Epoch 849: Validation loss decreased (149.058533 --> 148.725113).\n",
            "\t Train_Loss: 38.0127 Val_Loss: 148.7251  BEST VAL Loss: 148.7251\n",
            "\n",
            "Epoch 850: Validation loss decreased (148.725113 --> 148.409424).\n",
            "\t Train_Loss: 37.9196 Val_Loss: 148.4094  BEST VAL Loss: 148.4094\n",
            "\n",
            "Epoch 851: Validation loss decreased (148.409424 --> 148.061493).\n",
            "\t Train_Loss: 37.8271 Val_Loss: 148.0615  BEST VAL Loss: 148.0615\n",
            "\n",
            "Epoch 852: Validation loss decreased (148.061493 --> 147.875732).\n",
            "\t Train_Loss: 37.7345 Val_Loss: 147.8757  BEST VAL Loss: 147.8757\n",
            "\n",
            "Epoch 853: Validation loss decreased (147.875732 --> 147.504211).\n",
            "\t Train_Loss: 37.6424 Val_Loss: 147.5042  BEST VAL Loss: 147.5042\n",
            "\n",
            "Epoch 854: Validation loss decreased (147.504211 --> 147.320892).\n",
            "\t Train_Loss: 37.5511 Val_Loss: 147.3209  BEST VAL Loss: 147.3209\n",
            "\n",
            "Epoch 855: Validation loss decreased (147.320892 --> 146.835281).\n",
            "\t Train_Loss: 37.4601 Val_Loss: 146.8353  BEST VAL Loss: 146.8353\n",
            "\n",
            "Epoch 856: Validation loss decreased (146.835281 --> 146.678879).\n",
            "\t Train_Loss: 37.3696 Val_Loss: 146.6789  BEST VAL Loss: 146.6789\n",
            "\n",
            "Epoch 857: Validation loss decreased (146.678879 --> 146.093918).\n",
            "\t Train_Loss: 37.2802 Val_Loss: 146.0939  BEST VAL Loss: 146.0939\n",
            "\n",
            "Epoch 858: Validation loss did not decrease\n",
            "\t Train_Loss: 37.1924 Val_Loss: 146.1194  BEST VAL Loss: 146.0939\n",
            "\n",
            "Epoch 859: Validation loss decreased (146.093918 --> 145.449966).\n",
            "\t Train_Loss: 37.1049 Val_Loss: 145.4500  BEST VAL Loss: 145.4500\n",
            "\n",
            "Epoch 860: Validation loss did not decrease\n",
            "\t Train_Loss: 37.0193 Val_Loss: 145.5728  BEST VAL Loss: 145.4500\n",
            "\n",
            "Epoch 861: Validation loss decreased (145.449966 --> 144.994064).\n",
            "\t Train_Loss: 36.9278 Val_Loss: 144.9941  BEST VAL Loss: 144.9941\n",
            "\n",
            "Epoch 862: Validation loss decreased (144.994064 --> 144.793854).\n",
            "\t Train_Loss: 36.8355 Val_Loss: 144.7939  BEST VAL Loss: 144.7939\n",
            "\n",
            "Epoch 863: Validation loss decreased (144.793854 --> 144.556793).\n",
            "\t Train_Loss: 36.7450 Val_Loss: 144.5568  BEST VAL Loss: 144.5568\n",
            "\n",
            "Epoch 864: Validation loss decreased (144.556793 --> 143.989487).\n",
            "\t Train_Loss: 36.6597 Val_Loss: 143.9895  BEST VAL Loss: 143.9895\n",
            "\n",
            "Epoch 865: Validation loss decreased (143.989487 --> 143.945404).\n",
            "\t Train_Loss: 36.5759 Val_Loss: 143.9454  BEST VAL Loss: 143.9454\n",
            "\n",
            "Epoch 866: Validation loss decreased (143.945404 --> 143.477661).\n",
            "\t Train_Loss: 36.4873 Val_Loss: 143.4777  BEST VAL Loss: 143.4777\n",
            "\n",
            "Epoch 867: Validation loss decreased (143.477661 --> 143.205353).\n",
            "\t Train_Loss: 36.3979 Val_Loss: 143.2054  BEST VAL Loss: 143.2054\n",
            "\n",
            "Epoch 868: Validation loss decreased (143.205353 --> 143.045959).\n",
            "\t Train_Loss: 36.3115 Val_Loss: 143.0460  BEST VAL Loss: 143.0460\n",
            "\n",
            "Epoch 869: Validation loss decreased (143.045959 --> 142.544586).\n",
            "\t Train_Loss: 36.2277 Val_Loss: 142.5446  BEST VAL Loss: 142.5446\n",
            "\n",
            "Epoch 870: Validation loss decreased (142.544586 --> 142.417313).\n",
            "\t Train_Loss: 36.1431 Val_Loss: 142.4173  BEST VAL Loss: 142.4173\n",
            "\n",
            "Epoch 871: Validation loss decreased (142.417313 --> 142.065109).\n",
            "\t Train_Loss: 36.0556 Val_Loss: 142.0651  BEST VAL Loss: 142.0651\n",
            "\n",
            "Epoch 872: Validation loss decreased (142.065109 --> 141.698776).\n",
            "\t Train_Loss: 35.9696 Val_Loss: 141.6988  BEST VAL Loss: 141.6988\n",
            "\n",
            "Epoch 873: Validation loss decreased (141.698776 --> 141.563553).\n",
            "\t Train_Loss: 35.8861 Val_Loss: 141.5636  BEST VAL Loss: 141.5636\n",
            "\n",
            "Epoch 874: Validation loss decreased (141.563553 --> 141.136627).\n",
            "\t Train_Loss: 35.8023 Val_Loss: 141.1366  BEST VAL Loss: 141.1366\n",
            "\n",
            "Epoch 875: Validation loss decreased (141.136627 --> 140.914154).\n",
            "\t Train_Loss: 35.7163 Val_Loss: 140.9142  BEST VAL Loss: 140.9142\n",
            "\n",
            "Epoch 876: Validation loss decreased (140.914154 --> 140.654846).\n",
            "\t Train_Loss: 35.6237 Val_Loss: 140.6548  BEST VAL Loss: 140.6548\n",
            "\n",
            "Epoch 877: Validation loss decreased (140.654846 --> 140.228699).\n",
            "\t Train_Loss: 35.5200 Val_Loss: 140.2287  BEST VAL Loss: 140.2287\n",
            "\n",
            "Epoch 878: Validation loss did not decrease\n",
            "\t Train_Loss: 35.4444 Val_Loss: 140.3192  BEST VAL Loss: 140.2287\n",
            "\n",
            "Epoch 879: Validation loss decreased (140.228699 --> 139.797073).\n",
            "\t Train_Loss: 35.3629 Val_Loss: 139.7971  BEST VAL Loss: 139.7971\n",
            "\n",
            "Epoch 880: Validation loss decreased (139.797073 --> 139.706131).\n",
            "\t Train_Loss: 35.2823 Val_Loss: 139.7061  BEST VAL Loss: 139.7061\n",
            "\n",
            "Epoch 881: Validation loss decreased (139.706131 --> 139.404129).\n",
            "\t Train_Loss: 35.1965 Val_Loss: 139.4041  BEST VAL Loss: 139.4041\n",
            "\n",
            "Epoch 882: Validation loss decreased (139.404129 --> 138.735275).\n",
            "\t Train_Loss: 35.1113 Val_Loss: 138.7353  BEST VAL Loss: 138.7353\n",
            "\n",
            "Epoch 883: Validation loss decreased (138.735275 --> 138.654388).\n",
            "\t Train_Loss: 35.0083 Val_Loss: 138.6544  BEST VAL Loss: 138.6544\n",
            "\n",
            "Epoch 884: Validation loss decreased (138.654388 --> 138.515045).\n",
            "\t Train_Loss: 34.9800 Val_Loss: 138.5150  BEST VAL Loss: 138.5150\n",
            "\n",
            "Epoch 885: Validation loss did not decrease\n",
            "\t Train_Loss: 34.8267 Val_Loss: 138.5344  BEST VAL Loss: 138.5150\n",
            "\n",
            "Epoch 886: Validation loss decreased (138.515045 --> 138.149750).\n",
            "\t Train_Loss: 34.7877 Val_Loss: 138.1497  BEST VAL Loss: 138.1497\n",
            "\n",
            "Epoch 887: Validation loss decreased (138.149750 --> 137.510345).\n",
            "\t Train_Loss: 34.7119 Val_Loss: 137.5103  BEST VAL Loss: 137.5103\n",
            "\n",
            "Epoch 888: Validation loss decreased (137.510345 --> 137.147293).\n",
            "\t Train_Loss: 34.6275 Val_Loss: 137.1473  BEST VAL Loss: 137.1473\n",
            "\n",
            "Epoch 889: Validation loss decreased (137.147293 --> 136.851868).\n",
            "\t Train_Loss: 34.5455 Val_Loss: 136.8519  BEST VAL Loss: 136.8519\n",
            "\n",
            "Epoch 890: Validation loss decreased (136.851868 --> 136.671234).\n",
            "\t Train_Loss: 34.4464 Val_Loss: 136.6712  BEST VAL Loss: 136.6712\n",
            "\n",
            "Epoch 891: Validation loss did not decrease\n",
            "\t Train_Loss: 34.3105 Val_Loss: 136.7983  BEST VAL Loss: 136.6712\n",
            "\n",
            "Epoch 892: Validation loss did not decrease\n",
            "\t Train_Loss: 34.1466 Val_Loss: 136.8560  BEST VAL Loss: 136.6712\n",
            "\n",
            "Epoch 893: Validation loss did not decrease\n",
            "\t Train_Loss: 34.1068 Val_Loss: 137.1344  BEST VAL Loss: 136.6712\n",
            "\n",
            "Epoch 894: Validation loss did not decrease\n",
            "\t Train_Loss: 33.9364 Val_Loss: 136.9898  BEST VAL Loss: 136.6712\n",
            "\n",
            "Epoch 895: Validation loss decreased (136.671234 --> 136.404388).\n",
            "\t Train_Loss: 33.8451 Val_Loss: 136.4044  BEST VAL Loss: 136.4044\n",
            "\n",
            "Epoch 896: Validation loss decreased (136.404388 --> 135.804199).\n",
            "\t Train_Loss: 33.6781 Val_Loss: 135.8042  BEST VAL Loss: 135.8042\n",
            "\n",
            "Epoch 897: Validation loss decreased (135.804199 --> 135.506104).\n",
            "\t Train_Loss: 33.6253 Val_Loss: 135.5061  BEST VAL Loss: 135.5061\n",
            "\n",
            "Epoch 898: Validation loss did not decrease\n",
            "\t Train_Loss: 33.5100 Val_Loss: 135.7432  BEST VAL Loss: 135.5061\n",
            "\n",
            "Epoch 899: Validation loss did not decrease\n",
            "\t Train_Loss: 33.4114 Val_Loss: 135.6548  BEST VAL Loss: 135.5061\n",
            "\n",
            "Epoch 900: Validation loss decreased (135.506104 --> 135.400162).\n",
            "\t Train_Loss: 33.2639 Val_Loss: 135.4002  BEST VAL Loss: 135.4002\n",
            "\n",
            "Epoch 901: Validation loss decreased (135.400162 --> 135.090942).\n",
            "\t Train_Loss: 33.2188 Val_Loss: 135.0909  BEST VAL Loss: 135.0909\n",
            "\n",
            "Epoch 902: Validation loss did not decrease\n",
            "\t Train_Loss: 33.0949 Val_Loss: 135.1187  BEST VAL Loss: 135.0909\n",
            "\n",
            "Epoch 903: Validation loss decreased (135.090942 --> 134.170654).\n",
            "\t Train_Loss: 33.0316 Val_Loss: 134.1707  BEST VAL Loss: 134.1707\n",
            "\n",
            "Epoch 904: Validation loss decreased (134.170654 --> 133.752045).\n",
            "\t Train_Loss: 32.8743 Val_Loss: 133.7520  BEST VAL Loss: 133.7520\n",
            "\n",
            "Epoch 905: Validation loss did not decrease\n",
            "\t Train_Loss: 32.7935 Val_Loss: 133.8957  BEST VAL Loss: 133.7520\n",
            "\n",
            "Epoch 906: Validation loss decreased (133.752045 --> 133.644333).\n",
            "\t Train_Loss: 32.6607 Val_Loss: 133.6443  BEST VAL Loss: 133.6443\n",
            "\n",
            "Epoch 907: Validation loss did not decrease\n",
            "\t Train_Loss: 32.5933 Val_Loss: 133.6852  BEST VAL Loss: 133.6443\n",
            "\n",
            "Epoch 908: Validation loss decreased (133.644333 --> 133.190155).\n",
            "\t Train_Loss: 32.4535 Val_Loss: 133.1902  BEST VAL Loss: 133.1902\n",
            "\n",
            "Epoch 909: Validation loss decreased (133.190155 --> 133.117081).\n",
            "\t Train_Loss: 32.3457 Val_Loss: 133.1171  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 910: Validation loss did not decrease\n",
            "\t Train_Loss: 32.4629 Val_Loss: 189.6872  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 911: Validation loss did not decrease\n",
            "\t Train_Loss: 51.1744 Val_Loss: 153.2354  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 912: Validation loss did not decrease\n",
            "\t Train_Loss: 39.1285 Val_Loss: 157.9647  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 913: Validation loss did not decrease\n",
            "\t Train_Loss: 41.4291 Val_Loss: 158.3462  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 914: Validation loss did not decrease\n",
            "\t Train_Loss: 41.4414 Val_Loss: 159.6176  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 915: Validation loss did not decrease\n",
            "\t Train_Loss: 40.5913 Val_Loss: 162.1235  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 916: Validation loss did not decrease\n",
            "\t Train_Loss: 40.2312 Val_Loss: 163.7437  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 917: Validation loss did not decrease\n",
            "\t Train_Loss: 40.4271 Val_Loss: 163.4124  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 918: Validation loss did not decrease\n",
            "\t Train_Loss: 40.5168 Val_Loss: 161.3271  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 919: Validation loss did not decrease\n",
            "\t Train_Loss: 40.0908 Val_Loss: 158.7229  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 920: Validation loss did not decrease\n",
            "\t Train_Loss: 39.4184 Val_Loss: 157.4906  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 921: Validation loss did not decrease\n",
            "\t Train_Loss: 39.5194 Val_Loss: 156.9937  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 922: Validation loss did not decrease\n",
            "\t Train_Loss: 39.8173 Val_Loss: 156.4134  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 923: Validation loss did not decrease\n",
            "\t Train_Loss: 39.3458 Val_Loss: 169.2274  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 924: Validation loss did not decrease\n",
            "\t Train_Loss: 41.6397 Val_Loss: 156.6368  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 925: Validation loss did not decrease\n",
            "\t Train_Loss: 38.8161 Val_Loss: 157.1779  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 926: Validation loss did not decrease\n",
            "\t Train_Loss: 38.7821 Val_Loss: 157.6424  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 927: Validation loss did not decrease\n",
            "\t Train_Loss: 38.6274 Val_Loss: 157.6383  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 928: Validation loss did not decrease\n",
            "\t Train_Loss: 38.4185 Val_Loss: 157.0482  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 929: Validation loss did not decrease\n",
            "\t Train_Loss: 38.2224 Val_Loss: 156.1869  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 930: Validation loss did not decrease\n",
            "\t Train_Loss: 38.0614 Val_Loss: 155.2928  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 931: Validation loss did not decrease\n",
            "\t Train_Loss: 38.1813 Val_Loss: 154.3342  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 932: Validation loss did not decrease\n",
            "\t Train_Loss: 37.8185 Val_Loss: 153.6821  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 933: Validation loss did not decrease\n",
            "\t Train_Loss: 37.7446 Val_Loss: 153.4926  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 934: Validation loss did not decrease\n",
            "\t Train_Loss: 37.4814 Val_Loss: 153.8329  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 935: Validation loss did not decrease\n",
            "\t Train_Loss: 37.3532 Val_Loss: 153.8399  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 936: Validation loss did not decrease\n",
            "\t Train_Loss: 37.3570 Val_Loss: 152.7733  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 937: Validation loss did not decrease\n",
            "\t Train_Loss: 37.0136 Val_Loss: 151.7669  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 938: Validation loss did not decrease\n",
            "\t Train_Loss: 36.8689 Val_Loss: 151.3618  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 939: Validation loss did not decrease\n",
            "\t Train_Loss: 36.6236 Val_Loss: 151.4149  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 940: Validation loss did not decrease\n",
            "\t Train_Loss: 36.4044 Val_Loss: 151.2445  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 941: Validation loss did not decrease\n",
            "\t Train_Loss: 36.0291 Val_Loss: 151.0769  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 942: Validation loss did not decrease\n",
            "\t Train_Loss: 35.7658 Val_Loss: 151.0590  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 943: Validation loss did not decrease\n",
            "\t Train_Loss: 35.6703 Val_Loss: 150.1987  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 944: Validation loss did not decrease\n",
            "\t Train_Loss: 35.5412 Val_Loss: 149.8102  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 945: Validation loss did not decrease\n",
            "\t Train_Loss: 35.0267 Val_Loss: 150.1463  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 946: Validation loss did not decrease\n",
            "\t Train_Loss: 35.2641 Val_Loss: 148.6126  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 947: Validation loss did not decrease\n",
            "\t Train_Loss: 34.5796 Val_Loss: 147.9953  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 948: Validation loss did not decrease\n",
            "\t Train_Loss: 34.5928 Val_Loss: 147.9487  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 949: Validation loss did not decrease\n",
            "\t Train_Loss: 34.0355 Val_Loss: 148.1144  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 950: Validation loss did not decrease\n",
            "\t Train_Loss: 34.1996 Val_Loss: 146.5296  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 951: Validation loss did not decrease\n",
            "\t Train_Loss: 33.7685 Val_Loss: 146.0033  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 952: Validation loss did not decrease\n",
            "\t Train_Loss: 33.8787 Val_Loss: 145.7428  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 953: Validation loss did not decrease\n",
            "\t Train_Loss: 33.1906 Val_Loss: 146.9862  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 954: Validation loss did not decrease\n",
            "\t Train_Loss: 34.0913 Val_Loss: 144.6809  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 955: Validation loss did not decrease\n",
            "\t Train_Loss: 33.1653 Val_Loss: 144.5018  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 956: Validation loss did not decrease\n",
            "\t Train_Loss: 34.0227 Val_Loss: 144.3205  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 957: Validation loss did not decrease\n",
            "\t Train_Loss: 32.7958 Val_Loss: 144.9248  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 958: Validation loss did not decrease\n",
            "\t Train_Loss: 32.6095 Val_Loss: 144.9941  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 959: Validation loss did not decrease\n",
            "\t Train_Loss: 32.9842 Val_Loss: 142.6239  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 960: Validation loss did not decrease\n",
            "\t Train_Loss: 32.0804 Val_Loss: 141.4488  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 961: Validation loss did not decrease\n",
            "\t Train_Loss: 32.2894 Val_Loss: 140.8780  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 962: Validation loss did not decrease\n",
            "\t Train_Loss: 32.2522 Val_Loss: 140.7912  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 963: Validation loss did not decrease\n",
            "\t Train_Loss: 31.6886 Val_Loss: 141.5694  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 964: Validation loss did not decrease\n",
            "\t Train_Loss: 31.4803 Val_Loss: 141.7138  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 965: Validation loss did not decrease\n",
            "\t Train_Loss: 31.4893 Val_Loss: 140.4356  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 966: Validation loss did not decrease\n",
            "\t Train_Loss: 31.0849 Val_Loss: 139.8665  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 967: Validation loss did not decrease\n",
            "\t Train_Loss: 31.1531 Val_Loss: 139.3837  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 968: Validation loss did not decrease\n",
            "\t Train_Loss: 30.6864 Val_Loss: 140.3007  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 969: Validation loss did not decrease\n",
            "\t Train_Loss: 30.9638 Val_Loss: 138.2777  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 970: Validation loss did not decrease\n",
            "\t Train_Loss: 30.2366 Val_Loss: 137.7765  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 971: Validation loss did not decrease\n",
            "\t Train_Loss: 30.1078 Val_Loss: 139.3266  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 972: Validation loss did not decrease\n",
            "\t Train_Loss: 29.9606 Val_Loss: 136.9080  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 973: Validation loss did not decrease\n",
            "\t Train_Loss: 29.6045 Val_Loss: 136.5533  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 974: Validation loss did not decrease\n",
            "\t Train_Loss: 29.2656 Val_Loss: 137.7677  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 975: Validation loss did not decrease\n",
            "\t Train_Loss: 29.4166 Val_Loss: 138.7149  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 976: Validation loss did not decrease\n",
            "\t Train_Loss: 29.3020 Val_Loss: 135.4903  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 977: Validation loss did not decrease\n",
            "\t Train_Loss: 28.5314 Val_Loss: 135.7016  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 978: Validation loss did not decrease\n",
            "\t Train_Loss: 29.4024 Val_Loss: 133.5788  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 979: Validation loss did not decrease\n",
            "\t Train_Loss: 29.0931 Val_Loss: 133.8227  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 980: Validation loss did not decrease\n",
            "\t Train_Loss: 28.1863 Val_Loss: 139.5574  BEST VAL Loss: 133.1171\n",
            "\n",
            "Epoch 981: Validation loss decreased (133.117081 --> 132.888519).\n",
            "\t Train_Loss: 30.6179 Val_Loss: 132.8885  BEST VAL Loss: 132.8885\n",
            "\n",
            "Epoch 982: Validation loss decreased (132.888519 --> 132.445221).\n",
            "\t Train_Loss: 29.2263 Val_Loss: 132.4452  BEST VAL Loss: 132.4452\n",
            "\n",
            "Epoch 983: Validation loss decreased (132.445221 --> 132.330109).\n",
            "\t Train_Loss: 29.9580 Val_Loss: 132.3301  BEST VAL Loss: 132.3301\n",
            "\n",
            "Epoch 984: Validation loss did not decrease\n",
            "\t Train_Loss: 28.6114 Val_Loss: 133.7748  BEST VAL Loss: 132.3301\n",
            "\n",
            "Epoch 985: Validation loss did not decrease\n",
            "\t Train_Loss: 28.7893 Val_Loss: 134.0618  BEST VAL Loss: 132.3301\n",
            "\n",
            "Epoch 986: Validation loss decreased (132.330109 --> 132.181000).\n",
            "\t Train_Loss: 29.1721 Val_Loss: 132.1810  BEST VAL Loss: 132.1810\n",
            "\n",
            "Epoch 987: Validation loss decreased (132.181000 --> 131.403427).\n",
            "\t Train_Loss: 27.7737 Val_Loss: 131.4034  BEST VAL Loss: 131.4034\n",
            "\n",
            "Epoch 988: Validation loss decreased (131.403427 --> 130.695053).\n",
            "\t Train_Loss: 28.5843 Val_Loss: 130.6951  BEST VAL Loss: 130.6951\n",
            "\n",
            "Epoch 989: Validation loss decreased (130.695053 --> 130.228165).\n",
            "\t Train_Loss: 28.2877 Val_Loss: 130.2282  BEST VAL Loss: 130.2282\n",
            "\n",
            "Epoch 990: Validation loss did not decrease\n",
            "\t Train_Loss: 27.2287 Val_Loss: 130.7159  BEST VAL Loss: 130.2282\n",
            "\n",
            "Epoch 991: Validation loss decreased (130.228165 --> 129.340683).\n",
            "\t Train_Loss: 28.3719 Val_Loss: 129.3407  BEST VAL Loss: 129.3407\n",
            "\n",
            "Epoch 992: Validation loss decreased (129.340683 --> 129.194382).\n",
            "\t Train_Loss: 26.8015 Val_Loss: 129.1944  BEST VAL Loss: 129.1944\n",
            "\n",
            "Epoch 993: Validation loss decreased (129.194382 --> 128.962479).\n",
            "\t Train_Loss: 27.4658 Val_Loss: 128.9625  BEST VAL Loss: 128.9625\n",
            "\n",
            "Epoch 994: Validation loss did not decrease\n",
            "\t Train_Loss: 26.6707 Val_Loss: 130.3482  BEST VAL Loss: 128.9625\n",
            "\n",
            "Epoch 995: Validation loss did not decrease\n",
            "\t Train_Loss: 26.7832 Val_Loss: 142.8925  BEST VAL Loss: 128.9625\n",
            "\n",
            "Epoch 996: Validation loss decreased (128.962479 --> 128.221405).\n",
            "\t Train_Loss: 28.5808 Val_Loss: 128.2214  BEST VAL Loss: 128.2214\n",
            "\n",
            "Epoch 997: Validation loss decreased (128.221405 --> 126.350487).\n",
            "\t Train_Loss: 28.6621 Val_Loss: 126.3505  BEST VAL Loss: 126.3505\n",
            "\n",
            "Epoch 998: Validation loss decreased (126.350487 --> 125.947754).\n",
            "\t Train_Loss: 28.3861 Val_Loss: 125.9478  BEST VAL Loss: 125.9478\n",
            "\n",
            "Epoch 999: Validation loss did not decrease\n",
            "\t Train_Loss: 26.0878 Val_Loss: 128.3348  BEST VAL Loss: 125.9478\n",
            "\n",
            "Epoch 1000: Validation loss decreased (125.947754 --> 125.905457).\n",
            "\t Train_Loss: 28.1692 Val_Loss: 125.9055  BEST VAL Loss: 125.9055\n",
            "\n",
            "Epoch 1001: Validation loss did not decrease\n",
            "\t Train_Loss: 25.6281 Val_Loss: 126.7391  BEST VAL Loss: 125.9055\n",
            "\n",
            "Epoch 1002: Validation loss did not decrease\n",
            "\t Train_Loss: 27.2971 Val_Loss: 127.8369  BEST VAL Loss: 125.9055\n",
            "\n",
            "Epoch 1003: Validation loss did not decrease\n",
            "\t Train_Loss: 26.3117 Val_Loss: 126.6009  BEST VAL Loss: 125.9055\n",
            "\n",
            "Epoch 1004: Validation loss did not decrease\n",
            "\t Train_Loss: 25.7844 Val_Loss: 126.7250  BEST VAL Loss: 125.9055\n",
            "\n",
            "Epoch 1005: Validation loss decreased (125.905457 --> 123.990463).\n",
            "\t Train_Loss: 26.7964 Val_Loss: 123.9905  BEST VAL Loss: 123.9905\n",
            "\n",
            "Epoch 1006: Validation loss decreased (123.990463 --> 123.450111).\n",
            "\t Train_Loss: 24.9591 Val_Loss: 123.4501  BEST VAL Loss: 123.4501\n",
            "\n",
            "Epoch 1007: Validation loss decreased (123.450111 --> 122.947266).\n",
            "\t Train_Loss: 25.9451 Val_Loss: 122.9473  BEST VAL Loss: 122.9473\n",
            "\n",
            "Epoch 1008: Validation loss decreased (122.947266 --> 122.467224).\n",
            "\t Train_Loss: 25.3040 Val_Loss: 122.4672  BEST VAL Loss: 122.4672\n",
            "\n",
            "Epoch 1009: Validation loss did not decrease\n",
            "\t Train_Loss: 24.8209 Val_Loss: 122.6783  BEST VAL Loss: 122.4672\n",
            "\n",
            "Epoch 1010: Validation loss decreased (122.467224 --> 122.082314).\n",
            "\t Train_Loss: 25.2714 Val_Loss: 122.0823  BEST VAL Loss: 122.0823\n",
            "\n",
            "Epoch 1011: Validation loss did not decrease\n",
            "\t Train_Loss: 24.1304 Val_Loss: 122.0847  BEST VAL Loss: 122.0823\n",
            "\n",
            "Epoch 1012: Validation loss decreased (122.082314 --> 121.672646).\n",
            "\t Train_Loss: 24.8565 Val_Loss: 121.6726  BEST VAL Loss: 121.6726\n",
            "\n",
            "Epoch 1013: Validation loss did not decrease\n",
            "\t Train_Loss: 23.8826 Val_Loss: 122.6637  BEST VAL Loss: 121.6726\n",
            "\n",
            "Epoch 1014: Validation loss decreased (121.672646 --> 121.393272).\n",
            "\t Train_Loss: 24.0275 Val_Loss: 121.3933  BEST VAL Loss: 121.3933\n",
            "\n",
            "Epoch 1015: Validation loss decreased (121.393272 --> 119.802368).\n",
            "\t Train_Loss: 23.7713 Val_Loss: 119.8024  BEST VAL Loss: 119.8024\n",
            "\n",
            "Epoch 1016: Validation loss decreased (119.802368 --> 119.092651).\n",
            "\t Train_Loss: 23.4920 Val_Loss: 119.0927  BEST VAL Loss: 119.0927\n",
            "\n",
            "Epoch 1017: Validation loss decreased (119.092651 --> 118.995262).\n",
            "\t Train_Loss: 23.6026 Val_Loss: 118.9953  BEST VAL Loss: 118.9953\n",
            "\n",
            "Epoch 1018: Validation loss did not decrease\n",
            "\t Train_Loss: 22.9571 Val_Loss: 120.7315  BEST VAL Loss: 118.9953\n",
            "\n",
            "Epoch 1019: Validation loss decreased (118.995262 --> 118.458397).\n",
            "\t Train_Loss: 23.1809 Val_Loss: 118.4584  BEST VAL Loss: 118.4584\n",
            "\n",
            "Epoch 1020: Validation loss decreased (118.458397 --> 118.124123).\n",
            "\t Train_Loss: 22.6119 Val_Loss: 118.1241  BEST VAL Loss: 118.1241\n",
            "\n",
            "Epoch 1021: Validation loss did not decrease\n",
            "\t Train_Loss: 22.7136 Val_Loss: 121.4148  BEST VAL Loss: 118.1241\n",
            "\n",
            "Epoch 1022: Validation loss decreased (118.124123 --> 115.136497).\n",
            "\t Train_Loss: 22.5841 Val_Loss: 115.1365  BEST VAL Loss: 115.1365\n",
            "\n",
            "Epoch 1023: Validation loss decreased (115.136497 --> 113.806198).\n",
            "\t Train_Loss: 22.1732 Val_Loss: 113.8062  BEST VAL Loss: 113.8062\n",
            "\n",
            "Epoch 1024: Validation loss did not decrease\n",
            "\t Train_Loss: 22.4441 Val_Loss: 113.8325  BEST VAL Loss: 113.8062\n",
            "\n",
            "Epoch 1025: Validation loss did not decrease\n",
            "\t Train_Loss: 22.0624 Val_Loss: 115.0529  BEST VAL Loss: 113.8062\n",
            "\n",
            "Epoch 1026: Validation loss did not decrease\n",
            "\t Train_Loss: 21.5803 Val_Loss: 117.3156  BEST VAL Loss: 113.8062\n",
            "\n",
            "Epoch 1027: Validation loss did not decrease\n",
            "\t Train_Loss: 21.5383 Val_Loss: 117.1508  BEST VAL Loss: 113.8062\n",
            "\n",
            "Epoch 1028: Validation loss did not decrease\n",
            "\t Train_Loss: 21.5238 Val_Loss: 114.9288  BEST VAL Loss: 113.8062\n",
            "\n",
            "Epoch 1029: Validation loss decreased (113.806198 --> 113.352501).\n",
            "\t Train_Loss: 21.2027 Val_Loss: 113.3525  BEST VAL Loss: 113.3525\n",
            "\n",
            "Epoch 1030: Validation loss decreased (113.352501 --> 111.942833).\n",
            "\t Train_Loss: 20.9988 Val_Loss: 111.9428  BEST VAL Loss: 111.9428\n",
            "\n",
            "Epoch 1031: Validation loss decreased (111.942833 --> 111.247818).\n",
            "\t Train_Loss: 20.8413 Val_Loss: 111.2478  BEST VAL Loss: 111.2478\n",
            "\n",
            "Epoch 1032: Validation loss did not decrease\n",
            "\t Train_Loss: 20.7018 Val_Loss: 111.9716  BEST VAL Loss: 111.2478\n",
            "\n",
            "Epoch 1033: Validation loss did not decrease\n",
            "\t Train_Loss: 20.4344 Val_Loss: 112.9635  BEST VAL Loss: 111.2478\n",
            "\n",
            "Epoch 1034: Validation loss decreased (111.247818 --> 110.498245).\n",
            "\t Train_Loss: 20.4495 Val_Loss: 110.4982  BEST VAL Loss: 110.4982\n",
            "\n",
            "Epoch 1035: Validation loss decreased (110.498245 --> 109.481667).\n",
            "\t Train_Loss: 20.2042 Val_Loss: 109.4817  BEST VAL Loss: 109.4817\n",
            "\n",
            "Epoch 1036: Validation loss decreased (109.481667 --> 109.235275).\n",
            "\t Train_Loss: 19.9327 Val_Loss: 109.2353  BEST VAL Loss: 109.2353\n",
            "\n",
            "Epoch 1037: Validation loss decreased (109.235275 --> 108.405273).\n",
            "\t Train_Loss: 19.9557 Val_Loss: 108.4053  BEST VAL Loss: 108.4053\n",
            "\n",
            "Epoch 1038: Validation loss did not decrease\n",
            "\t Train_Loss: 19.6727 Val_Loss: 108.6909  BEST VAL Loss: 108.4053\n",
            "\n",
            "Epoch 1039: Validation loss did not decrease\n",
            "\t Train_Loss: 19.5029 Val_Loss: 109.6706  BEST VAL Loss: 108.4053\n",
            "\n",
            "Epoch 1040: Validation loss decreased (108.405273 --> 108.284706).\n",
            "\t Train_Loss: 19.4712 Val_Loss: 108.2847  BEST VAL Loss: 108.2847\n",
            "\n",
            "Epoch 1041: Validation loss decreased (108.284706 --> 106.712990).\n",
            "\t Train_Loss: 19.2051 Val_Loss: 106.7130  BEST VAL Loss: 106.7130\n",
            "\n",
            "Epoch 1042: Validation loss decreased (106.712990 --> 105.952881).\n",
            "\t Train_Loss: 19.0808 Val_Loss: 105.9529  BEST VAL Loss: 105.9529\n",
            "\n",
            "Epoch 1043: Validation loss decreased (105.952881 --> 104.856125).\n",
            "\t Train_Loss: 18.9078 Val_Loss: 104.8561  BEST VAL Loss: 104.8561\n",
            "\n",
            "Epoch 1044: Validation loss decreased (104.856125 --> 103.954727).\n",
            "\t Train_Loss: 18.7580 Val_Loss: 103.9547  BEST VAL Loss: 103.9547\n",
            "\n",
            "Epoch 1045: Validation loss did not decrease\n",
            "\t Train_Loss: 18.6510 Val_Loss: 104.1667  BEST VAL Loss: 103.9547\n",
            "\n",
            "Epoch 1046: Validation loss did not decrease\n",
            "\t Train_Loss: 18.4336 Val_Loss: 103.9925  BEST VAL Loss: 103.9547\n",
            "\n",
            "Epoch 1047: Validation loss decreased (103.954727 --> 102.839622).\n",
            "\t Train_Loss: 18.3113 Val_Loss: 102.8396  BEST VAL Loss: 102.8396\n",
            "\n",
            "Epoch 1048: Validation loss decreased (102.839622 --> 102.546486).\n",
            "\t Train_Loss: 18.1997 Val_Loss: 102.5465  BEST VAL Loss: 102.5465\n",
            "\n",
            "Epoch 1049: Validation loss decreased (102.546486 --> 101.775558).\n",
            "\t Train_Loss: 17.9914 Val_Loss: 101.7756  BEST VAL Loss: 101.7756\n",
            "\n",
            "Epoch 1050: Validation loss decreased (101.775558 --> 100.666130).\n",
            "\t Train_Loss: 17.8574 Val_Loss: 100.6661  BEST VAL Loss: 100.6661\n",
            "\n",
            "Epoch 1051: Validation loss decreased (100.666130 --> 100.601517).\n",
            "\t Train_Loss: 17.7593 Val_Loss: 100.6015  BEST VAL Loss: 100.6015\n",
            "\n",
            "Epoch 1052: Validation loss decreased (100.601517 --> 100.180649).\n",
            "\t Train_Loss: 17.5748 Val_Loss: 100.1806  BEST VAL Loss: 100.1806\n",
            "\n",
            "Epoch 1053: Validation loss decreased (100.180649 --> 99.383949).\n",
            "\t Train_Loss: 17.4140 Val_Loss: 99.3839  BEST VAL Loss: 99.3839\n",
            "\n",
            "Epoch 1054: Validation loss decreased (99.383949 --> 99.187515).\n",
            "\t Train_Loss: 17.3066 Val_Loss: 99.1875  BEST VAL Loss: 99.1875\n",
            "\n",
            "Epoch 1055: Validation loss decreased (99.187515 --> 98.141373).\n",
            "\t Train_Loss: 17.1577 Val_Loss: 98.1414  BEST VAL Loss: 98.1414\n",
            "\n",
            "Epoch 1056: Validation loss decreased (98.141373 --> 97.080078).\n",
            "\t Train_Loss: 16.9996 Val_Loss: 97.0801  BEST VAL Loss: 97.0801\n",
            "\n",
            "Epoch 1057: Validation loss decreased (97.080078 --> 96.719139).\n",
            "\t Train_Loss: 16.8763 Val_Loss: 96.7191  BEST VAL Loss: 96.7191\n",
            "\n",
            "Epoch 1058: Validation loss decreased (96.719139 --> 95.955917).\n",
            "\t Train_Loss: 16.7452 Val_Loss: 95.9559  BEST VAL Loss: 95.9559\n",
            "\n",
            "Epoch 1059: Validation loss decreased (95.955917 --> 95.656425).\n",
            "\t Train_Loss: 16.5939 Val_Loss: 95.6564  BEST VAL Loss: 95.6564\n",
            "\n",
            "Epoch 1060: Validation loss decreased (95.656425 --> 95.517899).\n",
            "\t Train_Loss: 16.4555 Val_Loss: 95.5179  BEST VAL Loss: 95.5179\n",
            "\n",
            "Epoch 1061: Validation loss decreased (95.517899 --> 94.659645).\n",
            "\t Train_Loss: 16.3371 Val_Loss: 94.6596  BEST VAL Loss: 94.6596\n",
            "\n",
            "Epoch 1062: Validation loss decreased (94.659645 --> 94.092209).\n",
            "\t Train_Loss: 16.2054 Val_Loss: 94.0922  BEST VAL Loss: 94.0922\n",
            "\n",
            "Epoch 1063: Validation loss decreased (94.092209 --> 93.341904).\n",
            "\t Train_Loss: 16.0582 Val_Loss: 93.3419  BEST VAL Loss: 93.3419\n",
            "\n",
            "Epoch 1064: Validation loss decreased (93.341904 --> 92.410751).\n",
            "\t Train_Loss: 15.9279 Val_Loss: 92.4108  BEST VAL Loss: 92.4108\n",
            "\n",
            "Epoch 1065: Validation loss decreased (92.410751 --> 92.079323).\n",
            "\t Train_Loss: 15.8057 Val_Loss: 92.0793  BEST VAL Loss: 92.0793\n",
            "\n",
            "Epoch 1066: Validation loss decreased (92.079323 --> 91.549881).\n",
            "\t Train_Loss: 15.6673 Val_Loss: 91.5499  BEST VAL Loss: 91.5499\n",
            "\n",
            "Epoch 1067: Validation loss decreased (91.549881 --> 90.944626).\n",
            "\t Train_Loss: 15.5317 Val_Loss: 90.9446  BEST VAL Loss: 90.9446\n",
            "\n",
            "Epoch 1068: Validation loss decreased (90.944626 --> 90.493347).\n",
            "\t Train_Loss: 15.4110 Val_Loss: 90.4933  BEST VAL Loss: 90.4933\n",
            "\n",
            "Epoch 1069: Validation loss decreased (90.493347 --> 89.623032).\n",
            "\t Train_Loss: 15.2856 Val_Loss: 89.6230  BEST VAL Loss: 89.6230\n",
            "\n",
            "Epoch 1070: Validation loss decreased (89.623032 --> 88.965111).\n",
            "\t Train_Loss: 15.1561 Val_Loss: 88.9651  BEST VAL Loss: 88.9651\n",
            "\n",
            "Epoch 1071: Validation loss decreased (88.965111 --> 88.636337).\n",
            "\t Train_Loss: 15.0367 Val_Loss: 88.6363  BEST VAL Loss: 88.6363\n",
            "\n",
            "Epoch 1072: Validation loss decreased (88.636337 --> 88.155739).\n",
            "\t Train_Loss: 14.9187 Val_Loss: 88.1557  BEST VAL Loss: 88.1557\n",
            "\n",
            "Epoch 1073: Validation loss decreased (88.155739 --> 87.878601).\n",
            "\t Train_Loss: 14.7968 Val_Loss: 87.8786  BEST VAL Loss: 87.8786\n",
            "\n",
            "Epoch 1074: Validation loss decreased (87.878601 --> 87.347618).\n",
            "\t Train_Loss: 14.6758 Val_Loss: 87.3476  BEST VAL Loss: 87.3476\n",
            "\n",
            "Epoch 1075: Validation loss decreased (87.347618 --> 86.604774).\n",
            "\t Train_Loss: 14.5594 Val_Loss: 86.6048  BEST VAL Loss: 86.6048\n",
            "\n",
            "Epoch 1076: Validation loss decreased (86.604774 --> 86.162453).\n",
            "\t Train_Loss: 14.4473 Val_Loss: 86.1625  BEST VAL Loss: 86.1625\n",
            "\n",
            "Epoch 1077: Validation loss decreased (86.162453 --> 85.682213).\n",
            "\t Train_Loss: 14.3341 Val_Loss: 85.6822  BEST VAL Loss: 85.6822\n",
            "\n",
            "Epoch 1078: Validation loss decreased (85.682213 --> 85.339851).\n",
            "\t Train_Loss: 14.2176 Val_Loss: 85.3399  BEST VAL Loss: 85.3399\n",
            "\n",
            "Epoch 1079: Validation loss decreased (85.339851 --> 84.989311).\n",
            "\t Train_Loss: 14.1063 Val_Loss: 84.9893  BEST VAL Loss: 84.9893\n",
            "\n",
            "Epoch 1080: Validation loss decreased (84.989311 --> 84.330513).\n",
            "\t Train_Loss: 13.9993 Val_Loss: 84.3305  BEST VAL Loss: 84.3305\n",
            "\n",
            "Epoch 1081: Validation loss decreased (84.330513 --> 83.729858).\n",
            "\t Train_Loss: 13.8911 Val_Loss: 83.7299  BEST VAL Loss: 83.7299\n",
            "\n",
            "Epoch 1082: Validation loss decreased (83.729858 --> 83.242249).\n",
            "\t Train_Loss: 13.7865 Val_Loss: 83.2422  BEST VAL Loss: 83.2422\n",
            "\n",
            "Epoch 1083: Validation loss decreased (83.242249 --> 82.783997).\n",
            "\t Train_Loss: 13.6855 Val_Loss: 82.7840  BEST VAL Loss: 82.7840\n",
            "\n",
            "Epoch 1084: Validation loss decreased (82.783997 --> 82.460770).\n",
            "\t Train_Loss: 13.5834 Val_Loss: 82.4608  BEST VAL Loss: 82.4608\n",
            "\n",
            "Epoch 1085: Validation loss decreased (82.460770 --> 82.000725).\n",
            "\t Train_Loss: 13.4816 Val_Loss: 82.0007  BEST VAL Loss: 82.0007\n",
            "\n",
            "Epoch 1086: Validation loss decreased (82.000725 --> 81.422516).\n",
            "\t Train_Loss: 13.3819 Val_Loss: 81.4225  BEST VAL Loss: 81.4225\n",
            "\n",
            "Epoch 1087: Validation loss decreased (81.422516 --> 81.002548).\n",
            "\t Train_Loss: 13.2851 Val_Loss: 81.0025  BEST VAL Loss: 81.0025\n",
            "\n",
            "Epoch 1088: Validation loss decreased (81.002548 --> 80.572090).\n",
            "\t Train_Loss: 13.1891 Val_Loss: 80.5721  BEST VAL Loss: 80.5721\n",
            "\n",
            "Epoch 1089: Validation loss decreased (80.572090 --> 80.128105).\n",
            "\t Train_Loss: 13.0945 Val_Loss: 80.1281  BEST VAL Loss: 80.1281\n",
            "\n",
            "Epoch 1090: Validation loss decreased (80.128105 --> 79.687965).\n",
            "\t Train_Loss: 13.0029 Val_Loss: 79.6880  BEST VAL Loss: 79.6880\n",
            "\n",
            "Epoch 1091: Validation loss decreased (79.687965 --> 79.130478).\n",
            "\t Train_Loss: 12.9119 Val_Loss: 79.1305  BEST VAL Loss: 79.1305\n",
            "\n",
            "Epoch 1092: Validation loss decreased (79.130478 --> 78.708130).\n",
            "\t Train_Loss: 12.8225 Val_Loss: 78.7081  BEST VAL Loss: 78.7081\n",
            "\n",
            "Epoch 1093: Validation loss decreased (78.708130 --> 78.358749).\n",
            "\t Train_Loss: 12.7351 Val_Loss: 78.3587  BEST VAL Loss: 78.3587\n",
            "\n",
            "Epoch 1094: Validation loss decreased (78.358749 --> 77.905174).\n",
            "\t Train_Loss: 12.6498 Val_Loss: 77.9052  BEST VAL Loss: 77.9052\n",
            "\n",
            "Epoch 1095: Validation loss decreased (77.905174 --> 77.509384).\n",
            "\t Train_Loss: 12.5653 Val_Loss: 77.5094  BEST VAL Loss: 77.5094\n",
            "\n",
            "Epoch 1096: Validation loss decreased (77.509384 --> 77.145363).\n",
            "\t Train_Loss: 12.4815 Val_Loss: 77.1454  BEST VAL Loss: 77.1454\n",
            "\n",
            "Epoch 1097: Validation loss decreased (77.145363 --> 76.828598).\n",
            "\t Train_Loss: 12.3992 Val_Loss: 76.8286  BEST VAL Loss: 76.8286\n",
            "\n",
            "Epoch 1098: Validation loss decreased (76.828598 --> 76.542206).\n",
            "\t Train_Loss: 12.3184 Val_Loss: 76.5422  BEST VAL Loss: 76.5422\n",
            "\n",
            "Epoch 1099: Validation loss decreased (76.542206 --> 76.129456).\n",
            "\t Train_Loss: 12.2389 Val_Loss: 76.1295  BEST VAL Loss: 76.1295\n",
            "\n",
            "Epoch 1100: Validation loss decreased (76.129456 --> 75.764656).\n",
            "\t Train_Loss: 12.1595 Val_Loss: 75.7647  BEST VAL Loss: 75.7647\n",
            "\n",
            "Epoch 1101: Validation loss decreased (75.764656 --> 75.359802).\n",
            "\t Train_Loss: 12.0817 Val_Loss: 75.3598  BEST VAL Loss: 75.3598\n",
            "\n",
            "Epoch 1102: Validation loss decreased (75.359802 --> 75.184341).\n",
            "\t Train_Loss: 12.0081 Val_Loss: 75.1843  BEST VAL Loss: 75.1843\n",
            "\n",
            "Epoch 1103: Validation loss decreased (75.184341 --> 74.797935).\n",
            "\t Train_Loss: 11.9333 Val_Loss: 74.7979  BEST VAL Loss: 74.7979\n",
            "\n",
            "Epoch 1104: Validation loss decreased (74.797935 --> 74.386612).\n",
            "\t Train_Loss: 11.8599 Val_Loss: 74.3866  BEST VAL Loss: 74.3866\n",
            "\n",
            "Epoch 1105: Validation loss decreased (74.386612 --> 74.058617).\n",
            "\t Train_Loss: 11.7870 Val_Loss: 74.0586  BEST VAL Loss: 74.0586\n",
            "\n",
            "Epoch 1106: Validation loss decreased (74.058617 --> 73.794907).\n",
            "\t Train_Loss: 11.7157 Val_Loss: 73.7949  BEST VAL Loss: 73.7949\n",
            "\n",
            "Epoch 1107: Validation loss decreased (73.794907 --> 73.687943).\n",
            "\t Train_Loss: 11.6404 Val_Loss: 73.6879  BEST VAL Loss: 73.6879\n",
            "\n",
            "Epoch 1108: Validation loss decreased (73.687943 --> 72.767319).\n",
            "\t Train_Loss: 11.6291 Val_Loss: 72.7673  BEST VAL Loss: 72.7673\n",
            "\n",
            "Epoch 1109: Validation loss did not decrease\n",
            "\t Train_Loss: 11.5771 Val_Loss: 73.1364  BEST VAL Loss: 72.7673\n",
            "\n",
            "Epoch 1110: Validation loss decreased (72.767319 --> 72.561676).\n",
            "\t Train_Loss: 11.5361 Val_Loss: 72.5617  BEST VAL Loss: 72.5617\n",
            "\n",
            "Epoch 1111: Validation loss decreased (72.561676 --> 72.282028).\n",
            "\t Train_Loss: 11.4186 Val_Loss: 72.2820  BEST VAL Loss: 72.2820\n",
            "\n",
            "Epoch 1112: Validation loss decreased (72.282028 --> 71.917908).\n",
            "\t Train_Loss: 11.3505 Val_Loss: 71.9179  BEST VAL Loss: 71.9179\n",
            "\n",
            "Epoch 1113: Validation loss decreased (71.917908 --> 71.205620).\n",
            "\t Train_Loss: 11.3210 Val_Loss: 71.2056  BEST VAL Loss: 71.2056\n",
            "\n",
            "Epoch 1114: Validation loss did not decrease\n",
            "\t Train_Loss: 11.2593 Val_Loss: 71.6639  BEST VAL Loss: 71.2056\n",
            "\n",
            "Epoch 1115: Validation loss did not decrease\n",
            "\t Train_Loss: 11.1699 Val_Loss: 71.4671  BEST VAL Loss: 71.2056\n",
            "\n",
            "Epoch 1116: Validation loss decreased (71.205620 --> 70.471695).\n",
            "\t Train_Loss: 11.1183 Val_Loss: 70.4717  BEST VAL Loss: 70.4717\n",
            "\n",
            "Epoch 1117: Validation loss decreased (70.471695 --> 70.438164).\n",
            "\t Train_Loss: 11.0753 Val_Loss: 70.4382  BEST VAL Loss: 70.4382\n",
            "\n",
            "Epoch 1118: Validation loss decreased (70.438164 --> 70.277138).\n",
            "\t Train_Loss: 11.0026 Val_Loss: 70.2771  BEST VAL Loss: 70.2771\n",
            "\n",
            "Epoch 1119: Validation loss decreased (70.277138 --> 69.818329).\n",
            "\t Train_Loss: 10.9374 Val_Loss: 69.8183  BEST VAL Loss: 69.8183\n",
            "\n",
            "Epoch 1120: Validation loss decreased (69.818329 --> 69.638626).\n",
            "\t Train_Loss: 10.8975 Val_Loss: 69.6386  BEST VAL Loss: 69.6386\n",
            "\n",
            "Epoch 1121: Validation loss decreased (69.638626 --> 69.126663).\n",
            "\t Train_Loss: 10.8386 Val_Loss: 69.1267  BEST VAL Loss: 69.1267\n",
            "\n",
            "Epoch 1122: Validation loss decreased (69.126663 --> 68.972351).\n",
            "\t Train_Loss: 10.7778 Val_Loss: 68.9724  BEST VAL Loss: 68.9724\n",
            "\n",
            "Epoch 1123: Validation loss did not decrease\n",
            "\t Train_Loss: 10.7285 Val_Loss: 69.0839  BEST VAL Loss: 68.9724\n",
            "\n",
            "Epoch 1124: Validation loss decreased (68.972351 --> 68.511948).\n",
            "\t Train_Loss: 10.6853 Val_Loss: 68.5119  BEST VAL Loss: 68.5119\n",
            "\n",
            "Epoch 1125: Validation loss decreased (68.511948 --> 68.070053).\n",
            "\t Train_Loss: 10.6285 Val_Loss: 68.0701  BEST VAL Loss: 68.0701\n",
            "\n",
            "Epoch 1126: Validation loss did not decrease\n",
            "\t Train_Loss: 10.5789 Val_Loss: 68.0775  BEST VAL Loss: 68.0701\n",
            "\n",
            "Epoch 1127: Validation loss decreased (68.070053 --> 67.767136).\n",
            "\t Train_Loss: 10.5379 Val_Loss: 67.7671  BEST VAL Loss: 67.7671\n",
            "\n",
            "Epoch 1128: Validation loss decreased (67.767136 --> 67.489944).\n",
            "\t Train_Loss: 10.4920 Val_Loss: 67.4899  BEST VAL Loss: 67.4899\n",
            "\n",
            "Epoch 1129: Validation loss decreased (67.489944 --> 67.206505).\n",
            "\t Train_Loss: 10.4383 Val_Loss: 67.2065  BEST VAL Loss: 67.2065\n",
            "\n",
            "Epoch 1130: Validation loss decreased (67.206505 --> 66.919762).\n",
            "\t Train_Loss: 10.3988 Val_Loss: 66.9198  BEST VAL Loss: 66.9198\n",
            "\n",
            "Epoch 1131: Validation loss did not decrease\n",
            "\t Train_Loss: 10.3590 Val_Loss: 66.9822  BEST VAL Loss: 66.9198\n",
            "\n",
            "Epoch 1132: Validation loss decreased (66.919762 --> 66.716957).\n",
            "\t Train_Loss: 10.3103 Val_Loss: 66.7170  BEST VAL Loss: 66.7170\n",
            "\n",
            "Epoch 1133: Validation loss decreased (66.716957 --> 66.240021).\n",
            "\t Train_Loss: 10.2673 Val_Loss: 66.2400  BEST VAL Loss: 66.2400\n",
            "\n",
            "Epoch 1134: Validation loss decreased (66.240021 --> 66.222519).\n",
            "\t Train_Loss: 10.2323 Val_Loss: 66.2225  BEST VAL Loss: 66.2225\n",
            "\n",
            "Epoch 1135: Validation loss decreased (66.222519 --> 66.052719).\n",
            "\t Train_Loss: 10.1878 Val_Loss: 66.0527  BEST VAL Loss: 66.0527\n",
            "\n",
            "Epoch 1136: Validation loss decreased (66.052719 --> 65.717918).\n",
            "\t Train_Loss: 10.1448 Val_Loss: 65.7179  BEST VAL Loss: 65.7179\n",
            "\n",
            "Epoch 1137: Validation loss decreased (65.717918 --> 65.502365).\n",
            "\t Train_Loss: 10.1137 Val_Loss: 65.5024  BEST VAL Loss: 65.5024\n",
            "\n",
            "Epoch 1138: Validation loss decreased (65.502365 --> 65.339661).\n",
            "\t Train_Loss: 10.0697 Val_Loss: 65.3397  BEST VAL Loss: 65.3397\n",
            "\n",
            "Epoch 1139: Validation loss decreased (65.339661 --> 65.159958).\n",
            "\t Train_Loss: 10.0289 Val_Loss: 65.1600  BEST VAL Loss: 65.1600\n",
            "\n",
            "Epoch 1140: Validation loss decreased (65.159958 --> 64.996696).\n",
            "\t Train_Loss: 9.9932 Val_Loss: 64.9967  BEST VAL Loss: 64.9967\n",
            "\n",
            "Epoch 1141: Validation loss decreased (64.996696 --> 64.692329).\n",
            "\t Train_Loss: 9.9573 Val_Loss: 64.6923  BEST VAL Loss: 64.6923\n",
            "\n",
            "Epoch 1142: Validation loss decreased (64.692329 --> 64.510300).\n",
            "\t Train_Loss: 9.9189 Val_Loss: 64.5103  BEST VAL Loss: 64.5103\n",
            "\n",
            "Epoch 1143: Validation loss decreased (64.510300 --> 64.378258).\n",
            "\t Train_Loss: 9.8828 Val_Loss: 64.3783  BEST VAL Loss: 64.3783\n",
            "\n",
            "Epoch 1144: Validation loss decreased (64.378258 --> 64.066795).\n",
            "\t Train_Loss: 9.8493 Val_Loss: 64.0668  BEST VAL Loss: 64.0668\n",
            "\n",
            "Epoch 1145: Validation loss decreased (64.066795 --> 63.878517).\n",
            "\t Train_Loss: 9.8135 Val_Loss: 63.8785  BEST VAL Loss: 63.8785\n",
            "\n",
            "Epoch 1146: Validation loss decreased (63.878517 --> 63.783508).\n",
            "\t Train_Loss: 9.7779 Val_Loss: 63.7835  BEST VAL Loss: 63.7835\n",
            "\n",
            "Epoch 1147: Validation loss decreased (63.783508 --> 63.571838).\n",
            "\t Train_Loss: 9.7450 Val_Loss: 63.5718  BEST VAL Loss: 63.5718\n",
            "\n",
            "Epoch 1148: Validation loss decreased (63.571838 --> 63.385998).\n",
            "\t Train_Loss: 9.7118 Val_Loss: 63.3860  BEST VAL Loss: 63.3860\n",
            "\n",
            "Epoch 1149: Validation loss decreased (63.385998 --> 63.190441).\n",
            "\t Train_Loss: 9.6772 Val_Loss: 63.1904  BEST VAL Loss: 63.1904\n",
            "\n",
            "Epoch 1150: Validation loss decreased (63.190441 --> 62.998676).\n",
            "\t Train_Loss: 9.6445 Val_Loss: 62.9987  BEST VAL Loss: 62.9987\n",
            "\n",
            "Epoch 1151: Validation loss decreased (62.998676 --> 62.859833).\n",
            "\t Train_Loss: 9.6127 Val_Loss: 62.8598  BEST VAL Loss: 62.8598\n",
            "\n",
            "Epoch 1152: Validation loss decreased (62.859833 --> 62.626793).\n",
            "\t Train_Loss: 9.5799 Val_Loss: 62.6268  BEST VAL Loss: 62.6268\n",
            "\n",
            "Epoch 1153: Validation loss decreased (62.626793 --> 62.447193).\n",
            "\t Train_Loss: 9.5476 Val_Loss: 62.4472  BEST VAL Loss: 62.4472\n",
            "\n",
            "Epoch 1154: Validation loss decreased (62.447193 --> 62.357903).\n",
            "\t Train_Loss: 9.5167 Val_Loss: 62.3579  BEST VAL Loss: 62.3579\n",
            "\n",
            "Epoch 1155: Validation loss decreased (62.357903 --> 62.143871).\n",
            "\t Train_Loss: 9.4859 Val_Loss: 62.1439  BEST VAL Loss: 62.1439\n",
            "\n",
            "Epoch 1156: Validation loss decreased (62.143871 --> 61.955589).\n",
            "\t Train_Loss: 9.4549 Val_Loss: 61.9556  BEST VAL Loss: 61.9556\n",
            "\n",
            "Epoch 1157: Validation loss decreased (61.955589 --> 61.836395).\n",
            "\t Train_Loss: 9.4250 Val_Loss: 61.8364  BEST VAL Loss: 61.8364\n",
            "\n",
            "Epoch 1158: Validation loss decreased (61.836395 --> 61.660858).\n",
            "\t Train_Loss: 9.3956 Val_Loss: 61.6609  BEST VAL Loss: 61.6609\n",
            "\n",
            "Epoch 1159: Validation loss decreased (61.660858 --> 61.515362).\n",
            "\t Train_Loss: 9.3660 Val_Loss: 61.5154  BEST VAL Loss: 61.5154\n",
            "\n",
            "Epoch 1160: Validation loss decreased (61.515362 --> 61.350658).\n",
            "\t Train_Loss: 9.3369 Val_Loss: 61.3507  BEST VAL Loss: 61.3507\n",
            "\n",
            "Epoch 1161: Validation loss decreased (61.350658 --> 61.196495).\n",
            "\t Train_Loss: 9.3082 Val_Loss: 61.1965  BEST VAL Loss: 61.1965\n",
            "\n",
            "Epoch 1162: Validation loss decreased (61.196495 --> 61.085602).\n",
            "\t Train_Loss: 9.2798 Val_Loss: 61.0856  BEST VAL Loss: 61.0856\n",
            "\n",
            "Epoch 1163: Validation loss decreased (61.085602 --> 60.895546).\n",
            "\t Train_Loss: 9.2517 Val_Loss: 60.8955  BEST VAL Loss: 60.8955\n",
            "\n",
            "Epoch 1164: Validation loss decreased (60.895546 --> 60.762115).\n",
            "\t Train_Loss: 9.2237 Val_Loss: 60.7621  BEST VAL Loss: 60.7621\n",
            "\n",
            "Epoch 1165: Validation loss decreased (60.762115 --> 60.659737).\n",
            "\t Train_Loss: 9.1960 Val_Loss: 60.6597  BEST VAL Loss: 60.6597\n",
            "\n",
            "Epoch 1166: Validation loss decreased (60.659737 --> 60.463379).\n",
            "\t Train_Loss: 9.1689 Val_Loss: 60.4634  BEST VAL Loss: 60.4634\n",
            "\n",
            "Epoch 1167: Validation loss decreased (60.463379 --> 60.313824).\n",
            "\t Train_Loss: 9.1419 Val_Loss: 60.3138  BEST VAL Loss: 60.3138\n",
            "\n",
            "Epoch 1168: Validation loss decreased (60.313824 --> 60.171619).\n",
            "\t Train_Loss: 9.1149 Val_Loss: 60.1716  BEST VAL Loss: 60.1716\n",
            "\n",
            "Epoch 1169: Validation loss decreased (60.171619 --> 60.005432).\n",
            "\t Train_Loss: 9.0885 Val_Loss: 60.0054  BEST VAL Loss: 60.0054\n",
            "\n",
            "Epoch 1170: Validation loss decreased (60.005432 --> 59.872875).\n",
            "\t Train_Loss: 9.0624 Val_Loss: 59.8729  BEST VAL Loss: 59.8729\n",
            "\n",
            "Epoch 1171: Validation loss decreased (59.872875 --> 59.726097).\n",
            "\t Train_Loss: 9.0364 Val_Loss: 59.7261  BEST VAL Loss: 59.7261\n",
            "\n",
            "Epoch 1172: Validation loss decreased (59.726097 --> 59.607658).\n",
            "\t Train_Loss: 9.0106 Val_Loss: 59.6077  BEST VAL Loss: 59.6077\n",
            "\n",
            "Epoch 1173: Validation loss decreased (59.607658 --> 59.460518).\n",
            "\t Train_Loss: 8.9851 Val_Loss: 59.4605  BEST VAL Loss: 59.4605\n",
            "\n",
            "Epoch 1174: Validation loss decreased (59.460518 --> 59.296043).\n",
            "\t Train_Loss: 8.9599 Val_Loss: 59.2960  BEST VAL Loss: 59.2960\n",
            "\n",
            "Epoch 1175: Validation loss decreased (59.296043 --> 59.194458).\n",
            "\t Train_Loss: 8.9350 Val_Loss: 59.1945  BEST VAL Loss: 59.1945\n",
            "\n",
            "Epoch 1176: Validation loss decreased (59.194458 --> 59.050148).\n",
            "\t Train_Loss: 8.9102 Val_Loss: 59.0501  BEST VAL Loss: 59.0501\n",
            "\n",
            "Epoch 1177: Validation loss decreased (59.050148 --> 58.915039).\n",
            "\t Train_Loss: 8.8856 Val_Loss: 58.9150  BEST VAL Loss: 58.9150\n",
            "\n",
            "Epoch 1178: Validation loss decreased (58.915039 --> 58.807655).\n",
            "\t Train_Loss: 8.8614 Val_Loss: 58.8077  BEST VAL Loss: 58.8077\n",
            "\n",
            "Epoch 1179: Validation loss decreased (58.807655 --> 58.666553).\n",
            "\t Train_Loss: 8.8373 Val_Loss: 58.6666  BEST VAL Loss: 58.6666\n",
            "\n",
            "Epoch 1180: Validation loss decreased (58.666553 --> 58.541515).\n",
            "\t Train_Loss: 8.8134 Val_Loss: 58.5415  BEST VAL Loss: 58.5415\n",
            "\n",
            "Epoch 1181: Validation loss decreased (58.541515 --> 58.411480).\n",
            "\t Train_Loss: 8.7897 Val_Loss: 58.4115  BEST VAL Loss: 58.4115\n",
            "\n",
            "Epoch 1182: Validation loss decreased (58.411480 --> 58.298023).\n",
            "\t Train_Loss: 8.7662 Val_Loss: 58.2980  BEST VAL Loss: 58.2980\n",
            "\n",
            "Epoch 1183: Validation loss decreased (58.298023 --> 58.173145).\n",
            "\t Train_Loss: 8.7429 Val_Loss: 58.1731  BEST VAL Loss: 58.1731\n",
            "\n",
            "Epoch 1184: Validation loss decreased (58.173145 --> 58.028419).\n",
            "\t Train_Loss: 8.7199 Val_Loss: 58.0284  BEST VAL Loss: 58.0284\n",
            "\n",
            "Epoch 1185: Validation loss decreased (58.028419 --> 57.921410).\n",
            "\t Train_Loss: 8.6970 Val_Loss: 57.9214  BEST VAL Loss: 57.9214\n",
            "\n",
            "Epoch 1186: Validation loss decreased (57.921410 --> 57.783195).\n",
            "\t Train_Loss: 8.6744 Val_Loss: 57.7832  BEST VAL Loss: 57.7832\n",
            "\n",
            "Epoch 1187: Validation loss decreased (57.783195 --> 57.662788).\n",
            "\t Train_Loss: 8.6519 Val_Loss: 57.6628  BEST VAL Loss: 57.6628\n",
            "\n",
            "Epoch 1188: Validation loss decreased (57.662788 --> 57.558727).\n",
            "\t Train_Loss: 8.6296 Val_Loss: 57.5587  BEST VAL Loss: 57.5587\n",
            "\n",
            "Epoch 1189: Validation loss decreased (57.558727 --> 57.430336).\n",
            "\t Train_Loss: 8.6074 Val_Loss: 57.4303  BEST VAL Loss: 57.4303\n",
            "\n",
            "Epoch 1190: Validation loss decreased (57.430336 --> 57.311684).\n",
            "\t Train_Loss: 8.5855 Val_Loss: 57.3117  BEST VAL Loss: 57.3117\n",
            "\n",
            "Epoch 1191: Validation loss decreased (57.311684 --> 57.184074).\n",
            "\t Train_Loss: 8.5638 Val_Loss: 57.1841  BEST VAL Loss: 57.1841\n",
            "\n",
            "Epoch 1192: Validation loss decreased (57.184074 --> 57.076042).\n",
            "\t Train_Loss: 8.5422 Val_Loss: 57.0760  BEST VAL Loss: 57.0760\n",
            "\n",
            "Epoch 1193: Validation loss decreased (57.076042 --> 56.952881).\n",
            "\t Train_Loss: 8.5208 Val_Loss: 56.9529  BEST VAL Loss: 56.9529\n",
            "\n",
            "Epoch 1194: Validation loss decreased (56.952881 --> 56.844147).\n",
            "\t Train_Loss: 8.4995 Val_Loss: 56.8441  BEST VAL Loss: 56.8441\n",
            "\n",
            "Epoch 1195: Validation loss decreased (56.844147 --> 56.739880).\n",
            "\t Train_Loss: 8.4785 Val_Loss: 56.7399  BEST VAL Loss: 56.7399\n",
            "\n",
            "Epoch 1196: Validation loss decreased (56.739880 --> 56.614563).\n",
            "\t Train_Loss: 8.4576 Val_Loss: 56.6146  BEST VAL Loss: 56.6146\n",
            "\n",
            "Epoch 1197: Validation loss decreased (56.614563 --> 56.516418).\n",
            "\t Train_Loss: 8.4369 Val_Loss: 56.5164  BEST VAL Loss: 56.5164\n",
            "\n",
            "Epoch 1198: Validation loss decreased (56.516418 --> 56.406506).\n",
            "\t Train_Loss: 8.4163 Val_Loss: 56.4065  BEST VAL Loss: 56.4065\n",
            "\n",
            "Epoch 1199: Validation loss decreased (56.406506 --> 56.303150).\n",
            "\t Train_Loss: 8.3959 Val_Loss: 56.3032  BEST VAL Loss: 56.3032\n",
            "\n",
            "Epoch 1200: Validation loss decreased (56.303150 --> 56.191204).\n",
            "\t Train_Loss: 8.3757 Val_Loss: 56.1912  BEST VAL Loss: 56.1912\n",
            "\n",
            "Epoch 1201: Validation loss decreased (56.191204 --> 56.086926).\n",
            "\t Train_Loss: 8.3556 Val_Loss: 56.0869  BEST VAL Loss: 56.0869\n",
            "\n",
            "Epoch 1202: Validation loss decreased (56.086926 --> 55.974342).\n",
            "\t Train_Loss: 8.3357 Val_Loss: 55.9743  BEST VAL Loss: 55.9743\n",
            "\n",
            "Epoch 1203: Validation loss decreased (55.974342 --> 55.866905).\n",
            "\t Train_Loss: 8.3160 Val_Loss: 55.8669  BEST VAL Loss: 55.8669\n",
            "\n",
            "Epoch 1204: Validation loss decreased (55.866905 --> 55.771221).\n",
            "\t Train_Loss: 8.2964 Val_Loss: 55.7712  BEST VAL Loss: 55.7712\n",
            "\n",
            "Epoch 1205: Validation loss decreased (55.771221 --> 55.657581).\n",
            "\t Train_Loss: 8.2769 Val_Loss: 55.6576  BEST VAL Loss: 55.6576\n",
            "\n",
            "Epoch 1206: Validation loss decreased (55.657581 --> 55.557198).\n",
            "\t Train_Loss: 8.2576 Val_Loss: 55.5572  BEST VAL Loss: 55.5572\n",
            "\n",
            "Epoch 1207: Validation loss decreased (55.557198 --> 55.446705).\n",
            "\t Train_Loss: 8.2385 Val_Loss: 55.4467  BEST VAL Loss: 55.4467\n",
            "\n",
            "Epoch 1208: Validation loss decreased (55.446705 --> 55.346069).\n",
            "\t Train_Loss: 8.2195 Val_Loss: 55.3461  BEST VAL Loss: 55.3461\n",
            "\n",
            "Epoch 1209: Validation loss decreased (55.346069 --> 55.237682).\n",
            "\t Train_Loss: 8.2006 Val_Loss: 55.2377  BEST VAL Loss: 55.2377\n",
            "\n",
            "Epoch 1210: Validation loss decreased (55.237682 --> 55.145386).\n",
            "\t Train_Loss: 8.1819 Val_Loss: 55.1454  BEST VAL Loss: 55.1454\n",
            "\n",
            "Epoch 1211: Validation loss decreased (55.145386 --> 55.034863).\n",
            "\t Train_Loss: 8.1633 Val_Loss: 55.0349  BEST VAL Loss: 55.0349\n",
            "\n",
            "Epoch 1212: Validation loss decreased (55.034863 --> 54.937904).\n",
            "\t Train_Loss: 8.1448 Val_Loss: 54.9379  BEST VAL Loss: 54.9379\n",
            "\n",
            "Epoch 1213: Validation loss decreased (54.937904 --> 54.833729).\n",
            "\t Train_Loss: 8.1265 Val_Loss: 54.8337  BEST VAL Loss: 54.8337\n",
            "\n",
            "Epoch 1214: Validation loss decreased (54.833729 --> 54.737854).\n",
            "\t Train_Loss: 8.1083 Val_Loss: 54.7379  BEST VAL Loss: 54.7379\n",
            "\n",
            "Epoch 1215: Validation loss decreased (54.737854 --> 54.633568).\n",
            "\t Train_Loss: 8.0903 Val_Loss: 54.6336  BEST VAL Loss: 54.6336\n",
            "\n",
            "Epoch 1216: Validation loss decreased (54.633568 --> 54.542469).\n",
            "\t Train_Loss: 8.0723 Val_Loss: 54.5425  BEST VAL Loss: 54.5425\n",
            "\n",
            "Epoch 1217: Validation loss decreased (54.542469 --> 54.434258).\n",
            "\t Train_Loss: 8.0545 Val_Loss: 54.4343  BEST VAL Loss: 54.4343\n",
            "\n",
            "Epoch 1218: Validation loss decreased (54.434258 --> 54.344105).\n",
            "\t Train_Loss: 8.0368 Val_Loss: 54.3441  BEST VAL Loss: 54.3441\n",
            "\n",
            "Epoch 1219: Validation loss decreased (54.344105 --> 54.240410).\n",
            "\t Train_Loss: 8.0192 Val_Loss: 54.2404  BEST VAL Loss: 54.2404\n",
            "\n",
            "Epoch 1220: Validation loss decreased (54.240410 --> 54.156666).\n",
            "\t Train_Loss: 8.0016 Val_Loss: 54.1567  BEST VAL Loss: 54.1567\n",
            "\n",
            "Epoch 1221: Validation loss decreased (54.156666 --> 54.047279).\n",
            "\t Train_Loss: 7.9841 Val_Loss: 54.0473  BEST VAL Loss: 54.0473\n",
            "\n",
            "Epoch 1222: Validation loss decreased (54.047279 --> 53.980263).\n",
            "\t Train_Loss: 7.9663 Val_Loss: 53.9803  BEST VAL Loss: 53.9803\n",
            "\n",
            "Epoch 1223: Validation loss decreased (53.980263 --> 53.916710).\n",
            "\t Train_Loss: 7.9477 Val_Loss: 53.9167  BEST VAL Loss: 53.9167\n",
            "\n",
            "Epoch 1224: Validation loss decreased (53.916710 --> 53.676678).\n",
            "\t Train_Loss: 7.9286 Val_Loss: 53.6767  BEST VAL Loss: 53.6767\n",
            "\n",
            "Epoch 1225: Validation loss did not decrease\n",
            "\t Train_Loss: 7.9101 Val_Loss: 53.9424  BEST VAL Loss: 53.6767\n",
            "\n",
            "Epoch 1226: Validation loss decreased (53.676678 --> 53.189159).\n",
            "\t Train_Loss: 7.8940 Val_Loss: 53.1892  BEST VAL Loss: 53.1892\n",
            "\n",
            "Epoch 1227: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8976 Val_Loss: 53.8146  BEST VAL Loss: 53.1892\n",
            "\n",
            "Epoch 1228: Validation loss decreased (53.189159 --> 53.082527).\n",
            "\t Train_Loss: 7.9053 Val_Loss: 53.0825  BEST VAL Loss: 53.0825\n",
            "\n",
            "Epoch 1229: Validation loss did not decrease\n",
            "\t Train_Loss: 7.9620 Val_Loss: 54.1514  BEST VAL Loss: 53.0825\n",
            "\n",
            "Epoch 1230: Validation loss decreased (53.082527 --> 52.139965).\n",
            "\t Train_Loss: 8.0653 Val_Loss: 52.1400  BEST VAL Loss: 52.1400\n",
            "\n",
            "Epoch 1231: Validation loss did not decrease\n",
            "\t Train_Loss: 8.2922 Val_Loss: 54.3887  BEST VAL Loss: 52.1400\n",
            "\n",
            "Epoch 1232: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1823 Val_Loss: 54.2498  BEST VAL Loss: 52.1400\n",
            "\n",
            "Epoch 1233: Validation loss decreased (52.139965 --> 51.565746).\n",
            "\t Train_Loss: 8.0539 Val_Loss: 51.5657  BEST VAL Loss: 51.5657\n",
            "\n",
            "Epoch 1234: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8768 Val_Loss: 53.1829  BEST VAL Loss: 51.5657\n",
            "\n",
            "Epoch 1235: Validation loss did not decrease\n",
            "\t Train_Loss: 7.9061 Val_Loss: 53.7745  BEST VAL Loss: 51.5657\n",
            "\n",
            "Epoch 1236: Validation loss did not decrease\n",
            "\t Train_Loss: 8.3277 Val_Loss: 52.5554  BEST VAL Loss: 51.5657\n",
            "\n",
            "Epoch 1237: Validation loss did not decrease\n",
            "\t Train_Loss: 7.9544 Val_Loss: 51.6465  BEST VAL Loss: 51.5657\n",
            "\n",
            "Epoch 1238: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7743 Val_Loss: 53.5269  BEST VAL Loss: 51.5657\n",
            "\n",
            "Epoch 1239: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7954 Val_Loss: 53.1958  BEST VAL Loss: 51.5657\n",
            "\n",
            "Epoch 1240: Validation loss decreased (51.565746 --> 50.730778).\n",
            "\t Train_Loss: 7.8468 Val_Loss: 50.7308  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1241: Validation loss did not decrease\n",
            "\t Train_Loss: 7.9485 Val_Loss: 52.9940  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1242: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7799 Val_Loss: 53.3946  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1243: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7117 Val_Loss: 51.5944  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1244: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7301 Val_Loss: 52.1629  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1245: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7750 Val_Loss: 52.7228  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1246: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7466 Val_Loss: 51.6588  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1247: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6243 Val_Loss: 51.0260  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1248: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6328 Val_Loss: 51.9259  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1249: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6596 Val_Loss: 52.2481  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1250: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6141 Val_Loss: 50.8819  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1251: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5654 Val_Loss: 51.7947  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1252: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5203 Val_Loss: 52.0999  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1253: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5281 Val_Loss: 50.9486  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1254: Validation loss did not decrease\n",
            "\t Train_Loss: 7.5120 Val_Loss: 51.0685  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1255: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4974 Val_Loss: 51.6941  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1256: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4767 Val_Loss: 50.9534  BEST VAL Loss: 50.7308\n",
            "\n",
            "Epoch 1257: Validation loss decreased (50.730778 --> 50.637238).\n",
            "\t Train_Loss: 7.4433 Val_Loss: 50.6372  BEST VAL Loss: 50.6372\n",
            "\n",
            "Epoch 1258: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4381 Val_Loss: 51.3109  BEST VAL Loss: 50.6372\n",
            "\n",
            "Epoch 1259: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4237 Val_Loss: 50.9241  BEST VAL Loss: 50.6372\n",
            "\n",
            "Epoch 1260: Validation loss decreased (50.637238 --> 50.189110).\n",
            "\t Train_Loss: 7.4084 Val_Loss: 50.1891  BEST VAL Loss: 50.1891\n",
            "\n",
            "Epoch 1261: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4006 Val_Loss: 51.0531  BEST VAL Loss: 50.1891\n",
            "\n",
            "Epoch 1262: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3777 Val_Loss: 50.8355  BEST VAL Loss: 50.1891\n",
            "\n",
            "Epoch 1263: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3612 Val_Loss: 50.2214  BEST VAL Loss: 50.1891\n",
            "\n",
            "Epoch 1264: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3511 Val_Loss: 50.7419  BEST VAL Loss: 50.1891\n",
            "\n",
            "Epoch 1265: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3343 Val_Loss: 50.6563  BEST VAL Loss: 50.1891\n",
            "\n",
            "Epoch 1266: Validation loss decreased (50.189110 --> 49.982533).\n",
            "\t Train_Loss: 7.3235 Val_Loss: 49.9825  BEST VAL Loss: 49.9825\n",
            "\n",
            "Epoch 1267: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3106 Val_Loss: 50.2050  BEST VAL Loss: 49.9825\n",
            "\n",
            "Epoch 1268: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2937 Val_Loss: 50.4672  BEST VAL Loss: 49.9825\n",
            "\n",
            "Epoch 1269: Validation loss decreased (49.982533 --> 49.790382).\n",
            "\t Train_Loss: 7.2809 Val_Loss: 49.7904  BEST VAL Loss: 49.7904\n",
            "\n",
            "Epoch 1270: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2654 Val_Loss: 49.9180  BEST VAL Loss: 49.7904\n",
            "\n",
            "Epoch 1271: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2505 Val_Loss: 50.2556  BEST VAL Loss: 49.7904\n",
            "\n",
            "Epoch 1272: Validation loss decreased (49.790382 --> 49.650688).\n",
            "\t Train_Loss: 7.2393 Val_Loss: 49.6507  BEST VAL Loss: 49.6507\n",
            "\n",
            "Epoch 1273: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2263 Val_Loss: 49.7192  BEST VAL Loss: 49.6507\n",
            "\n",
            "Epoch 1274: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2134 Val_Loss: 49.9952  BEST VAL Loss: 49.6507\n",
            "\n",
            "Epoch 1275: Validation loss decreased (49.650688 --> 49.618023).\n",
            "\t Train_Loss: 7.2011 Val_Loss: 49.6180  BEST VAL Loss: 49.6180\n",
            "\n",
            "Epoch 1276: Validation loss decreased (49.618023 --> 49.458717).\n",
            "\t Train_Loss: 7.1850 Val_Loss: 49.4587  BEST VAL Loss: 49.4587\n",
            "\n",
            "Epoch 1277: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1705 Val_Loss: 49.7909  BEST VAL Loss: 49.4587\n",
            "\n",
            "Epoch 1278: Validation loss decreased (49.458717 --> 49.373360).\n",
            "\t Train_Loss: 7.1584 Val_Loss: 49.3734  BEST VAL Loss: 49.3734\n",
            "\n",
            "Epoch 1279: Validation loss decreased (49.373360 --> 49.195366).\n",
            "\t Train_Loss: 7.1435 Val_Loss: 49.1954  BEST VAL Loss: 49.1954\n",
            "\n",
            "Epoch 1280: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1307 Val_Loss: 49.4788  BEST VAL Loss: 49.1954\n",
            "\n",
            "Epoch 1281: Validation loss decreased (49.195366 --> 49.189552).\n",
            "\t Train_Loss: 7.1183 Val_Loss: 49.1896  BEST VAL Loss: 49.1896\n",
            "\n",
            "Epoch 1282: Validation loss decreased (49.189552 --> 49.084297).\n",
            "\t Train_Loss: 7.1036 Val_Loss: 49.0843  BEST VAL Loss: 49.0843\n",
            "\n",
            "Epoch 1283: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0921 Val_Loss: 49.2712  BEST VAL Loss: 49.0843\n",
            "\n",
            "Epoch 1284: Validation loss decreased (49.084297 --> 49.063416).\n",
            "\t Train_Loss: 7.0802 Val_Loss: 49.0634  BEST VAL Loss: 49.0634\n",
            "\n",
            "Epoch 1285: Validation loss decreased (49.063416 --> 48.775364).\n",
            "\t Train_Loss: 7.0667 Val_Loss: 48.7754  BEST VAL Loss: 48.7754\n",
            "\n",
            "Epoch 1286: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0552 Val_Loss: 49.0411  BEST VAL Loss: 48.7754\n",
            "\n",
            "Epoch 1287: Validation loss decreased (48.775364 --> 48.732567).\n",
            "\t Train_Loss: 7.0431 Val_Loss: 48.7326  BEST VAL Loss: 48.7326\n",
            "\n",
            "Epoch 1288: Validation loss decreased (48.732567 --> 48.717060).\n",
            "\t Train_Loss: 7.0318 Val_Loss: 48.7171  BEST VAL Loss: 48.7171\n",
            "\n",
            "Epoch 1289: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0207 Val_Loss: 48.7225  BEST VAL Loss: 48.7171\n",
            "\n",
            "Epoch 1290: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0110 Val_Loss: 48.7485  BEST VAL Loss: 48.7171\n",
            "\n",
            "Epoch 1291: Validation loss decreased (48.717060 --> 48.367939).\n",
            "\t Train_Loss: 6.9998 Val_Loss: 48.3679  BEST VAL Loss: 48.3679\n",
            "\n",
            "Epoch 1292: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9942 Val_Loss: 48.7758  BEST VAL Loss: 48.3679\n",
            "\n",
            "Epoch 1293: Validation loss decreased (48.367939 --> 48.339100).\n",
            "\t Train_Loss: 6.9849 Val_Loss: 48.3391  BEST VAL Loss: 48.3391\n",
            "\n",
            "Epoch 1294: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9823 Val_Loss: 48.4964  BEST VAL Loss: 48.3391\n",
            "\n",
            "Epoch 1295: Validation loss decreased (48.339100 --> 48.272129).\n",
            "\t Train_Loss: 6.9666 Val_Loss: 48.2721  BEST VAL Loss: 48.2721\n",
            "\n",
            "Epoch 1296: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9627 Val_Loss: 48.4740  BEST VAL Loss: 48.2721\n",
            "\n",
            "Epoch 1297: Validation loss decreased (48.272129 --> 47.943359).\n",
            "\t Train_Loss: 6.9430 Val_Loss: 47.9434  BEST VAL Loss: 47.9434\n",
            "\n",
            "Epoch 1298: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9373 Val_Loss: 48.4290  BEST VAL Loss: 47.9434\n",
            "\n",
            "Epoch 1299: Validation loss decreased (47.943359 --> 47.888226).\n",
            "\t Train_Loss: 6.9159 Val_Loss: 47.8882  BEST VAL Loss: 47.8882\n",
            "\n",
            "Epoch 1300: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9058 Val_Loss: 48.1476  BEST VAL Loss: 47.8882\n",
            "\n",
            "Epoch 1301: Validation loss decreased (47.888226 --> 47.875923).\n",
            "\t Train_Loss: 6.8863 Val_Loss: 47.8759  BEST VAL Loss: 47.8759\n",
            "\n",
            "Epoch 1302: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8786 Val_Loss: 48.0692  BEST VAL Loss: 47.8759\n",
            "\n",
            "Epoch 1303: Validation loss decreased (47.875923 --> 47.625488).\n",
            "\t Train_Loss: 6.8614 Val_Loss: 47.6255  BEST VAL Loss: 47.6255\n",
            "\n",
            "Epoch 1304: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8548 Val_Loss: 48.0332  BEST VAL Loss: 47.6255\n",
            "\n",
            "Epoch 1305: Validation loss decreased (47.625488 --> 47.470684).\n",
            "\t Train_Loss: 6.8386 Val_Loss: 47.4707  BEST VAL Loss: 47.4707\n",
            "\n",
            "Epoch 1306: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8346 Val_Loss: 47.8805  BEST VAL Loss: 47.4707\n",
            "\n",
            "Epoch 1307: Validation loss decreased (47.470684 --> 47.411144).\n",
            "\t Train_Loss: 6.8194 Val_Loss: 47.4111  BEST VAL Loss: 47.4111\n",
            "\n",
            "Epoch 1308: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8195 Val_Loss: 47.7660  BEST VAL Loss: 47.4111\n",
            "\n",
            "Epoch 1309: Validation loss decreased (47.411144 --> 47.207863).\n",
            "\t Train_Loss: 6.7995 Val_Loss: 47.2079  BEST VAL Loss: 47.2079\n",
            "\n",
            "Epoch 1310: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7967 Val_Loss: 47.7207  BEST VAL Loss: 47.2079\n",
            "\n",
            "Epoch 1311: Validation loss decreased (47.207863 --> 47.041878).\n",
            "\t Train_Loss: 6.7745 Val_Loss: 47.0419  BEST VAL Loss: 47.0419\n",
            "\n",
            "Epoch 1312: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7694 Val_Loss: 47.5911  BEST VAL Loss: 47.0419\n",
            "\n",
            "Epoch 1313: Validation loss decreased (47.041878 --> 47.025951).\n",
            "\t Train_Loss: 6.7462 Val_Loss: 47.0260  BEST VAL Loss: 47.0260\n",
            "\n",
            "Epoch 1314: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7377 Val_Loss: 47.3706  BEST VAL Loss: 47.0260\n",
            "\n",
            "Epoch 1315: Validation loss decreased (47.025951 --> 46.904865).\n",
            "\t Train_Loss: 6.7161 Val_Loss: 46.9049  BEST VAL Loss: 46.9049\n",
            "\n",
            "Epoch 1316: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7082 Val_Loss: 47.2925  BEST VAL Loss: 46.9049\n",
            "\n",
            "Epoch 1317: Validation loss decreased (46.904865 --> 46.662827).\n",
            "\t Train_Loss: 6.6908 Val_Loss: 46.6628  BEST VAL Loss: 46.6628\n",
            "\n",
            "Epoch 1318: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6867 Val_Loss: 47.2596  BEST VAL Loss: 46.6628\n",
            "\n",
            "Epoch 1319: Validation loss decreased (46.662827 --> 46.524315).\n",
            "\t Train_Loss: 6.6714 Val_Loss: 46.5243  BEST VAL Loss: 46.5243\n",
            "\n",
            "Epoch 1320: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6712 Val_Loss: 47.1597  BEST VAL Loss: 46.5243\n",
            "\n",
            "Epoch 1321: Validation loss decreased (46.524315 --> 46.473267).\n",
            "\t Train_Loss: 6.6547 Val_Loss: 46.4733  BEST VAL Loss: 46.4733\n",
            "\n",
            "Epoch 1322: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6561 Val_Loss: 47.0224  BEST VAL Loss: 46.4733\n",
            "\n",
            "Epoch 1323: Validation loss decreased (46.473267 --> 46.339996).\n",
            "\t Train_Loss: 6.6319 Val_Loss: 46.3400  BEST VAL Loss: 46.3400\n",
            "\n",
            "Epoch 1324: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6255 Val_Loss: 46.9155  BEST VAL Loss: 46.3400\n",
            "\n",
            "Epoch 1325: Validation loss decreased (46.339996 --> 46.157848).\n",
            "\t Train_Loss: 6.5998 Val_Loss: 46.1578  BEST VAL Loss: 46.1578\n",
            "\n",
            "Epoch 1326: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5907 Val_Loss: 46.8521  BEST VAL Loss: 46.1578\n",
            "\n",
            "Epoch 1327: Validation loss decreased (46.157848 --> 46.052174).\n",
            "\t Train_Loss: 6.5699 Val_Loss: 46.0522  BEST VAL Loss: 46.0522\n",
            "\n",
            "Epoch 1328: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5624 Val_Loss: 46.7101  BEST VAL Loss: 46.0522\n",
            "\n",
            "Epoch 1329: Validation loss decreased (46.052174 --> 45.972633).\n",
            "\t Train_Loss: 6.5451 Val_Loss: 45.9726  BEST VAL Loss: 45.9726\n",
            "\n",
            "Epoch 1330: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5419 Val_Loss: 46.5899  BEST VAL Loss: 45.9726\n",
            "\n",
            "Epoch 1331: Validation loss decreased (45.972633 --> 45.807171).\n",
            "\t Train_Loss: 6.5270 Val_Loss: 45.8072  BEST VAL Loss: 45.8072\n",
            "\n",
            "Epoch 1332: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5292 Val_Loss: 46.5859  BEST VAL Loss: 45.8072\n",
            "\n",
            "Epoch 1333: Validation loss decreased (45.807171 --> 45.575878).\n",
            "\t Train_Loss: 6.5118 Val_Loss: 45.5759  BEST VAL Loss: 45.5759\n",
            "\n",
            "Epoch 1334: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5187 Val_Loss: 46.6426  BEST VAL Loss: 45.5759\n",
            "\n",
            "Epoch 1335: Validation loss decreased (45.575878 --> 45.377522).\n",
            "\t Train_Loss: 6.4968 Val_Loss: 45.3775  BEST VAL Loss: 45.3775\n",
            "\n",
            "Epoch 1336: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5079 Val_Loss: 46.5982  BEST VAL Loss: 45.3775\n",
            "\n",
            "Epoch 1337: Validation loss decreased (45.377522 --> 45.220097).\n",
            "\t Train_Loss: 6.4776 Val_Loss: 45.2201  BEST VAL Loss: 45.2201\n",
            "\n",
            "Epoch 1338: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4868 Val_Loss: 46.4497  BEST VAL Loss: 45.2201\n",
            "\n",
            "Epoch 1339: Validation loss decreased (45.220097 --> 45.010021).\n",
            "\t Train_Loss: 6.4517 Val_Loss: 45.0100  BEST VAL Loss: 45.0100\n",
            "\n",
            "Epoch 1340: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4604 Val_Loss: 46.4238  BEST VAL Loss: 45.0100\n",
            "\n",
            "Epoch 1341: Validation loss decreased (45.010021 --> 44.819313).\n",
            "\t Train_Loss: 6.4241 Val_Loss: 44.8193  BEST VAL Loss: 44.8193\n",
            "\n",
            "Epoch 1342: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4278 Val_Loss: 46.3687  BEST VAL Loss: 44.8193\n",
            "\n",
            "Epoch 1343: Validation loss decreased (44.819313 --> 44.789326).\n",
            "\t Train_Loss: 6.3914 Val_Loss: 44.7893  BEST VAL Loss: 44.7893\n",
            "\n",
            "Epoch 1344: Validation loss did not decrease\n",
            "\t Train_Loss: 6.3908 Val_Loss: 46.0946  BEST VAL Loss: 44.7893\n",
            "\n",
            "Epoch 1345: Validation loss did not decrease\n",
            "\t Train_Loss: 6.3570 Val_Loss: 44.8454  BEST VAL Loss: 44.7893\n",
            "\n",
            "Epoch 1346: Validation loss did not decrease\n",
            "\t Train_Loss: 6.3580 Val_Loss: 45.6483  BEST VAL Loss: 44.7893\n",
            "\n",
            "Epoch 1347: Validation loss decreased (44.789326 --> 44.737286).\n",
            "\t Train_Loss: 6.3358 Val_Loss: 44.7373  BEST VAL Loss: 44.7373\n",
            "\n",
            "Epoch 1348: Validation loss did not decrease\n",
            "\t Train_Loss: 6.3600 Val_Loss: 45.6037  BEST VAL Loss: 44.7373\n",
            "\n",
            "Epoch 1349: Validation loss decreased (44.737286 --> 44.403252).\n",
            "\t Train_Loss: 6.3381 Val_Loss: 44.4033  BEST VAL Loss: 44.4033\n",
            "\n",
            "Epoch 1350: Validation loss did not decrease\n",
            "\t Train_Loss: 6.3838 Val_Loss: 45.8133  BEST VAL Loss: 44.4033\n",
            "\n",
            "Epoch 1351: Validation loss decreased (44.403252 --> 44.082741).\n",
            "\t Train_Loss: 6.3202 Val_Loss: 44.0827  BEST VAL Loss: 44.0827\n",
            "\n",
            "Epoch 1352: Validation loss did not decrease\n",
            "\t Train_Loss: 6.3217 Val_Loss: 45.8472  BEST VAL Loss: 44.0827\n",
            "\n",
            "Epoch 1353: Validation loss did not decrease\n",
            "\t Train_Loss: 6.2517 Val_Loss: 44.2946  BEST VAL Loss: 44.0827\n",
            "\n",
            "Epoch 1354: Validation loss did not decrease\n",
            "\t Train_Loss: 6.2108 Val_Loss: 45.1644  BEST VAL Loss: 44.0827\n",
            "\n",
            "Epoch 1355: Validation loss did not decrease\n",
            "\t Train_Loss: 6.1739 Val_Loss: 44.3928  BEST VAL Loss: 44.0827\n",
            "\n",
            "Epoch 1356: Validation loss did not decrease\n",
            "\t Train_Loss: 6.1501 Val_Loss: 44.7262  BEST VAL Loss: 44.0827\n",
            "\n",
            "Epoch 1357: Validation loss did not decrease\n",
            "\t Train_Loss: 6.1331 Val_Loss: 44.3090  BEST VAL Loss: 44.0827\n",
            "\n",
            "Epoch 1358: Validation loss did not decrease\n",
            "\t Train_Loss: 6.1166 Val_Loss: 44.3906  BEST VAL Loss: 44.0827\n",
            "\n",
            "Epoch 1359: Validation loss did not decrease\n",
            "\t Train_Loss: 6.1043 Val_Loss: 44.2526  BEST VAL Loss: 44.0827\n",
            "\n",
            "Epoch 1360: Validation loss did not decrease\n",
            "\t Train_Loss: 6.0956 Val_Loss: 44.5958  BEST VAL Loss: 44.0827\n",
            "\n",
            "Epoch 1361: Validation loss decreased (44.082741 --> 43.781261).\n",
            "\t Train_Loss: 6.1058 Val_Loss: 43.7813  BEST VAL Loss: 43.7813\n",
            "\n",
            "Epoch 1362: Validation loss did not decrease\n",
            "\t Train_Loss: 6.2306 Val_Loss: 45.2553  BEST VAL Loss: 43.7813\n",
            "\n",
            "Epoch 1363: Validation loss decreased (43.781261 --> 43.001945).\n",
            "\t Train_Loss: 6.3916 Val_Loss: 43.0019  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1364: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3826 Val_Loss: 45.1224  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1365: Validation loss did not decrease\n",
            "\t Train_Loss: 8.1508 Val_Loss: 45.8692  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1366: Validation loss did not decrease\n",
            "\t Train_Loss: 14.8223 Val_Loss: 47.9189  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1367: Validation loss did not decrease\n",
            "\t Train_Loss: 12.9094 Val_Loss: 56.4410  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1368: Validation loss did not decrease\n",
            "\t Train_Loss: 12.2670 Val_Loss: 55.3420  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1369: Validation loss did not decrease\n",
            "\t Train_Loss: 14.2008 Val_Loss: 45.6349  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1370: Validation loss did not decrease\n",
            "\t Train_Loss: 12.2297 Val_Loss: 43.2136  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1371: Validation loss did not decrease\n",
            "\t Train_Loss: 10.7655 Val_Loss: 48.6968  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1372: Validation loss did not decrease\n",
            "\t Train_Loss: 11.2495 Val_Loss: 56.9804  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1373: Validation loss did not decrease\n",
            "\t Train_Loss: 11.9194 Val_Loss: 59.7306  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1374: Validation loss did not decrease\n",
            "\t Train_Loss: 11.6327 Val_Loss: 59.3885  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1375: Validation loss did not decrease\n",
            "\t Train_Loss: 11.2781 Val_Loss: 57.6219  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1376: Validation loss did not decrease\n",
            "\t Train_Loss: 11.5558 Val_Loss: 55.3242  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1377: Validation loss did not decrease\n",
            "\t Train_Loss: 11.6670 Val_Loss: 51.5568  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1378: Validation loss did not decrease\n",
            "\t Train_Loss: 10.9911 Val_Loss: 45.9349  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1379: Validation loss did not decrease\n",
            "\t Train_Loss: 10.5343 Val_Loss: 44.2708  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1380: Validation loss did not decrease\n",
            "\t Train_Loss: 10.2577 Val_Loss: 43.4944  BEST VAL Loss: 43.0019\n",
            "\n",
            "Epoch 1381: Validation loss decreased (43.001945 --> 42.085407).\n",
            "\t Train_Loss: 10.1429 Val_Loss: 42.0854  BEST VAL Loss: 42.0854\n",
            "\n",
            "Epoch 1382: Validation loss decreased (42.085407 --> 40.072395).\n",
            "\t Train_Loss: 9.8745 Val_Loss: 40.0724  BEST VAL Loss: 40.0724\n",
            "\n",
            "Epoch 1383: Validation loss decreased (40.072395 --> 39.720497).\n",
            "\t Train_Loss: 9.5145 Val_Loss: 39.7205  BEST VAL Loss: 39.7205\n",
            "\n",
            "Epoch 1384: Validation loss did not decrease\n",
            "\t Train_Loss: 9.5120 Val_Loss: 40.5638  BEST VAL Loss: 39.7205\n",
            "\n",
            "Epoch 1385: Validation loss did not decrease\n",
            "\t Train_Loss: 9.2700 Val_Loss: 42.5541  BEST VAL Loss: 39.7205\n",
            "\n",
            "Epoch 1386: Validation loss did not decrease\n",
            "\t Train_Loss: 9.2784 Val_Loss: 40.8163  BEST VAL Loss: 39.7205\n",
            "\n",
            "Epoch 1387: Validation loss decreased (39.720497 --> 39.655182).\n",
            "\t Train_Loss: 8.8831 Val_Loss: 39.6552  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1388: Validation loss did not decrease\n",
            "\t Train_Loss: 8.9595 Val_Loss: 41.5352  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1389: Validation loss did not decrease\n",
            "\t Train_Loss: 8.5529 Val_Loss: 45.2086  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1390: Validation loss did not decrease\n",
            "\t Train_Loss: 8.4014 Val_Loss: 46.8799  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1391: Validation loss did not decrease\n",
            "\t Train_Loss: 7.8479 Val_Loss: 48.6432  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1392: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6020 Val_Loss: 50.5655  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1393: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7119 Val_Loss: 49.5520  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1394: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4848 Val_Loss: 49.6266  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1395: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1997 Val_Loss: 50.9058  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1396: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2398 Val_Loss: 49.6409  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1397: Validation loss did not decrease\n",
            "\t Train_Loss: 7.2561 Val_Loss: 46.3431  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1398: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0093 Val_Loss: 45.7660  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1399: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9132 Val_Loss: 47.3844  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1400: Validation loss did not decrease\n",
            "\t Train_Loss: 6.9480 Val_Loss: 44.4911  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1401: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8275 Val_Loss: 42.1172  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1402: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7944 Val_Loss: 42.0110  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1403: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7322 Val_Loss: 42.8564  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1404: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5803 Val_Loss: 43.5228  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1405: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5044 Val_Loss: 43.3724  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1406: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5035 Val_Loss: 43.0157  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1407: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4748 Val_Loss: 43.0216  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1408: Validation loss did not decrease\n",
            "\t Train_Loss: 6.3993 Val_Loss: 42.8958  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1409: Validation loss did not decrease\n",
            "\t Train_Loss: 6.3591 Val_Loss: 40.8922  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1410: Validation loss did not decrease\n",
            "\t Train_Loss: 6.3142 Val_Loss: 42.8906  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1411: Validation loss did not decrease\n",
            "\t Train_Loss: 6.3380 Val_Loss: 41.4029  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1412: Validation loss did not decrease\n",
            "\t Train_Loss: 6.2494 Val_Loss: 41.9648  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1413: Validation loss did not decrease\n",
            "\t Train_Loss: 6.2783 Val_Loss: 45.0291  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1414: Validation loss did not decrease\n",
            "\t Train_Loss: 6.2803 Val_Loss: 41.5572  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1415: Validation loss did not decrease\n",
            "\t Train_Loss: 6.1768 Val_Loss: 43.2347  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1416: Validation loss did not decrease\n",
            "\t Train_Loss: 6.1036 Val_Loss: 46.0379  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1417: Validation loss did not decrease\n",
            "\t Train_Loss: 6.2584 Val_Loss: 41.1501  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1418: Validation loss did not decrease\n",
            "\t Train_Loss: 6.1718 Val_Loss: 41.4185  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1419: Validation loss did not decrease\n",
            "\t Train_Loss: 6.0108 Val_Loss: 44.7243  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1420: Validation loss did not decrease\n",
            "\t Train_Loss: 6.1849 Val_Loss: 40.5658  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1421: Validation loss did not decrease\n",
            "\t Train_Loss: 6.0720 Val_Loss: 40.0631  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1422: Validation loss did not decrease\n",
            "\t Train_Loss: 6.0110 Val_Loss: 43.5349  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1423: Validation loss did not decrease\n",
            "\t Train_Loss: 6.0985 Val_Loss: 41.2692  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1424: Validation loss did not decrease\n",
            "\t Train_Loss: 5.9384 Val_Loss: 40.9487  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1425: Validation loss did not decrease\n",
            "\t Train_Loss: 5.9226 Val_Loss: 43.0734  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1426: Validation loss did not decrease\n",
            "\t Train_Loss: 6.0340 Val_Loss: 41.2254  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1427: Validation loss did not decrease\n",
            "\t Train_Loss: 5.9299 Val_Loss: 41.2224  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1428: Validation loss did not decrease\n",
            "\t Train_Loss: 5.8554 Val_Loss: 42.4103  BEST VAL Loss: 39.6552\n",
            "\n",
            "Epoch 1429: Validation loss decreased (39.655182 --> 39.545746).\n",
            "\t Train_Loss: 5.9870 Val_Loss: 39.5457  BEST VAL Loss: 39.5457\n",
            "\n",
            "Epoch 1430: Validation loss did not decrease\n",
            "\t Train_Loss: 5.9219 Val_Loss: 40.4727  BEST VAL Loss: 39.5457\n",
            "\n",
            "Epoch 1431: Validation loss did not decrease\n",
            "\t Train_Loss: 5.8339 Val_Loss: 42.8420  BEST VAL Loss: 39.5457\n",
            "\n",
            "Epoch 1432: Validation loss decreased (39.545746 --> 39.032948).\n",
            "\t Train_Loss: 6.0279 Val_Loss: 39.0329  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1433: Validation loss did not decrease\n",
            "\t Train_Loss: 5.9868 Val_Loss: 40.0140  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1434: Validation loss did not decrease\n",
            "\t Train_Loss: 5.8200 Val_Loss: 43.9609  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1435: Validation loss did not decrease\n",
            "\t Train_Loss: 6.1633 Val_Loss: 39.5205  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1436: Validation loss did not decrease\n",
            "\t Train_Loss: 6.1487 Val_Loss: 39.6962  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1437: Validation loss did not decrease\n",
            "\t Train_Loss: 5.9329 Val_Loss: 43.6804  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1438: Validation loss did not decrease\n",
            "\t Train_Loss: 6.2595 Val_Loss: 40.5819  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1439: Validation loss did not decrease\n",
            "\t Train_Loss: 5.8644 Val_Loss: 39.4847  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1440: Validation loss did not decrease\n",
            "\t Train_Loss: 5.9565 Val_Loss: 42.0645  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1441: Validation loss did not decrease\n",
            "\t Train_Loss: 5.9347 Val_Loss: 40.1128  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1442: Validation loss did not decrease\n",
            "\t Train_Loss: 5.6905 Val_Loss: 39.7858  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1443: Validation loss did not decrease\n",
            "\t Train_Loss: 5.8277 Val_Loss: 41.5248  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1444: Validation loss did not decrease\n",
            "\t Train_Loss: 5.7011 Val_Loss: 40.6999  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1445: Validation loss did not decrease\n",
            "\t Train_Loss: 5.6803 Val_Loss: 39.5581  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1446: Validation loss did not decrease\n",
            "\t Train_Loss: 5.7472 Val_Loss: 41.7023  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1447: Validation loss did not decrease\n",
            "\t Train_Loss: 5.6400 Val_Loss: 41.8274  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1448: Validation loss did not decrease\n",
            "\t Train_Loss: 5.6749 Val_Loss: 39.3510  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1449: Validation loss did not decrease\n",
            "\t Train_Loss: 5.7036 Val_Loss: 40.1465  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1450: Validation loss did not decrease\n",
            "\t Train_Loss: 5.6055 Val_Loss: 41.8877  BEST VAL Loss: 39.0329\n",
            "\n",
            "Epoch 1451: Validation loss decreased (39.032948 --> 38.302635).\n",
            "\t Train_Loss: 5.7203 Val_Loss: 38.3026  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1452: Validation loss did not decrease\n",
            "\t Train_Loss: 5.7153 Val_Loss: 39.1358  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1453: Validation loss did not decrease\n",
            "\t Train_Loss: 5.5827 Val_Loss: 41.8135  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1454: Validation loss did not decrease\n",
            "\t Train_Loss: 5.7505 Val_Loss: 38.5658  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1455: Validation loss did not decrease\n",
            "\t Train_Loss: 5.7657 Val_Loss: 39.3689  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1456: Validation loss did not decrease\n",
            "\t Train_Loss: 5.5843 Val_Loss: 42.5145  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1457: Validation loss did not decrease\n",
            "\t Train_Loss: 5.8754 Val_Loss: 39.0007  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1458: Validation loss did not decrease\n",
            "\t Train_Loss: 5.8106 Val_Loss: 39.2934  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1459: Validation loss did not decrease\n",
            "\t Train_Loss: 5.6616 Val_Loss: 42.3729  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1460: Validation loss did not decrease\n",
            "\t Train_Loss: 5.9128 Val_Loss: 39.3754  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1461: Validation loss did not decrease\n",
            "\t Train_Loss: 5.6062 Val_Loss: 38.9272  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1462: Validation loss did not decrease\n",
            "\t Train_Loss: 5.6711 Val_Loss: 41.6225  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1463: Validation loss did not decrease\n",
            "\t Train_Loss: 5.7042 Val_Loss: 39.1366  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1464: Validation loss did not decrease\n",
            "\t Train_Loss: 5.5116 Val_Loss: 39.1499  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1465: Validation loss did not decrease\n",
            "\t Train_Loss: 5.5785 Val_Loss: 41.2786  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1466: Validation loss did not decrease\n",
            "\t Train_Loss: 5.5454 Val_Loss: 39.6577  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1467: Validation loss did not decrease\n",
            "\t Train_Loss: 5.4679 Val_Loss: 38.9662  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1468: Validation loss did not decrease\n",
            "\t Train_Loss: 5.5131 Val_Loss: 40.9281  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1469: Validation loss did not decrease\n",
            "\t Train_Loss: 5.4736 Val_Loss: 40.2708  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1470: Validation loss did not decrease\n",
            "\t Train_Loss: 5.4451 Val_Loss: 38.9827  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1471: Validation loss did not decrease\n",
            "\t Train_Loss: 5.4684 Val_Loss: 40.0681  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1472: Validation loss did not decrease\n",
            "\t Train_Loss: 5.4288 Val_Loss: 40.3378  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1473: Validation loss did not decrease\n",
            "\t Train_Loss: 5.4309 Val_Loss: 38.9092  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1474: Validation loss did not decrease\n",
            "\t Train_Loss: 5.4417 Val_Loss: 39.7603  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1475: Validation loss did not decrease\n",
            "\t Train_Loss: 5.4073 Val_Loss: 40.3495  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1476: Validation loss did not decrease\n",
            "\t Train_Loss: 5.4085 Val_Loss: 39.2729  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1477: Validation loss did not decrease\n",
            "\t Train_Loss: 5.4163 Val_Loss: 39.7547  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1478: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3845 Val_Loss: 40.0877  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1479: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3869 Val_Loss: 39.2241  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1480: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3950 Val_Loss: 39.7167  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1481: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3625 Val_Loss: 39.7793  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1482: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3675 Val_Loss: 38.7740  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1483: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3749 Val_Loss: 39.6463  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1484: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3425 Val_Loss: 39.6977  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1485: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3434 Val_Loss: 38.7389  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1486: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3515 Val_Loss: 39.6223  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1487: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3221 Val_Loss: 39.7253  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1488: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3218 Val_Loss: 38.6001  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1489: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3312 Val_Loss: 39.4579  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1490: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3043 Val_Loss: 39.5157  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1491: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2984 Val_Loss: 38.5655  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1492: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3058 Val_Loss: 39.2631  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1493: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2871 Val_Loss: 39.1086  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1494: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2748 Val_Loss: 38.6882  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1495: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2775 Val_Loss: 39.3073  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1496: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2690 Val_Loss: 38.8081  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1497: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2559 Val_Loss: 38.8375  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1498: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2505 Val_Loss: 39.2733  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1499: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2486 Val_Loss: 38.5582  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1500: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2420 Val_Loss: 38.9769  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1501: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2303 Val_Loss: 39.1006  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1502: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2256 Val_Loss: 38.4769  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1503: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2237 Val_Loss: 38.9657  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1504: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2149 Val_Loss: 38.7277  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1505: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2053 Val_Loss: 38.6417  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1506: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1997 Val_Loss: 38.8434  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1507: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1959 Val_Loss: 38.3576  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1508: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1903 Val_Loss: 38.7867  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1509: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1815 Val_Loss: 38.5884  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1510: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1742 Val_Loss: 38.3785  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1511: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1692 Val_Loss: 38.7184  BEST VAL Loss: 38.3026\n",
            "\n",
            "Epoch 1512: Validation loss decreased (38.302635 --> 38.300865).\n",
            "\t Train_Loss: 5.1643 Val_Loss: 38.3009  BEST VAL Loss: 38.3009\n",
            "\n",
            "Epoch 1513: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1582 Val_Loss: 38.5317  BEST VAL Loss: 38.3009\n",
            "\n",
            "Epoch 1514: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1505 Val_Loss: 38.3937  BEST VAL Loss: 38.3009\n",
            "\n",
            "Epoch 1515: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1436 Val_Loss: 38.3151  BEST VAL Loss: 38.3009\n",
            "\n",
            "Epoch 1516: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1379 Val_Loss: 38.4598  BEST VAL Loss: 38.3009\n",
            "\n",
            "Epoch 1517: Validation loss decreased (38.300865 --> 38.096001).\n",
            "\t Train_Loss: 5.1327 Val_Loss: 38.0960  BEST VAL Loss: 38.0960\n",
            "\n",
            "Epoch 1518: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1273 Val_Loss: 38.4506  BEST VAL Loss: 38.0960\n",
            "\n",
            "Epoch 1519: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1208 Val_Loss: 38.1586  BEST VAL Loss: 38.0960\n",
            "\n",
            "Epoch 1520: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1139 Val_Loss: 38.2373  BEST VAL Loss: 38.0960\n",
            "\n",
            "Epoch 1521: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1072 Val_Loss: 38.1894  BEST VAL Loss: 38.0960\n",
            "\n",
            "Epoch 1522: Validation loss decreased (38.096001 --> 38.087029).\n",
            "\t Train_Loss: 5.1010 Val_Loss: 38.0870  BEST VAL Loss: 38.0870\n",
            "\n",
            "Epoch 1523: Validation loss did not decrease\n",
            "\t Train_Loss: 5.0953 Val_Loss: 38.2133  BEST VAL Loss: 38.0870\n",
            "\n",
            "Epoch 1524: Validation loss decreased (38.087029 --> 37.899414).\n",
            "\t Train_Loss: 5.0897 Val_Loss: 37.8994  BEST VAL Loss: 37.8994\n",
            "\n",
            "Epoch 1525: Validation loss did not decrease\n",
            "\t Train_Loss: 5.0843 Val_Loss: 38.1878  BEST VAL Loss: 37.8994\n",
            "\n",
            "Epoch 1526: Validation loss decreased (37.899414 --> 37.819725).\n",
            "\t Train_Loss: 5.0784 Val_Loss: 37.8197  BEST VAL Loss: 37.8197\n",
            "\n",
            "Epoch 1527: Validation loss did not decrease\n",
            "\t Train_Loss: 5.0728 Val_Loss: 38.1248  BEST VAL Loss: 37.8197\n",
            "\n",
            "Epoch 1528: Validation loss decreased (37.819725 --> 37.751274).\n",
            "\t Train_Loss: 5.0668 Val_Loss: 37.7513  BEST VAL Loss: 37.7513\n",
            "\n",
            "Epoch 1529: Validation loss did not decrease\n",
            "\t Train_Loss: 5.0613 Val_Loss: 38.1131  BEST VAL Loss: 37.7513\n",
            "\n",
            "Epoch 1530: Validation loss decreased (37.751274 --> 37.633621).\n",
            "\t Train_Loss: 5.0554 Val_Loss: 37.6336  BEST VAL Loss: 37.6336\n",
            "\n",
            "Epoch 1531: Validation loss did not decrease\n",
            "\t Train_Loss: 5.0505 Val_Loss: 38.0918  BEST VAL Loss: 37.6336\n",
            "\n",
            "Epoch 1532: Validation loss decreased (37.633621 --> 37.495743).\n",
            "\t Train_Loss: 5.0453 Val_Loss: 37.4957  BEST VAL Loss: 37.4957\n",
            "\n",
            "Epoch 1533: Validation loss did not decrease\n",
            "\t Train_Loss: 5.0430 Val_Loss: 38.1758  BEST VAL Loss: 37.4957\n",
            "\n",
            "Epoch 1534: Validation loss decreased (37.495743 --> 37.184799).\n",
            "\t Train_Loss: 5.0399 Val_Loss: 37.1848  BEST VAL Loss: 37.1848\n",
            "\n",
            "Epoch 1535: Validation loss did not decrease\n",
            "\t Train_Loss: 5.0469 Val_Loss: 38.3646  BEST VAL Loss: 37.1848\n",
            "\n",
            "Epoch 1536: Validation loss decreased (37.184799 --> 36.857147).\n",
            "\t Train_Loss: 5.0455 Val_Loss: 36.8571  BEST VAL Loss: 36.8571\n",
            "\n",
            "Epoch 1537: Validation loss did not decrease\n",
            "\t Train_Loss: 5.0763 Val_Loss: 38.4794  BEST VAL Loss: 36.8571\n",
            "\n",
            "Epoch 1538: Validation loss did not decrease\n",
            "\t Train_Loss: 5.0469 Val_Loss: 37.0276  BEST VAL Loss: 36.8571\n",
            "\n",
            "Epoch 1539: Validation loss did not decrease\n",
            "\t Train_Loss: 5.0546 Val_Loss: 38.2831  BEST VAL Loss: 36.8571\n",
            "\n",
            "Epoch 1540: Validation loss did not decrease\n",
            "\t Train_Loss: 5.0149 Val_Loss: 37.4374  BEST VAL Loss: 36.8571\n",
            "\n",
            "Epoch 1541: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9987 Val_Loss: 37.8833  BEST VAL Loss: 36.8571\n",
            "\n",
            "Epoch 1542: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9855 Val_Loss: 37.5498  BEST VAL Loss: 36.8571\n",
            "\n",
            "Epoch 1543: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9777 Val_Loss: 37.4790  BEST VAL Loss: 36.8571\n",
            "\n",
            "Epoch 1544: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9718 Val_Loss: 37.5403  BEST VAL Loss: 36.8571\n",
            "\n",
            "Epoch 1545: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9669 Val_Loss: 37.1383  BEST VAL Loss: 36.8571\n",
            "\n",
            "Epoch 1546: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9646 Val_Loss: 37.7563  BEST VAL Loss: 36.8571\n",
            "\n",
            "Epoch 1547: Validation loss decreased (36.857147 --> 36.483929).\n",
            "\t Train_Loss: 4.9690 Val_Loss: 36.4839  BEST VAL Loss: 36.4839\n",
            "\n",
            "Epoch 1548: Validation loss did not decrease\n",
            "\t Train_Loss: 5.0101 Val_Loss: 38.3899  BEST VAL Loss: 36.4839\n",
            "\n",
            "Epoch 1549: Validation loss decreased (36.483929 --> 35.815289).\n",
            "\t Train_Loss: 5.0336 Val_Loss: 35.8153  BEST VAL Loss: 35.8153\n",
            "\n",
            "Epoch 1550: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2256 Val_Loss: 37.9733  BEST VAL Loss: 35.8153\n",
            "\n",
            "Epoch 1551: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9693 Val_Loss: 39.6422  BEST VAL Loss: 35.8153\n",
            "\n",
            "Epoch 1552: Validation loss decreased (35.815289 --> 35.016815).\n",
            "\t Train_Loss: 5.1552 Val_Loss: 35.0168  BEST VAL Loss: 35.0168\n",
            "\n",
            "Epoch 1553: Validation loss did not decrease\n",
            "\t Train_Loss: 6.0244 Val_Loss: 37.8344  BEST VAL Loss: 35.0168\n",
            "\n",
            "Epoch 1554: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2164 Val_Loss: 43.1746  BEST VAL Loss: 35.0168\n",
            "\n",
            "Epoch 1555: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6378 Val_Loss: 37.6330  BEST VAL Loss: 35.0168\n",
            "\n",
            "Epoch 1556: Validation loss did not decrease\n",
            "\t Train_Loss: 9.0360 Val_Loss: 38.9119  BEST VAL Loss: 35.0168\n",
            "\n",
            "Epoch 1557: Validation loss did not decrease\n",
            "\t Train_Loss: 5.9270 Val_Loss: 40.8193  BEST VAL Loss: 35.0168\n",
            "\n",
            "Epoch 1558: Validation loss did not decrease\n",
            "\t Train_Loss: 9.5559 Val_Loss: 41.7569  BEST VAL Loss: 35.0168\n",
            "\n",
            "Epoch 1559: Validation loss did not decrease\n",
            "\t Train_Loss: 7.6493 Val_Loss: 38.6775  BEST VAL Loss: 35.0168\n",
            "\n",
            "Epoch 1560: Validation loss did not decrease\n",
            "\t Train_Loss: 10.6915 Val_Loss: 40.3995  BEST VAL Loss: 35.0168\n",
            "\n",
            "Epoch 1561: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4045 Val_Loss: 44.3651  BEST VAL Loss: 35.0168\n",
            "\n",
            "Epoch 1562: Validation loss decreased (35.016815 --> 32.016712).\n",
            "\t Train_Loss: 10.2794 Val_Loss: 32.0167  BEST VAL Loss: 32.0167\n",
            "\n",
            "Epoch 1563: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3919 Val_Loss: 33.0094  BEST VAL Loss: 32.0167\n",
            "\n",
            "Epoch 1564: Validation loss did not decrease\n",
            "\t Train_Loss: 7.3559 Val_Loss: 38.6845  BEST VAL Loss: 32.0167\n",
            "\n",
            "Epoch 1565: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1559 Val_Loss: 42.0883  BEST VAL Loss: 32.0167\n",
            "\n",
            "Epoch 1566: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7721 Val_Loss: 43.8732  BEST VAL Loss: 32.0167\n",
            "\n",
            "Epoch 1567: Validation loss decreased (32.016712 --> 31.798435).\n",
            "\t Train_Loss: 6.8159 Val_Loss: 31.7984  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1568: Validation loss did not decrease\n",
            "\t Train_Loss: 7.4577 Val_Loss: 32.1711  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1569: Validation loss did not decrease\n",
            "\t Train_Loss: 7.0271 Val_Loss: 44.8874  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1570: Validation loss did not decrease\n",
            "\t Train_Loss: 5.7357 Val_Loss: 51.5172  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1571: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7886 Val_Loss: 34.8740  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1572: Validation loss did not decrease\n",
            "\t Train_Loss: 7.1919 Val_Loss: 32.8246  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1573: Validation loss did not decrease\n",
            "\t Train_Loss: 7.7395 Val_Loss: 34.1185  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1574: Validation loss did not decrease\n",
            "\t Train_Loss: 6.7576 Val_Loss: 44.9314  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1575: Validation loss did not decrease\n",
            "\t Train_Loss: 6.4123 Val_Loss: 46.8212  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1576: Validation loss did not decrease\n",
            "\t Train_Loss: 6.5515 Val_Loss: 37.8392  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1577: Validation loss did not decrease\n",
            "\t Train_Loss: 5.8568 Val_Loss: 35.8727  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1578: Validation loss did not decrease\n",
            "\t Train_Loss: 5.9057 Val_Loss: 37.3303  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1579: Validation loss did not decrease\n",
            "\t Train_Loss: 5.5028 Val_Loss: 36.1320  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1580: Validation loss did not decrease\n",
            "\t Train_Loss: 5.8480 Val_Loss: 40.2378  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1581: Validation loss did not decrease\n",
            "\t Train_Loss: 6.6318 Val_Loss: 34.6979  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1582: Validation loss did not decrease\n",
            "\t Train_Loss: 6.8321 Val_Loss: 32.1663  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1583: Validation loss did not decrease\n",
            "\t Train_Loss: 6.2084 Val_Loss: 33.0869  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1584: Validation loss did not decrease\n",
            "\t Train_Loss: 5.4654 Val_Loss: 41.3297  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1585: Validation loss did not decrease\n",
            "\t Train_Loss: 6.1639 Val_Loss: 39.4997  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1586: Validation loss did not decrease\n",
            "\t Train_Loss: 5.8559 Val_Loss: 36.1379  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1587: Validation loss did not decrease\n",
            "\t Train_Loss: 6.1556 Val_Loss: 36.1125  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1588: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3863 Val_Loss: 34.8398  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1589: Validation loss did not decrease\n",
            "\t Train_Loss: 6.0350 Val_Loss: 32.8910  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1590: Validation loss did not decrease\n",
            "\t Train_Loss: 5.4037 Val_Loss: 33.4794  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1591: Validation loss did not decrease\n",
            "\t Train_Loss: 5.6374 Val_Loss: 36.6477  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1592: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2300 Val_Loss: 38.7292  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1593: Validation loss did not decrease\n",
            "\t Train_Loss: 5.7283 Val_Loss: 34.0073  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1594: Validation loss did not decrease\n",
            "\t Train_Loss: 5.4244 Val_Loss: 35.4731  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1595: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3293 Val_Loss: 39.5320  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1596: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3194 Val_Loss: 39.7118  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1597: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3033 Val_Loss: 36.3226  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1598: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2344 Val_Loss: 35.7929  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1599: Validation loss did not decrease\n",
            "\t Train_Loss: 5.3988 Val_Loss: 39.0454  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1600: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9931 Val_Loss: 40.5785  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1601: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1841 Val_Loss: 37.3231  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1602: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1504 Val_Loss: 35.7518  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1603: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2897 Val_Loss: 37.4404  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1604: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9363 Val_Loss: 40.3176  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1605: Validation loss did not decrease\n",
            "\t Train_Loss: 5.2963 Val_Loss: 35.3428  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1606: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1599 Val_Loss: 34.9517  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1607: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1787 Val_Loss: 37.5646  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1608: Validation loss did not decrease\n",
            "\t Train_Loss: 5.0618 Val_Loss: 39.4930  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1609: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1722 Val_Loss: 37.8497  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1610: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9447 Val_Loss: 36.3943  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1611: Validation loss did not decrease\n",
            "\t Train_Loss: 5.1164 Val_Loss: 37.4187  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1612: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9428 Val_Loss: 38.0393  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1613: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9784 Val_Loss: 36.5393  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1614: Validation loss did not decrease\n",
            "\t Train_Loss: 5.0174 Val_Loss: 35.2537  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1615: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9730 Val_Loss: 35.8482  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1616: Validation loss did not decrease\n",
            "\t Train_Loss: 4.8884 Val_Loss: 37.0344  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1617: Validation loss did not decrease\n",
            "\t Train_Loss: 4.8979 Val_Loss: 36.5980  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1618: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9660 Val_Loss: 36.7856  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1619: Validation loss did not decrease\n",
            "\t Train_Loss: 4.8639 Val_Loss: 36.8312  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1620: Validation loss did not decrease\n",
            "\t Train_Loss: 4.9186 Val_Loss: 36.1037  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1621: Validation loss did not decrease\n",
            "\t Train_Loss: 4.8324 Val_Loss: 36.3960  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1622: Validation loss did not decrease\n",
            "\t Train_Loss: 4.8685 Val_Loss: 37.4511  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1623: Validation loss did not decrease\n",
            "\t Train_Loss: 4.8153 Val_Loss: 37.4944  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1624: Validation loss did not decrease\n",
            "\t Train_Loss: 4.8866 Val_Loss: 35.6852  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1625: Validation loss did not decrease\n",
            "\t Train_Loss: 4.8467 Val_Loss: 36.5779  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1626: Validation loss did not decrease\n",
            "\t Train_Loss: 4.8275 Val_Loss: 38.1804  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1627: Validation loss did not decrease\n",
            "\t Train_Loss: 4.8325 Val_Loss: 37.3053  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1628: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7816 Val_Loss: 35.8464  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1629: Validation loss did not decrease\n",
            "\t Train_Loss: 4.8379 Val_Loss: 36.7405  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1630: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7652 Val_Loss: 37.6864  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1631: Validation loss did not decrease\n",
            "\t Train_Loss: 4.8130 Val_Loss: 36.2628  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1632: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7699 Val_Loss: 35.8425  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1633: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7798 Val_Loss: 37.1327  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1634: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7652 Val_Loss: 37.5224  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1635: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7527 Val_Loss: 36.4638  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1636: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7538 Val_Loss: 36.0937  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1637: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7376 Val_Loss: 36.7261  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1638: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7529 Val_Loss: 36.6915  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1639: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7259 Val_Loss: 36.3340  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1640: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7319 Val_Loss: 36.4253  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1641: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7216 Val_Loss: 36.2604  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1642: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7095 Val_Loss: 36.2525  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1643: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7178 Val_Loss: 36.5509  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1644: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6984 Val_Loss: 36.5798  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1645: Validation loss did not decrease\n",
            "\t Train_Loss: 4.7074 Val_Loss: 36.1241  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1646: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6989 Val_Loss: 36.6437  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1647: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6871 Val_Loss: 37.0388  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1648: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6950 Val_Loss: 36.3319  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1649: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6796 Val_Loss: 36.1273  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1650: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6807 Val_Loss: 36.7150  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1651: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6749 Val_Loss: 36.4188  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1652: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6656 Val_Loss: 35.8567  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1653: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6676 Val_Loss: 36.1071  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1654: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6592 Val_Loss: 36.4200  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1655: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6557 Val_Loss: 36.1913  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1656: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6545 Val_Loss: 36.0992  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1657: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6459 Val_Loss: 36.1342  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1658: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6451 Val_Loss: 36.0551  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1659: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6413 Val_Loss: 36.1578  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1660: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6350 Val_Loss: 36.1378  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1661: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6338 Val_Loss: 35.8670  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1662: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6290 Val_Loss: 36.0699  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1663: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6237 Val_Loss: 36.1995  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1664: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6223 Val_Loss: 35.8098  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1665: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6182 Val_Loss: 35.9163  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1666: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6120 Val_Loss: 36.1109  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1667: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6108 Val_Loss: 35.7724  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1668: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6072 Val_Loss: 35.8036  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1669: Validation loss did not decrease\n",
            "\t Train_Loss: 4.6009 Val_Loss: 35.9703  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1670: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5992 Val_Loss: 35.7696  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1671: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5965 Val_Loss: 35.8005  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1672: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5899 Val_Loss: 35.7467  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1673: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5872 Val_Loss: 35.6160  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1674: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5853 Val_Loss: 35.8552  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1675: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5799 Val_Loss: 35.6950  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1676: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5751 Val_Loss: 35.5315  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1677: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5729 Val_Loss: 35.7335  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1678: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5693 Val_Loss: 35.5882  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1679: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5646 Val_Loss: 35.5228  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1680: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5608 Val_Loss: 35.5691  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1681: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5579 Val_Loss: 35.4342  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1682: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5548 Val_Loss: 35.5539  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1683: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5504 Val_Loss: 35.4506  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1684: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5464 Val_Loss: 35.4100  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1685: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5430 Val_Loss: 35.4860  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1686: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5400 Val_Loss: 35.2815  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1687: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5366 Val_Loss: 35.3702  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1688: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5326 Val_Loss: 35.2999  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1689: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5287 Val_Loss: 35.3090  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1690: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5250 Val_Loss: 35.2750  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1691: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5216 Val_Loss: 35.1770  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1692: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5184 Val_Loss: 35.2987  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1693: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5151 Val_Loss: 35.1372  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1694: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5118 Val_Loss: 35.2183  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1695: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5084 Val_Loss: 35.0524  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1696: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5051 Val_Loss: 35.2065  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1697: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5017 Val_Loss: 34.9867  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1698: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4988 Val_Loss: 35.1430  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1699: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4961 Val_Loss: 34.8586  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1700: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4949 Val_Loss: 35.1788  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1701: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4946 Val_Loss: 34.6664  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1702: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5027 Val_Loss: 35.3070  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1703: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5101 Val_Loss: 34.4189  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1704: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5514 Val_Loss: 35.2918  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1705: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5260 Val_Loss: 34.6034  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1706: Validation loss did not decrease\n",
            "\t Train_Loss: 4.5367 Val_Loss: 35.3296  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1707: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4914 Val_Loss: 34.8136  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1708: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4749 Val_Loss: 35.0830  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1709: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4641 Val_Loss: 34.8305  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1710: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4587 Val_Loss: 34.8211  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1711: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4543 Val_Loss: 34.7883  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1712: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4504 Val_Loss: 34.7552  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1713: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4472 Val_Loss: 34.6926  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1714: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4440 Val_Loss: 34.5145  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1715: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4413 Val_Loss: 34.6860  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1716: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4417 Val_Loss: 34.1708  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1717: Validation loss did not decrease\n",
            "\t Train_Loss: 4.4581 Val_Loss: 35.1388  BEST VAL Loss: 31.7984\n",
            "\n",
            "Epoch 1718: Validation loss did not decrease\n",
            "Early stopped at epoch : 1718\n"
          ]
        }
      ],
      "source": [
        "LSTM_best_model, train_losses, val_losses = trainer(LSTM_model, X_train, y_train, X_val, y_val, optimizer, criterion, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "rOoQ6lrfFYQo",
        "outputId": "668ca972-b989-4dc6-d368-db61b50eaaf5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_losses, label = 'Train_loss')\n",
        "plt.plot(val_losses, label = 'validation_loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVxb1IHaYwmU"
      },
      "source": [
        "---\n",
        "### 6.4 Evaluate model on validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "gGzInAaoDBWy"
      },
      "outputs": [],
      "source": [
        "val_predict_LSTM = LSTM_best_model(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "0plcD3u8DKqa",
        "outputId": "ba1ea705-0ace-41a1-cd5b-39ee8fe0b15d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(df[-len(y_val):].index, y_val.cpu(), label=\"actual\", marker=\"o\")\n",
        "plt.plot(df[-len(y_val):].index, val_predict_LSTM.detach().cpu(), label=\"predicted\", marker=\"o\")\n",
        "plt.title(\"Electric production IP prediction by LSTM RNN model\", fontsize=25)\n",
        "plt.ylabel(\"ylabel\")\n",
        "plt.legend(title_fontsize=14, fontsize=13, fancybox=True, shadow=True, frameon=True)\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WfqFMJLan26"
      },
      "source": [
        "---\n",
        "---\n",
        "## 7 Comaprison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "R7E2YreFari1",
        "outputId": "56a86025-f9aa-4e0e-d8a9-b3108b3f6f77"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(df[-len(y_val):].index, y_val.cpu(), label=\"actual\", marker=\"o\")\n",
        "plt.plot(df[-len(y_val):].index, val_predict_RNN.detach().cpu(), label=\"predicted_RNN\", marker=\"o\")\n",
        "plt.plot(df[-len(y_val):].index, val_predict_GRU.detach().cpu(), label=\"predicted_GRU\", marker=\"o\")\n",
        "plt.plot(df[-len(y_val):].index, val_predict_LSTM.detach().cpu(), label=\"predicted_LSTM\", marker=\"o\")\n",
        "plt.title(\"Electric production IP prediction\", fontsize=25)\n",
        "plt.ylabel(\"ylabel\")\n",
        "plt.legend(title_fontsize=14, fontsize=13, fancybox=True, shadow=True, frameon=True)\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McCOcrqqhXkt"
      },
      "source": [
        "\n",
        "<b>1-Rank these architectures based on their performance?\n",
        "\n",
        "2-Why are they ranked in this order?\n",
        "\n",
        "3-Run the notebook again with look_back = 15.\n",
        "write about the difference in the comparison plot and the possible cause for that difference.</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UesAMIOPG49X"
      },
      "source": [
        "<font color='#73FF73'><b>Your answer:</b></font>\n",
        "\n",
        "1- The performance of the three architectures, from highest to lowest, is as follows:\n",
        "\n",
        "   1. LSTM (Long Short-Term Memory)\n",
        "   2. GRU (Gated Recurrent Unit)\n",
        "   3. RNN (Vanilla Recurrent Neural Network)\n",
        "\n",
        "<hr/> \n",
        "\n",
        "2- The ranking of these models can be attributed to their inherent architectural differences which impact their ability to handle long-term dependencies in sequences:\n",
        "\n",
        "   - **LSTM**: LSTMs are designed to avoid the long-term dependency problem in RNNs. They remember information for long periods of time and are therefore better suited for complex tasks that require learning long-term temporal dependencies. This is achieved through a sophisticated gate mechanism that controls the flow of information into and out of the memory cell.\n",
        "\n",
        "   - **GRU**: GRUs, like LSTMs, also have gating mechanisms that modulate the flow of information to the hidden state. However, they have fewer gates and do not possess a separate memory cell. This makes them computationally more efficient than LSTMs but at the cost of expressive power. Therefore, while they perform better than vanilla RNNs, they may not perform as well as LSTMs for tasks requiring complex long-term dependencies.\n",
        "\n",
        "   - **RNN**: Vanilla RNNs suffer from the vanishing gradient problem, which makes it difficult for them to learn and represent long-term dependencies in the data. This is likely why they perform worse than GRU and LSTM models, which are specifically designed to tackle this issue.\n",
        "\n",
        "<hr/>\n",
        "\n",
        "3- The comparison plot of the LSTM, GRU, and RNN models performance shows a difference in the accuracy of prediction on the validation data for the three models. From the training data, it is also evident that the loss values, for all three models, had noticable decrease. The reduction in the loss function indicates that the models are learning and performing better on the validation data after changing the lookback value from 60 to 15.\n",
        "\n",
        "The improved performance with a reduced lookback value can be attributed to the nature of the data and the inherent characteristics of Recurrent Neural Networks (RNNs), including LSTM and GRU.\n",
        "\n",
        "1. **Temporal Dependencies**: RNNs are designed to capture temporal dependencies in sequence data. The lookback period determines how many previous time steps the model considers when making a prediction. If the underlying process has short-term dependencies (i.e., future values primarily depend on recent past values), a smaller lookback period may be more appropriate. In this case, reducing the lookback value from 60 to 15 might have allowed the models to better capture the relevant short-term trends in the data.\n",
        "\n",
        "2. **Overfitting**: A larger lookback period increases the complexity of the model as it needs to learn and remember more temporal dependencies. This could lead to overfitting, especially when the dataset is small (~400 entries), as in this case. Overfitting refers to a model that learns the training data too well, capturing noise in addition to the underlying pattern. Such a model performs poorly on unseen data. By reducing the lookback period, the model complexity was reduced, likely making it less prone to overfitting.\n",
        "\n",
        "3. **Data Characteristics**: The 'Value' in the dataset, which probably represents electric production, might be influenced more by recent events (e.g., weather conditions, demand fluctuations) rather than events that occurred a long time ago. Therefore, a smaller lookback value that focuses on more recent data might result in better performance.\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTUd8HKsHEG0"
      },
      "source": [
        "### Important Note\n",
        "There are two versions of these notebooks, in two separate files. One executed with lookback of 60, the other with lookback of 15."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
