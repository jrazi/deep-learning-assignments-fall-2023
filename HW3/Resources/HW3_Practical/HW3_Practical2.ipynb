{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 3 Part 2\n",
        "\n",
        "## Course Name: Deep Learning\n",
        "#### Lecturers: Dr. Beigy\n",
        "\n",
        "---\n",
        "\n",
        "#### Notebooks Supervised By: Zeinab Sadat Taghavi\n",
        "#### Notebooks Prepared By: Zahra Khoramnejad, Mehran Sarmadi, Zahra Rahimi\n",
        "\n",
        "**Contact**: Ask your questions in Quera\n",
        "\n",
        "---\n",
        "\n",
        "### Instructions:\n",
        "- Complete all exercises presented in this notebook.\n",
        "- Ensure you run each cell after you've entered your solution.\n",
        "- After completing the exercises, save the notebook and <font color='red'>follow the submission guidelines provided in the PDF.</font>\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "DHvhhpBU-QtI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Generation\n",
        "\n",
        "<p align='justify'>Text generation task involves generating new text based on a given input or a prompt. It is a natural language processing (NLP) task that aims to generate coherent and contextually relevant text.\n",
        "\n",
        "In text generation, a model is trained on a large corpus of text data and learns the patterns and structures of the language. This model can then be used to generate new text by sampling from the learned distribution of words or characters.\n",
        "\n",
        "Text generation has various applications, including chatbots, language translation, poetry generation, and content creation. It can be implemented using different techniques such as `recurrent neural networks (RNNs)`, `transformers`, and `Markov chains`.\n",
        "\n",
        "The goal of text generation is to produce text that is fluent, coherent, and contextually relevant. It requires a deep understanding of the language and the ability to generate text that follows grammatical rules and maintains semantic coherence.</p>"
      ],
      "metadata": {
        "id": "LG6yNYAmreI_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Charachter-level text generation"
      ],
      "metadata": {
        "id": "-u6fGIqx0LIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One stage of the task of text generation is mapping, which can be at the word or character level. At this stage, a number is assigned to each word or character.\n",
        "\n",
        "In this exercise, we generate text at the character level. Because generating text at the word level, even though it leads to more meaningful outputs, requires a rich dataset with a high number of word repetitions."
      ],
      "metadata": {
        "id": "cKhboP-Y0TrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will implement models based on `recurrent networks` for text generation and compare the performance of different models. In the following, we will check the performance of the best models on different datasets and compare the results"
      ],
      "metadata": {
        "id": "00sNsfmXtW6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The steps of this exercise are as follows:\n",
        "1. Train RNN and LSTM\n",
        "2. FineTuning\n",
        "3. Experiment on different datasets"
      ],
      "metadata": {
        "id": "jw8uJvD8vTyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "nb9egMrmAhXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Train RNN and LSTM"
      ],
      "metadata": {
        "id": "SBqL42w1vt1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "dP0JQJIj2rL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7cTJANKwpck",
        "outputId": "94e67019-c1e8-4570-8f6b-a40394484c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "hJSsyWUyv8KC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We use the dataset of `Shakespeare's plays` as the main dataset for this exercise"
      ],
      "metadata": {
        "id": "oHGryhW7wbsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\" -c -P {'data/'}"
      ],
      "metadata": {
        "id": "eUNd0YrFwW2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Load data in amout of 30kb for training models"
      ],
      "metadata": {
        "id": "hYntrpS_Arse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sh_data_file = \"./data/input.txt\"\n",
        "sh_data = open(sh_data_file, 'r').read(30000)"
      ],
      "metadata": {
        "id": "xYsndtIoxd0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Charachter mapping"
      ],
      "metadata": {
        "id": "Pj-xesSRwI9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For better performance of the model, we limit the set of allowed characters"
      ],
      "metadata": {
        "id": "Jl-LIH_Syl0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = list(string.ascii_lowercase + '\\n' + ' ' + ':' + '.')\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "id": "KLiOHN8sCSe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping of char-index\n",
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }"
      ],
      "metadata": {
        "id": "xvP9iW3FyT6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing"
      ],
      "metadata": {
        "id": "nh8Fo1WnwC9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_extraneous_characters(data, valid_char_list):\n",
        "    pattern = f\"[^{re.escape(''.join(valid_char_list))}]\"\n",
        "    return re.sub(pattern, '', data)"
      ],
      "metadata": {
        "id": "vxGtjsgay0x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sh_data = remove_extraneous_characters(sh_data.lower(), chars)\n",
        "sh_data_size = len(sh_data)\n",
        "\n",
        "# Extract indexes of data characters\n",
        "sh_data = list(sh_data)\n",
        "for i, ch in enumerate(sh_data):\n",
        "    sh_data[i] = char_to_ix[ch]\n",
        "\n",
        "sh_data = torch.tensor(sh_data).to(device)\n",
        "sh_data = torch.unsqueeze(sh_data, dim=1)"
      ],
      "metadata": {
        "id": "KscUSBpbyRNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modeling"
      ],
      "metadata": {
        "id": "Df7TxCxOzueM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In this part define RNN and LSTM model, according to the mentioned characteristics and function inputs.\n"
      ],
      "metadata": {
        "id": "Rsj67WalA4fY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###RNN"
      ],
      "metadata": {
        "id": "kFj9nkzoz2Hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size=512, num_layers=3, dropout_enable=False):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout_enable = dropout_enable\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.hidden_state = None\n",
        "        ####################################\n",
        "        ######### Your code begins #########\n",
        "        ####################################\n",
        "        # Define self.rnn with model inputs\n",
        "        # Define self.decoder for decoding output character from last hidden state\n",
        "        # You can use torch.nn library\n",
        "\n",
        "        self.rnn = None\n",
        "        self.decoder = None\n",
        "\n",
        "        ####################################\n",
        "        ######### Your code ends ###########\n",
        "        ####################################\n",
        "\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        ####################################\n",
        "        ######### Your code begins #########\n",
        "        ####################################\n",
        "        # Implement forward part of model and save last hidden state on self.hidden_state\n",
        "\n",
        "\n",
        "        ####################################\n",
        "        ######### Your code ends ###########\n",
        "        ####################################\n",
        "\n",
        "        return output\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def load_model(self, path):\n",
        "        self.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "fgmKXfb1zuAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LSTM"
      ],
      "metadata": {
        "id": "xeoymmMx7RKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size=512, num_layers=3, dropout_enable=False):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout_enable = dropout_enable\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.hidden_state = None\n",
        "\n",
        "        ####################################\n",
        "        ######### Your code begins #########\n",
        "        ####################################\n",
        "        # Define self.lstm with model inputs\n",
        "        # Define self.decoder for decoding output character from last hidden state\n",
        "        # You can use torch.nn library\n",
        "\n",
        "        self.lstm = None\n",
        "        self.decoder = None\n",
        "\n",
        "        ####################################\n",
        "        ######### Your code ends ###########\n",
        "        ####################################\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        ####################################\n",
        "        ######### Your code begins #########\n",
        "        ####################################\n",
        "        # Implement forward part of model and save last hidden state on self.hidden_state\n",
        "\n",
        "\n",
        "        ####################################\n",
        "        ######### Your code ends ###########\n",
        "        ####################################\n",
        "\n",
        "        return output\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def load_model(self, path):\n",
        "        self.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "4PQDAnxc7Q26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "Y9XQWqoXwM4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_sample_output(model, data, data_size, test_output_len = 200):\n",
        "    # Use this function to print sample that model generates from its current hidden state and random input character\n",
        "    # test_output_len is total num of characters in output test sequence\n",
        "\n",
        "    test_output = \"\"\n",
        "    data_ptr = 0\n",
        "\n",
        "    rand_index = np.random.randint(data_size-1)\n",
        "    input_seq = data[rand_index : rand_index+1]\n",
        "\n",
        "    while True:\n",
        "        output = model(input_seq)\n",
        "\n",
        "        output = F.softmax(torch.squeeze(output), dim=0)\n",
        "        dist = Categorical(output)\n",
        "        index = dist.sample().item()\n",
        "\n",
        "        test_output += ix_to_char[index]\n",
        "\n",
        "        input_seq[0][0] = index\n",
        "        data_ptr += 1\n",
        "\n",
        "        if data_ptr > test_output_len:\n",
        "            break\n",
        "\n",
        "    print(\"Train Sample +++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "    print(test_output)\n",
        "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
      ],
      "metadata": {
        "id": "ruPWrO7Z9JM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For construction of each sample in the dataset, the output sequence is\n",
        "obtained from the shift of one character from the input sequence. For example, when sequence_length is 10 and our text is `Hello world`. The input sequence would be `Hello worl`, and the target sequence `ello world`."
      ],
      "metadata": {
        "id": "WC337ho-XX-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, data, data_size, epoch, optimizer, seq_len=200):\n",
        "    # seq_length is length of training data sequence\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    total_loss = 0\n",
        "    sample_number = 0\n",
        "\n",
        "    ####################################\n",
        "    ######### Your code begins #########\n",
        "    ####################################\n",
        "    # Define training process for one epoch of input model\n",
        "    # At the end of every ten epochs, print current loss and a sample output of the model using print_sample_output function\n",
        "    # Feed all data sample to model by iterating over input data\n",
        "\n",
        "    ####################################\n",
        "    ######### Your code ends ###########\n",
        "    ####################################\n",
        "\n",
        "    return total_loss / sample_number"
      ],
      "metadata": {
        "id": "aPpDSsZU7vWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_rnn(data, data_size, model_save_file):\n",
        "    # RNN parameters\n",
        "    hidden_size = 512\n",
        "    num_layers = 6\n",
        "    lr = 0.002\n",
        "    epoch_num = 100\n",
        "    losses = []\n",
        "\n",
        "    ####################################\n",
        "    ######### Your code begins #########\n",
        "    ####################################\n",
        "    # Define training process in the specified number of epochs for RNN model\n",
        "    # Use train_epoch function for train the model for one epoch\n",
        "    # Use Adam as optimizer\n",
        "    # Save best model in model_save_file address for next usage\n",
        "\n",
        "\n",
        "    ####################################\n",
        "    ######### Your code ends ###########\n",
        "    ####################################\n",
        "\n",
        "    return losses"
      ],
      "metadata": {
        "id": "1NT_mZuMf4do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lstm(data, data_size, model_save_file):\n",
        "    # LSTM parameters\n",
        "    hidden_size = 512\n",
        "    num_layers = 3\n",
        "    lr = 0.002\n",
        "    epoch_num = 100\n",
        "    losses = []\n",
        "\n",
        "    ####################################\n",
        "    ######### Your code begins #########\n",
        "    ####################################\n",
        "    # Define training process in the specified number of epochs for LSTM model\n",
        "    # Use train_epoch function for train the model for one epoch\n",
        "    # Use Adam as optimizer\n",
        "    # Save best model in model_save_file address for next usage\n",
        "\n",
        "\n",
        "    ####################################\n",
        "    ######### Your code ends ###########\n",
        "    ####################################\n",
        "\n",
        "    return losses"
      ],
      "metadata": {
        "id": "gd-wyFT4gerv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "KW4HTBwBEoHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_sh_losses = train_rnn(sh_data, sh_data_size, './model_sh_rnn.pth')"
      ],
      "metadata": {
        "id": "-mA-QGewD22i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "0LNMgGhjEqZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_sh_losses = train_lstm(sh_data, sh_data_size, './model_sh_lstm.pth')"
      ],
      "metadata": {
        "id": "oA6zVNt6Ep7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generating texts"
      ],
      "metadata": {
        "id": "tUGxc-Z1wRiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A sample text to input the model"
      ],
      "metadata": {
        "id": "43rEOvbopt3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sample_text = 'First Citizen:\\nYou are all resolved rather to die than to famish?\\n'\n",
        "\n",
        "def create_input_sample_dataset(input_sample_text):\n",
        "    input_sample = remove_extraneous_characters(input_sample_text.lower(), chars)\n",
        "    input_sample = list(input_sample)\n",
        "    for i, ch in enumerate(input_sample):\n",
        "        input_sample[i] = char_to_ix[ch]\n",
        "\n",
        "    input_sample = torch.tensor(input_sample).to(device)\n",
        "    input_sample = torch.unsqueeze(input_sample, dim=1)\n",
        "    return input_sample"
      ],
      "metadata": {
        "id": "2gkZC4UagpoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This function generates the output generated by the model for the input sample, and if the input sample text is not given, it samples a sequence of original data and gives it to the model."
      ],
      "metadata": {
        "id": "m7N1xZocpFIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, data, data_size, input_sample_test = None, output_len=1000):\n",
        "    model.eval()\n",
        "    data_ptr = 0\n",
        "    test_output=\"\"\n",
        "\n",
        "    if input_sample_test is not None:\n",
        "        index = 0\n",
        "        seq_len = len(input_sample_test)\n",
        "        input_seq = input_sample_test[index : index + seq_len-1]\n",
        "    else:\n",
        "        # If input sample not declared, select an initial string from the data of 10 characters randomly\n",
        "        index = np.random.randint(data_size - 11)\n",
        "        seq_len = 10\n",
        "        input_seq = data[index : index + 9]\n",
        "\n",
        "   # Set last hidden state of model by feeding input sequence to model\n",
        "    output = model(input_seq)\n",
        "\n",
        "    # Last charachter feed to model\n",
        "    if input_sample_test is not None:\n",
        "        input_seq = input_sample_test[index + seq_len-1 : index + seq_len]\n",
        "    else:\n",
        "        input_seq = data[index + seq_len-1 : index + seq_len]\n",
        "\n",
        "    while True:\n",
        "        output = model(input_seq)\n",
        "\n",
        "        output = F.softmax(torch.squeeze(output), dim=0)\n",
        "        dist = Categorical(output)\n",
        "        index = dist.sample().item()\n",
        "\n",
        "        test_output += ix_to_char[index]\n",
        "        input_seq[0][0] = index\n",
        "        data_ptr += 1\n",
        "\n",
        "        if data_ptr  > output_len:\n",
        "            break\n",
        "\n",
        "    print(\"Eaxmple of generated text --------------------------------------------------------------------------\")\n",
        "    print(test_output)\n",
        "    print(\"----------------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "zTFXBqKqII_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "MatZYKCUFOSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_rnn =  RNN(vocab_size, vocab_size, 512, 6).to(device)\n",
        "best_model_rnn.load_model('./model_sh_rnn.pth')\n",
        "print(\"best loss\", min(rnn_sh_losses))\n",
        "generate_text(best_model_rnn, sh_data, sh_data_size)"
      ],
      "metadata": {
        "id": "-oT9TsOBFQ9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "Fwr90H6eFPqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_lstm =  LSTM(vocab_size, vocab_size, 512, 3).to(device)\n",
        "best_model_lstm.load_model('./model_sh_lstm.pth')\n",
        "print(\"best loss\", min(lstm_sh_losses))\n",
        "generate_text(best_model_lstm, sh_data, sh_data_size)"
      ],
      "metadata": {
        "id": "R2DUmeREFUkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the losses"
      ],
      "metadata": {
        "id": "_thNtUicv2kd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_If3o7grbO8"
      },
      "outputs": [],
      "source": [
        "def plot_losses(losses):\n",
        "    xpoints = np.array(range(len(losses)))\n",
        "    ypoints = np.array(losses)\n",
        "\n",
        "    plt.plot(xpoints, ypoints, color='blue',label='losses')\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "ylDZpjFtJ6Mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(rnn_sh_losses)"
      ],
      "metadata": {
        "id": "lvQC5FNzJ4Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "nbd_-EFInd-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(lstm_sh_losses)"
      ],
      "metadata": {
        "id": "g44i0NiKJ97c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report"
      ],
      "metadata": {
        "id": "nkoXQFMmKbU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the texts generated from different models and the losses during the training process of the models, analyze what is the reason for the difference in the result of models.\n",
        "\n",
        "Which model works better and what do you think are the reasons?"
      ],
      "metadata": {
        "id": "liCOCuR5KeFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#73FF73'><b>Your answer : </b></font>"
      ],
      "metadata": {
        "id": "_TMkOL1uK8AU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "j3UI0UnS9tzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. FineTuning"
      ],
      "metadata": {
        "id": "UjJP-PvXLKVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FineTuning is a technique used in neural network training where a pre-trained model is further trained on a new task or dataset. It allows us to leverage the knowledge and representations learned by a pre-trained model and adapt it to a specific task or domain.\n",
        "\n",
        "In this exercise, we first train the models with a `wikipedia` dataset that contains english texts, then we fine-tune this pre-trained model again with the Shakespeare play dataset to check the effect of this method on different models."
      ],
      "metadata": {
        "id": "DqR62s6qMfc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Wikipedia dataset"
      ],
      "metadata": {
        "id": "hrBfhPcpOB-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3.amazonaws.com/fast-ai-nlp/wikitext-2.tgz"
      ],
      "metadata": {
        "id": "UiqBbrV4kSYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf '/content/wikitext-2.tgz' -C '/content/data'"
      ],
      "metadata": {
        "id": "ecXOywp5lv0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat './data/wikitext-2/train.csv' | tr -d '\\n' > ./data/wikitext.txt"
      ],
      "metadata": {
        "id": "c52RASUHpGM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing"
      ],
      "metadata": {
        "id": "6Sfwpof1OGOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_wiki_data(data):\n",
        "    repl=''\n",
        "    data=re.sub('\\(', repl, data)\n",
        "    data=re.sub('\\)', repl, data)\n",
        "    for pattern in set(re.findall(\"=.*=\",data)):\n",
        "        data=re.sub(pattern, repl, data)\n",
        "    for pattern in set(re.findall(\"<unk>\",data)):\n",
        "        data=re.sub(pattern,repl,data)\n",
        "    for pattern in set(re.findall(r\"[^\\w ]\", data)):\n",
        "        repl=''\n",
        "        if pattern=='-':\n",
        "            repl=' '\n",
        "        if pattern!='.' and pattern!=\"\\'\":\n",
        "            data=re.sub(\"\\\\\"+pattern, repl, data)\n",
        "\n",
        "    return data\n",
        "\n",
        "def load_data(filepath):\n",
        "    f=open(filepath)\n",
        "    return f.read()"
      ],
      "metadata": {
        "id": "CniodW0Knkld",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wikidata=load_data(\"./data/wikitext.txt\")\n",
        "data=wikidata[:]\n",
        "data=clean_wiki_data(data)\n",
        "wikiPreprocessed_file = open(\"./data/wiki_preprocesed.txt\", \"w\")\n",
        "f = wikiPreprocessed_file.write(data)\n",
        "wikiPreprocessed_file.close()"
      ],
      "metadata": {
        "id": "N-BjAHGHpm4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Load data in amount of 50kb for finetuning"
      ],
      "metadata": {
        "id": "MxILpQvZmFs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wi_data_file = \"./data/wiki_preprocesed.txt\"\n",
        "wi_data = open(wi_data_file, 'r').read(50000)"
      ],
      "metadata": {
        "id": "Q9AUJmRFPGqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wi_data = remove_extraneous_characters(wi_data.lower(), chars)\n",
        "wi_data_size = len(wi_data)\n",
        "\n",
        "wi_data = list(wi_data)\n",
        "for i, ch in enumerate(wi_data):\n",
        "    wi_data[i] = char_to_ix[ch]\n",
        "\n",
        "wi_data = torch.tensor(wi_data).to(device)\n",
        "wi_data = torch.unsqueeze(wi_data, dim=1)"
      ],
      "metadata": {
        "id": "hdxMOch8e4mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-training by wikipedia dataset"
      ],
      "metadata": {
        "id": "_Z9RXj7fOPFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "WQRRXlSDfVEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_wi_losses = train_rnn(wi_data, wi_data_size, './model_wi_rnn.pth')"
      ],
      "metadata": {
        "id": "00m3G13vfcQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "iI8hukxjfc0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_wi_losses = train_lstm(wi_data, wi_data_size, './model_wi_lstm.pth')"
      ],
      "metadata": {
        "id": "b5KmatWPhUYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetuning by Shakespeare"
      ],
      "metadata": {
        "id": "s4EDmKGTOTaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define the following functions to use the previous model as a pre-trained model and fine-tunes it using Shakespeare's plays dataset with lower learning rate."
      ],
      "metadata": {
        "id": "J99viDjUqxUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune_rnn(data, data_size, model_save_file, model_pretrained_path):\n",
        "    # RNN parameters\n",
        "    hidden_size = 512\n",
        "    num_layers = 6\n",
        "    lr = 0.001\n",
        "    epoch_num = 100\n",
        "    losses = []\n",
        "\n",
        "    ####################################\n",
        "    ######### Your code begins #########\n",
        "    ####################################\n",
        "    # In this section finetune the model that trained by wikipedia dataset with Shakespeare plays dataset\n",
        "\n",
        "\n",
        "    ####################################\n",
        "    ######### Your code ends ###########\n",
        "    ####################################\n",
        "\n",
        "    return losses"
      ],
      "metadata": {
        "id": "FKa2cGcVjRje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune_lstm(data, data_size, model_save_file, model_pretrained_path):\n",
        "    # LSTM parameters\n",
        "    hidden_size = 512\n",
        "    num_layers = 3\n",
        "    lr = 0.001\n",
        "    epoch_num = 100\n",
        "    losses = []\n",
        "\n",
        "    ####################################\n",
        "    ######### Your code begins #########\n",
        "    ####################################\n",
        "    # In this section finetune the model that trained by wikipedia dataset with Shakespeare plays dataset\n",
        "\n",
        "\n",
        "    ####################################\n",
        "    ######### Your code ends ###########\n",
        "    ####################################\n",
        "\n",
        "    return losses"
      ],
      "metadata": {
        "id": "ijG0lP75lHfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "wwqLT0A0mSuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_sh_finetune_losses = finetune_rnn(sh_data, sh_data_size, './model_sh_finetune_rnn.pth', './model_wi_rnn.pth')"
      ],
      "metadata": {
        "id": "DixZCVqZmV8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "By2oc0qlmUeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_sh_finetune_losses = finetune_lstm(sh_data, sh_data_size, './model_sh_finetune_lstm.pth', './model_wi_lstm.pth')"
      ],
      "metadata": {
        "id": "m5tlC-O6nJdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Losses"
      ],
      "metadata": {
        "id": "gPr9aM-COlGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses_together(losses1, losses2):\n",
        "    xpoints = np.array(range(len(losses1)))\n",
        "    ypoints1 = np.array(losses1)\n",
        "    ypoints2 = np.array(losses2)\n",
        "\n",
        "    plt.plot(xpoints, ypoints1, color='blue',label='base_losses' )\n",
        "    plt.plot(xpoints, ypoints2, color='red',label='finetune_losses' )\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "seWKCPaCnQ2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "pl3ao3hXnne2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses_together(rnn_sh_losses, rnn_sh_finetune_losses)"
      ],
      "metadata": {
        "id": "oCiLrTAahpTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "kGI_uZZhnpdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses_together(lstm_sh_losses, lstm_sh_finetune_losses)"
      ],
      "metadata": {
        "id": "liBF6jxUnPpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report"
      ],
      "metadata": {
        "id": "_3bCGDXxOvGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, fine-tuning has an effect in improving the training of the main model.\n",
        "\n",
        "By analyzing the obtained results, state the advantage of finetuning after pre-training the model by public dataset, and compare its performance in different models"
      ],
      "metadata": {
        "id": "SOiRxwHGnnag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#73FF73'><b>Your answer : </b></font>"
      ],
      "metadata": {
        "id": "NAEoxdCInnW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "----"
      ],
      "metadata": {
        "id": "6mVIAlPZLjaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Experiment on different datasets"
      ],
      "metadata": {
        "id": "L3RR1kMxnnUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous section, you saw the performance results of the text generation model using the Shakespeare plays dataset. In the following, you will check the results of the LSTM model on the dialogues of the `Friends series`"
      ],
      "metadata": {
        "id": "P7BcgGRrqBqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "Wa54a7knq4N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-08/friends.csv -O ./data/Friends.csv"
      ],
      "metadata": {
        "id": "u2XhR0uprKNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## preprocessing"
      ],
      "metadata": {
        "id": "0X_z5mS3q7EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "friends = pd.read_csv('./data/Friends.csv')\n",
        "friends = friends.dropna()\n",
        "friends = friends[friends['speaker'].str.contains('SCENE')==False]\n",
        "friends['speaker'] = friends['speaker'].apply(lambda sp: sp.lower().capitalize().split(' ')[0])\n",
        "friends_texts = friends.drop(['episode','season','scene','utterance'], axis='columns')\n",
        "friends_texts.head()"
      ],
      "metadata": {
        "id": "7IbK2Ean-l1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"./data/fiends.txt\", \"w\")\n",
        "for i,row in friends_texts.iterrows():\n",
        "    f.write(row['speaker'] + ':\\n' + row['text'] + '\\n\\n')\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "mEaZR1jS-q_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fr_data_file = \"./data/fiends.txt\"\n",
        "fr_data = open(fr_data_file, 'r').read(30000)\n",
        "fr_data = remove_extraneous_characters(fr_data.lower(), chars)\n",
        "fr_data_size = len(fr_data)\n",
        "\n",
        "fr_data = list(fr_data)\n",
        "for i, ch in enumerate(fr_data):\n",
        "    fr_data[i] = char_to_ix[ch]\n",
        "\n",
        "fr_data = torch.tensor(fr_data).to(device)\n",
        "fr_data = torch.unsqueeze(fr_data, dim=1)"
      ],
      "metadata": {
        "id": "1SPBHV5u-62e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train finetuned LSTM by friends dataset"
      ],
      "metadata": {
        "id": "6drMR6Gtq_jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_fr_finetune_losses = finetune_lstm(fr_data, fr_data_size, './model_fr_lstm.pth', './model_wi_lstm.pth')"
      ],
      "metadata": {
        "id": "J7ruLz2r_O3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating texts"
      ],
      "metadata": {
        "id": "62xwUDiPrEDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_lstm =  LSTM(vocab_size, vocab_size, 512, 3).to(device)\n",
        "best_model_lstm.load_model('./model_fr_lstm.pth')\n",
        "print(\"best loss\", min(lstm_fr_finetune_losses))\n",
        "generate_text(best_model_lstm, fr_data, fr_data_size)"
      ],
      "metadata": {
        "id": "26S9Um9Jnm9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As you can see, the LSTM network has been able to learn the features of different datasets in terms of sentence length and writing style and use it in text generation."
      ],
      "metadata": {
        "id": "Z7s2pjFjR-l4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The output of finetuned models on different datasets on the input sample"
      ],
      "metadata": {
        "id": "7BGd20eltW3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In this section, you can see the result of the text generated by models with a sample input text."
      ],
      "metadata": {
        "id": "Rp_UEVqAQuvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sample_text = \"Hello, have a nice day.\\n\""
      ],
      "metadata": {
        "id": "NS_NqaJruKQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_lstm =  LSTM(vocab_size, vocab_size, 512, 3).to(device)\n",
        "best_model_lstm.load_model('./model_fr_lstm.pth')\n",
        "generate_text(best_model_lstm, fr_data, fr_data_size, create_input_sample_dataset(input_sample_text),100)"
      ],
      "metadata": {
        "id": "mWgLQM0G2r7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_lstm =  LSTM(vocab_size, vocab_size, 512, 3).to(device)\n",
        "best_model_lstm.load_model('./model_sh_finetune_lstm.pth')\n",
        "generate_text(best_model_lstm, sh_data, sh_data_size, create_input_sample_dataset(input_sample_text),100)"
      ],
      "metadata": {
        "id": "gmFUUJCUtLKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report"
      ],
      "metadata": {
        "id": "kT-dTrk_RQyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the sample input and output produced by the fine-tuned model with the Shakespeare dataset and the Friends dataset, which output is more meaningful and what is the reason for this difference?"
      ],
      "metadata": {
        "id": "vNJdGJN1RLpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#73FF73'><b>Your answer : </b></font>"
      ],
      "metadata": {
        "id": "k4nBCaS2RWN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "----"
      ],
      "metadata": {
        "id": "Tq_1cBKGRX8i"
      }
    }
  ]
}