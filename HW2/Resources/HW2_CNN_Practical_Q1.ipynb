{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>HW2 - Convolutional Neural Networks- Practical Q1_Part A</h1>\n",
        "<h3><font color=yellow>Total Points: 100</font></h3>\n",
        "\n"
      ],
      "metadata": {
        "id": "849QzkvEBGwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=greeen>Please, name this file as HW2_Q1_{Student_ID}.ipynb</font>"
      ],
      "metadata": {
        "id": "5Y5gDX4CBVyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Full Name: ------</h2>\n",
        "<h2>Student ID: ------</h2>"
      ],
      "metadata": {
        "id": "sRy4HrDaD2z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "WzeRgnpFB1xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "p188oEp6B8MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparing Data"
      ],
      "metadata": {
        "id": "opCpH1BuBLXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "\n",
        "#defining the transforms we need (converting images to tensor and normalizing)\n",
        "transform=...\n",
        "\n",
        "## Download FashionMNIST dataset\n",
        "train_set = ...\n",
        "test_set = ...\n",
        "#################################################################################\n",
        "                            \"\"\"\"  5 Points  \"\"\"\"\n",
        "#################################################################################"
      ],
      "metadata": {
        "id": "alTsAHfBA7_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using GPU if it's available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# split training set into train and validation data\n",
        "torch.manual_seed(0)\n",
        "\n",
        "train_size = ...\n",
        "val_size = ...\n",
        "train_ds, val_ds = ...\n",
        "\n",
        "#################################################################################\n",
        "                            \"\"\"\"  5 Points  \"\"\"\"\n",
        "#################################################################################"
      ],
      "metadata": {
        "id": "07KYSrwPA79o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# Loading the dataset into memory using Dataloader\n",
        "# use your desired batch size and shuffle is necessary\n",
        "\n",
        "train_dataloader = ...\n",
        "val_dataloader = ...\n",
        "test_dataloader = ...\n",
        "\n",
        "classes = train_set.classes\n",
        "\n",
        "#################################################################################\n",
        "                            \"\"\"\"  5 Points  \"\"\"\"\n",
        "#################################################################################"
      ],
      "metadata": {
        "id": "TQwGfomCBkc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing a few data samples"
      ],
      "metadata": {
        "id": "LEXCDCqhCFgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get some random training images\n",
        "dataiter = iter(train_dataloader)\n",
        "images, labels = next(dataiter)\n",
        "fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(10, 8), subplot_kw={'xticks': [], 'yticks': []})\n",
        "for i,ax in zip(range(0,6),axes.flat):\n",
        "    img,label=images[i],labels[i]\n",
        "    ax.imshow(img.permute(1, 2, 0))\n",
        "    ax.set_title(f\"Label: {classes[label]}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qBT2C717CLw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building Model Arcitechture"
      ],
      "metadata": {
        "id": "ZOLK-EhmBkxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Implement the Convolutional Neural Network shown below:</h2>"
      ],
      "metadata": {
        "id": "dDedxeSBMRZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1eN-rEyMCmApg7tASsmtkBQM7HbU1ZORH'>"
      ],
      "metadata": {
        "id": "in1gnPRdZ8aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Simple_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Simple_CNN, self).__init__()\n",
        "    #################################################################################\n",
        "    #                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "    #################################################################################\n",
        "    \"\"\" Defining layers \"\"\"\n",
        "    #Your Code Here\n",
        "\n",
        "    #################################################################################\n",
        "                                   \"\"\"\"  15 Points  \"\"\"\"\n",
        "    #################################################################################\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    #################################################################################\n",
        "    #                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "    #################################################################################\n",
        "    \"\"\" Implement the forward propagation steps \"\"\"\n",
        "    #Your Code Here\n",
        "    ...\n",
        "    out=...\n",
        "    #################################################################################\n",
        "                                   \"\"\"\"  10 Points  \"\"\"\"\n",
        "    #################################################################################\n",
        "    return out\n",
        "\n",
        "\n",
        "  def Fit(self, num_epochs, train_loader, val_loader, optimizer, criterion):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies=[]\n",
        "    val_accuracies=[]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      train_per_epoch_loss=0\n",
        "      train_data_total = 0\n",
        "      train_data_correct = 0\n",
        "\n",
        "      ####### Training Phase ########\n",
        "      self.train()\n",
        "      with tqdm(train_loader, unit=\"batch\") as batches:\n",
        "        epoch_loss = 0\n",
        "        for images, labels in batches:\n",
        "          batches.set_description(f\"Epoch {epoch + 1}\")\n",
        "          #################################################################################\n",
        "          #                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "          #################################################################################\n",
        "          \"\"\" Implement training steps \"\"\"\n",
        "          #Your Code Here\n",
        "          ....\n",
        "          ....\n",
        "\n",
        "          predictions = ...\n",
        "          train_data_correct += ...\n",
        "          train_data_total += ...\n",
        "          train_per_epoch_loss += ...\n",
        "          #################################################################################\n",
        "                                       \"\"\"\"  15 Points  \"\"\"\"\n",
        "          #################################################################################\n",
        "          batches.set_postfix(train_loss = (train_per_epoch_loss/len(train_loader)), train_accuracy = (train_data_correct.item() * 100 / train_data_total)) # show loss and accuracy per batch of data\n",
        "\n",
        "\n",
        "      train_accuracy = train_data_correct * 100 / train_data_total\n",
        "      train_accuracies.append(train_accuracy.item())\n",
        "      train_losses.append(train_per_epoch_loss/len(train_loader))\n",
        "\n",
        "\n",
        "      ####### Validation Phase ########\n",
        "      val_per_epoch_loss=0\n",
        "      val_data_total = 0\n",
        "      val_data_correct = 0\n",
        "\n",
        "      self.eval()\n",
        "      with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "          #################################################################################\n",
        "          #                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "          #################################################################################\n",
        "          \"\"\" Implement Validation steps \"\"\"\n",
        "          #Your Code Here\n",
        "          ...\n",
        "          .....\n",
        "\n",
        "          predictions = ...\n",
        "          val_data_correct += ...\n",
        "          val_data_total += ...\n",
        "          #################################################################################\n",
        "                                       \"\"\"\"  15 Points  \"\"\"\"\n",
        "          #################################################################################\n",
        "\n",
        "      val_accuracy = val_data_correct * 100 / val_data_total\n",
        "      val_losses.append(val_per_epoch_loss/len(val_loader))\n",
        "      val_accuracies.append(val_accuracy.item())\n",
        "\n",
        "      print(f\"End of Epoch {epoch + 1}: Validation accuray: {val_accuracy.item()}, Validation Loss: {val_per_epoch_loss/len(val_loader)}\")\n",
        "      print(\"-\"*40)\n",
        "\n",
        "    self.history={\n",
        "      'train_losses':train_losses,\n",
        "      'val_losses':val_losses,\n",
        "      'train_accuracies':train_accuracies,\n",
        "      'val_accuracies':val_accuracies\n",
        "    }\n",
        "    return self.history\n"
      ],
      "metadata": {
        "id": "SIaTB9OjBkay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Simple_CNN()\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JISVdplBBkYo",
        "outputId": "ad21891c-af16-4c8a-f3d8-8d9d164e79ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple_CNN(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc1): Linear(in_features=2304, out_features=600, bias=True)\n",
            "  (drop): Dropout2d(p=0.25, inplace=False)\n",
            "  (fc2): Linear(in_features=600, out_features=120, bias=True)\n",
            "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the model"
      ],
      "metadata": {
        "id": "RK6U0xqKBnvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "num_epochs=...\n",
        "criterion = ...\n",
        "learning_rate = ...\n",
        "optimizer = ...\n",
        "#################################################################################\n",
        "                              \"\"\"\"  10 Points  \"\"\"\"\n",
        "#################################################################################\n",
        "history=model.Fit(num_epochs, train_dataloader, val_dataloader, optimizer, criterion)"
      ],
      "metadata": {
        "id": "k2yv6kyiBkU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot losses\n",
        "plt.subplots(figsize=(7, 5))\n",
        "sns.set_style(\"dark\")\n",
        "sns.lineplot(data=history['val_losses'],label=\"Validation Loss\")\n",
        "sns.lineplot(data=np.asarray(history['train_losses']),label=\"Train Loss\").set(title=\"loss change during training\", xlabel=\"epoch\", ylabel=\"loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D7oxHFfGBrJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot Accuracy\n",
        "plt.subplots(figsize=(7, 5))\n",
        "sns.set_style(\"dark\")\n",
        "sns.lineplot(data=history['val_accuracies'],label=\"Validation Accuracy\")\n",
        "sns.lineplot(data=np.asarray(history['train_accuracies']),label=\"Train Accuracy\").set(title=\"Accuracy change during training\", xlabel=\"epoch\", ylabel=\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Du09eLBFvdaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction on Test Data"
      ],
      "metadata": {
        "id": "I8g5wCmTBr83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(images, model):\n",
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "  #Your Code Here\n",
        "\n",
        "#################################################################################\n",
        "                              \"\"\"\"  10 Points  \"\"\"\"\n",
        "#################################################################################\n",
        "  return predicted"
      ],
      "metadata": {
        "id": "hnMKAdUeBrtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Result on Test Data**"
      ],
      "metadata": {
        "id": "fb8IGy4xGLi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "y_pred_list = []\n",
        "y_true_list = []\n",
        "with torch.no_grad():\n",
        "  for data in test_dataloader:\n",
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "    #Your Code Here\n",
        "\n",
        "#################################################################################\n",
        "                              \"\"\"\"  10 Points  \"\"\"\"\n",
        "#################################################################################\n",
        "    for  x in predicted.cpu().numpy(): y_pred_list.append(x)\n",
        "    for  x in labels.cpu().numpy(): y_true_list.append(x)\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ],
      "metadata": {
        "id": "n71GHyxPBrrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification report**"
      ],
      "metadata": {
        "id": "DJXPU8nMGQzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true_list, y_pred_list, target_names=classes))"
      ],
      "metadata": {
        "id": "balnIJ9XJ41e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix = confusion_matrix(y_true_list, y_pred_list)\n",
        "sns.heatmap(cf_matrix, xticklabels=classes, yticklabels=classes, annot=True, cmap='Blues', fmt='g')"
      ],
      "metadata": {
        "id": "JFomDTeKA757"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying a random set of images from test data**"
      ],
      "metadata": {
        "id": "V0sMeTEQGTIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(test_dataloader)\n",
        "images, labels = next(dataiter)\n",
        "predicted=predict(images, model)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 7), subplot_kw={'xticks': [], 'yticks': []})\n",
        "for i,ax in zip(range(0,16),axes.flat):\n",
        "    img,label=images[i],labels[i]\n",
        "    pred=predicted[i]\n",
        "    ax.imshow(img.permute(1, 2, 0))\n",
        "    ax.set_title(f\"True: {classes[label]}\\n Predicted: {classes[pred]}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jItl08WCGVsJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}